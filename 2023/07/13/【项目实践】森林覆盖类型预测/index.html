<!DOCTYPE html><html lang="zh-CN" data-theme="dark"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>【数据分析实践】森林覆盖类型预测 | 岁染</title><meta name="keywords" content="项目实践"><meta name="author" content="Kagura,651421775@qq.com"><meta name="copyright" content="Kagura"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#0d0d0d"><meta name="description" content="基于ML+DL融合的森林覆盖类型预测">
<meta property="og:type" content="article">
<meta property="og:title" content="【数据分析实践】森林覆盖类型预测">
<meta property="og:url" content="http://example.com/2023/07/13/%E3%80%90%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5%E3%80%91%E6%A3%AE%E6%9E%97%E8%A6%86%E7%9B%96%E7%B1%BB%E5%9E%8B%E9%A2%84%E6%B5%8B/index.html">
<meta property="og:site_name" content="岁染">
<meta property="og:description" content="基于ML+DL融合的森林覆盖类型预测">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://w.wallhaven.cc/full/x6/wallhaven-x6l7vv.jpg">
<meta property="article:published_time" content="2023-07-13T00:56:04.243Z">
<meta property="article:modified_time" content="2023-07-13T00:57:10.083Z">
<meta property="article:author" content="Kagura">
<meta property="article:tag" content="项目实践">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://w.wallhaven.cc/full/x6/wallhaven-x6l7vv.jpg"><link rel="shortcut icon" href="/img/3d.png"><link rel="canonical" href="http://example.com/2023/07/13/%E3%80%90%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5%E3%80%91%E6%A3%AE%E6%9E%97%E8%A6%86%E7%9B%96%E7%B1%BB%E5%9E%8B%E9%A2%84%E6%B5%8B/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '【数据分析实践】森林覆盖类型预测',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-07-13 08:57:10'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/custom.css"><link rel="stylesheet" href="/css/universe.css"><script src="https://npm.elemecdn.com/echarts@4.7.0/dist/echarts.min.js"></script><style type="text/css">#toggle-sidebar {bottom: 80px}</style><style type="text/css">#toggle-sidebar {left:100px}</style><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/swiper/swiper-bundle.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-card-history/baiduhistory/css/main.css"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-categories-card/lib/categorybar.css"><link rel="stylesheet" href="https://unpkg.zhimg.com/hexo-butterfly-clock/lib/clock.min.css" /><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.2.0"><link rel="alternate" href="/atom.xml" title="岁染" type="application/atom+xml">
</head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://images.jingyeqian.com/i/2021/03/21/6375192146687954551533103.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">120</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">47</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-heartbeat"></i><span> 清单</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/bangumis/"><i class="fa-fw fas fa-music"></i><span> 番剧</span></a></li><li><a class="site-page child" href="/Diary"><i class="fa-fw fas fa-images"></i><span> 日记</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li><li><a class="site-page child" href="/Todo-List"><i class="fa-fw fas fa-bell"></i><span> Todo-List</span></a></li><li><a class="site-page child" href="/PDF"><i class="fa-fw fas fa-windows"></i><span> PDF</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://w.wallhaven.cc/full/x6/wallhaven-x6l7vv.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">岁染</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-heartbeat"></i><span> 清单</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/bangumis/"><i class="fa-fw fas fa-music"></i><span> 番剧</span></a></li><li><a class="site-page child" href="/Diary"><i class="fa-fw fas fa-images"></i><span> 日记</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li><li><a class="site-page child" href="/Todo-List"><i class="fa-fw fas fa-bell"></i><span> Todo-List</span></a></li><li><a class="site-page child" href="/PDF"><i class="fa-fw fas fa-windows"></i><span> PDF</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">【数据分析实践】森林覆盖类型预测</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-07-13T00:56:04.243Z" title="发表于 2023-07-13 08:56:04">2023-07-13</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-07-13T00:57:10.083Z" title="更新于 2023-07-13 08:57:10">2023-07-13</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E4%B8%8D%E6%83%B3%E5%AD%A6%E8%BE%A3/">不想学辣</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">8.2k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>36分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="【数据分析实践】森林覆盖类型预测"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="Kaggle-竞赛-Forest-Cover-Type-Prediction-森林覆盖类型预测">Kaggle 竞赛 Forest Cover Type Prediction 森林覆盖类型预测</h2>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://raw.githubusercontent.com/Chen-XiaoLv/ML-in-Geochemistry/master/READEME/image-20230701114337359.png" alt="image-20230701114337359"></p>
<hr>
<h3 id="Description">Description</h3>
<p>在这个比赛中，你被要求从严格的地图变量（相对于遥感数据）中预测森林覆盖类型（主要的树木覆盖种类）。一个给定的30×30米单元的实际森林覆盖类型是由美国森林服务局（USFS）第二区域资源信息系统数据确定的。然后从美国地质调查局和美国林业局获得的数据中得出独立变量。数据为原始形式（未按比例），包含定性自变量的二进制列数据，如荒野地区和土壤类型。</p>
<p>本研究区包括位于科罗拉多州北部罗斯福国家森林的四个荒野地区。这些地区代表了人为干扰最小的森林，因此，现有的森林覆盖类型更多的是生态过程的结果，而不是森林管理实践。</p>
<h3 id="Requirement">Requirement</h3>
<figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">numpy==1.23.3</span><br><span class="line">pandas==1.4.4</span><br><span class="line">pyecharts=2.0.1</span><br><span class="line">sklearn==1.1.3</span><br><span class="line">seaborn==0.11.2</span><br><span class="line">torch==1.12.0+cu116</span><br><span class="line">xgboost==1.7.1</span><br><span class="line">lightgbm==3.3.3</span><br></pre></td></tr></table></figure>
<hr>
<p>项目的流程图如下</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">graph LR</span><br><span class="line">    id1(问题建模)--&gt;id2(数据探索)</span><br><span class="line">    id2--&gt;id3(特征工程)</span><br><span class="line">    id3--&gt;id4(模型训练)</span><br><span class="line">    id4--&gt;id5(模型融合)</span><br><span class="line">        </span><br></pre></td></tr></table></figure>
<p>我们将从这五个部分介绍本赛题。</p>
<hr>
<h2 id="一-赛题理解">一 赛题理解</h2>
<h3 id="1-背景">1 背景</h3>
<p>本次竞赛使用了美国森林服务局(US Forest Service)提供的30x30m分辨率的森林覆盖类型区域，包括一个训练集和一个测试集。要求采用训练集的数据对测试集的森林覆盖类型进行预测。</p>
<h3 id="2-数据">2 数据</h3>
<p>该数据集一共有十三个属性，包括高程、坡度、坡向、到水文地物的垂直距离、水平距离、到道路的水平距离等，主要包括整形的定量数据和one-hot编码过的定名数据</p>
<h3 id="3-评价指标">3 评价指标</h3>
<p>赛题中并未给出，由于模型是一个多分类问题，我们选择采用多分类交叉熵和R2系数来进行评价。</p>
<p>交叉熵</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>L</mi><mi>o</mi><mi>s</mi><mi>s</mi><mo>=</mo><mo>−</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>c</mi><mo>−</mo><mn>1</mn></mrow></munderover><msub><mi>y</mi><mi>i</mi></msub><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>p</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Loss=-\sum^{c-1}_{i=0}y_i\log (p_i)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">L</span><span class="mord mathnormal">oss</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.0788em;vertical-align:-1.2777em;"></span><span class="mord">−</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8011em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
<p>R2系数</p>
<p>R2系数又称决定系数，反映因变量的全部变异能通过回归关系被自变量解释的比例</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msup><mi>R</mi><mn>2</mn></msup><mo>=</mo><mn>1</mn><mo>−</mo><mfrac><mrow><mi>M</mi><mi>S</mi><mi>E</mi></mrow><mrow><mi>V</mi><mi>A</mi><mi>R</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">R^2=1-\frac{MSE}{VAR}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8641em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:2.0463em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3603em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">MSE</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mi>S</mi><mi>E</mi></mrow><annotation encoding="application/x-tex">MSE</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">MSE</span></span></span></span>表示均方误差，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mi>A</mi><mi>R</mi></mrow><annotation encoding="application/x-tex">VAR</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span>表示方差，值得注意的是，均方误差代表与真实值的偏差，而方差则是与平均值的偏差。</p>
<p>本项目的主要流程如下：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://raw.githubusercontent.com/Chen-XiaoLv/ML-in-Geochemistry/7f3240dd46093a5db3cd81fb7026384e9a27b6ac/READEME/%E6%9C%AA%E5%91%BD%E5%90%8D%E7%BB%98%E5%9B%BE.drawio.svg" alt="未命名绘图.drawio"></p>
<hr>
<h2 id="二-数据探索性分析">二 数据探索性分析</h2>
<p>在本阶段，主要工作是对数据有一个简单的认识，以及对数据进行一定的预处理。</p>
<h3 id="1-前期准备与数据读取">1 前期准备与数据读取</h3>
<h4 id="1-1-模块导入">1.1 模块导入</h4>
<p>本次使用的模块如下：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://github.com/Chen-XiaoLv/ML-in-Geochemistry/raw/master/READEME/image-20230703000609508.png" alt="image-20230703000609508"></p>
<p>直接先导进去吧</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> power_transform</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> pyecharts.charts <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span> options <span class="keyword">as</span> opts</span><br><span class="line"><span class="keyword">from</span> pyecharts.<span class="built_in">globals</span> <span class="keyword">import</span> CurrentConfig</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler,MinMaxScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"><span class="keyword">import</span> torch </span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> alive_progress</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader,Dataset</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> plot_importance, plot_tree</span><br><span class="line"><span class="keyword">import</span> lightgbm <span class="keyword">as</span> lgb</span><br><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure>
<h4 id="1-2-绘图模块">1.2 绘图模块</h4>
<p>由于需要不停地调用可视化模块接口，这里我搞了些函数方便调用，不装<code>pyecharts</code>的话也没关系，完全可以用<code>matplotlib</code>代替的，这里只是为了美观些🌟</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">DrawBox</span>(<span class="params">x,y_data</span>):</span><br><span class="line">    box_plot = Boxplot()</span><br><span class="line">    box_plot = (</span><br><span class="line">        box_plot.add_xaxis(xaxis_data=[i <span class="keyword">for</span> i <span class="keyword">in</span> x])</span><br><span class="line">            .add_yaxis(series_name=<span class="string">&quot;箱线图&quot;</span>, y_axis=box_plot.prepare_data(y_data))</span><br><span class="line">            .set_global_opts(</span><br><span class="line">            title_opts=opts.TitleOpts(</span><br><span class="line">                pos_left=<span class="string">&quot;left&quot;</span>, title=<span class="string">&quot;数值数据分布情况&quot;</span></span><br><span class="line">            ),</span><br><span class="line">            xaxis_opts=opts.AxisOpts(</span><br><span class="line">                type_=<span class="string">&quot;category&quot;</span>,</span><br><span class="line">                boundary_gap=<span class="literal">True</span>,</span><br><span class="line">                splitline_opts=opts.SplitLineOpts(is_show=<span class="literal">True</span>),  <span class="comment"># 分割线显示与否</span></span><br><span class="line">            ),</span><br><span class="line">            yaxis_opts=opts.AxisOpts(  <span class="comment"># y轴</span></span><br><span class="line">                type_=<span class="string">&quot;value&quot;</span>,</span><br><span class="line">                splitarea_opts=opts.SplitAreaOpts(</span><br><span class="line">                    is_show=<span class="literal">True</span>, areastyle_opts=opts.AreaStyleOpts(opacity=<span class="number">1</span>)  <span class="comment"># 横向分割</span></span><br><span class="line">                ),</span><br><span class="line">            ),</span><br><span class="line">        )</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> box_plot</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Draw</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,x,y,ylabel,title,xname,yname</span>):</span><br><span class="line">        self.x=x</span><br><span class="line">        self.y=y</span><br><span class="line">        self.ylabel=ylabel</span><br><span class="line">        self.title=title</span><br><span class="line">        self.xname=xname</span><br><span class="line">        self.yname=yname</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">draw</span>(<span class="params">self,tool</span>):</span><br><span class="line">        tool.add_xaxis(self.x)</span><br><span class="line">        <span class="keyword">for</span> i, j <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.y):</span><br><span class="line">            tool.add_yaxis(self.ylabel[i], j)</span><br><span class="line"></span><br><span class="line">        tool.set_series_opts(markpoint_opts=opts.MarkPointOpts(</span><br><span class="line">            data=[opts.MarkPointItem(type_=<span class="string">&quot;max&quot;</span>, name=<span class="string">&quot;最大值&quot;</span>),  <span class="comment">##设置最大值 标记</span></span><br><span class="line">                  opts.MarkPointItem(type_=<span class="string">&quot;min&quot;</span>, name=<span class="string">&quot;最小值&quot;</span>),  <span class="comment"># 设置最小值标记</span></span><br><span class="line">                  ], symbol=<span class="string">&#x27;diamond&#x27;</span>, symbol_size=<span class="number">45</span>), markline_opts=opts.MarkLineOpts(</span><br><span class="line">            data=[opts.MarkLineItem(type_=<span class="string">&quot;average&quot;</span>, name=<span class="string">&quot;平均值&quot;</span>)]</span><br><span class="line">        ))</span><br><span class="line">        tool.set_global_opts(title_opts=opts.TitleOpts(title=self.title)</span><br><span class="line">                             , toolbox_opts=opts.ToolboxOpts()</span><br><span class="line">                             )</span><br><span class="line">        <span class="keyword">return</span> tool</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DrawBar</span>(<span class="title class_ inherited__">Draw</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,x,y,ylabel,title,xname,yname</span>):</span><br><span class="line">        <span class="built_in">super</span>(DrawBar, self).__init__(x,y,ylabel,title,xname,yname)</span><br><span class="line">        tool=Bar()</span><br><span class="line">        self.d=self.draw(tool)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">render</span>(<span class="params">self,path</span>):</span><br><span class="line">        self.d.render(path)</span><br><span class="line"><span class="comment"># 折线图</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DrawLine</span>(<span class="title class_ inherited__">Draw</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,x,y,ylabel,title,xname,yname</span>):</span><br><span class="line">        <span class="built_in">super</span>(DrawLine, self).__init__(x,y,ylabel,title,xname,yname)</span><br><span class="line">        tool=Line()</span><br><span class="line">        self.d=self.draw(tool)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">render</span>(<span class="params">self,path</span>):</span><br><span class="line">        self.d.render(path)</span><br></pre></td></tr></table></figure>
<h3 id="2-数据分布情况">2 数据分布情况</h3>
<p>好了结束了前期准备后，我们就可以对数据进行探索啦！这里简单举个栗子，本项目主要学习的是方法啦。数据可以在这里下载：<a target="_blank" rel="noopener" href="https://www.kaggle.com/competitions/forest-cover-type-prediction/code">这里</a></p>
<p>读取数据并进行初步的统计量探索</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">path=<span class="string">r&quot;YourWorkSpace&quot;</span></span><br><span class="line">train,test=pd.read_csv(path+<span class="string">r&quot;/train.csv&quot;</span>),pd.read_csv(path+<span class="string">r&quot;/test.csv&quot;</span>)</span><br><span class="line">ori=copy.deepcopy(train)</span><br><span class="line">label=train[<span class="string">&#x27;Cover_Type&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p>查看数据表的话，用<code>df.head(n)</code>就行</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train.head()</span><br></pre></td></tr></table></figure>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://github.com/Chen-XiaoLv/ML-in-Geochemistry/raw/master/READEME/image-20230703001232959.png" alt="image-20230703001232959" style="zoom:50%;">
<p>接着是统计量：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train.describe()</span><br></pre></td></tr></table></figure>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://github.com/Chen-XiaoLv/ML-in-Geochemistry/raw/master/READEME/image-20230703001302406.png" alt="image-20230703001302406" style="zoom:50%;">
<p>数据的维度：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">train.shape</span><br><span class="line"></span><br><span class="line"><span class="comment"># (15120,56)</span></span><br></pre></td></tr></table></figure>
<p>这个数据从第十一维特征<code>Wilderness_Area1</code>开始就全是名义数据(定名数据)了，因而我们在分析其分布情况时，需要分开进行。</p>
<p>别忘了看看数据有没有缺失值!</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> train.columns:</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">any</span>(train[i].isnull()):</span><br><span class="line">        <span class="built_in">print</span>(i)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> test.columns:</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">any</span>(test[i].isnull()):</span><br><span class="line">        <span class="built_in">print</span>(i)</span><br></pre></td></tr></table></figure>
<p>上面这种方式可以将带有缺失值的列获取出来，根据列特征的不同数据格式选择不同的方法进行处理。然后接下来要对样本标签的分布进行查看，如果样本分布不均衡，很可能会影响模型的训练结果。一般来说，针对分布不均衡情况，可以进行的操作有：</p>
<ul>
<li>降采样</li>
<li>上采样</li>
<li>生成式模型(自动编码机、受限玻尔兹曼机、对抗生成网络、扩散模型等)</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">d=train.groupby(<span class="string">&quot;Cover_Type&quot;</span>)[<span class="string">&quot;Id&quot;</span>].count()</span><br><span class="line"><span class="comment"># 通过上面的探索，我们发现实际上`Id`这一列是没有用的，那么就删除啦</span></span><br><span class="line">train_x,label=train.iloc[:,<span class="number">1</span>:-<span class="number">1</span>],train.iloc[:,-<span class="number">1</span>]</span><br><span class="line">train.drop([<span class="string">&#x27;Id&#x27;</span>,<span class="string">&#x27;Cover_Type&#x27;</span>],axis=<span class="number">1</span>,inplace=<span class="literal">True</span>)</span><br><span class="line">test.drop(<span class="string">&#x27;Id&#x27;</span>,axis=<span class="number">1</span>,inplace=<span class="literal">True</span>)</span><br><span class="line">DrawBar([i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">8</span>)],[d.tolist()],[<span class="string">&quot;count&quot;</span>],<span class="string">&quot;标签均衡&quot;</span>,<span class="string">&quot;cover_type&quot;</span>,<span class="string">&quot;count&quot;</span>).d.render_notebook()</span><br></pre></td></tr></table></figure>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://github.com/Chen-XiaoLv/ML-in-Geochemistry/raw/master/READEME/image-20230703002051796.png" alt="image-20230703002051796" style="zoom:50%;">
<p>这个数据集已经做过采样了，所以我们不需要在样本分布上做文章。</p>
<h4 id="2-1-数值数据分布情况">2.1 数值数据分布情况</h4>
<p>本数据集中，数值型数据刚好是前十列。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">numeric_col=train.columns[:<span class="number">10</span>]</span><br><span class="line">categorical_col=train.columns[<span class="number">10</span>:]</span><br></pre></td></tr></table></figure>
<p>利用<code>seaborn</code>的<code>histplot(data,kde=True)</code>可以在绘制数据分箱直方图的同时，绘制密度分布图，帮助我们更好的分析数据的情况。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">16</span>,<span class="number">12</span>),dpi=<span class="number">200</span>)</span><br><span class="line"><span class="keyword">for</span> idx,col <span class="keyword">in</span> <span class="built_in">enumerate</span>(numeric_col):</span><br><span class="line">    plt.subplot(<span class="number">5</span>,<span class="number">2</span>,idx+<span class="number">1</span>)</span><br><span class="line">    sns.histplot(train[col],kde=<span class="literal">True</span>)</span><br><span class="line">    plt.xlabel(col)</span><br><span class="line">plt.tight_layout() <span class="comment"># 调整分布</span></span><br></pre></td></tr></table></figure>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://github.com/Chen-XiaoLv/ML-in-Geochemistry/raw/master/READEME/image-20230703002544091.png" style="zoom:50%;">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://github.com/Chen-XiaoLv/ML-in-Geochemistry/raw/master/READEME/image-20230703002559197.png" alt="image-20230703002559197" style="zoom:50%;">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://github.com/Chen-XiaoLv/ML-in-Geochemistry/raw/master/READEME/image-20230703002613434.png" alt="image-20230703002613434" style="zoom:50%;">
<p>可以发现每种数据的分布都不相同，理论上为了方便我们的计算工作，需要将其转化为正态分布。</p>
<p><strong>♨️ 数据相关性分析</strong></p>
<p>这部分主要探索数字数据之间的相关性，反映出数据分布之间的潜在联系</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">num=train[numeric_col]</span><br><span class="line">Standarder=StandardScaler()</span><br><span class="line">num_std=Standarder.fit_transform(num)</span><br><span class="line">num_std.mean(axis=<span class="number">0</span>),num_std.std(axis=<span class="number">0</span>)</span><br><span class="line">plt.figure(figsize=(<span class="number">14</span>,<span class="number">12</span>))</span><br><span class="line">sns.heatmap(num.corr(),annot=<span class="literal">True</span>,fmt=<span class="string">&quot;.2f&quot;</span>,cmap=<span class="string">&quot;coolwarm&quot;</span>)</span><br></pre></td></tr></table></figure>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://github.com/Chen-XiaoLv/ML-in-Geochemistry/raw/master/READEME/image-20230703002757865.png" alt="image-20230703002757865" style="zoom:50%;">
<p>可以看到的是，坡度与山体阴影呈负相关关系，像元到水文特征的垂直距离和水平距离之间具有较强的相关性。</p>
<h4 id="2-2-名义数据分布情况">2.2 名义数据分布情况</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">DrawCategoricalData</span>(<span class="params">x</span>):</span><br><span class="line">    d=ori.groupby([x,<span class="string">&quot;Cover_Type&quot;</span>])[<span class="string">&quot;Id&quot;</span>].count()</span><br><span class="line">    b=Bar()</span><br><span class="line">    b.add_xaxis([i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">8</span>)])</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">        c=np.array([<span class="number">0</span>]*<span class="number">8</span>)</span><br><span class="line">        c[d[i].index]=d[i]</span><br><span class="line">        b.add_yaxis(</span><br><span class="line">            <span class="string">f&quot;Val <span class="subst">&#123;i&#125;</span>&quot;</span>,c[<span class="number">1</span>:].tolist(),stack=<span class="string">&quot;1&quot;</span></span><br><span class="line">        )</span><br><span class="line">    b.set_global_opts(title_opts=opts.TitleOpts(title=<span class="string">&quot;%s 数据分布情况&quot;</span>%x))</span><br><span class="line">    <span class="keyword">return</span> b</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">categorical_col=train.columns[<span class="number">10</span>:]</span><br><span class="line">i=<span class="number">0</span></span><br><span class="line">DrawCategoricalData(categorical_col[i]).render_notebook()</span><br></pre></td></tr></table></figure>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://github.com/Chen-XiaoLv/ML-in-Geochemistry/raw/master/READEME/image-20230703003036357.png" style="zoom:50%;">
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">i+=<span class="number">1</span></span><br><span class="line">DrawCategoricalData(categorical_col[i]).render_notebook()</span><br></pre></td></tr></table></figure>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://github.com/Chen-XiaoLv/ML-in-Geochemistry/raw/master/READEME/image-20230703003104247.png" style="zoom:50%;">
<p>通过柱状堆叠图，我们可以发现，Wilderness_Area这个字段数据也是十分均衡，而且有些字段取1时，对结果取值有较大的影响，该数据的信息熵较大。</p>
<h4 id="3-数据清洗">3 数据清洗</h4>
<p>此阶段主要针对三类情况：</p>
<ul>
<li>缺失值</li>
<li>噪声</li>
<li>数据不一致问题</li>
</ul>
<p>我们在第二阶段已经探查过了，该数据不存在缺失值，数据不一致问题实际上也不存在，那么剩下的就是噪声数据的处理</p>
<p>下面这段代码是调用上面写的绘图函数的，用来绘制箱线图，可以直接跳过，这边做个简单展示</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">i=<span class="number">0</span></span><br><span class="line">DrawBox([numeric_col[i]],[train[numeric_col[i]]]).render_notebook()</span><br></pre></td></tr></table></figure>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://github.com/Chen-XiaoLv/ML-in-Geochemistry/raw/master/READEME/image-20230703003233783.png" alt="image-20230703003233783" style="zoom:50%;">
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DrawBox(numeric_col[:<span class="number">3</span>],num_std[:<span class="number">3</span>]).render_notebook()</span><br></pre></td></tr></table></figure>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://github.com/Chen-XiaoLv/ML-in-Geochemistry/raw/master/READEME/image-20230703003300042.png" style="zoom:50%;">
<p>我们可以直接用<code>pandas</code>的绘图接口：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">16</span>,<span class="number">9</span>),dpi=<span class="number">300</span>)</span><br><span class="line">pd.DataFrame(num_std).boxplot()</span><br></pre></td></tr></table></figure>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://github.com/Chen-XiaoLv/ML-in-Geochemistry/raw/master/READEME/image-20230703003358841.png" style="zoom:50%;">
<p>可以看到，有很多类都有一些异常值。这些异常值是通过百分位数极差计算的：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>I</mi><mi>Q</mi><mi>R</mi><mo>=</mo><msub><mi>Q</mi><mn>3</mn></msub><mo>−</mo><msub><mi>Q</mi><mn>1</mn></msub><mspace linebreak="newline"></mspace><mi>I</mi><mi>Q</mi><msub><mi>R</mi><mi>b</mi></msub><mo>=</mo><msub><mi>Q</mi><mn>1</mn></msub><mo>−</mo><mn>1.5</mn><mo>∗</mo><mi>I</mi><mi>Q</mi><mi>R</mi><mspace linebreak="newline"></mspace><mi>I</mi><mi>Q</mi><msub><mi>R</mi><mi>u</mi></msub><mo>=</mo><mi>Q</mi><mn>3</mn><mo>+</mo><mn>1.5</mn><mo>∗</mo><mi>I</mi><mi>Q</mi><mi>R</mi></mrow><annotation encoding="application/x-tex">IQR=Q_3-Q_1
\\
IQR_b=Q_1-1.5*IQR\\
IQR_u=Q3+1.5*IQR
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal" style="margin-right:0.00773em;">QR</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">b</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1.5</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal" style="margin-right:0.00773em;">QR</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">u</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">Q</span><span class="mord">3</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1.5</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal" style="margin-right:0.00773em;">QR</span></span></span></span></span></p>
<p>然后我们现在就想把这些异常点去掉，有一个比较简单的方式，就是利用<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mi>α</mi></mrow><annotation encoding="application/x-tex">3\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">3</span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span></span></span></span>法则</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">Outlier</span>(<span class="params">x</span>):</span><br><span class="line">    blidx=(x.mean()-<span class="number">3</span>*x.std()&gt;x)|(x.mean()+<span class="number">3</span>*x.std()&lt;x)</span><br><span class="line">    idx=np.arange(x.shape[<span class="number">0</span>])[blidx]</span><br><span class="line">    outlier=x.iloc[idx]</span><br><span class="line">    <span class="keyword">return</span> outlier</span><br><span class="line">c=num.apply(Outlier,axis=<span class="number">0</span>)</span><br><span class="line">c.count()</span><br></pre></td></tr></table></figure>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://github.com/Chen-XiaoLv/ML-in-Geochemistry/raw/master/READEME/image-20230703003706613.png" alt="image-20230703003706613" style="zoom:50%;">
<p>可以看到，总共有<code>1130</code>个数据属于异常值。</p>
<p>当然，是否删除离群点还需要考虑实际情况，譬如这个离群点是由什么原因造成的？是否是采集过程中造成的，还是数据本身的特性导致的？</p>
<p>如果是后者，其实不建议进行处理。适当的保留噪声会提高模型的泛化能力</p>
<p>至此，我们已经简单完成了EDA阶段的工作。</p>
<p>下一个阶段是特征工程(Feature Engineering)</p>
<hr>
<h2 id="三-特征工程">三 特征工程</h2>
<p>在机器学习中，特征工程阶段的好坏往往决定了最终结果的好坏，而深度学习实际上没有这种烦恼，我们将尝试传统机器学习树模型和深度学习模型，分析并比较不同模型的结果，当然，这里会选择一份做了特征工程的数据和一份不做特征工程的数据进行比对，但由于树模型和深度学习模型都带有不确定性，最终的评价不一定准确，考虑到服务器性能，也不做大数据统计了，仅仅做一些简单的工作</p>
<p>特征工程的主要任务包括数据预处理、特征变换、特征提取和特征选择，在之前的工作中，我们已经做过部分预处理了，包括：</p>
<ul>
<li>剔除异常值</li>
<li>删除不需要的列</li>
<li>分析数据的分布</li>
</ul>
<h3 id="1-特征变换">1 特征变换</h3>
<p>可以通过幂律变换<code>sklearn.preprogressing.power_transform</code>对数据进行转换，当然要求数据不能为非正数。本数据存在负数，因而我们的考量是：</p>
<ul>
<li>先做归一化去除负数影响</li>
<li>添加极小项避免零值影响</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据转为正态分布</span></span><br><span class="line">t_x_d,t_y_d=train_drop_outlier.iloc[:,<span class="number">1</span>:-<span class="number">1</span>],train_drop_outlier.iloc[:,-<span class="number">1</span>]</span><br><span class="line">col_td=t_x_d[numeric_col]</span><br><span class="line">mmS=MinMaxScaler()</span><br><span class="line">col_td=mmS.fit_transform(col_td)</span><br><span class="line">col_td+=<span class="number">1e-5</span></span><br><span class="line">c_d_p=power_transform(col_td,method=<span class="string">&#x27;box-cox&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看分布</span></span><br><span class="line">t_x_d[numeric_col]=c_d_p</span><br><span class="line">t_x_d.head()</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">16</span>,<span class="number">12</span>),dpi=<span class="number">200</span>)</span><br><span class="line"><span class="keyword">for</span> idx,col <span class="keyword">in</span> <span class="built_in">enumerate</span>(numeric_col):</span><br><span class="line">    plt.subplot(<span class="number">5</span>,<span class="number">2</span>,idx+<span class="number">1</span>)</span><br><span class="line">    sns.histplot(t_x_d[col],kde=<span class="literal">True</span>)</span><br><span class="line">    plt.xlabel(col)</span><br><span class="line">plt.tight_layout()</span><br></pre></td></tr></table></figure>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://github.com/Chen-XiaoLv/ML-in-Geochemistry/raw/master/READEME/image-20230703004217364.png" alt="image-20230703004217364" style="zoom:50%;">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://github.com/Chen-XiaoLv/ML-in-Geochemistry/raw/master/READEME/image-20230703004232612.png" alt="image-20230703004232612" style="zoom:50%;">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://github.com/Chen-XiaoLv/ML-in-Geochemistry/raw/master/READEME/image-20230703004242720.png" alt="image-20230703004242720" style="zoom:50%;">
<p>可以看到，此时之前的长尾分布基本上都被转化为近似正态了。</p>
<p>当然，这组数据做不做正态影响不大，起码对于信息熵没有增益，那么我们就不做了，省的数据区间出错，那么现在就轮到<code>特征提取</code>或者说<code>特征构造</code>阶段了</p>
<h3 id="2-特征提取">2 特征提取</h3>
<p>主要构造的特征有：</p>
<ul>
<li>高程坡向比</li>
<li>高程坡度比</li>
<li>坡度坡向比</li>
<li>水文特征切比雪夫距离</li>
<li>水文特征闵可夫斯基距离(p=1,p=2)</li>
<li>高程水文欧氏距离比</li>
<li>高程公路欧氏距离比</li>
<li>坡度公路比</li>
<li>水文公路比</li>
<li>山体阴影几何平均值</li>
<li>山体阴影平均值</li>
<li>山体阴影标准差</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">distance</span>(<span class="params">x,y,p=<span class="number">2</span></span>):</span><br><span class="line">    <span class="keyword">return</span> (x**p+y**p)**(<span class="number">1</span>/p)</span><br><span class="line">x_t_o,l_o=train_drop_outlier.iloc[:,<span class="number">1</span>:-<span class="number">1</span>],train_drop_outlier.iloc[:,-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">x_t_o[<span class="string">&quot;v1&quot;</span>]=x_t_o[<span class="string">&quot;Elevation&quot;</span>]/x_t_o[<span class="string">&#x27;Aspect&#x27;</span>]</span><br><span class="line">x_t_o[<span class="string">&quot;v2&quot;</span>]=x_t_o[<span class="string">&quot;Elevation&quot;</span>]/x_t_o[<span class="string">&#x27;Slope&#x27;</span>]</span><br><span class="line">x_t_o[<span class="string">&quot;v3&quot;</span>]=x_t_o[<span class="string">&quot;Aspect&quot;</span>]/x_t_o[<span class="string">&#x27;Slope&#x27;</span>]</span><br><span class="line">x_t_o[<span class="string">&quot;v4&quot;</span>]=distance(x_t_o[<span class="string">&quot;Horizontal_Distance_To_Hydrology&quot;</span>],x_t_o[<span class="string">&#x27;Vertical_Distance_To_Hydrology&#x27;</span>])</span><br><span class="line">x_t_o[<span class="string">&#x27;v5&#x27;</span>]=distance(x_t_o[<span class="string">&quot;Horizontal_Distance_To_Hydrology&quot;</span>],x_t_o[<span class="string">&#x27;Vertical_Distance_To_Hydrology&#x27;</span>],<span class="number">1</span>)</span><br><span class="line">x_t_o[<span class="string">&#x27;v6&#x27;</span>]=x_t_o[<span class="string">&#x27;Elevation&#x27;</span>]/x_t_o[<span class="string">&#x27;v4&#x27;</span>]</span><br><span class="line">x_t_o[<span class="string">&#x27;v7&#x27;</span>]=x_t_o[<span class="string">&#x27;Elevation&#x27;</span>]/x_t_o[<span class="string">&#x27;Horizontal_Distance_To_Roadways&#x27;</span>]</span><br><span class="line">x_t_o[<span class="string">&#x27;v8&#x27;</span>]=(x_t_o[<span class="string">&#x27;Hillshade_9am&#x27;</span>]+x_t_o[<span class="string">&#x27;Hillshade_Noon&#x27;</span>]+x_t_o[<span class="string">&#x27;Hillshade_3pm&#x27;</span>]).mean()</span><br><span class="line">x_t_o[<span class="string">&#x27;v9&#x27;</span>]=(x_t_o[<span class="string">&#x27;Hillshade_9am&#x27;</span>]+x_t_o[<span class="string">&#x27;Hillshade_Noon&#x27;</span>]+x_t_o[<span class="string">&#x27;Hillshade_3pm&#x27;</span>]).std()</span><br><span class="line">x_t_o[<span class="string">&#x27;v10&#x27;</span>]=(x_t_o[<span class="string">&#x27;Hillshade_9am&#x27;</span>]**<span class="number">2</span>+x_t_o[<span class="string">&#x27;Hillshade_Noon&#x27;</span>]**<span class="number">2</span>+x_t_o[<span class="string">&#x27;Hillshade_3pm&#x27;</span>]**<span class="number">2</span>)**<span class="number">0.5</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>OK现在我们就有一些奇奇怪怪的特征了。</p>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://github.com/Chen-XiaoLv/ML-in-Geochemistry/raw/master/READEME/image-20230703031337694.png" alt="image-20230703031337694" style="zoom:50%;">
<p>啊实际上有些特征不能用，因为发生了除零错误。</p>
<h3 id="3-特征选择">3 特征选择</h3>
<p>特征选择的方式有很多，我们现在介绍一些降维的工具：</p>
<ul>
<li>通过流形学习的非线性降维方式<code>T-SNE</code>对数据进行降维，避免数据之间冗余度过高以及可能带来的维灾害(虽然特征工程就没构建几个特征)</li>
<li>PCA</li>
<li>LDA</li>
<li>LLE</li>
</ul>
<p>这边的话，由于特征较少，时间有限，就没有做降维了，简单给个栗子。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line">pca=PCA(n_components=<span class="number">10</span>)</span><br><span class="line">x=standarder.fit_transform(x_t_o)</span><br><span class="line">x=pca.fit_transform(x)</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="四-模型训练">四 模型训练</h2>
<h3 id="1-准备工作">1 准备工作</h3>
<h4 id="1-1-数据拆分">1.1 数据拆分</h4>
<p>拆分喽</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x_train,x_val,y_train,y_val=train_test_split(train,label,test_size=<span class="number">0.3</span>)</span><br><span class="line">x_train.shape</span><br><span class="line"></span><br><span class="line"><span class="comment"># (10584, 54)</span></span><br></pre></td></tr></table></figure>
<h4 id="1-2-标准化去除量纲影响">1.2 标准化去除量纲影响</h4>
<p>实际上我们之前做过一次，但是不碍事，再做一次体验一下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x_train_scale=Standarder.fit_transform(x_train)</span><br><span class="line">x_val_scale=Standarder.fit_transform(x_val)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">accuracy</span>(<span class="params">y_pre,y</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">sum</span>(y_pre==y)/<span class="built_in">len</span>(y) <span class="comment"># 这东西用来计算预测准确度的</span></span><br></pre></td></tr></table></figure>
<h3 id="2-机器学习模型">2 机器学习模型</h3>
<h4 id="2-1-树模型">2.1 树模型</h4>
<p><strong>随机森林🌳</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">rf=RandomForestClassifier(max_features=<span class="string">&#x27;auto&#x27;</span>,oob_score=<span class="literal">True</span>,random_state=<span class="number">2023</span>,n_jobs=-<span class="number">1</span>)</span><br><span class="line">rf.fit(x_train_scale,y_train)</span><br><span class="line">rf.score(x_val_scale,y_val)</span><br><span class="line"><span class="comment"># 0.857583774250441</span></span><br></pre></td></tr></table></figure>
<p><strong>XGboost🌲</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 算法参数</span></span><br><span class="line">params = &#123;</span><br><span class="line">    <span class="comment"># 通用参数</span></span><br><span class="line">    <span class="string">&#x27;booster&#x27;</span>: <span class="string">&#x27;gbtree&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;nthread&#x27;</span>: <span class="number">4</span>,</span><br><span class="line">    <span class="comment"># &#x27;num_feature&#x27;: 5,  # Boosting过程中用到的特征维数，设置为特征个数，xgboost会自动设置，无需人为设置。</span></span><br><span class="line">    <span class="string">&#x27;seed&#x27;</span>: <span class="number">1000</span>,</span><br><span class="line">    <span class="comment"># 任务参数</span></span><br><span class="line">    <span class="string">&#x27;objective&#x27;</span>: <span class="string">&#x27;multi:softmax&#x27;</span>,  <span class="comment"># 多分类问题</span></span><br><span class="line">    <span class="string">&#x27;num_class&#x27;</span>: <span class="number">7</span>,  <span class="comment">#类别总数，与multi softmax并用 6</span></span><br><span class="line">    <span class="comment"># 提升参数</span></span><br><span class="line">    <span class="string">&#x27;gamma&#x27;</span>: <span class="number">0.1</span>,</span><br><span class="line">    <span class="string">&#x27;max_depth&#x27;</span>: <span class="number">11</span>,</span><br><span class="line">    <span class="string">&#x27;lambda&#x27;</span>: <span class="number">2</span>,</span><br><span class="line">    <span class="string">&#x27;subsample&#x27;</span>: <span class="number">0.7</span>,</span><br><span class="line">    <span class="string">&#x27;colsample_bytree&#x27;</span>: <span class="number">0.7</span>,</span><br><span class="line">    <span class="string">&#x27;min_child_weight&#x27;</span>: <span class="number">5</span>,</span><br><span class="line">    <span class="string">&#x27;eta&#x27;</span>: <span class="number">0.1</span>,</span><br><span class="line">    <span class="comment"># &#x27;eval_metric&#x27;: &#x27;auc&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 注意多分类xgboost需要修改label映射</span></span><br><span class="line">y_train_xg=y_train-<span class="number">1</span></span><br><span class="line">y_val_xg=y_val-<span class="number">1</span></span><br><span class="line"></span><br><span class="line">dtrain=xgb.DMatrix(data=x_train_scale,label=y_train_xg)</span><br><span class="line">dtest=xgb.DMatrix(data=x_val_scale,label=y_val_xg)</span><br><span class="line">watchlist=[(dtrain,<span class="string">&quot;train&quot;</span>),(dtest,<span class="string">&quot;valid_data&quot;</span>)]</span><br><span class="line">model=xgb.train(params,dtrain,num_boost_round=<span class="number">2023</span>,evals=watchlist,early_stopping_rounds=<span class="number">200</span>,verbose_eval=<span class="number">500</span>)</span><br><span class="line">accuracy(model.predict(dtest),y_val_xg)</span><br><span class="line"></span><br><span class="line"><span class="comment">#0.8507495590828924 </span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xgb.plot_importance(model,height=<span class="number">0.8</span>,title=<span class="string">&#x27;Influence Ranking&#x27;</span>, ylabel=<span class="string">&#x27;Feature&#x27;</span>,max_num_features=<span class="number">20</span>)</span><br></pre></td></tr></table></figure>
<p>查看特征影响得分：</p>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://github.com/Chen-XiaoLv/ML-in-Geochemistry/raw/master/READEME/image-20230703005437156.png" alt="image-20230703005437156" style="zoom:50%;">
<p><strong>LightGBM🌴</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">params=&#123;<span class="string">&#x27;num_leaves&#x27;</span>:<span class="number">54</span>,<span class="string">&#x27;objective&#x27;</span>: <span class="string">&#x27;multi:softmax&#x27;</span>,<span class="string">&#x27;max_depth&#x27;</span>:<span class="number">18</span>,<span class="string">&#x27;learning_rate&#x27;</span>:<span class="number">0.01</span>,<span class="string">&#x27;boosting&#x27;</span>:<span class="string">&#x27;gbdt&#x27;</span>&#125;</span><br><span class="line">model=lgb.LGBMClassifier(**params,n_estimators=<span class="number">2000</span>,nthread=<span class="number">4</span>,n_jobs=-<span class="number">1</span>)</span><br><span class="line">model.fit(x_train_scale,y_train,verbose=<span class="number">200</span>)</span><br><span class="line">accuracy(model.predict(x_val_scale,num_iteration=model.best_iteration_),y_val)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 0.8630952380952381</span></span><br></pre></td></tr></table></figure>
<h4 id="2-2-支持向量机">2.2 支持向量机</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line">param_grid=&#123;</span><br><span class="line">    <span class="string">&quot;gamma&quot;</span>:[<span class="number">0.05</span>*i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">13</span>)],</span><br><span class="line">    <span class="string">&quot;C&quot;</span>:[<span class="number">0.1</span>*i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">21</span>)]</span><br><span class="line">&#125;</span><br><span class="line">cl=svm.SVC(kernel=<span class="string">&#x27;poly&#x27;</span>,gamma=<span class="number">0.1</span>,decision_function_shape=<span class="string">&#x27;ovo&#x27;</span>,C=<span class="number">1.0</span>)</span><br><span class="line">search=GridSearchCV(cl,param_grid=param_grid,cv=<span class="number">5</span>,n_jobs=-<span class="number">1</span>, scoring=<span class="string">&quot;accuracy&quot;</span>)</span><br><span class="line">search.fit(x_train_scale,y_train)</span><br><span class="line">cl=search.best_estimator_</span><br><span class="line">z=cl.predict(x_val_scale)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 0.8167989417989417</span></span><br></pre></td></tr></table></figure>
<h4 id="2-3-优化">2.3 优化</h4>
<p>讲到调优，机器学习的两大工作一个是特征工程，一个就是调参了，努力成为一名优秀的调参侠吧(笑)</p>
<p>我们通过<code>GridSearchCV</code>模块进行调参，以决策树和XGboost为例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">param_grid=&#123;</span><br><span class="line">    <span class="string">&#x27;n_estimators&#x27;</span>:[i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>,<span class="number">20</span>)],</span><br><span class="line">    <span class="string">&#x27;max_depth&#x27;</span>:[i*<span class="number">2</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)],</span><br><span class="line">    <span class="string">&#x27;criterion&#x27;</span>:[<span class="string">&#x27;entropy&#x27;</span>,<span class="string">&#x27;gini&#x27;</span>],</span><br><span class="line">&#125;</span><br><span class="line">rf=RandomForestClassifier(max_features=<span class="string">&#x27;auto&#x27;</span>,oob_score=<span class="literal">True</span>,random_state=<span class="number">2023</span>,n_jobs=-<span class="number">1</span>)</span><br><span class="line">clf=GridSearchCV(estimator=rf,param_grid=param_grid,scoring=<span class="string">&#x27;accuracy&#x27;</span>,cv=<span class="number">5</span>,n_jobs=-<span class="number">1</span>)</span><br><span class="line">clf.fit(x_train_scale,y_train)</span><br><span class="line">lr=clf.best_estimator_</span><br><span class="line">lr.fit(x_train_scale,y_train)</span><br><span class="line">m1=lr.predict(x_val_scale)</span><br><span class="line">accuracy(m1,y_val)</span><br></pre></td></tr></table></figure>
<p>通过格网搜索与交叉验证，寻找模型的最优参数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">pipe = Pipeline(</span><br><span class="line">        steps=[ (<span class="string">&quot;classifier&quot;</span>, XGBClassifier())]</span><br><span class="line">    )</span><br><span class="line">param_grid = &#123;</span><br><span class="line">        <span class="string">&quot;classifier__n_estimators&quot;</span>: [<span class="number">50</span>,<span class="number">100</span>,<span class="number">150</span>,<span class="number">200</span>,<span class="number">300</span>], <span class="comment"># 多少棵树</span></span><br><span class="line">        <span class="string">&quot;classifier__eta&quot;</span>: [<span class="number">0.05</span>, <span class="number">0.1</span>, <span class="number">0</span>,<span class="number">2</span>, <span class="number">0.3</span>], <span class="comment"># 学习率</span></span><br><span class="line">        <span class="string">&quot;classifier__max_depth&quot;</span>: [<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>], <span class="comment"># 树的最大深度</span></span><br><span class="line">        <span class="string">&quot;classifier__colsample_bytree&quot;</span>: [<span class="number">0.4</span>,<span class="number">0.6</span>,<span class="number">0.8</span>,<span class="number">1</span>], <span class="comment"># 选择多少列构建一个树</span></span><br><span class="line">        <span class="string">&quot;classifier__min_child_weight&quot;</span>: [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>] <span class="comment"># 叶子节点最小样本数目</span></span><br><span class="line">    &#125;</span><br><span class="line">search = GridSearchCV(pipe, param_grid, n_jobs=-<span class="number">1</span>, scoring=<span class="string">&quot;roc_auc&quot;</span>, cv=<span class="number">5</span>)</span><br><span class="line">search.fit(x_train_scale,y_train_xg)</span><br><span class="line">search.best_params</span><br><span class="line">search.score(x_val_scale,y_val_xg)</span><br></pre></td></tr></table></figure>
<p>这个过程十分吃服务器性能，而且可能费时不太好，需要一定的心理准备。</p>
<p>最终的结果如下(具有一定的优化空间，我这边基本上没怎么做调参)</p>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://github.com/Chen-XiaoLv/ML-in-Geochemistry/raw/master/READEME/image-20230703020017641.png" alt="image-20230703020017641" style="zoom:50%;">
<h3 id="3-深度学习模型">3 深度学习模型</h3>
<h4 id="3-1-构建数据集">3.1 构建数据集</h4>
<p>首先我们要有一个数据集，或者一个可迭代的容器存放我们的数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyDataSet</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,x,label</span>):</span><br><span class="line">        self.x,self.label=x,label</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        <span class="keyword">return</span> self.x[idx],self.label[idx]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.x)</span><br></pre></td></tr></table></figure>
<p>然后是将数据转化为<code>tensor</code>格式</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">x_t_tensor=torch.from_numpy(x_train_scale).<span class="built_in">float</span>()</span><br><span class="line">y_t_tensor=torch.LongTensor(y_train_xg.to_numpy()).reshape(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">y_t_tensor=torch.zeros(y_t_tensor.shape[<span class="number">0</span>],<span class="number">7</span>).scatter_(<span class="number">1</span>, y_t_tensor, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">x_v_tensor=torch.from_numpy(x_val_scale).<span class="built_in">float</span>()</span><br><span class="line">y_v_tensor=torch.torch.LongTensor(y_val_xg.to_numpy()).reshape(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">y_v_tensor=torch.zeros(y_v_tensor.shape[<span class="number">0</span>],<span class="number">7</span>).scatter_(<span class="number">1</span>, y_v_tensor, <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>再者是将这些放到数据容器中：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">train_DataLoader=DataLoader(</span><br><span class="line">    dataset=MyDataSet(x_t_tensor,y_t_tensor),</span><br><span class="line">    batch_size=<span class="number">64</span>,</span><br><span class="line">    shuffle=<span class="literal">True</span>,</span><br><span class="line">    drop_last=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">test_DataLoader=DataLoader(</span><br><span class="line">    dataset=MyDataSet(x_v_tensor,y_v_tensor),</span><br><span class="line">    batch_size=<span class="number">64</span>,</span><br><span class="line">    shuffle=<span class="literal">True</span>,</span><br><span class="line">    drop_last=<span class="literal">True</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h4 id="3-2-模型选择">3.2 模型选择</h4>
<p>目前，我们已经获得了七个简单的网络。值得注意的是，在简单的一维数据中，多层感知机理论上可以拟合任意的函数，但如果加大层数，用一些高维数据的tricks，反而不太能得到好的结果。这是因为复杂的网络其容量也会增大，想要在函数域中找到最优函数变得更加复杂，可能陷入局部最优解</p>
<p>再有，一维卷积神经网络的性能实际上在小样本上会略低于全连接层，也不太适合做Attention</p>
<p>网络的性能除却跟网络结构本身有关系外，主要还是与数据挂钩。吴恩达在CS229中说过，模型只是去逼近数据潜在的上限，目前，我们拿出来做深度学习的数据仅仅做过几个简单的处理，实际上后续可以考虑将做过特征工程的数据进行训练</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Net</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,in_features=<span class="number">54</span>,n_hidden1=<span class="number">128</span>,n_hidden2=<span class="number">256</span>,out_features=<span class="number">7</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line">        self.flatten=nn.Flatten()</span><br><span class="line">        self.hidden1=nn.Sequential(</span><br><span class="line">            nn.Linear(in_features,n_hidden1,<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm1d(n_hidden1),</span><br><span class="line">            nn.ReLU()</span><br><span class="line">        )</span><br><span class="line">        self.hidden2=nn.Sequential(</span><br><span class="line">            nn.Linear(n_hidden1,n_hidden2),</span><br><span class="line">            nn.BatchNorm1d(n_hidden2),</span><br><span class="line">            nn.ReLU()</span><br><span class="line">        )</span><br><span class="line">        self.out=nn.Sequential(nn.Linear(n_hidden2,out_features))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        x=self.flatten(x)</span><br><span class="line">        x=self.hidden2(self.hidden1(x))</span><br><span class="line">        <span class="keyword">return</span> F.softmax(self.out(x),dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BasicConv1d</span>(nn.Module):</span><br><span class="line">    <span class="comment"># 一个Conv+Bn+ReLU</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,in_channel,out_channel,kernel,stride,padding=<span class="number">0</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(BasicConv1d, self).__init__()</span><br><span class="line">        self.cbr=nn.Sequential(</span><br><span class="line">            nn.Conv1d(in_channels=in_channel,out_channels=out_channel,kernel_size=kernel,stride=stride,</span><br><span class="line">                      padding=padding),</span><br><span class="line">            nn.BatchNorm1d(out_channel,eps=<span class="number">0.001</span>,momentum=<span class="number">0.1</span>,affine=<span class="literal">True</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">False</span>)</span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        <span class="keyword">return</span> self.cbr(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 一个简单的Inception模块</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Mixed_5b</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Mixed_5b, self).__init__()</span><br><span class="line">        self.branch0=BasicConv1d(<span class="number">54</span>,<span class="number">96</span>,kernel=<span class="number">1</span>,stride=<span class="number">1</span>)</span><br><span class="line">        self.branch1=nn.Sequential(</span><br><span class="line">            BasicConv1d(<span class="number">54</span>,<span class="number">48</span>,kernel=<span class="number">1</span>,stride=<span class="number">1</span>),</span><br><span class="line">            BasicConv1d(<span class="number">48</span>,<span class="number">64</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">        )</span><br><span class="line">        self.branch2=nn.Sequential(</span><br><span class="line">            BasicConv1d(<span class="number">54</span>,<span class="number">64</span>,kernel=<span class="number">1</span>,stride=<span class="number">1</span>),</span><br><span class="line">            BasicConv1d(<span class="number">64</span>,<span class="number">96</span>,kernel=<span class="number">3</span>,stride=<span class="number">1</span>,padding=<span class="number">1</span>),</span><br><span class="line">            BasicConv1d(<span class="number">96</span>,<span class="number">96</span>,kernel=<span class="number">3</span>,stride=<span class="number">1</span>,padding=<span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line">        self.branch3=nn.Sequential(</span><br><span class="line">            BasicConv1d(<span class="number">54</span>,<span class="number">64</span>,<span class="number">1</span>,<span class="number">1</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.linear=nn.Sequential(</span><br><span class="line">            nn.BatchNorm1d(<span class="number">320</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Flatten(),</span><br><span class="line">            nn.Dropout(<span class="number">0.5</span>),</span><br><span class="line">            nn.Linear(<span class="number">320</span>,<span class="number">256</span>),</span><br><span class="line">            nn.BatchNorm1d(<span class="number">256</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">256</span>,<span class="number">7</span>),</span><br><span class="line">            nn.Softmax(dim=<span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>),x.size(<span class="number">1</span>),<span class="number">1</span>)</span><br><span class="line">        x0=self.branch0(x)</span><br><span class="line">        x1=self.branch1(x)</span><br><span class="line">        x2=self.branch2(x)</span><br><span class="line">        x3=self.branch3(x)</span><br><span class="line">        out=torch.cat((x0,x1,x2,x3),<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> self.linear(out)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Block35</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,scale=<span class="number">1.0</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(Block35,self).__init__()</span><br><span class="line">        self.scale=scale</span><br><span class="line">        self.branch0=BasicConv1d(<span class="number">54</span>,<span class="number">32</span>,kernel=<span class="number">1</span>,stride=<span class="number">1</span>)</span><br><span class="line">        self.branch1=nn.Sequential(</span><br><span class="line">            BasicConv1d(<span class="number">54</span>,<span class="number">32</span>,<span class="number">1</span>,<span class="number">1</span>),</span><br><span class="line">            BasicConv1d(<span class="number">32</span>,<span class="number">32</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line">        self.branch2=nn.Sequential(</span><br><span class="line">            BasicConv1d(<span class="number">54</span>,<span class="number">32</span>,<span class="number">1</span>,<span class="number">1</span>),</span><br><span class="line">            BasicConv1d(<span class="number">32</span>,<span class="number">48</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>),</span><br><span class="line">            BasicConv1d(<span class="number">48</span>,<span class="number">64</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line">        self.conv1d=nn.Conv1d(<span class="number">128</span>,<span class="number">54</span>,kernel_size=<span class="number">1</span>,stride=<span class="number">1</span>)</span><br><span class="line">        self.relu=nn.ReLU(inplace=<span class="literal">False</span>)</span><br><span class="line">        self.Linear=nn.Sequential(</span><br><span class="line">            nn.Flatten(),</span><br><span class="line">            nn.Linear(<span class="number">54</span>,<span class="number">256</span>,<span class="number">1</span>),</span><br><span class="line">            nn.BatchNorm1d(<span class="number">256</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">256</span>,<span class="number">7</span>,<span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>),x.size(<span class="number">1</span>),<span class="number">1</span>)</span><br><span class="line">        x0,x1,x2=self.branch0(x),self.branch1(x),self.branch2(x)</span><br><span class="line">        out=torch.cat((x0,x1,x2),<span class="number">1</span>)</span><br><span class="line">        out=self.conv1d(out)</span><br><span class="line">        out=out*self.scale+x</span><br><span class="line">        out=self.relu(out)</span><br><span class="line">        <span class="keyword">return</span> F.softmax(self.Linear(out),dim=<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Net2</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Net2, self).__init__()</span><br><span class="line">        self.conv1=nn.Conv1d(<span class="number">54</span>,<span class="number">128</span>,<span class="number">1</span>)</span><br><span class="line">        self.conv2=nn.Conv1d(<span class="number">54</span>,<span class="number">128</span>,<span class="number">1</span>)</span><br><span class="line">        self.conv3=nn.Conv1d(<span class="number">54</span>,<span class="number">128</span>,<span class="number">1</span>)</span><br><span class="line">        self.re=nn.ReLU()</span><br><span class="line">        self.bn1=nn.BatchNorm1d(<span class="number">128</span>)</span><br><span class="line">        </span><br><span class="line">        self.Conv=nn.Sequential(</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Conv1d(<span class="number">128</span>, <span class="number">164</span>,<span class="number">1</span>,<span class="number">1</span>),</span><br><span class="line">            nn.BatchNorm1d(<span class="number">164</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Conv1d(<span class="number">164</span>, <span class="number">128</span>,<span class="number">1</span>,<span class="number">1</span>),</span><br><span class="line">            nn.Dropout(<span class="number">0.5</span>),</span><br><span class="line">            nn.BatchNorm1d(<span class="number">128</span>),</span><br><span class="line">            nn.ReLU()</span><br><span class="line">        )</span><br><span class="line">        self.fl=nn.Flatten()</span><br><span class="line">        self.Linear=nn.Sequential(</span><br><span class="line"></span><br><span class="line">            nn.Linear(<span class="number">128</span>, <span class="number">256</span>),</span><br><span class="line">            nn.Dropout(<span class="number">0.5</span>),</span><br><span class="line">            nn.BatchNorm1d(<span class="number">256</span>),</span><br><span class="line">            nn.LeakyReLU(),</span><br><span class="line">            nn.Linear(<span class="number">256</span>, <span class="number">128</span>),</span><br><span class="line">            nn.BatchNorm1d(<span class="number">128</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">128</span>, <span class="number">7</span>),</span><br><span class="line">            nn.Softmax(dim=<span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>),x.size(<span class="number">1</span>),<span class="number">1</span>)</span><br><span class="line">        x1=self.conv1(x)</span><br><span class="line">        x3=self.conv3(x)</span><br><span class="line">        x2=self.conv2(x)</span><br><span class="line">        x=self.re(self.bn1(x1+x2+x3))</span><br><span class="line">        x=self.Conv(x)</span><br><span class="line">        x=self.fl(x)</span><br><span class="line">        </span><br><span class="line">    </span><br><span class="line">        </span><br><span class="line">       </span><br><span class="line">        <span class="keyword">return</span> self.Linear(x)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Net3</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,in_features=<span class="number">54</span>,n_hidden1=<span class="number">128</span>,n_hidden2=<span class="number">256</span>,n_hidden3=<span class="number">512</span>,out_features=<span class="number">7</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(Net3, self).__init__()</span><br><span class="line">        self.flatten=nn.Flatten()</span><br><span class="line">        self.hidden1=nn.Sequential(</span><br><span class="line">            nn.Linear(in_features,n_hidden1,<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm1d(n_hidden1),</span><br><span class="line">            nn.ReLU()</span><br><span class="line">        )</span><br><span class="line">        self.hidden2=nn.Sequential(</span><br><span class="line">            nn.Linear(n_hidden1,n_hidden2),</span><br><span class="line">            nn.BatchNorm1d(n_hidden2),</span><br><span class="line">            nn.ReLU()</span><br><span class="line">        )</span><br><span class="line">        self.hidden3=nn.Sequential(</span><br><span class="line">            nn.Linear(n_hidden2,n_hidden3),</span><br><span class="line">            nn.BatchNorm1d(n_hidden3),</span><br><span class="line">            nn.ReLU()</span><br><span class="line">        )</span><br><span class="line">        self.out=nn.Sequential(nn.Linear(n_hidden3,out_features))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        x=self.flatten(x)</span><br><span class="line">        x=self.hidden2(self.hidden1(x))</span><br><span class="line">        x=self.hidden3(x)</span><br><span class="line">        <span class="keyword">return</span> F.softmax(self.out(x),dim=<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Net4</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,in_features=<span class="number">54</span>,n_hidden1=<span class="number">128</span>,n_hidden2=<span class="number">256</span>,n_hidden3=<span class="number">512</span>,out_features=<span class="number">7</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(Net4, self).__init__()</span><br><span class="line">        self.flatten=nn.Flatten()</span><br><span class="line">        self.hidden1=nn.Sequential(</span><br><span class="line">            nn.Linear(in_features,n_hidden1,<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm1d(n_hidden1),</span><br><span class="line">            nn.ReLU()</span><br><span class="line">        )</span><br><span class="line">        self.hidden2=nn.Sequential(</span><br><span class="line">            nn.Linear(in_features,n_hidden2),</span><br><span class="line">            nn.BatchNorm1d(n_hidden2),</span><br><span class="line">            nn.ReLU()</span><br><span class="line">        )</span><br><span class="line">        self.hidden3=nn.Sequential(</span><br><span class="line">            nn.Linear(n_hidden1+n_hidden2,n_hidden3),</span><br><span class="line">            nn.BatchNorm1d(n_hidden3),</span><br><span class="line">            nn.ReLU()</span><br><span class="line">        )</span><br><span class="line">        self.out=nn.Sequential(nn.Linear(n_hidden3,out_features))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        x=self.flatten(x)</span><br><span class="line">        x1=self.hidden1(x)</span><br><span class="line">        x2=self.hidden2(x)</span><br><span class="line">        x=self.hidden3(torch.concat([x1,x2],dim=<span class="number">1</span>))</span><br><span class="line">        <span class="keyword">return</span> F.softmax(self.out(x),dim=<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Net5</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,in_features=<span class="number">54</span>,n_hidden1=<span class="number">54</span>,n_hidden2=<span class="number">256</span>,n_hidden3=<span class="number">512</span>,out_features=<span class="number">7</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(Net5, self).__init__()</span><br><span class="line">        self.flatten=nn.Flatten()</span><br><span class="line">        self.hidden1=nn.Sequential(</span><br><span class="line">            nn.Linear(in_features,n_hidden1,<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm1d(n_hidden1),</span><br><span class="line">            nn.ReLU()</span><br><span class="line">        )</span><br><span class="line">        self.hidden2=nn.Sequential(</span><br><span class="line">            nn.Linear(in_features,n_hidden2),</span><br><span class="line">            nn.BatchNorm1d(n_hidden2),</span><br><span class="line">            nn.ReLU()</span><br><span class="line">        )</span><br><span class="line">        self.hidden3=nn.Sequential(</span><br><span class="line">            nn.Linear(n_hidden2,n_hidden2),</span><br><span class="line">            nn.BatchNorm1d(n_hidden2),</span><br><span class="line">            nn.ReLU()</span><br><span class="line">        )</span><br><span class="line">        self.hidden4=nn.Sequential(</span><br><span class="line">            nn.Linear(n_hidden2,n_hidden3),</span><br><span class="line">            nn.BatchNorm1d(n_hidden3),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line"></span><br><span class="line">        )</span><br><span class="line">        self.out=nn.Sequential(nn.Linear(n_hidden3,out_features))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        x=self.flatten(x)</span><br><span class="line">        x1=self.hidden1(x)</span><br><span class="line">        x2=self.hidden2(x+x1)</span><br><span class="line">        x3=self.hidden3(x2)</span><br><span class="line">        o=self.hidden4(x3+x2)</span><br><span class="line">        <span class="keyword">return</span> F.softmax(self.out(o),dim=<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Net6</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,in_features=<span class="number">54</span>,n_hidden1=<span class="number">54</span>,n_hidden2=<span class="number">512</span>,n_hidden3=<span class="number">1024</span>,out_features=<span class="number">7</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(Net6, self).__init__()</span><br><span class="line">        self.flatten=nn.Flatten()</span><br><span class="line">        self.hidden1=nn.Sequential(</span><br><span class="line">            nn.Linear(in_features,n_hidden1,<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm1d(n_hidden1),</span><br><span class="line">            nn.ReLU()</span><br><span class="line">        )</span><br><span class="line">        self.hidden2=nn.Sequential(</span><br><span class="line">            nn.Linear(in_features,n_hidden1),</span><br><span class="line">            nn.Dropout(<span class="number">0.5</span>),</span><br><span class="line">            nn.BatchNorm1d(n_hidden1),</span><br><span class="line">            nn.ReLU()</span><br><span class="line">        )</span><br><span class="line">        self.hidden3=nn.Sequential(</span><br><span class="line">            nn.Linear(in_features,n_hidden2),</span><br><span class="line">            nn.BatchNorm1d(n_hidden2),</span><br><span class="line">            nn.ReLU()</span><br><span class="line">        )</span><br><span class="line">        self.hidden5=nn.Sequential(</span><br><span class="line">            nn.Linear(n_hidden2,n_hidden3),</span><br><span class="line">            nn.BatchNorm1d(n_hidden3),</span><br><span class="line">            nn.ReLU()</span><br><span class="line">        )</span><br><span class="line">        self.out=nn.Sequential(nn.Linear(n_hidden3,out_features))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        x=self.flatten(x)</span><br><span class="line">        x1=self.hidden1(x)</span><br><span class="line">        x2=self.hidden2(x)</span><br><span class="line">        x3=self.hidden3(x2+x1+x)</span><br><span class="line"></span><br><span class="line">        o=self.hidden5(x3)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> F.softmax(self.out(o),dim=<span class="number">1</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="3-3-训练阶段">3.3 训练阶段</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">Net_train_loss=[]</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">model,seed,epoch=<span class="number">200</span></span>):</span><br><span class="line">    <span class="keyword">global</span> Net_train_loss</span><br><span class="line">    <span class="comment"># 这边统一用交叉熵和自适应距估计优化器</span></span><br><span class="line">    path=<span class="string">r&quot;YourPath\%s.pth&quot;</span>%seed</span><br><span class="line">    criterion=nn.CrossEntropyLoss()</span><br><span class="line">    optimizer=torch.optim.Adam(model.parameters(),lr=<span class="number">1e-4</span>,betas=(<span class="number">0.9</span>,<span class="number">0.99</span>),</span><br><span class="line">                               eps=<span class="number">1e-08</span>,weight_decay=<span class="number">0</span>)</span><br><span class="line">    device=<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br><span class="line">    model.to(device)</span><br><span class="line">    criterion.to(device)</span><br><span class="line">    Loss=[]</span><br><span class="line">    Acc=[]</span><br><span class="line">    ELoss=[]</span><br><span class="line">    EAcc=[]</span><br><span class="line">    BEST_ACC=<span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> e <span class="keyword">in</span> <span class="built_in">range</span>(epoch):</span><br><span class="line">        train_loss = <span class="number">0</span></span><br><span class="line">        train_acc=<span class="number">0</span></span><br><span class="line">        model.train()</span><br><span class="line">        <span class="keyword">with</span> alive_progress.alive_bar(<span class="built_in">len</span>(train_DataLoader),force_tty=<span class="literal">True</span>) <span class="keyword">as</span> bar:</span><br><span class="line">            <span class="keyword">for</span> idx,(x,y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_DataLoader):</span><br><span class="line">                x,y=x.to(device),y.to(device)</span><br><span class="line">                y_pre=model(x)</span><br><span class="line"></span><br><span class="line">                optimizer.zero_grad()</span><br><span class="line">                loss=criterion(y,y_pre)</span><br><span class="line">                loss.backward()</span><br><span class="line">                optimizer.step()</span><br><span class="line"></span><br><span class="line">                train_loss+=loss.item()</span><br><span class="line">                _,pre=y_pre.<span class="built_in">max</span>(<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">                num_correct=(pre.to(<span class="string">&quot;cpu&quot;</span>)==np.argmax(y.to(<span class="string">&quot;cpu&quot;</span>),axis=<span class="number">1</span>)).<span class="built_in">sum</span>().item()</span><br><span class="line">                acc=num_correct/x.shape[<span class="number">0</span>]</span><br><span class="line">                train_acc+=acc</span><br><span class="line">                bar()</span><br><span class="line">        <span class="keyword">if</span> (k:=train_acc/<span class="built_in">len</span>(train_DataLoader))&gt;BEST_ACC:</span><br><span class="line">            BEST_ACC=k</span><br><span class="line">            </span><br><span class="line">            state = &#123;</span><br><span class="line">                <span class="string">&#x27;epoch&#x27;</span>: e,</span><br><span class="line">                <span class="string">&#x27;best_acc&#x27;</span>: k,</span><br><span class="line">                <span class="string">&#x27;model_state_dict&#x27;</span>: model.state_dict(),</span><br><span class="line">                <span class="string">&#x27;optimizer_state_dict&#x27;</span>: optimizer.state_dict(),</span><br><span class="line">            &#125;</span><br><span class="line">            torch.save(state, path)</span><br><span class="line">        Loss.append(train_loss/<span class="built_in">len</span>(train_DataLoader))</span><br><span class="line">        Acc.append(train_acc/<span class="built_in">len</span>(train_DataLoader))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;epoch : <span class="subst">&#123;e+<span class="number">1</span>&#125;</span> / <span class="subst">&#123;epoch&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Train Loss : <span class="subst">&#123;train_loss/<span class="built_in">len</span>(train_DataLoader)&#125;</span>, Train Acc : <span class="subst">&#123;train_acc/<span class="built_in">len</span>(train_DataLoader)&#125;</span>&quot;</span>)</span><br><span class="line">    Net_train_loss.append(Acc)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">net1=Net()</span><br><span class="line">train(net1,<span class="string">&quot;Net1&quot;</span>)</span><br><span class="line"></span><br><span class="line">net2=Mixed_5b()</span><br><span class="line">train(net2,<span class="string">&quot;Net2&quot;</span>)</span><br><span class="line"></span><br><span class="line">net3=Net3()</span><br><span class="line">train(net3,<span class="string">&quot;Net3&quot;</span>)</span><br><span class="line"></span><br><span class="line">net4=Block35()</span><br><span class="line">train(net4,<span class="string">&quot;Net4&quot;</span>)</span><br><span class="line"></span><br><span class="line">net5=Net4()</span><br><span class="line">train(net5,<span class="string">&quot;Net5&quot;</span>)</span><br><span class="line"></span><br><span class="line">net6=Net5()</span><br><span class="line">train(net6,<span class="string">&quot;Net6&quot;</span>)</span><br><span class="line"></span><br><span class="line">net7=Net6()</span><br><span class="line">train(net7,<span class="string">&quot;Net7&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>训练结束后，我们就可以载入模型的参数和结果啦。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载最优参数</span></span><br><span class="line">Nets=[net1,net2,net3,net4,net5,net6,net7]</span><br><span class="line">BestAcc=[]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">8</span>):</span><br><span class="line">    checkpoint=torch.load(<span class="string">r&quot;YourPath\Net%s.pth&quot;</span>%i)</span><br><span class="line">    Nets[i-<span class="number">1</span>].load_state_dict(checkpoint[<span class="string">&quot;model_state_dict&quot;</span>])</span><br><span class="line">    BestAcc.append(checkpoint[<span class="string">&quot;best_acc&quot;</span>])</span><br></pre></td></tr></table></figure>
<p>我们用训练好的模型去计算在验证集上的结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">pre=[]</span><br><span class="line">eval_acc=[]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> Nets:</span><br><span class="line">    i.<span class="built_in">eval</span>()</span><br><span class="line">    i.to(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">    net_pre=i(x_v_tensor)</span><br><span class="line">    eval_acc.append(accuracy(torch.<span class="built_in">max</span>(net_pre,<span class="number">1</span>)[<span class="number">1</span>],y_v_tensor.argmax(<span class="number">1</span>)).item())</span><br><span class="line">    <span class="keyword">if</span> pre==[]:</span><br><span class="line">        pre=net_pre</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        pre+=net_pre</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看验证集和训练集精度变化情况</span></span><br><span class="line">b=Bar()</span><br><span class="line">b.add_xaxis([<span class="string">&quot;Net%i&quot;</span>%i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">8</span>)])</span><br><span class="line">b.add_yaxis(<span class="string">&quot;Train Acc&quot;</span>,[<span class="built_in">round</span>(i,<span class="number">3</span>) <span class="keyword">for</span> i <span class="keyword">in</span> BestAcc])</span><br><span class="line">b.add_yaxis(<span class="string">&quot;Val Acc&quot;</span>,[<span class="built_in">round</span>(i,<span class="number">3</span>) <span class="keyword">for</span> i <span class="keyword">in</span> eval_acc])</span><br><span class="line">b.set_series_opts(markpoint_opts=opts.MarkPointOpts(</span><br><span class="line">        data=[opts.MarkPointItem(type_=<span class="string">&quot;max&quot;</span>, name=<span class="string">&quot;最大值&quot;</span>),  <span class="comment">##设置最大值 标记</span></span><br><span class="line">              opts.MarkPointItem(type_=<span class="string">&quot;min&quot;</span>, name=<span class="string">&quot;最小值&quot;</span>),  <span class="comment"># 设置最小值标记</span></span><br><span class="line">              ], symbol=<span class="string">&#x27;pin&#x27;</span>, symbol_size=<span class="number">60</span>), markline_opts=opts.MarkLineOpts(</span><br><span class="line">        data=[opts.MarkLineItem(type_=<span class="string">&quot;average&quot;</span>, name=<span class="string">&quot;平均值&quot;</span>)]</span><br><span class="line">    ))</span><br><span class="line">b.render_notebook()</span><br></pre></td></tr></table></figure>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://github.com/Chen-XiaoLv/ML-in-Geochemistry/raw/master/READEME/image-20230703010331579.png" alt="image-20230703010331579" style="zoom:50%;">
<p>可以看到，在验证集上，模型的性能有所下降，这是由于原本的模型对于训练集发生了过拟合现象。Net1实际上是最简单的二层全连接层，尽管它的训练速度最快，参数最少，在训练集上表现良好，但其泛化能力远不如其他模型。而Net2则对验证集的表现良好。</p>
<p>总体来说，模型在验证集上的平均精度略微下降。</p>
<h2 id="五-模型融合">五 模型融合</h2>
<p>模型融合通过提升特征多样性、样本多样性和模态多样性，可以进一步增加模型的泛化能力和鲁棒性。</p>
<p>根据方法的不同，可以分为过程融合和结果融合。</p>
<p><strong>过程融合🍉</strong></p>
<p>过程融合最基本的有Bagging和Boosting，Bagging就是多个弱分类器堆叠在一起，Boosting就是基于弱分类器分错的结果输入后一个分类器中，从而实现弱模型媲美强模型的过程。</p>
<p><strong>结果融合🍌</strong></p>
<p>主要有以下几种方法</p>
<ul>
<li>加权法</li>
<li>stacking</li>
<li>Blending</li>
</ul>
<p>我们这边使用结果融合，通过尝试直接叠加法、软投票法和Stacking方式，分析并给出一个相对较好的结果</p>
<h3 id="1-线性融合">1 线性融合</h3>
<h4 id="1-1-投票法">1.1 投票法</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">z_1=accuracy(torch.<span class="built_in">max</span>(pre,<span class="number">1</span>)[<span class="number">1</span>],y_v_tensor.argmax(<span class="number">1</span>)).item() <span class="comment"># 直接投票</span></span><br></pre></td></tr></table></figure>
<h4 id="2-2-加权投票">2.2 加权投票</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 结果加权投票</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">vote</span>(<span class="params">weight</span>):</span><br><span class="line">    pre_1=[]</span><br><span class="line">    <span class="keyword">for</span> _,i <span class="keyword">in</span> <span class="built_in">enumerate</span>(Nets):</span><br><span class="line">        i.<span class="built_in">eval</span>()</span><br><span class="line">        i.to(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">        net_pre=i(x_v_tensor)*weight[_]</span><br><span class="line">        <span class="keyword">if</span> pre_1==[]:</span><br><span class="line">            pre_1=net_pre</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            pre_1+=net_pre</span><br><span class="line">    <span class="keyword">return</span> pre_1</span><br><span class="line"></span><br><span class="line">z_2=accuracy(torch.<span class="built_in">max</span>(vote(eval_acc),<span class="number">1</span>)[<span class="number">1</span>],y_v_tensor.argmax(<span class="number">1</span>)).item()</span><br></pre></td></tr></table></figure>
<h4 id="2-3-软投票">2.3 软投票</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 基于Softmax投票</span></span><br><span class="line">k=<span class="built_in">sum</span>([np.exp(i) <span class="keyword">for</span> i <span class="keyword">in</span> eval_acc])</span><br><span class="line">sm=[np.exp(i)/k <span class="keyword">for</span> i <span class="keyword">in</span> eval_acc]</span><br><span class="line">z_3=accuracy(torch.<span class="built_in">max</span>(vote(sm),<span class="number">1</span>)[<span class="number">1</span>],y_v_tensor.argmax(<span class="number">1</span>)).item()</span><br></pre></td></tr></table></figure>
<h3 id="2-Stacking">2 Stacking</h3>
<p>将多个分类器的概率结果作为一个简单分类器的输入，经过该分类器进行输出，我们这边执行两种方法：</p>
<ul>
<li>数值叠加</li>
<li>特征叠加</li>
</ul>
<p>简单分类器选择一个简单的NN</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">NN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,in_channel=<span class="number">7</span>,out_channel=<span class="number">7</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(NN, self).__init__()</span><br><span class="line">        self.hidden=nn.Sequential(</span><br><span class="line">            nn.Linear(in_channel,<span class="number">128</span>),</span><br><span class="line">            nn.BatchNorm1d(<span class="number">128</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">128</span>,<span class="number">256</span>),</span><br><span class="line">            nn.BatchNorm1d(<span class="number">256</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">256</span>,<span class="number">648</span>),</span><br><span class="line">            nn.BatchNorm1d(<span class="number">648</span>),</span><br><span class="line">            nn.Dropout(<span class="number">0.2</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">648</span>,<span class="number">7</span>)</span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        <span class="keyword">return</span> F.softmax(self.hidden(x))</span><br></pre></td></tr></table></figure>
<h4 id="2-1-数值叠加">2.1 数值叠加</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数值叠加</span></span><br><span class="line">input_data=[]</span><br><span class="line"><span class="keyword">for</span> _,i <span class="keyword">in</span> <span class="built_in">enumerate</span>(Nets):</span><br><span class="line">    i.<span class="built_in">eval</span>()</span><br><span class="line">    i.to(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">    net_pre=i(x_t_tensor)</span><br><span class="line">    <span class="keyword">if</span> input_data==[]:</span><br><span class="line">        input_data=net_pre</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        input_data+=net_pre</span><br><span class="line">x=input_data.tolist()</span><br><span class="line">input_data=torch.tensor(x)</span><br><span class="line">input_data.shape</span><br></pre></td></tr></table></figure>
<p>值得注意的是，这里通过<code>tolist()</code>来回转换变换内存地址，否则<code>torch</code>在反向传播执行计算图时会把上面那段代码也算进去，导致报错。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据集</span></span><br><span class="line">stackingData=DataLoader(MyDataSet(input_data.<span class="built_in">float</span>(),y_t_tensor),batch_size=<span class="number">64</span>,shuffle=<span class="literal">True</span>,drop_last=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 模型</span></span><br><span class="line">net_s_1=NN(<span class="number">7</span>,<span class="number">7</span>)</span><br><span class="line"><span class="comment"># 训练</span></span><br><span class="line">train(net_s_1,<span class="string">&quot;Net_S_1&quot;</span>,n=stackingData,epoch=<span class="number">50</span>)</span><br><span class="line"><span class="comment"># 载入</span></span><br><span class="line">net_s_1.load_state_dict(torch.load(<span class="string">r&quot;YourPath\Net_S_1.pth&quot;</span>)[<span class="string">&quot;model_state_dict&quot;</span>])</span><br><span class="line">net_s_1.to(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"><span class="comment"># 预测结果</span></span><br><span class="line">z_4=accuracy(torch.<span class="built_in">max</span>(net_s_1(pre),<span class="number">1</span>)[<span class="number">1</span>],y_v_tensor.<span class="built_in">max</span>(<span class="number">1</span>)[<span class="number">1</span>]).item()</span><br></pre></td></tr></table></figure>
<h4 id="2-2-特征叠加">2.2 特征叠加</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 特征叠加</span></span><br><span class="line">input_data=[]</span><br><span class="line"><span class="keyword">for</span> _,i <span class="keyword">in</span> <span class="built_in">enumerate</span>(Nets):</span><br><span class="line">    i.<span class="built_in">eval</span>()</span><br><span class="line">    i.to(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">    net_pre=i(x_t_tensor)</span><br><span class="line">    <span class="keyword">if</span> input_data==[]:</span><br><span class="line">        input_data=net_pre</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        input_data=torch.concat([input_data,net_pre],<span class="number">1</span>)</span><br><span class="line">x=input_data.tolist()</span><br><span class="line">input_data=torch.tensor(x)</span><br><span class="line">input_data.shape</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">stackingData=DataLoader(MyDataSet(input_data.<span class="built_in">float</span>(),y_t_tensor),batch_size=<span class="number">64</span>,shuffle=<span class="literal">True</span>,drop_last=<span class="literal">True</span>)</span><br><span class="line">net_s_2=NN(<span class="number">49</span>,<span class="number">7</span>)</span><br><span class="line">train(net_s_2,<span class="string">&quot;Net_S_2&quot;</span>,n=stackingData,epoch=<span class="number">200</span>)</span><br><span class="line">net_s_2.load_state_dict(torch.load(<span class="string">r&quot;YourPath\Net_S_2.pth&quot;</span>)[<span class="string">&quot;model_state_dict&quot;</span>])</span><br><span class="line">net_s_2.to(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">z_5=accuracy(torch.<span class="built_in">max</span>(net_s_1(pre),<span class="number">1</span>)[<span class="number">1</span>],y_v_tensor.<span class="built_in">max</span>(<span class="number">1</span>)[<span class="number">1</span>]).item()</span><br></pre></td></tr></table></figure>
<h3 id="3-结果分析">3 结果分析</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">b=Line()</span><br><span class="line">b.add_xaxis([<span class="string">&quot;直接投票&quot;</span>,<span class="string">&quot;结果分配投票&quot;</span>,<span class="string">&quot;Softmax软投票&quot;</span>,<span class="string">&quot;数据叠加&quot;</span>,<span class="string">&quot;特征叠加&quot;</span>])</span><br><span class="line">b.add_yaxis(<span class="string">&quot;结果精度&quot;</span>,[<span class="built_in">round</span>(i,<span class="number">5</span>) <span class="keyword">for</span> i <span class="keyword">in</span> [z_1,z_2,z_3,z_4,z_5]])</span><br><span class="line">b.set_global_opts(yaxis_opts=opts.AxisOpts(min_=<span class="string">&quot;dataMin&quot;</span>,max_=<span class="string">&quot;dataMax&quot;</span>))</span><br><span class="line">b.render_notebook()</span><br></pre></td></tr></table></figure>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://github.com/Chen-XiaoLv/ML-in-Geochemistry/raw/master/READEME/image-20230703011113022.png" alt="image-20230703011113022" style="zoom:50%;">
<p>之前单模在验证集上最高的0.888，平均是0.86，特征叠加的结果会优于之前单模最好结果。</p>
<p>值得一提的是，特征叠加的方法在训练集上最高性能达到了0.93，这个结果远超之前单模的最好结果0.894。当然，用深度学习网络作为输出分类器，高收益的同时也带来了高风险，根据输出分类器的性能，最终结果也会上下浮动。为了避免这种情况，我们其实可以使用Ridge回归、Lasso回归、简单随机森林等模型作为输出模型。</p>
<hr>
<h2 id="六-结果分析">六 结果分析</h2>
<p><strong>以下是各模型的分类性能</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">b=Bar()</span><br><span class="line">b.add_xaxis([i <span class="keyword">for</span> i <span class="keyword">in</span> ML_PRE.keys()]+[<span class="string">&quot;Net%s&quot;</span>%i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">7</span>)])</span><br><span class="line">b.add_yaxis(<span class="string">&quot;机器学习准确率&quot;</span>,[<span class="built_in">round</span>(i[<span class="number">1</span>],<span class="number">3</span>) <span class="keyword">for</span> i <span class="keyword">in</span> ML_PRE.values()],markpoint_opts=opts.MarkPointOpts(</span><br><span class="line">            data=[opts.MarkPointItem(type_=<span class="string">&quot;min&quot;</span>, name=<span class="string">&quot;最小值&quot;</span>),opts.MarkPointItem(type_=<span class="string">&quot;max&quot;</span>,name=<span class="string">&quot;最大值&quot;</span>)],symbol=<span class="string">&#x27;pin&#x27;</span>, symbol_size=<span class="number">55</span>))</span><br><span class="line">b.add_yaxis(<span class="string">&quot;深度学习准确率&quot;</span>,[<span class="literal">None</span>]*<span class="number">4</span>+[<span class="built_in">round</span>(i,<span class="number">3</span>) <span class="keyword">for</span> i <span class="keyword">in</span> eval_acc],markpoint_opts=opts.MarkPointOpts(</span><br><span class="line">            data=[opts.MarkPointItem(type_=<span class="string">&quot;min&quot;</span>, name=<span class="string">&quot;最小值&quot;</span>),opts.MarkPointItem(type_=<span class="string">&quot;max&quot;</span>,name=<span class="string">&quot;最大值&quot;</span>)],symbol=<span class="string">&#x27;arrow&#x27;</span>, symbol_size=<span class="number">55</span>))</span><br><span class="line">b.set_global_opts(xaxis_opts=opts.AxisOpts(axislabel_opts=opts.LabelOpts(rotate=-<span class="number">15</span>)),</span><br><span class="line">                     title_opts=opts.TitleOpts(title=<span class="string">&quot;模型准确率&quot;</span>))</span><br><span class="line">b.render_notebook()</span><br></pre></td></tr></table></figure>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2023/07/13/%E3%80%90%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5%E3%80%91%E6%A3%AE%E6%9E%97%E8%A6%86%E7%9B%96%E7%B1%BB%E5%9E%8B%E9%A2%84%E6%B5%8B/image-20230703021324827.png" alt="image-20230703021324827" style="zoom:50%;">
<p>在小样本跟少量特征的情况下，机器学习模型的性能与深度学习模型的性能差距不大，当然这里的深度学习模型只是一些非常简单的模型。</p>
<p><strong>以下是性能最强的两个深度学习模型与两个最强的机器学习模型进行融合的结果</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Net3 Net6</span></span><br><span class="line">net3,net6=Nets[<span class="number">2</span>],Nets[-<span class="number">1</span>]</span><br><span class="line"><span class="comment"># 做个最简单的线性加权</span></span><br><span class="line">z1=torch.<span class="built_in">max</span>(net3(x_v_tensor),<span class="number">1</span>)[<span class="number">1</span>]+<span class="number">1</span></span><br><span class="line">z2=torch.<span class="built_in">max</span>(net6(x_v_tensor),<span class="number">1</span>)[<span class="number">1</span>]+<span class="number">1</span></span><br><span class="line">z3=ML_PRE[<span class="string">&#x27;LightGBM&#x27;</span>][<span class="number">0</span>]</span><br><span class="line">z4=ML_PRE[<span class="string">&#x27;RF&#x27;</span>][<span class="number">0</span>]</span><br><span class="line">z=torch.concat([z1.reshape(z1.shape[<span class="number">0</span>],<span class="number">1</span>),z2.reshape(z1.shape[<span class="number">0</span>],<span class="number">1</span>),torch.Tensor(z3).reshape(z1.shape[<span class="number">0</span>],<span class="number">1</span>),torch.Tensor(z4).reshape(z1.shape[<span class="number">0</span>],<span class="number">1</span>)],dim=<span class="number">1</span>)</span><br><span class="line">e=pd.DataFrame(z.numpy())</span><br><span class="line"><span class="comment"># 后处理</span></span><br><span class="line"><span class="comment"># 一般在提交的时候整的</span></span><br><span class="line"><span class="comment"># 取众数就好了</span></span><br><span class="line">ans=[]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(e.shape[<span class="number">0</span>]):</span><br><span class="line">    ans.append(e.iloc[i].mode().values[<span class="number">0</span>])</span><br><span class="line">accuracy(ans,y_val)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 0.8838183421516755</span></span><br></pre></td></tr></table></figure>
<p>emm，这个性能略好于Net6，大于机器学习模型，小于Net3。</p>
<p>值得注意的是，在后处理过程中，模型投票产生的结果可能是：</p>
<ul>
<li>四票全中</li>
<li>三票A一票B</li>
<li>两票A两票B</li>
<li>两票A一票B一票C</li>
<li>ABCD各一票</li>
</ul>
<p>由于这里是把结果拿出来了而不是概率(概率请参考深度学习融合)，所以我们规定：三票四票的直接就是输出标签，两票A两票B选择创建分支，两票A一票B一票C选择A，ABCD各一票则随机选。</p>
<p>举个简单的后处理栗子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">ans=[]</span><br><span class="line">ans2=[]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(e.shape[<span class="number">0</span>]):</span><br><span class="line">    v=[<span class="number">0</span>]*<span class="number">8</span></span><br><span class="line">    fir=<span class="literal">True</span></span><br><span class="line">    c=<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(e.shape[<span class="number">1</span>]):</span><br><span class="line">        v[<span class="built_in">int</span>(e.iloc[i,j])]+=<span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> idx,_ <span class="keyword">in</span> <span class="built_in">enumerate</span>(v):</span><br><span class="line">        <span class="keyword">if</span> _==<span class="number">4</span> <span class="keyword">or</span> _==<span class="number">3</span>:</span><br><span class="line">            ans.append(idx)</span><br><span class="line">            ans2.append(idx)</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">elif</span> _==<span class="number">2</span>:</span><br><span class="line">            <span class="keyword">if</span> fir:</span><br><span class="line">                ans.append(idx)</span><br><span class="line">                ans2.append(idx)</span><br><span class="line">                fir=<span class="literal">False</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                ans2[-<span class="number">1</span>]=idx</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">elif</span> _==<span class="number">1</span>:</span><br><span class="line">            c+=<span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> c==<span class="number">4</span>:</span><br><span class="line">        ans.append(e.iloc[i,<span class="number">0</span>])</span><br><span class="line">        ans2.append(e.iloc[i,<span class="number">2</span>])</span><br></pre></td></tr></table></figure>
<p>这段代码是我在半夜三点神志不清的时候写的，难免像坨屎，应该有很大的优化空间。但不管怎么说，这种后处理方式确实拿到了更好的结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">accuracy(ans,y_val) <span class="comment"># 0.8833774250440917</span></span><br><span class="line">accuracy(ans2,y_val) <span class="comment"># 0.8893298059964727</span></span><br></pre></td></tr></table></figure>
<p>这个结果超过了之前单模最好结果Net3，算是有提升吧。</p>
<p>实际上，我们对深度学习模型的融合也需要进行后处理，这样也能提高些分数。</p>
<p>就不做Stacking了，大概就是这样</p>
<p><strong>以下是特征工程对于机器学习模型的提升</strong></p>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://github.com/Chen-XiaoLv/ML-in-Geochemistry/raw/master/READEME/image-20230703032934826.png" alt="image-20230703032934826" style="zoom:50%;">
<p>这个图不太直观啊，我们逐个来看看是否有提升：</p>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://github.com/Chen-XiaoLv/ML-in-Geochemistry/raw/master/READEME/image-20230703033627960.png" alt="image-20230703033627960" style="zoom:50%;">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://github.com/Chen-XiaoLv/ML-in-Geochemistry/raw/master/READEME/image-20230703033803478.png" alt="image-20230703033803478" style="zoom:50%;">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://github.com/Chen-XiaoLv/ML-in-Geochemistry/raw/master/READEME/image-20230703033914021.png" alt="image-20230703033914021" style="zoom:50%;">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://github.com/Chen-XiaoLv/ML-in-Geochemistry/raw/master/READEME/image-20230703033954456.png" alt="image-20230703033954456" style="zoom:50%;">
<p>这里面仅仅构建了几个简单的特征，剔除了异常值，结果得到了明显的提升。但是相应的，异常值会带来泛化能力的提高，模型鲁棒性增强，需要根据具体情况决定是否对异常值进行剔除。</p>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css"></article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/">项目实践</a></div><div class="post_share"><div class="social-share" data-image="https://w.wallhaven.cc/full/x6/wallhaven-x6l7vv.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/07/14/%E3%80%90Typora%E3%80%91%E5%B8%B8%E7%94%A8%E5%85%AC%E5%BC%8F%E6%9F%A5%E8%AF%A2/"><img class="prev-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://w.wallhaven.cc/full/j3/wallhaven-j3m8y5.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">【Typora】常用公式查询</div></div></a></div><div class="next-post pull-right"><a href="/2023/07/07/Docker%20Web%20%E7%8E%AF%E5%A2%83/"><img class="next-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img-blog.csdnimg.cn/20200718094952975.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info"></div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2023/05/20/%E3%80%90%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5%E3%80%91%E7%8C%AB%E5%8D%81%E4%BA%8C%E5%88%86%E7%B1%BB/" title="【数据分析实践】猫十二分类"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://w.wallhaven.cc/full/x6/wallhaven-x6l7vv.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-05-20</div><div class="title">【数据分析实践】猫十二分类</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div><div id="comment-switch"><span class="first-comment">Valine</span><span class="switch-btn"></span><span class="second-comment">Disqus</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div><div><div id="disqus_thread"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://images.jingyeqian.com/i/2021/03/21/6375192146687954551533103.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Kagura</div><div class="author-info__description">May we all be who we want to be</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">120</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">47</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://blog.csdn.net/qq_45957458?type=blog"><i></i><span>about me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/xxxxx" target="_blank" title="Github"><i class="fab fa-github"></i></a></div></div><script src="https://fastly.jsdelivr.net/gh/xiaopengand/blogCdn@latest/xzxr/twopeople1.js"></script><script src="https://fastly.jsdelivr.net/gh/xiaopengand/blogCdn@latest/xzxr/zdog.dist.js"></script><script id="rendered-js" src="https://fastly.jsdelivr.net/gh/xiaopengand/blogCdn@latest/xzxr/twopeople.js"></script><style>.card-widget.card-announcement {
margin: 0;
align-items: center;
justify-content: center;
text-align: center;
}
canvas {
display: block;
margin: 0 auto;
cursor: move;
}</style><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Kaggle-%E7%AB%9E%E8%B5%9B-Forest-Cover-Type-Prediction-%E6%A3%AE%E6%9E%97%E8%A6%86%E7%9B%96%E7%B1%BB%E5%9E%8B%E9%A2%84%E6%B5%8B"><span class="toc-number">1.</span> <span class="toc-text">Kaggle 竞赛 Forest Cover Type Prediction 森林覆盖类型预测</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Description"><span class="toc-number">1.1.</span> <span class="toc-text">Description</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Requirement"><span class="toc-number">1.2.</span> <span class="toc-text">Requirement</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80-%E8%B5%9B%E9%A2%98%E7%90%86%E8%A7%A3"><span class="toc-number">2.</span> <span class="toc-text">一 赛题理解</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E8%83%8C%E6%99%AF"><span class="toc-number">2.1.</span> <span class="toc-text">1 背景</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E6%95%B0%E6%8D%AE"><span class="toc-number">2.2.</span> <span class="toc-text">2 数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87"><span class="toc-number">2.3.</span> <span class="toc-text">3 评价指标</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C-%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90"><span class="toc-number">3.</span> <span class="toc-text">二 数据探索性分析</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%89%8D%E6%9C%9F%E5%87%86%E5%A4%87%E4%B8%8E%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%8F%96"><span class="toc-number">3.1.</span> <span class="toc-text">1 前期准备与数据读取</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-1-%E6%A8%A1%E5%9D%97%E5%AF%BC%E5%85%A5"><span class="toc-number">3.1.1.</span> <span class="toc-text">1.1 模块导入</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-2-%E7%BB%98%E5%9B%BE%E6%A8%A1%E5%9D%97"><span class="toc-number">3.1.2.</span> <span class="toc-text">1.2 绘图模块</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E6%95%B0%E6%8D%AE%E5%88%86%E5%B8%83%E6%83%85%E5%86%B5"><span class="toc-number">3.2.</span> <span class="toc-text">2 数据分布情况</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-%E6%95%B0%E5%80%BC%E6%95%B0%E6%8D%AE%E5%88%86%E5%B8%83%E6%83%85%E5%86%B5"><span class="toc-number">3.2.1.</span> <span class="toc-text">2.1 数值数据分布情况</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-%E5%90%8D%E4%B9%89%E6%95%B0%E6%8D%AE%E5%88%86%E5%B8%83%E6%83%85%E5%86%B5"><span class="toc-number">3.2.2.</span> <span class="toc-text">2.2 名义数据分布情况</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97"><span class="toc-number">3.2.3.</span> <span class="toc-text">3 数据清洗</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89-%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B"><span class="toc-number">4.</span> <span class="toc-text">三 特征工程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E7%89%B9%E5%BE%81%E5%8F%98%E6%8D%A2"><span class="toc-number">4.1.</span> <span class="toc-text">1 特征变换</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96"><span class="toc-number">4.2.</span> <span class="toc-text">2 特征提取</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9"><span class="toc-number">4.3.</span> <span class="toc-text">3 特征选择</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83"><span class="toc-number">5.</span> <span class="toc-text">四 模型训练</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C"><span class="toc-number">5.1.</span> <span class="toc-text">1 准备工作</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-1-%E6%95%B0%E6%8D%AE%E6%8B%86%E5%88%86"><span class="toc-number">5.1.1.</span> <span class="toc-text">1.1 数据拆分</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-2-%E6%A0%87%E5%87%86%E5%8C%96%E5%8E%BB%E9%99%A4%E9%87%8F%E7%BA%B2%E5%BD%B1%E5%93%8D"><span class="toc-number">5.1.2.</span> <span class="toc-text">1.2 标准化去除量纲影响</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B"><span class="toc-number">5.2.</span> <span class="toc-text">2 机器学习模型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-%E6%A0%91%E6%A8%A1%E5%9E%8B"><span class="toc-number">5.2.1.</span> <span class="toc-text">2.1 树模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA"><span class="toc-number">5.2.2.</span> <span class="toc-text">2.2 支持向量机</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-3-%E4%BC%98%E5%8C%96"><span class="toc-number">5.2.3.</span> <span class="toc-text">2.3 优化</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B"><span class="toc-number">5.3.</span> <span class="toc-text">3 深度学习模型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-%E6%9E%84%E5%BB%BA%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">5.3.1.</span> <span class="toc-text">3.1 构建数据集</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9"><span class="toc-number">5.3.2.</span> <span class="toc-text">3.2 模型选择</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-3-%E8%AE%AD%E7%BB%83%E9%98%B6%E6%AE%B5"><span class="toc-number">5.3.3.</span> <span class="toc-text">3.3 训练阶段</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94-%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88"><span class="toc-number">6.</span> <span class="toc-text">五 模型融合</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E7%BA%BF%E6%80%A7%E8%9E%8D%E5%90%88"><span class="toc-number">6.1.</span> <span class="toc-text">1 线性融合</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-1-%E6%8A%95%E7%A5%A8%E6%B3%95"><span class="toc-number">6.1.1.</span> <span class="toc-text">1.1 投票法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-%E5%8A%A0%E6%9D%83%E6%8A%95%E7%A5%A8"><span class="toc-number">6.1.2.</span> <span class="toc-text">2.2 加权投票</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-3-%E8%BD%AF%E6%8A%95%E7%A5%A8"><span class="toc-number">6.1.3.</span> <span class="toc-text">2.3 软投票</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-Stacking"><span class="toc-number">6.2.</span> <span class="toc-text">2 Stacking</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-%E6%95%B0%E5%80%BC%E5%8F%A0%E5%8A%A0"><span class="toc-number">6.2.1.</span> <span class="toc-text">2.1 数值叠加</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-%E7%89%B9%E5%BE%81%E5%8F%A0%E5%8A%A0"><span class="toc-number">6.2.2.</span> <span class="toc-text">2.2 特征叠加</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E7%BB%93%E6%9E%9C%E5%88%86%E6%9E%90"><span class="toc-number">6.3.</span> <span class="toc-text">3 结果分析</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%AD-%E7%BB%93%E6%9E%9C%E5%88%86%E6%9E%90"><span class="toc-number">7.</span> <span class="toc-text">六 结果分析</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/07/23/%E3%80%90GEE%E3%80%91GEE%E4%B8%AD%E6%96%87%E9%A3%9F%E7%94%A8%E8%AF%B4%E6%98%8E%E4%B9%A6%EF%BC%81/" title="【GEE】GEE中文食用说明书！"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://w.wallhaven.cc/full/1p/wallhaven-1ppld1.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【GEE】GEE中文食用说明书！"/></a><div class="content"><a class="title" href="/2023/07/23/%E3%80%90GEE%E3%80%91GEE%E4%B8%AD%E6%96%87%E9%A3%9F%E7%94%A8%E8%AF%B4%E6%98%8E%E4%B9%A6%EF%BC%81/" title="【GEE】GEE中文食用说明书！">【GEE】GEE中文食用说明书！</a><time datetime="2023-07-23T12:43:08.603Z" title="发表于 2023-07-23 20:43:08">2023-07-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/07/17/%E3%80%90GEE%E3%80%91GeeMap/" title="【GEE】GeeMap食用说明书"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://w.wallhaven.cc/full/1p/wallhaven-1ppld1.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【GEE】GeeMap食用说明书"/></a><div class="content"><a class="title" href="/2023/07/17/%E3%80%90GEE%E3%80%91GeeMap/" title="【GEE】GeeMap食用说明书">【GEE】GeeMap食用说明书</a><time datetime="2023-07-17T12:28:33.343Z" title="发表于 2023-07-17 20:28:33">2023-07-17</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/07/16/JavaSCript/" title="无题"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img-blog.csdnimg.cn/20200718094952975.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="无题"/></a><div class="content"><a class="title" href="/2023/07/16/JavaSCript/" title="无题">无题</a><time datetime="2023-07-16T14:18:42.163Z" title="发表于 2023-07-16 22:18:42">2023-07-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/07/14/%E3%80%90Typora%E3%80%91%E5%B8%B8%E7%94%A8%E5%85%AC%E5%BC%8F%E6%9F%A5%E8%AF%A2/" title="【Typora】常用公式查询"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://w.wallhaven.cc/full/j3/wallhaven-j3m8y5.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【Typora】常用公式查询"/></a><div class="content"><a class="title" href="/2023/07/14/%E3%80%90Typora%E3%80%91%E5%B8%B8%E7%94%A8%E5%85%AC%E5%BC%8F%E6%9F%A5%E8%AF%A2/" title="【Typora】常用公式查询">【Typora】常用公式查询</a><time datetime="2023-07-14T02:13:41.525Z" title="发表于 2023-07-14 10:13:41">2023-07-14</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/07/13/%E3%80%90%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5%E3%80%91%E6%A3%AE%E6%9E%97%E8%A6%86%E7%9B%96%E7%B1%BB%E5%9E%8B%E9%A2%84%E6%B5%8B/" title="【数据分析实践】森林覆盖类型预测"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://w.wallhaven.cc/full/x6/wallhaven-x6l7vv.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【数据分析实践】森林覆盖类型预测"/></a><div class="content"><a class="title" href="/2023/07/13/%E3%80%90%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5%E3%80%91%E6%A3%AE%E6%9E%97%E8%A6%86%E7%9B%96%E7%B1%BB%E5%9E%8B%E9%A2%84%E6%B5%8B/" title="【数据分析实践】森林覆盖类型预测">【数据分析实践】森林覆盖类型预测</a><time datetime="2023-07-13T00:56:04.243Z" title="发表于 2023-07-13 08:56:04">2023-07-13</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('https://w.wallhaven.cc/full/x6/wallhaven-x6l7vv.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2023 By Kagura</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">All amazing things you see have been tempered by mediocrity</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script src="/js/search/local-search.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js"></script><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script><script>(() => {
  const $mermaidWrap = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaidWrap.length) {
    window.runMermaid = () => {
      window.loadMermaid = true
      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

      Array.from($mermaidWrap).forEach((item, index) => {
        const mermaidSrc = item.firstElementChild
        const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
        const mermaidID = 'mermaid-' + index
        const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent
        mermaid.mermaidAPI.render(mermaidID, mermaidDefinition, (svgCode) => {
          mermaidSrc.insertAdjacentHTML('afterend', svgCode)
        })
      })
    }

    const loadMermaid = () => {
      window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
    }

    window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
  }
})()</script><script>function loadValine () {
  function initValine () {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: '',
      appKey: '',
      avatar: 'monsterid',
      serverURLs: '',
      emojiMaps: "",
      path: window.location.pathname,
      visitor: false
    }, null))
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Valine' === 'Valine' || !true) {
  if (true) btf.loadComment(document.getElementById('vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script><script>function loadDisqus () {
  var disqus_config = function () {
    this.page.url = 'http://example.com/2023/07/13/%E3%80%90%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5%E3%80%91%E6%A3%AE%E6%9E%97%E8%A6%86%E7%9B%96%E7%B1%BB%E5%9E%8B%E9%A2%84%E6%B5%8B/'
    this.page.identifier = '/2023/07/13/%E3%80%90%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5%E3%80%91%E6%A3%AE%E6%9E%97%E8%A6%86%E7%9B%96%E7%B1%BB%E5%9E%8B%E9%A2%84%E6%B5%8B/'
    this.page.title = '【数据分析实践】森林覆盖类型预测'
  };

  window.disqusReset = () => {
    DISQUS.reset({
      reload: true,
      config: disqus_config
    })
  }

  if (window.DISQUS) disqusReset()
  else {
    (function() { 
      var d = document, s = d.createElement('script');
      s.src = 'https://.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  }

  document.getElementById('darkmode').addEventListener('click', () => {
    setTimeout(() => window.disqusReset(), 200)
  })
}

if ('Valine' === 'Disqus' || !true) {
  if (true) btf.loadComment(document.getElementById('disqus_thread'), loadDisqus)
  else loadDisqus()
} else {
  function loadOtherComment () {
    loadDisqus()
  }
}
</script></div><script defer src="https://npm.elemecdn.com/jquery@latest/dist/jquery.min.js"></script><script data-pjax defer src="https://npm.elemecdn.com/tzy-blog/lib/js/theme/chocolate.js"></script><script data-pjax defer src="/js/fish.js"></script><canvas id="universe"></canvas><script defer src="/js/universe.js"></script><script async src="/js/diytitle.js"></script><div class="aplayer no-destroy" data-id="7401064131" data-server="tencent" data-type="playlist" data-fixed="true" data-autoplay="false"> </div><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/fireworks.min.js"></script><script id="canvas_nest" defer="defer" color="255,255,255" opacity="0.8" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/metingjs/dist/Meting.min.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener scroll 
  window.tocScrollFn && window.removeEventListener('scroll', window.tocScrollFn)
  window.scrollCollect && window.removeEventListener('scroll', scrollCollect)

  typeof preloader === 'object' && preloader.initLoading()
  document.getElementById('rightside').style.cssText = "opacity: ''; transform: ''"
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

  typeof disqusjs === 'object' && disqusjs.destroy()
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()

  typeof preloader === 'object' && preloader.endLoading()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --><script data-pjax>function history_calendar_injector_config(){
                var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
                var item_html = '<div class="card-widget card-history"><div class="card-content"><div class="item-headline"><i class="fas fa-clock fa-spin"></i><span>那年今日</span></div><div id="history-baidu" style="height: 100px;overflow: hidden"><div class="history_swiper-container" id="history-container" style="width: 100%;height: 100%"><div class="swiper-wrapper" id="history_container_wrapper" style="height:20px"></div></div></div></div>';
                console.log('已挂载history_calendar')
                // parent_div_git.innerHTML=item_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",item_html) // 有报错，但不影响使用(支持pjax跳转)
            }if( document.getElementsByClassName('sticky_layout')[0] && (location.pathname ==='all'|| 'all' ==='all')){

            history_calendar_injector_config()
        } </script><script data-pjax  src="https://cdn.jsdelivr.net/npm/swiper/swiper-bundle.min.js"></script><script data-pjax src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-card-history/baiduhistory/js/main.js"></script><script data-pjax>
    function butterfly_categories_card_injector_config(){
      var parent_div_git = document.getElementById('recent-posts');
      var item_html = '<style>li.categoryBar-list-item{width:32.3%;}.categoryBar-list{max-height: 190px;overflow:auto;}.categoryBar-list::-webkit-scrollbar{width:0!important}@media screen and (max-width: 650px){.categoryBar-list{max-height: 160px;}}</style><div class="recent-post-item" style="height:auto;width:100%;padding:0px;"><div id="categoryBar"><ul class="categoryBar-list"><li class="categoryBar-list-item" style="background:url(https://npm.elemecdn.com/akilar-candyassets/image/cover1.webp);"> <a class="categoryBar-list-link" onclick="pjax.loadUrl(&quot;categories/琐碎日常/&quot;);" href="javascript:void(0);">琐碎日常</a><span class="categoryBar-list-count">4</span><span class="categoryBar-list-descr">摸鱼人的摸鱼日常</span></li><li class="categoryBar-list-item" style="background:url(https://npm.elemecdn.com/akilar-candyassets/image/cover2.webp);"> <a class="categoryBar-list-link" onclick="pjax.loadUrl(&quot;categories/梦时风月/&quot;);" href="javascript:void(0);">梦时风月</a><span class="categoryBar-list-count">5</span><span class="categoryBar-list-descr">生活虐我千百遍</span></li><li class="categoryBar-list-item" style="background:url(https://npm.elemecdn.com/akilar-candyassets/image/cover3.webp);"> <a class="categoryBar-list-link" onclick="pjax.loadUrl(&quot;categories/不想学辣/&quot;);" href="javascript:void(0);">不想学辣</a><span class="categoryBar-list-count">103</span><span class="categoryBar-list-descr">嘘，梦醒了可是要被吃掉的哦</span></li><li class="categoryBar-list-item" style="background:url(https://npm.elemecdn.com/akilar-candyassets/image/cover4.webp);"> <a class="categoryBar-list-link" onclick="pjax.loadUrl(&quot;categories/拾枝杂谈/&quot;);" href="javascript:void(0);">拾枝杂谈</a><span class="categoryBar-list-count">3</span><span class="categoryBar-list-descr">可能有用的小知识</span></li></ul></div></div>';
      console.log('已挂载butterfly_categories_card')
      parent_div_git.insertAdjacentHTML("afterbegin",item_html)
      }
    if( document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    butterfly_categories_card_injector_config()
    }
  </script><script data-pjax>
  function butterfly_clock_injector_config(){
    var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
    var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img class="entered loading" id="card-clock-loading" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://fastly.jsdelivr.net/gh/tzy13755126023/BLOG_SOURCE/theme_f/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading"/></div></div></div></div></div>';
    console.log('已挂载butterfly_clock')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'null'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_clock_injector_config();
  }
  else if (epage === cpage){
    butterfly_clock_injector_config();
  }
  </script><script src="https://pv.sohu.com/cityjson?ie=utf-8"></script><script data-pjax src="https://unpkg.zhimg.com/hexo-butterfly-clock/lib/clock.min.js"></script><!-- hexo injector body_end end --><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/tororo.model.json"},"display":{"position":"right","width":150,"height":300,"hOffset":20,"vOffset":-20},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/"});</script></body></html>