<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title><![CDATA[Python 奇怪的知识]]></title>
      <url>/2022/09/07/%E3%80%90Python%E3%80%91Python%E5%A5%87%E6%80%AA%E7%9A%84%E7%9F%A5%E8%AF%86/</url>
      <content type="html"><![CDATA[<h2 id="Python奇怪的知识">Python奇怪的知识</h2>
<h3 id="带余除法！"><strong>带余除法！</strong></h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">C,D=<span class="built_in">divmod</span>(A,B)</span><br><span class="line"></span><br><span class="line"><span class="comment"># eg.</span></span><br><span class="line"><span class="comment"># print(divmod(19,6))</span></span><br><span class="line"><span class="comment"># (3,1)</span></span><br></pre></td></tr></table></figure>
<h3 id="Join神器！">Join神器！</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">(<span class="string">&quot; &quot;</span>*A).join(B)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 注意啦！</span></span><br><span class="line"><span class="comment"># 以B[0]开头 B[n-1]结尾</span></span><br><span class="line"><span class="comment"># 中间穿插&quot; &quot;*A  </span></span><br></pre></td></tr></table></figure>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 不想学辣 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Python </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[【知乎转载】鼻炎成因及疗法]]></title>
      <url>/2022/09/07/%E3%80%90%E7%9F%A5%E4%B9%8E%E8%BD%AC%E8%BD%BD%E3%80%91%E9%BC%BB%E7%82%8E/</url>
      <content type="html"><![CDATA[<p>“通鼻喷剂”、“鼻甲切除术”的滥用，只追求迅速，不看长远。</p>
<p>通鼻喷剂，简直是鼻塞患者的“神药”一喷即灵，立竿见影的效果，殊不知这是在饮鸩止渴，一开始使用确实效果很好，但持续一段时间后，发现原来喷一下就通了，现在得喷两下、三下，并且药效越来越短，之前喷完两三个小时都不堵，现在不到半小时又堵了。于是剂量越用越大，使用次数越来越多，形成药物依赖。</p>
<p>我曾经有个鼻炎患者，买“通鼻喷剂”是以箱为单位，最后只要不用，鼻子就永远没畅通过。</p>
<p>这些“通鼻喷剂”从作用原理分类上属于减充血剂，也可以称为血管收缩剂。</p>
<p>药物性鼻炎就是长期过度使用这类药物而引发的。</p>
<p>鼻塞产生的原因是：血管通透性增加，使得大量血浆渗入黏膜组织，造成水肿堵塞了气道。</p>
<p>通过使用减充血剂，就像从源头上把供水的水管给关紧了，没有持续的体液供应，组织水肿就会消退，黏膜肿胀的问题缓解，气道重新恢复通畅。</p>
<p>但是，长期使用减充血剂后，血管的“阀门”会对药物变得越来越不敏感，更糟糕的是还会出现反跳性充血，因为经常使用减充血剂，血液流量减少了，不仅让黏膜组织得不到充足的营养供应，并且代谢的废物也会堆积在鼻腔，血管不得不代偿性扩张以平衡药物收缩血管的作用。</p>
<p>结果就是通鼻喷剂越用越多、效果越来越差、不用就不通，最后就成了“药物性鼻炎”</p>
<p>儿童用减充血剂的危害更大，因为儿童鼻黏膜娇嫩、血管丰富，药物吸收的更快，剂量更难以把控，效果和副作用更加明显，还有通过鼻咽后有被孩子吞食的风险，从胃部进入血液的药物会作用于全身，因此大部分减充血剂都禁止给儿童使用</p>
<p>除了通鼻喷剂，减充血剂还会藏在各种复方制剂中，最常见的是感冒药，在名称中带有“麻”字的感冒药通常含有减充血剂，所以需要家长们格外注意。</p>
<p>为了短暂的鼻子通畅，冒着承受严重副作用和药物依赖的风险，实在不值得。</p>
<p>空鼻综合征：每一次呼吸都是痛苦的折磨<br>
“一进入空调车，我每吸一口气，就感觉冷空气直接进入到我的肺里。”</p>
<p>“鼻子不痛，人难受、头疼、整晚睡不着觉…”</p>
<p>“晚上睡觉就像‘烙大饼’，左边鼻子堵了翻右边，右边又堵了再翻左边，经常堵醒或嗓子干，半夜起来喝水，一个晚上可以翻100次身。”</p>
<p>“睡不好、注意力不集中，像我这种原来学习能力很强的人，影响用脑感觉很痛苦，好多事都没精力做…”</p>
<p>这些人在描述自己的状况时，几乎都用了“生不如死”，每时每刻都要呼吸，而每一次呼吸都是痛苦的折磨。</p>
<p>都是因为手术切除部分鼻甲黏膜后，鼻黏膜对空气加温、加湿以及过滤的功能作用被破坏，吸入鼻腔的干冷空气直接进入气管肺部，还刺激着鼻腔分布的神经末梢，造成反射性头痛；这些直接吸进去的空气缺乏有效的清洁过滤，携带细菌进入还可能造成呼吸道感染。</p>
<p>切除肿胀的鼻黏膜后鼻腔本来是变宽大了，通气顺畅才对，为什么还会出现鼻塞？</p>
<p>是因为鼻黏膜上丰富的的末梢神经能感知气流，一旦被破坏就会感觉不到空气流动，产生鼻塞的感觉，还伴有头痛、嗅觉减退等症状。</p>
<p>除了鼻甲切除术，还有黏膜外黏膜消除术（如表面烧灼、激光治疗）</p>
<p>黏膜下消融术（如黏膜内烧灼、射频消融、激光治疗）等破坏黏膜的疗法都有造成空鼻综合征的风险。</p>
<p>上面所说的两种方法都是为了解决鼻塞的问题<br>
为什么会一直鼻塞，鼻塞的常见原因是什么？</p>
<p>1、过敏引起的鼻塞</p>
<p>吸入一些过敏原如花粉、尘螨、面粉等，引起过敏反应，鼻腔黏膜充血，影响空气吸入，造成鼻塞。这种需要查过敏原，从源头避免吸入过敏原。</p>
<p>2、慢性鼻炎</p>
<p>鼻腔纤毛摆动异常，无法运送垃圾出去，这些炎性物质不断堆积在鼻腔里，堆积的分泌物和炎性物质又不断刺激鼻黏膜，进一步加重纤毛摆动异常，如此形成恶性循环，鼻炎久而不愈。</p>
<p>这种慢性鼻炎需要抗炎排分泌物，从源头减少分泌物，然后修复鼻黏膜使纤毛恢复正常摆动，加快运送垃圾。</p>
<p>3、鼻中隔偏曲</p>
<p>大部分人的鼻中隔其实都会微微偏向鼻腔的某一侧，这并不会导致功能障碍，但如果鼻中隔“拗造型”太过放飞自我，扭成了“C”形或者“S”形时，问题就严重了，会造成经常流鼻血、鼻塞不通气等难受的病症。</p>
<p>4、外伤、发育不良</p>
<p>通鼻喷剂不是给孩子缓解鼻塞长期用的，手术切除鼻甲又会有“空鼻综合征”的风险，那么孩子鼻塞，家长该怎么办？试试这些方法<br>
鼻塞是症状，是因为鼻腔有炎症才会造成鼻塞，因此对付鼻塞的根本是消除炎症，降低血管通透性。缓解鼻塞的思路绝对不是收缩血管，相反，应该加快局部血液循环，带走潴留在组织中的液体，像大禹治水一样，堵不如疏。</p>
<p>1、按摩这些穴位</p>
<p>揉迎香穴、山根穴、风池穴、摩擦鼻梁</p>
<p>2、中药雾化&amp;水蒸汽</p>
<p>和之前咳嗽的蒸汽排痰法一样，用水蒸气熏蒸15~20分钟，注意温度距离，避免烫伤。</p>
<p>配合中药配方雾化，促进分泌物排出的同时修复黏膜、消除炎症。</p>
<p>3、半导体弱激光照射鼻黏膜</p>
<p>采用红光或红外光照射鼻腔黏膜，可以促进鼻黏膜局部血液循环，改善黏膜水肿缓解鼻塞。</p>
<p>这种激光照射知识一种缓解鼻塞症状的辅助治疗手段，和盐水洗鼻的作用类似，真正解决鼻塞，还是需要修鼻腔黏膜、消除炎症。</p>
<p>4、盐水洗鼻</p>
<p>盐水洗鼻是需要用药店的生理盐水，不是在家用食盐和水兑成生理盐水。并且盐水冲洗鼻腔需要一定水压和水量，要格外注意，因为有可能把炎性物质冲进更深地方，引发其他部位感染发炎。</p>
<p>人体有自己的黏液纤毛清除运动，所以要解决鼻塞，还是需要修复黏膜，让纤毛恢复正常摆动，加快运送垃圾，消除炎症刺激。</p>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 拾枝杂谈 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 知乎转载 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[【作品集】岁月拾珠]]></title>
      <url>/2022/09/07/%E3%80%90Artist%E3%80%91%E4%BD%9C%E5%93%81%E9%9B%86/</url>
      <content type="html"><![CDATA[<h1>岁染の设计集</h1>
<hr>
<p>随缘更新哦，主要是记录22年9月-25年6月的设计作品啦，看个乐呵吧！</p>
<hr>
<p><strong>Name</strong> 科普征文大赛海报</p>
<p><strong>Time</strong>  2022年9月1日</p>
<img src="/2022/09/07/%E3%80%90Artist%E3%80%91%E4%BD%9C%E5%93%81%E9%9B%86/image-20220908164603107.png" alt="image-20220908164603107" style="zoom:50%;">
<hr>
<p><strong>Name</strong> 新生杯篮球赛</p>
<p><strong>Time</strong>  2022年9月6日</p>
<img src="/2022/09/07/%E3%80%90Artist%E3%80%91%E4%BD%9C%E5%93%81%E9%9B%86/image-20220908164902050.png" alt="image-20220908164902050" style="zoom:50%;">
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 梦时风月 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 平面设计 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Numpy教程]]></title>
      <url>/2022/09/07/%E3%80%90%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E3%80%91Numpy%E5%85%A5%E9%97%A8/</url>
      <content type="html"><![CDATA[<h1>Numpy 教程</h1>
<p>什么是<code>Numpy</code>？Numpy(Numerical Python)是一个Python扩展库，支持大量的维度数组和矩阵运算，此外也针对数组运算提供大量的数学函数库。</p>
<p>其主要用于数组计算，特点包括：</p>
<ul>
<li>一个强大的N维数组对象ndarray</li>
<li>广播功能函数</li>
<li>整合C/C++/Fortran代码的工具</li>
<li>线性代数、傅里叶变换、随机数生成等功能</li>
</ul>
<hr>
<h2 id="一、Ndarray对象">一、Ndarray对象</h2>
<p>Ndarray(N-dimension array)是一个<code>N</code>维数组对象，他是一系列同类型数据的集合。</p>
<p>其内部构成为：</p>
<ul>
<li>一个指向数据的指针</li>
<li>数据类型<code>dtype</code>，描述在数组中的固定大小的格子</li>
<li>一个表示数组形状<code>shape</code>的元组</li>
<li>一个跨度元组<code>stride</code>,也就是我们索引切片的时候选择的跨度</li>
</ul>
<img src="/2022/09/07/%E3%80%90%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E3%80%91Numpy%E5%85%A5%E9%97%A8/image-20220907131758920.png" alt="image-20220907131758920" style="zoom:50%;">
<p>下面我们来看看具体的生成器：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">numpy.array(<span class="built_in">object</span>, dtype = <span class="literal">None</span>, copy = <span class="literal">True</span>, order = <span class="literal">None</span>, subok = <span class="literal">False</span>, ndmin = <span class="number">0</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">	object: 数组或嵌套的数列</span></span><br><span class="line"><span class="string">	dtype: 数据类型</span></span><br><span class="line"><span class="string">	copy: 对象是否需要复制(new的内存空间)</span></span><br><span class="line"><span class="string">	order: 创建数组的样式，A为任意方向，C为行方向，F为列方向</span></span><br><span class="line"><span class="string">	subok: 返回一个与基类型一致的数组</span></span><br><span class="line"><span class="string">	ndmin: 指定生成数组的最小维度</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p><strong>生成最小维度</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 最小维度  </span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line">a = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], ndmin =  <span class="number">2</span>)  </span><br><span class="line"><span class="built_in">print</span> (a)</span><br><span class="line"></span><br><span class="line"><span class="comment"># [[1 2 3 4 5]]</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>ndarray 对象由计算机内存的连续一维部分组成，并结合索引模式，将每个元素映射到内存块的一个位置。</p>
</blockquote>
<hr>
<h2 id="二、数据类型">二、数据类型</h2>
<table>
<thead>
<tr>
<th style="text-align:center">名称</th>
<th style="text-align:center">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">bool_</td>
<td style="text-align:center">布尔型数据类型（True 或者 False）</td>
</tr>
<tr>
<td style="text-align:center">int_</td>
<td style="text-align:center">默认的整数类型（类似于 C 语言中的 long，int32 或 int64）</td>
</tr>
<tr>
<td style="text-align:center">intc</td>
<td style="text-align:center">与 C 的 int 类型一样，一般是 int32 或 int 64</td>
</tr>
<tr>
<td style="text-align:center">intp</td>
<td style="text-align:center">用于索引的整数类型（类似于 C 的 ssize_t，一般情况下仍然是 int32 或 int64）</td>
</tr>
<tr>
<td style="text-align:center">int8</td>
<td style="text-align:center">字节（-128 to 127）</td>
</tr>
<tr>
<td style="text-align:center">int16</td>
<td style="text-align:center">整数（-32768 to 32767）</td>
</tr>
<tr>
<td style="text-align:center">int32</td>
<td style="text-align:center">整数（-2147483648 to 2147483647）</td>
</tr>
<tr>
<td style="text-align:center">int64</td>
<td style="text-align:center">整数（-9223372036854775808 to 9223372036854775807）</td>
</tr>
<tr>
<td style="text-align:center">uint8</td>
<td style="text-align:center">无符号整数（0 to 255）</td>
</tr>
<tr>
<td style="text-align:center">uint16</td>
<td style="text-align:center">无符号整数（0 to 65535）</td>
</tr>
<tr>
<td style="text-align:center">uint32</td>
<td style="text-align:center">无符号整数（0 to 4294967295）</td>
</tr>
<tr>
<td style="text-align:center">uint64</td>
<td style="text-align:center">无符号整数（0 to 18446744073709551615）</td>
</tr>
<tr>
<td style="text-align:center">float_</td>
<td style="text-align:center">float64 类型的简写</td>
</tr>
<tr>
<td style="text-align:center">float16</td>
<td style="text-align:center">半精度浮点数，包括：1 个符号位，5 个指数位，10 个尾数位</td>
</tr>
<tr>
<td style="text-align:center">float32</td>
<td style="text-align:center">单精度浮点数，包括：1 个符号位，8 个指数位，23 个尾数位</td>
</tr>
<tr>
<td style="text-align:center">float64</td>
<td style="text-align:center">双精度浮点数，包括：1 个符号位，11 个指数位，52 个尾数位</td>
</tr>
<tr>
<td style="text-align:center">complex_</td>
<td style="text-align:center">complex128 类型的简写，即 128 位复数</td>
</tr>
<tr>
<td style="text-align:center">complex64</td>
<td style="text-align:center">复数，表示双 32 位浮点数（实数部分和虚数部分）</td>
</tr>
<tr>
<td style="text-align:center">complex128</td>
<td style="text-align:center">复数，表示双 64 位浮点数（实数部分和虚数部分）</td>
</tr>
</tbody>
</table>
<hr>
<h2 id="三、数组属性">三、数组属性</h2>
<p>Numpy的数组维度数量称为秩(rank)，每一个线性的数组是一个轴(axis)，也就是维度。</p>
<p>例如：二维数组由两个一维数组构成：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>],[<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>]]</span><br><span class="line"></span><br><span class="line"><span class="comment"># [A,B,C]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 或者是：</span></span><br><span class="line"><span class="comment"># [ A,</span></span><br><span class="line"><span class="comment">#	B,</span></span><br><span class="line"><span class="comment">#   C ]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># A=[1,2,3]</span></span><br></pre></td></tr></table></figure>
<p>第一个一维数组中的每个元素又是一个一维数组。第一个轴也成为了底层数组，第二个则是底层数组中的数组，以此类推。</p>
<p>简单说一下，<code>axis=0</code>的情况表示沿着第0轴进行操作，也就是列，<code>axis=1</code>则是沿着第1轴进行操作，也就是行。</p>
<p><strong>常用属性</strong></p>
<table>
<thead>
<tr>
<th style="text-align:center">属性</th>
<th style="text-align:center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">ndarray.ndim</td>
<td style="text-align:center">秩，即轴的数量或维度的数量</td>
</tr>
<tr>
<td style="text-align:center">ndarray.shape</td>
<td style="text-align:center">数组的维度，对于矩阵，n 行 m 列</td>
</tr>
<tr>
<td style="text-align:center">ndarray.size</td>
<td style="text-align:center">数组元素的总个数，相当于 .shape 中 n*m 的值</td>
</tr>
<tr>
<td style="text-align:center">ndarray.dtype</td>
<td style="text-align:center">ndarray 对象的元素类型</td>
</tr>
<tr>
<td style="text-align:center">ndarray.itemsize</td>
<td style="text-align:center">ndarray 对象中每个元素的大小，以字节为单位</td>
</tr>
<tr>
<td style="text-align:center">ndarray.flags</td>
<td style="text-align:center">ndarray 对象的内存信息</td>
</tr>
<tr>
<td style="text-align:center">ndarray.real</td>
<td style="text-align:center">ndarray元素的实部</td>
</tr>
<tr>
<td style="text-align:center">ndarray.imag</td>
<td style="text-align:center">ndarray 元素的虚部</td>
</tr>
<tr>
<td style="text-align:center">ndarray.data</td>
<td style="text-align:center">包含实际数组元素的缓冲区，由于一般通过数组的索引获取元素，所以通常不需要使用这个属性。</td>
</tr>
</tbody>
</table>
<p><strong>示例</strong></p>
<p>1️⃣ <strong>ndim</strong></p>
<img src="/2022/09/07/%E3%80%90%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E3%80%91Numpy%E5%85%A5%E9%97%A8/image-20220907133648496.png" alt="image-20220907133648496" style="zoom:50%;">
<p>2️⃣ <strong>shape</strong></p>
<img src="/2022/09/07/%E3%80%90%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E3%80%91Numpy%E5%85%A5%E9%97%A8/image-20220907133713115.png" alt="image-20220907133713115" style="zoom:50%;">
<p>3️⃣ <strong>size</strong></p>
<img src="/2022/09/07/%E3%80%90%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E3%80%91Numpy%E5%85%A5%E9%97%A8/image-20220907133735406.png" alt="image-20220907133735406" style="zoom:50%;">
<p>4️⃣ <strong>dtype</strong></p>
<img src="/2022/09/07/%E3%80%90%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E3%80%91Numpy%E5%85%A5%E9%97%A8/image-20220907133818185.png" alt="image-20220907133818185" style="zoom:50%;">
<hr>
<h2 id="四、Numpy-创建数组">四、Numpy 创建数组</h2>
<p>除却使用<code>ndarray</code>底层构造器外，我们还可以采用以下的方式来创建数组哦。</p>
<p><strong>1️⃣ numpy.empty</strong></p>
<p>参数说明</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">numpy.empty(shape, dtype = <span class="built_in">float</span>, order = <span class="string">&#x27;C&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">	shape: 数组形状</span></span><br><span class="line"><span class="string">	dtype: 数据类型</span></span><br><span class="line"><span class="string">	order: 行优先还是列优先，表示在计算机内中存储元素的顺序</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p><strong>创建一个空数组</strong></p>
<img src="/2022/09/07/%E3%80%90%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E3%80%91Numpy%E5%85%A5%E9%97%A8/image-20220907134640835.png" alt="image-20220907134640835" style="zoom:50%;">
<p>数组的元素为随机数，因为并未进行初始化。</p>
<p><strong>2️⃣ numpy.zeros</strong></p>
<p>参数说明</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">numpy.zeros(shape, dtype = <span class="built_in">float</span>, order = <span class="string">&#x27;C&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><strong>创建一个零数组</strong></p>
<img src="/2022/09/07/%E3%80%90%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E3%80%91Numpy%E5%85%A5%E9%97%A8/image-20220907134826672.png" alt="image-20220907134826672" style="zoom:50%;">
<p><strong>3️⃣ numpy.ones(shape,dtype,order)</strong></p>
<p>使用方式一样哦，创建全1数组</p>
<p><strong>4️⃣ numpy.arange(start=0,stop,step,dtype)</strong></p>
<p>返回一个<code>0~n-1</code>的<code>ndarray</code>数组~</p>
<p><strong>5️⃣ numpy.full(shape,val)</strong></p>
<p>生成一个值全为<code>val</code>的数组~</p>
<p><strong>6️⃣ numpy.eye(n)</strong></p>
<p>生成单位矩阵~</p>
<p><strong>7️⃣ numpy.diag(list)</strong></p>
<p>生成对角线矩阵！</p>
<hr>
<p><strong>8️⃣ numpy.asarray(a,dtype,order)</strong></p>
<p>从给定的参数中生成<code>ndarray</code></p>
<p><strong>9️⃣ numpy.fromiter(iterable,dtype,count=-1)</strong></p>
<p>从可迭代对象中创建<code>ndarray</code>对象，返回一维数组，<code>count</code>表示读取的数据量，默认是读取所有数据</p>
<img src="/2022/09/07/%E3%80%90%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E3%80%91Numpy%E5%85%A5%E9%97%A8/image-20220907135445064.png" alt="image-20220907135445064" style="zoom:50%;">
<p><strong>☀️ numpy.linspace</strong></p>
<p>用于创建一个等差数列的<strong>一维数组</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">np.linspace(start, stop, num=<span class="number">50</span>, endpoint=<span class="literal">True</span>, retstep=<span class="literal">False</span>, dtype=<span class="literal">None</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">	endpoint: 是否包含终止点</span></span><br><span class="line"><span class="string">	retstep: 是否输出间距</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<img src="/2022/09/07/%E3%80%90%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E3%80%91Numpy%E5%85%A5%E9%97%A8/image-20220907135746065.png" alt="image-20220907135746065" style="zoom:50%;">
<img src="/2022/09/07/%E3%80%90%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E3%80%91Numpy%E5%85%A5%E9%97%A8/image-20220907135755667.png" alt="image-20220907135755667" style="zoom:50%;">
<p><strong>🌙 numpy.logspace</strong></p>
<p>用于创建一个等比数列</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">np.logspace(start, stop, num=<span class="number">50</span>, endpoint=<span class="literal">True</span>, base=<span class="number">10.0</span>, dtype=<span class="literal">None</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">	base: 默认底数</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<img src="/2022/09/07/%E3%80%90%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E3%80%91Numpy%E5%85%A5%E9%97%A8/image-20220907135938777.png" alt="image-20220907135938777" style="zoom:50%;">
<img src="/2022/09/07/%E3%80%90%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E3%80%91Numpy%E5%85%A5%E9%97%A8/image-20220907135953686.png" alt="image-20220907135953686" style="zoom:50%;">
<hr>
<h2 id="五、Numpy的切片和索引">五、Numpy的切片和索引</h2>
<p><code>ndarray</code>中的对象内容可以通过索引或切片来访问和修改。</p>
<p>有两种比较主流的索引方式：</p>
<ul>
<li>内置<code>slice</code>函数</li>
<li>冒号分隔符</li>
</ul>
<p>我们重点说<code>冒号分隔符</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A[star:step:end]</span><br></pre></td></tr></table></figure>
<p>注意<strong>左闭右开</strong>。</p>
<p>除却本身<code>list</code>的机制外，我们还可以采用省略号。</p>
<p>表示取到某一维度上的所有数据，譬如：</p>
<img src="/2022/09/07/%E3%80%90%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E3%80%91Numpy%E5%85%A5%E9%97%A8/image-20220907161127678.png" alt="image-20220907161127678" style="zoom:50%;">
<p>除此之外，<code>Numpy</code>有一些更高级的索引方式。</p>
<p><strong>1️⃣整数数组索引</strong></p>
<img src="/2022/09/07/%E3%80%90%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E3%80%91Numpy%E5%85%A5%E9%97%A8/image-20220907161408916.png" alt="image-20220907161408916" style="zoom:50%;">
<p>根据数组维度，第一个索引数组表示<code>axis=0</code>，第二个索引数组表示<code>axis=1</code>，他们之间的<code>一一映射</code>确保了行列之间的取值。</p>
<p><strong>维度不对会报错</strong></p>
<p>当然，当第一个数组或者第二个数组维度为<code>1</code>时，不会报错，表示就要这一个位置。</p>
<img src="/2022/09/07/%E3%80%90%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E3%80%91Numpy%E5%85%A5%E9%97%A8/image-20220907161526604.png" alt="image-20220907161526604" style="zoom:50%;">
<img src="/2022/09/07/%E3%80%90%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E3%80%91Numpy%E5%85%A5%E9%97%A8/image-20220907161653950.png" alt="image-20220907161653950" style="zoom:50%;">
<p>我们的索引可以与切片<code>:</code>或<code>...</code>进行组合：</p>
<img src="/2022/09/07/%E3%80%90%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E3%80%91Numpy%E5%85%A5%E9%97%A8/image-20220907162130989.png" alt="image-20220907162130989" style="zoom:50%;">
<p>基本上能满足项目需要的索引组合了。</p>
<p><strong>2️⃣ 布尔索引</strong></p>
<p>可以通过布尔运算来过滤指定条件之外的元素！</p>
<p>下面看个栗子：<br>
<img src="/2022/09/07/%E3%80%90%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E3%80%91Numpy%E5%85%A5%E9%97%A8/image-20220907162344660.png" alt="image-20220907162344660" style="zoom:50%;"></p>
<p>下面的实例采用了逻辑非<code>~</code>对<code>NaN</code>数据进行过滤</p>
<img src="/2022/09/07/%E3%80%90%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E3%80%91Numpy%E5%85%A5%E9%97%A8/image-20220907162441545.png" alt="image-20220907162441545" style="zoom:50%;">
<p>过滤非复数元素</p>
<img src="/2022/09/07/%E3%80%90%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E3%80%91Numpy%E5%85%A5%E9%97%A8/image-20220907162515978.png" alt="image-20220907162515978" style="zoom:50%;">
<p>3️⃣ <strong>花式索引</strong></p>
<p>利用整数数组进行索引。</p>
<p>花式索引总是将数据复制到新数组中。</p>
<img src="/2022/09/07/%E3%80%90%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E3%80%91Numpy%E5%85%A5%E9%97%A8/image-20220907163812907.png" alt="image-20220907163812907" style="zoom:50%;">
<hr>
<h2 id="六、Numpy的广播机制">六、Numpy的广播机制</h2>
<p>广播(Broadcast)是<code>numpy</code>对不同形状的数组进行数值计算的方式。</p>
<p>☀️</p>
<p>若两个数组<code>a</code>和<code>b</code>形状相同，对应的操作应当是每个元素之间的操作。</p>
<p>这要求维数相同，且各维度的长度相同。</p>
<img src="/2022/09/07/%E3%80%90%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E3%80%91Numpy%E5%85%A5%E9%97%A8/image-20220907164450631.png" alt="image-20220907164450631" style="zoom:50%;">
<p>🌙</p>
<p>在两个数组形状不同时，<code>numpy</code>将自动触发广播机制。</p>
<img src="/2022/09/07/%E3%80%90%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E3%80%91Numpy%E5%85%A5%E9%97%A8/image-20220907164553770.png" alt="image-20220907164553770" style="zoom:50%;">
<p>其内部运算逻辑如下图：</p>
<img src="/2022/09/07/%E3%80%90%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E3%80%91Numpy%E5%85%A5%E9%97%A8/image-20220907164617941.png" alt="image-20220907164617941" style="zoom:50%;">
<p>这种广播要求的是一定有一个维度长度是匹配的，将较小的数组通过重复扩张到大的维度，以匹配维度为核心进行运算。</p>
<p><strong>规则</strong></p>
<ul>
<li>让所有输入数组都向其中形状最长的数组看齐，形状中不足的部分都通过在前面加 1 补齐。
<ul>
<li>例如：a(2,3) b(3)—&gt;b(1,3)</li>
</ul>
</li>
<li>输出数组的形状是输入数组形状的各个维度上的最大值。</li>
<li>如果输入数组的某个维度和输出数组的对应维度的长度相同或者其长度为 1 时，这个数组能够用来计算，否则出错。</li>
<li>当输入数组的某个维度的长度为 1 时，沿着此维度运算时都用此维度上的第一组值。</li>
</ul>
<p><strong>简单理解</strong></p>
<p>对两个数组，分别比较他们的每一个维度（若其中一个数组没有当前维度则忽略），满足：</p>
<ul>
<li>数组拥有相同形状✅</li>
<li>当前维度的值相等✅</li>
<li>当前维度的值有一个是 1✅</li>
</ul>
<p>1️⃣ 同shape</p>
<img src="/2022/09/07/%E3%80%90%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E3%80%91Numpy%E5%85%A5%E9%97%A8/image-20220907165638282.png" alt="image-20220907165638282" style="zoom:50%;">
<p>2️⃣ 某个维度相等</p>
<img src="/2022/09/07/%E3%80%90%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E3%80%91Numpy%E5%85%A5%E9%97%A8/image-20220907165711782.png" alt="image-20220907165711782" style="zoom:50%;">
<img src="/2022/09/07/%E3%80%90%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E3%80%91Numpy%E5%85%A5%E9%97%A8/image-20220907165725149.png" alt="image-20220907165725149" style="zoom:50%;">
<p>3️⃣ 某个维度为1</p>
<img src="/2022/09/07/%E3%80%90%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E3%80%91Numpy%E5%85%A5%E9%97%A8/image-20220907165745186.png" alt="image-20220907165745186" style="zoom:50%;">
<p>4️⃣ 不满足上述条件</p>
<img src="/2022/09/07/%E3%80%90%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E3%80%91Numpy%E5%85%A5%E9%97%A8/image-20220907165815935.png" alt="image-20220907165815935" style="zoom:50%;">
<p>弹出ValueError错误</p>
<hr>
<h2 id="七、Numpy-数组操作与逻辑运算">七、Numpy 数组操作与逻辑运算</h2>
<p><strong>1️⃣ 逻辑运算</strong></p>
<img src="/2022/09/07/%E3%80%90%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E3%80%91Numpy%E5%85%A5%E9%97%A8/image-20220907170115856.png" alt="image-20220907170115856" style="zoom:50%;">
<img src="/2022/09/07/%E3%80%90%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E3%80%91Numpy%E5%85%A5%E9%97%A8/image-20220907170201190.png" alt="image-20220907170201190" style="zoom:50%;">
<img src="/2022/09/07/%E3%80%90%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E3%80%91Numpy%E5%85%A5%E9%97%A8/image-20220907170312288.png" alt="image-20220907170312288" style="zoom:50%;">
<p>2️⃣ <strong>通用判断函数</strong></p>
<ul>
<li>
<p><strong>np.all()</strong></p>
<ul>
<li>
<p>返回某个表达式中的元素是否全是满足条件</p>
</li>
<li>
<pre><code class="language-python">np.all(stock_day_rise[0:2,0:5] &gt; 0)
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+ **np.unique()**</span><br><span class="line"></span><br><span class="line">  + 返回唯一值</span><br><span class="line"></span><br><span class="line">  + ```python</span><br><span class="line">    np.unique(stock_day_rise[0:2,0:5].astype(int))</span><br></pre></td></tr></table></figure>

</code></pre>
</li>
</ul>
</li>
<li>
<p><strong>np.any()</strong></p>
<ul>
<li>
<p>只要有一个元素满足条件就返回<code>True</code></p>
</li>
<li>
<pre><code class="language-python">np.any(stock_day_rise[0:2,0:5] &gt; 0)
</code></pre>
</li>
</ul>
</li>
</ul>
<p>3️⃣ <strong>三元运算符</strong></p>
<ul>
<li>
<p><strong>np.where(ndarray , A , B)</strong></p>
<ul>
<li>
<p>如果满足条件，将元素替换为A，否则替换为B</p>
</li>
<li>
<pre><code class="language-python">np.where(temp &gt; 0, 1, 0)
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+ 常常结合`np.logical_and`和`np.logical_or`使用</span><br><span class="line"></span><br><span class="line">+ ```python</span><br><span class="line">  np.where(np.logical_and(temp &gt; 0.5, temp &lt; 1), 1, 0)</span><br><span class="line">  np.where(np.logical_or(temp &gt; 0.5, temp &lt; -0.5), 1, 0)</span><br></pre></td></tr></table></figure>
</code></pre>
</li>
</ul>
</li>
</ul>
<blockquote>
<p>数组操作<br>
Numpy包含了一些函数用于处理数组，大致可分为以下几类：</p>
</blockquote>
<ul>
<li>修改数组形状</li>
<li>翻转数组</li>
<li>修改数组维度</li>
<li>连接数组</li>
<li>分割数组</li>
<li>数组元素的添加与删除</li>
</ul>
<p><strong>1️⃣ 修改数组形状</strong></p>
<table>
<thead>
<tr>
<th style="text-align:center">函数</th>
<th style="text-align:center">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><code>reshape</code></td>
<td style="text-align:center">不改变数据的条件下修改形状</td>
</tr>
<tr>
<td style="text-align:center"><code>flat</code></td>
<td style="text-align:center">数组元素迭代器</td>
</tr>
<tr>
<td style="text-align:center"><code>flatten</code></td>
<td style="text-align:center">返回一份数组拷贝，对拷贝所做的修改不会影响原始数组</td>
</tr>
<tr>
<td style="text-align:center"><code>ravel</code></td>
<td style="text-align:center">返回展开数组</td>
</tr>
</tbody>
</table>
<hr>
<h2 id="八、位运算与字符串函数">八、位运算与字符串函数</h2>
<hr>
<h2 id="九、数学与统计函数">九、数学与统计函数</h2>
<hr>
<h2 id="十、矩阵与线性代数">十、矩阵与线性代数</h2>
<hr>
<h2 id="十一、排序、条件与选择">十一、排序、条件与选择</h2>
<hr>
<h2 id="十二、字节交换、副本与试图">十二、字节交换、副本与试图</h2>
<hr>
<h2 id="十三、IO">十三、IO</h2>
<hr>
<h2 id="十四、Matplotlib绘图">十四、Matplotlib绘图</h2>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 不想学辣 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 数据分析 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[英语口语常用表述]]></title>
      <url>/2022/09/06/%E3%80%90%E8%8B%B1%E8%AF%AD%E3%80%91%E8%8B%B1%E8%AF%AD%E5%8F%A3%E8%AF%AD%E5%B8%B8%E7%94%A8%E8%A1%A8%E8%BF%B0/</url>
      <content type="html"><![CDATA[<h2 id="英语口语常用表述">英语口语常用表述</h2>
<hr>
<h3 id="cut-it-out">cut it out</h3>
<ul>
<li>闭嘴！省省吧！</li>
</ul>
<h3 id="easy-peasy">easy-peasy</h3>
<ul>
<li>小菜一碟！</li>
<li>这个peasy是为了押韵将peace将成了peasy</li>
</ul>
<h3 id="stay-strong">stay strong</h3>
<ul>
<li>坚强起来</li>
</ul>
<h3 id="fat-chance">fat chance</h3>
<ul>
<li>没戏~</li>
<li>不可能！希望渺茫~</li>
</ul>
<h3 id="you-known-nothing">you known nothing</h3>
<ul>
<li>你啥都不知道！</li>
<li>你懂个锤子</li>
</ul>
<hr>
<h3 id="you-look-stunning">you look stunning</h3>
<ul>
<li>你看起来美爆了！</li>
</ul>
<h3 id="fancy-meeting-you-here">fancy meeting you here</h3>
<ul>
<li>真他娘的意外！这里也能见到你啊？</li>
</ul>
<h3 id="every-dog-has-its-day">every dog has its day</h3>
<ul>
<li>人人皆有出头日</li>
</ul>
<h3 id="No-matter-how-bad-your-current-situation-is">No matter how bad your current situation is</h3>
<ul>
<li>无论你的处境多糟</li>
</ul>
<h3 id="enjoy-your-stay">enjoy your stay</h3>
<ul>
<li>希望你开心咯~</li>
</ul>
<hr>
<blockquote>
<p><strong>In summary</strong></p>
</blockquote>
<p>Juddy: Hey Petter! <strong>Fancy meeting you here</strong>! <strong>You look stunning</strong>!</p>
<p>Petter: <strong>Cut it out</strong>! <strong>You know nothing</strong>! I am about to lose my job!</p>
<p>Juddy: <strong>Stay strong</strong>! Just <strong>easy-peasy</strong>！I hope you could get out of this trouble.</p>
<p>Petter: I hope so. But actually, <strong>fat chance</strong>.</p>
<p>Juddy: <strong>No matter how bad your current situations is</strong>, <strong>every dog has its day</strong>. <strong>Enjoy your stay</strong>.</p>
<hr>
<h3 id="don’t-tell-me-what-to-do">don’t tell me what to do</h3>
<ul>
<li>你在教我做事？</li>
</ul>
<h3 id="don’t-take-it-out-on-me">don’t take it out on me</h3>
<ul>
<li>老子不背锅！</li>
<li>别烦我</li>
</ul>
<h3 id="don’t-tush-me">don’t tush me</h3>
<ul>
<li>别催啦！</li>
<li>tush: 屁股，獠牙</li>
<li>bush: 灌木</li>
</ul>
<h3 id="a-promise-is-a-promise">a promise is a promise</h3>
<ul>
<li>君子一言，驷马难追</li>
</ul>
<h3 id="are-you-smoking">are you smoking?</h3>
<ul>
<li>你是不是傻</li>
</ul>
<hr>
<h3 id="be-a-man">be a man</h3>
<ul>
<li>像个男人一样</li>
<li>成熟点</li>
</ul>
<h3 id="boys-will-be-boys">boys will be boys</h3>
<ul>
<li>本性难移</li>
<li>狗改不了吃屎</li>
</ul>
<h3 id="don’t-freak-out">don’t freak out</h3>
<ul>
<li>淡定点</li>
<li>freak这个词本事表示怪人，怪异的，不正常的，作动词还能表示震惊，畏惧。</li>
</ul>
<h3 id="don’t-have-a-cow">don’t have a cow</h3>
<ul>
<li>别大惊小怪</li>
</ul>
<h3 id="don’t-give-me-that-look">don’t give me that look</h3>
<ul>
<li>别用那种眼神看我</li>
</ul>
<hr>
<blockquote>
<p><strong>In summary</strong></p>
</blockquote>
<p>A: Aha, I will never go to school! <strong>A primise is a primse</strong>!</p>
<p>B: <strong>Are you smoking</strong>? <strong>Be a man</strong> plz.</p>
<p>A: <strong>Don’t freak out</strong> and <strong>don’t give me that look</strong>! You know, <strong>boys will be boys</strong>, it’s rule!</p>
<p>B: <strong>Are you telling me what to do</strong>?c</p>
<p>A: <strong>Don’t take it out on me</strong>! <strong>Don’t have a cow</strong> and <strong>Don’t tush me</strong>! It’s none of your bissness.</p>
<hr>
<h3 id="can-I-ask-you-a-favor">can I ask you a favor?</h3>
<ul>
<li>能帮我忙吗~</li>
</ul>
<h3 id="I-don’t-follow">I don’t follow</h3>
<ul>
<li>我没跟上</li>
<li>我没听懂</li>
</ul>
<h3 id="hear-me-out">hear me out</h3>
<ul>
<li>让我听完</li>
</ul>
<h3 id="How-is-that-possible">How is that possible?</h3>
<ul>
<li>怎么可能</li>
</ul>
<h3 id="how-dare-you">how dare you</h3>
<ul>
<li>你好大的胆子！</li>
</ul>
<hr>
<h3 id="how-have-you-been">how have you been</h3>
<ul>
<li>最近过得怎么样</li>
</ul>
<h3 id="I-give-up">I give up</h3>
<ul>
<li>我放弃了</li>
</ul>
<h3 id="I-kid-you-not">I kid you not</h3>
<ul>
<li>我没跟你开玩笑</li>
</ul>
<h3 id="I-never-want-to-see-you-again">I never want to see you again</h3>
<ul>
<li>我再也不想见到你</li>
</ul>
<h3 id="I-take-full-responsibility">I take full responsibility</h3>
<ul>
<li>我负全责</li>
</ul>
<hr>
<blockquote>
<p><strong>In summary</strong></p>
</blockquote>
<p>A: Fancy meeting you here! <strong>How have youo been</strong>?</p>
<p>B: Fine! and … <strong>Could you do me a favor</strong>?</p>
<p>A: …Ok, so what should I do?</p>
<p>B: Help me Kill that guys!</p>
<p>A: …Ha? Sorry <strong>I don’t follow</strong>, could you repeat?</p>
<p>B: <strong>Hear me out,</strong> you need just to do is stab him!</p>
<p>A: <strong>How dare you</strong>! I give up!</p>
<p>B: Hey Hey Hey, <strong>I kid you not</strong> ! I mean, this knife is only a prop!</p>
<p>A: Oh… You just freak me out!</p>
<p>A few minutes passed…</p>
<p>A: What? Holy the shit!!! Why did he die! <strong>How that is possible</strong>!</p>
<p>B: Surprise! I lied to you~</p>
<p>A: <strong>I never want to see you again!</strong> Get out from my range!</p>
<p>B: Take it easy~ <strong>I will take full responsibility</strong>~</p>
<hr>
<h3 id="It’s-been-a-long-day">It’s been a long day</h3>
<ul>
<li>真是好累的一天~</li>
</ul>
<h3 id="I’m-speechless">I’m speechless</h3>
<ul>
<li>我服了你</li>
<li>speechless: 说不出话</li>
<li>Laura was speechless with rage.</li>
<li>一整个无语住了</li>
</ul>
<h3 id="I-don’t-know-what-to-say">I don’t know what to say</h3>
<ul>
<li>我不知道该怎么说才好</li>
</ul>
<h3 id="Try-harder">Try harder</h3>
<ul>
<li>再努力一点</li>
</ul>
<h3 id="What-happened-to-you">What happened to you</h3>
<ul>
<li>你怎么了</li>
</ul>
<hr>
<h3 id="You-are-nothing">You are nothing</h3>
<ul>
<li>你是个锤子</li>
</ul>
<h3 id="I’ve-heard-so-much-about-you">I’ve heard so much about you</h3>
<ul>
<li>久仰大名！</li>
</ul>
<h3 id="Cet-out-of-my-face">Cet out of my face</h3>
<ul>
<li>从我的眼前消失！</li>
</ul>
<h3 id="knock-it-off">knock it off</h3>
<ul>
<li>住手吧！</li>
</ul>
<h3 id="keep-a-low-profile">keep a low profile</h3>
<ul>
<li>保持低调</li>
<li>profile : 形象，轮廓，概述</li>
<li>profit: 利润</li>
</ul>
<hr>
<blockquote>
<p><strong>In summary</strong></p>
</blockquote>
<p>Boss: <strong>Try harder</strong>! How can you sleep at your age!</p>
<p>Ally: OK…</p>
<p>A few hours pass…</p>
<p>Ally: <strong>It’s been a long day!</strong> Finally, I can have a rest~</p>
<p>Boss: Ah, Stay and work overtime!</p>
<p>Ally: oh… <strong>I’m speechless</strong>…</p>
<p>Ally’s bestie: Ally ! Why do you look bad?</p>
<p>Ally: <strong>I don’t know what to say</strong>… My boss is a vampire!</p>
<p>Boss: Oh Ally! How fancy I meet you here !</p>
<p>Ally: plz <strong>get out of my face</strong> !!!</p>
<p>Boss: <strong>Knock it off</strong> ! And… you are Ally’s bestie, Mrs. Lily?</p>
<p>Lily: Yes, <strong>I’ve heard so much about you</strong> from Alliy.</p>
<p>Boss: Wooow, <strong>keep a low profile</strong>, I know I’m a great Boss~</p>
<p>Ally &amp; Lily: <strong>You Are Nothing</strong>!</p>
<hr>
<h3 id="keep-your-voice-down">keep your voice down</h3>
<ul>
<li>小点声</li>
</ul>
<h3 id="just-browsing">just browsing</h3>
<ul>
<li>随便看看</li>
</ul>
<h3 id="lay-low">lay low</h3>
<ul>
<li>低调点</li>
</ul>
<h3 id="I-don’t-give-a-shit">I don’t give a shit</h3>
<ul>
<li>老子不在乎</li>
</ul>
<h3 id="what’s-done-is-done">what’s done is done</h3>
<ul>
<li>覆水难收</li>
</ul>
<hr>
<h3 id="talk-is-cheap">talk is cheap</h3>
<ul>
<li>说着容易做着难</li>
</ul>
<h3 id="take-days">take days</h3>
<ul>
<li>需要几天的时间</li>
</ul>
<h3 id="talk-to-the-hand">talk to the hand</h3>
<ul>
<li>懒得理你</li>
</ul>
<h3 id="take-care">take care</h3>
<ul>
<li>保重</li>
</ul>
<h3 id="why-the-long-face">why the long face</h3>
<ul>
<li>为什么不高兴</li>
</ul>
<hr>
<blockquote>
<p><strong>In summary</strong></p>
</blockquote>
<p>A: Hello, what do you need?</p>
<p>B: <strong>I just browsing</strong>.</p>
<p>A: OKey Sir… Oh, you are Ms. Ye? The most famous star in the earth!</p>
<p>B: <strong>Lay low</strong> and keep your voice down. I  don’t want too many people to know I’m here.</p>
<p>A: Yes Sir! (with loudly voice)</p>
<p>B: … <strong>Talk to the hand</strong>. I need a gun with a Hello Kitty profile.</p>
<p>A: I’m sorry for that, this commodity is sold out. If you want , <strong>take days</strong> plz.</p>
<p>B: <strong>I don’t give a shit.</strong> I want to see it right away.</p>
<p>A: <strong>Talk is cheap</strong> sir! <strong>What’s done is done!</strong> <strong>Why the long face</strong> in you?</p>
<p>B: …<strong>Take care</strong> and say hello to the god.</p>
<hr>
<p><strong>一些套话</strong></p>
<p><strong>1. I really appreciate your making time in your schedules to attend today.</strong></p>
<p>我非常感谢你们今天抽空来参加这个会议。</p>
<p><strong>2. Thank you for…</strong></p>
<p>感谢您……</p>
<p><strong>Thank you for giving me this opportunity to speak about myself in this special occasion.</strong></p>
<p>感谢您给我这个机会在这个特别的场合介绍我自己。</p>
<p><strong>3. It is my honor…</strong></p>
<p>我很荣幸……</p>
<p><strong>It is my honor to introduce the president of our company, Mr. Jones.</strong></p>
<p>我很荣幸介绍我们公司总裁琼斯先生。</p>
<p><strong>4. On behalf of…</strong></p>
<p>代表……</p>
<p><strong>On behalf of our entire company, I want to thank you for inviting us to such an enjoyable Christmas party.</strong></p>
<p>我代表全公司，我想感谢您邀请我们参加这样一个令人愉快的圣诞晚会</p>
<p><strong>5. I’d be happy to…</strong></p>
<p>我很高兴……</p>
<p><strong>I’d be happy to tell you about my experiences.</strong></p>
<p>我很高兴和你们分享我的经验。</p>
<p><strong>6. What I am going to talk about today is…</strong></p>
<p>今天我想讲的是……</p>
<p><strong>What I am going to talk about today is the energy conservation issue.</strong></p>
<p>今天我想讲的是节能问题。</p>
<p><strong>7. How can we…?</strong></p>
<p>我们怎样才能……？</p>
<p><strong>How can we work more efficiently?</strong></p>
<p>我们怎样才能工作得更有效率呢？</p>
<p><strong>8.Thank you from the bottom of my heart for…</strong></p>
<p>我从心底感谢……</p>
<p><strong>Thank you from the bottom of my heart for giving me this chance to speak to you today.</strong></p>
<p>我从心底感谢你们今天给了解这个机会在你们前面讲话。</p>
<p><strong>9. So long as…</strong></p>
<p>只要……</p>
<p><strong>So long as we work together we can achieve great results.</strong></p>
<p>只要我们一起努力，我们就能取得巨大的成就。</p>
<p><strong>10. Working together…</strong></p>
<p>一起努力…</p>
<p><strong>Working together, we can make the future better.</strong></p>
<p>一起努力，我们将把未来变得更加美好。</p>
<p><strong>11. I should like to pay tribute to…</strong></p>
<p>我想对……表示敬意</p>
<p><strong>I should like to pay tribute to the dedication of all the professionals who worked on this project.</strong></p>
<p>我想对参与这个项目的所有专家的奉献表示敬意。</p>
<p><strong>12. I want to leave you with…</strong></p>
<p>我想留给你们…</p>
<p><strong>I want to leave you with one final word to remember, “teamwork”.</strong></p>
<p>我想让你们记住最后一个词：“团队合作”</p>
<p><strong>13. We sincerely hope…</strong></p>
<p>我们衷心希望…</p>
<p><strong>We sincerely hope that you will have a wonderful time tonight.</strong></p>
<p>我们衷心希望你们今晚过的开心。</p>
<p><strong>14. I look forward to…</strong></p>
<p>我期待……</p>
<p><strong>I look forward to seeing you again.</strong></p>
<p>我期待着再次见到你们。</p>
<p><strong>15. Best wishes for…</strong></p>
<p>对……致以良好的祝愿</p>
<p><strong>Best wishes for a very successful exhibition!</strong></p>
<p>对展会的成功致以美好的祝愿。</p>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 不想学辣 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 英语 </tag>
            
            <tag> 口语 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[LeetCode 309周赛&86双赛]]></title>
      <url>/2022/09/04/%E3%80%90LeetCode%E3%80%91309%E5%91%A8%E8%B5%9B&amp;86%E5%8F%8C%E8%B5%9B/</url>
      <content type="html"><![CDATA[<h1>309周赛&amp;86双赛</h1>
<hr>
<h2 id="前言">前言</h2>
<p>最近对自己太放纵了，属实是有点不太行。</p>
<p>接下来要上强度了！</p>
<hr>
<h2 id="309-是miHoYo冠名周赛">309 是miHoYo冠名周赛</h2>
<hr>
<h2 id="T1">T1</h2>
<img src="/2022/09/04/%E3%80%90LeetCode%E3%80%91309%E5%91%A8%E8%B5%9B&86%E5%8F%8C%E8%B5%9B/image-20220906175248073.png" alt="image-20220906175248073" style="zoom:50%;">
<p><strong>思路</strong></p>
<p>T1又是很简单的数组题，我们只需要判断两个元素出现位置中间隔的元素是否与给定的距离表相等即可。</p>
<p>而且哦，这种位置的选择，我们可以通过<code>hash</code>表的方式很容易的完成。尤其是前后位次关系。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">checkDistances</span>(<span class="params">self, s: <span class="built_in">str</span>, distance</span>):</span><br><span class="line">        hashmap=&#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> i,j <span class="keyword">in</span> <span class="built_in">enumerate</span>(s):</span><br><span class="line">            <span class="comment"># 记录第一次出现的位置</span></span><br><span class="line">            <span class="keyword">if</span> j <span class="keyword">not</span> <span class="keyword">in</span> hashmap.keys():</span><br><span class="line">                hashmap[j]=i</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># 判断第二次与第一次的差值是否等于距离表</span></span><br><span class="line">                val=i-hashmap[j]</span><br><span class="line">                <span class="keyword">if</span> val-<span class="number">1</span>!=distance[<span class="built_in">ord</span>(j)-<span class="built_in">ord</span>(<span class="string">&quot;a&quot;</span>)]:</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    </span><br></pre></td></tr></table></figure>
<p>这题是不是很像两数之和？<br>
那我们干脆一起把<code>86双</code>的<code>T1</code>一起讲了吧</p>
<p><img src="/2022/09/04/%E3%80%90LeetCode%E3%80%91309%E5%91%A8%E8%B5%9B&86%E5%8F%8C%E8%B5%9B/image-20220906175257692.png" alt="image-20220906175257692"></p>
<p>呐，这鬼题也是，判断连续的，我们只需要看这个值是否被记录过就好了</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">findSubarrays</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">        <span class="comment"># 要tm连续啊</span></span><br><span class="line">        <span class="comment"># 逆天</span></span><br><span class="line">        hashmap=&#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums)-<span class="number">1</span>):</span><br><span class="line">            val=nums[i]+nums[i+<span class="number">1</span>]</span><br><span class="line">            <span class="keyword">if</span> val <span class="keyword">in</span> hashmap.keys():</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">            hashmap[val]=<span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<hr>
<h2 id="T2">T2</h2>
<p><img src="/2022/09/04/%E3%80%90LeetCode%E3%80%91309%E5%91%A8%E8%B5%9B&86%E5%8F%8C%E8%B5%9B/image-20220906175309036.png" alt="image-20220906175309036"></p>
<p><strong>思路</strong></p>
<p>关键词：方法数！想到了什么？爬楼梯？斐波那契数列？没错，这种方法数，一般都有递推公式。这题也不例外。考虑两个方向，于是每次dp就能从左和从右。由于负数轴需要映射，为了简化操作，我们可以不用数组。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">numberOfWays</span>(<span class="params">self, startPos: <span class="built_in">int</span>, endPos: <span class="built_in">int</span>, k: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        MOD = <span class="number">10</span> ** <span class="number">9</span> + <span class="number">7</span></span><br><span class="line"><span class="meta">        @cache</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">f</span>(<span class="params">x: <span class="built_in">int</span>, left: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">abs</span>(x - endPos) &gt; left: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">            <span class="keyword">if</span> left == <span class="number">0</span>: <span class="keyword">return</span> <span class="number">1</span>  <span class="comment"># 成功到达终点，算一种方案</span></span><br><span class="line">            <span class="keyword">return</span> (f(x - <span class="number">1</span>, left - <span class="number">1</span>) + f(x + <span class="number">1</span>, left - <span class="number">1</span>)) % MOD</span><br><span class="line">        <span class="keyword">return</span> f(startPos, k)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>亦或是采用BFS进行广度搜索，得到所有可能的结果(相当于遍历，核心与DP相同)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">MOD = <span class="number">10</span>**<span class="number">9</span> + <span class="number">7</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">numberOfWays</span>(<span class="params">self, startPos: <span class="built_in">int</span>, endPos: <span class="built_in">int</span>, k: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="comment"># BFS模拟全局搜索</span></span><br><span class="line">        pre = defaultdict()</span><br><span class="line">        pre[startPos] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> k:</span><br><span class="line">            nex = defaultdict()</span><br><span class="line">            <span class="keyword">for</span> pos <span class="keyword">in</span> pre:</span><br><span class="line">                <span class="comment"># 每次都会更新下一次的方向</span></span><br><span class="line">                <span class="comment"># 并且都会进行一个累加，表示重新走过</span></span><br><span class="line">                <span class="comment"># 更新往左与往右的方案数</span></span><br><span class="line">                nex[pos + <span class="number">1</span>] += pre[pos]</span><br><span class="line">                nex[pos - <span class="number">1</span>] += pre[pos]</span><br><span class="line">            <span class="keyword">for</span> pos <span class="keyword">in</span> nex:</span><br><span class="line">                nex[pos] %= MOD</span><br><span class="line">            pre = nex</span><br><span class="line">            k -= <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> pre[endPos] % MOD</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>解法二：数学！</p>
<p>正着走:<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span>，负着走<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi><mo>−</mo><mi>X</mi></mrow><annotation encoding="application/x-tex">K-X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span>，距离<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span></span></span></span></p>
<p>我们有:</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>X</mi><mo>+</mo><mo stretchy="false">(</mo><mo>−</mo><mo stretchy="false">(</mo><mi>K</mi><mo>−</mo><mi>X</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>=</mo><mi>D</mi><mspace linebreak="newline"></mspace><mi>X</mi><mo>=</mo><mfrac><mrow><mi>D</mi><mo>+</mo><mi>K</mi></mrow><mn>2</mn></mfrac></mrow><annotation encoding="application/x-tex">X+(-(K-X))=D
\\
X=\frac{D+K}{2}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">−</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">))</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.0463em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3603em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<p>于是，转换为求解：从<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span>中取<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span>个正数。</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msubsup><mi>C</mi><mi>K</mi><mrow><mn>1</mn><mi mathvariant="normal">/</mi><mn>2</mn><mo stretchy="false">(</mo><mi>D</mi><mo>+</mo><mi>K</mi><mo stretchy="false">)</mo></mrow></msubsup></mrow><annotation encoding="application/x-tex">C^{1/2(D+K)}_K
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.3383em;vertical-align:-0.2935em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em;"><span style="top:-2.4065em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span><span style="top:-3.2198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1/2</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">D</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2935em;"><span></span></span></span></span></span></span></span></span></span></span></p>
<p>那，关于Python如何求组合数，其实有一个内置函数<code>comb</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">numberOfWays</span>(<span class="params">self, startPos: <span class="built_in">int</span>, endPos: <span class="built_in">int</span>, k: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        MOD=<span class="number">10</span>**<span class="number">9</span>+<span class="number">7</span></span><br><span class="line">        d=<span class="built_in">abs</span>(endPos-startPos)</span><br><span class="line">        <span class="keyword">if</span> (k-<span class="built_in">abs</span>(endPos-startPos))&amp;<span class="number">1</span> <span class="keyword">or</span> k&lt;<span class="built_in">abs</span>(endPos-startPos):</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="keyword">return</span> comb(k,(d+k)//<span class="number">2</span>)%MOD</span><br></pre></td></tr></table></figure>
<p>不用Comb的话，我们可以这样写：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">comb</span>(<span class="params">m,n</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> m&gt;n <span class="keyword">or</span> <span class="built_in">type</span>(m)!=<span class="built_in">int</span> <span class="keyword">or</span> <span class="built_in">type</span>(n)!=<span class="built_in">int</span>:</span><br><span class="line">        <span class="comment"># 必须是整数且满足大小关系</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> rank(n)//(rank(m)*rank(n-m))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">rank</span>(<span class="params">n</span>):</span><br><span class="line">    <span class="keyword">if</span> n==<span class="number">0</span> <span class="keyword">or</span> n==<span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    ans=<span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>,n+<span class="number">1</span>):</span><br><span class="line">        ans*=i</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">int</span>(ans)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">numberOfWays</span>(<span class="params">self, startPos: <span class="built_in">int</span>, endPos: <span class="built_in">int</span>, k: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        MOD=<span class="number">10</span>**<span class="number">9</span>+<span class="number">7</span></span><br><span class="line">        d=<span class="built_in">abs</span>(endPos-startPos)</span><br><span class="line">        <span class="keyword">if</span> (k-<span class="built_in">abs</span>(endPos-startPos))&amp;<span class="number">1</span> <span class="keyword">or</span> k&lt;<span class="built_in">abs</span>(endPos-startPos):</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="keyword">return</span> comb(k,(d+k)//<span class="number">2</span>)%MOD</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="T3">T3</h3>
<p><img src="/2022/09/04/%E3%80%90LeetCode%E3%80%91309%E5%91%A8%E8%B5%9B&86%E5%8F%8C%E8%B5%9B/image-20220906175316163.png" alt="image-20220906175316163"></p>
<p><strong>思路</strong></p>
<p>位运算+双指针优化</p>
<p>其实看到这个连续就应该想到用双指针了。</p>
<p>当然，我的解法会遍历左右指针所有值，导致复杂度为：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mi>m</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(nm)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal">nm</span><span class="mclose">)</span></span></span></span></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">longestNiceSubarray</span>(<span class="params">self, nums</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="comment"># 滑动窗口</span></span><br><span class="line">        left=right=<span class="number">0</span></span><br><span class="line">        ans=<span class="number">0</span></span><br><span class="line">        n=<span class="built_in">len</span>(nums)</span><br><span class="line">        <span class="keyword">while</span> right&lt;n:</span><br><span class="line">            i=breakPoint=left</span><br><span class="line">            change=<span class="literal">False</span></span><br><span class="line">            <span class="keyword">while</span> i&lt;right:</span><br><span class="line">                <span class="keyword">if</span> nums[right]&amp;nums[i]!=<span class="number">0</span>:</span><br><span class="line">                    <span class="comment"># 只要是有一个够不成了</span></span><br><span class="line">                    <span class="comment"># 我们从构不成的位置重新构建子串</span></span><br><span class="line">                    <span class="comment"># 首先的尝试就是跳过</span></span><br><span class="line">                    breakPoint=i</span><br><span class="line">                    change=<span class="literal">True</span></span><br><span class="line">                    <span class="comment"># 子串肯定比原串小</span></span><br><span class="line">                    <span class="comment"># 所以不需要考虑，下次的截断点就是bp+1</span></span><br><span class="line">                i+=<span class="number">1</span></span><br><span class="line">                <span class="comment"># 加入</span></span><br><span class="line">            left=breakPoint+<span class="number">1</span> <span class="keyword">if</span> change <span class="keyword">or</span> breakPoint!=left <span class="keyword">else</span> left</span><br><span class="line">            ans=<span class="built_in">max</span>(ans,<span class="built_in">len</span>(nums[left:right+<span class="number">1</span>]))</span><br><span class="line">            right+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> ans</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>用位运算的话，复杂度上其实也差不多啦</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">longestNiceSubarray</span>(<span class="params">self, nums</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="comment"># 滑动窗口</span></span><br><span class="line">        left=right=<span class="number">0</span></span><br><span class="line">        ans=<span class="number">0</span></span><br><span class="line">        n=<span class="built_in">len</span>(nums)</span><br><span class="line">        or_=<span class="number">0</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">while</span> right&lt;n:</span><br><span class="line">            <span class="keyword">while</span> or_&amp;nums[right]:</span><br><span class="line">                or_^=nums[left]</span><br><span class="line">                left+=<span class="number">1</span></span><br><span class="line">                <span class="comment"># 加入</span></span><br><span class="line">            or_|=nums[right]</span><br><span class="line">            ans=<span class="built_in">max</span>(ans,right-left+<span class="number">1</span>)</span><br><span class="line">            right+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> ans</span><br></pre></td></tr></table></figure>
<p>当然，最后写的漂亮点，就是：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">longestNiceSubarray</span>(<span class="params">self, nums</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        ans=left=or_=<span class="number">0</span></span><br><span class="line">        <span class="comment"># or_用来存放运算结果</span></span><br><span class="line">        <span class="comment"># 加入：or_| x</span></span><br><span class="line">        <span class="comment"># 剔除: or_^ x</span></span><br><span class="line">        <span class="keyword">for</span> right,x <span class="keyword">in</span> <span class="built_in">enumerate</span>(nums):</span><br><span class="line">            <span class="keyword">while</span> or_&amp;x:</span><br><span class="line">                <span class="comment"># 此时需要剔除了</span></span><br><span class="line">                or_^=nums[left]</span><br><span class="line">                left+=<span class="number">1</span></span><br><span class="line">            or_|=x</span><br><span class="line">            ans=<span class="built_in">max</span>(ans,right-left+<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> ans</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="T4">T4</h3>
<p><img src="/2022/09/04/%E3%80%90LeetCode%E3%80%91309%E5%91%A8%E8%B5%9B&86%E5%8F%8C%E8%B5%9B/image-20220906175321646.png" alt="image-20220906175321646"></p>
<p><strong>思路</strong></p>
<p>初见这个题的时候，想到的应该是贪心，谁有空就给谁，谁的时间最短谁就空闲。</p>
<p>于是我写了个不能AC的解:</p>
<p>超！！！！我这个解随便改改逻辑就AC了！！！！！！</p>
<p>超！！！！</p>
<p>我也做出T4了！！！！</p>
<p>这是离AK最近的一次！</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">mostBooked</span>(<span class="params">self, n: <span class="built_in">int</span>, meetings</span>):</span><br><span class="line">        st=[[] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line">        val=[<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line">        n=<span class="built_in">len</span>(meetings)</span><br><span class="line">        i=<span class="number">0</span></span><br><span class="line">        now=<span class="number">0</span></span><br><span class="line">        meetings.sort(key=<span class="keyword">lambda</span> x:x[<span class="number">0</span>])</span><br><span class="line">        change=[<span class="literal">None</span>,<span class="literal">None</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> i&lt;n:</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> change[<span class="number">0</span>]!=<span class="literal">None</span>:</span><br><span class="line">                s,e=change</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                s, e = meetings[i]</span><br><span class="line">                <span class="keyword">if</span> now&lt;=s:</span><br><span class="line">                    <span class="comment"># 提前</span></span><br><span class="line">                    now=s</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    e+=now-s</span><br><span class="line">                    s=now</span><br><span class="line">                    </span><br><span class="line">                </span><br><span class="line"></span><br><span class="line">            <span class="comment"># 时间到了</span></span><br><span class="line">            <span class="keyword">for</span> _ <span class="keyword">in</span> st:</span><br><span class="line">                <span class="keyword">if</span> _ <span class="keyword">and</span> _[<span class="number">0</span>]&lt;=now:</span><br><span class="line">                    _.pop()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 有无空闲</span></span><br><span class="line">            <span class="keyword">for</span> l,j <span class="keyword">in</span> <span class="built_in">enumerate</span>(st):</span><br><span class="line">                <span class="keyword">if</span> j==[]:</span><br><span class="line">                    val[l]+=<span class="number">1</span></span><br><span class="line">                    j.append(e)</span><br><span class="line">                    now=s</span><br><span class="line">                    i+=<span class="number">1</span></span><br><span class="line">                    change[<span class="number">0</span>]=<span class="literal">None</span></span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                now=<span class="built_in">min</span>([i[<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> st])</span><br><span class="line">                now=<span class="built_in">max</span>(now,s)</span><br><span class="line">                change=[now,now+(e-s)]</span><br><span class="line"></span><br><span class="line">        check=val[<span class="number">0</span>]</span><br><span class="line">        idx=<span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i,j <span class="keyword">in</span> <span class="built_in">enumerate</span>(val):</span><br><span class="line">            <span class="keyword">if</span> j&gt;check:</span><br><span class="line">                check=j</span><br><span class="line">                idx=i</span><br><span class="line">        <span class="keyword">return</span> idx</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>两个堆来回倒实现任务队列！</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> heapq <span class="keyword">import</span> heappop</span><br><span class="line"><span class="keyword">from</span> heapq <span class="keyword">import</span> heappush</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">mostBooked</span>(<span class="params">self, n: <span class="built_in">int</span>, meetings</span>):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 当会议室未占用，会有限提供资源给开始时间早的。</span></span><br><span class="line">        <span class="comment"># 两个堆来模拟，一个表示可用的会议室，另一个表示正在开会的会议室</span></span><br><span class="line"></span><br><span class="line">        cnt=[<span class="number">0</span>]*n</span><br><span class="line">        idle=<span class="built_in">list</span>(<span class="built_in">range</span>(n)) <span class="comment"># 可用的会议室</span></span><br><span class="line">        using=[]<span class="comment"># (结束时间，会议室编号)</span></span><br><span class="line">        meetings.sort() <span class="comment"># 必要的排序</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> st,end <span class="keyword">in</span> meetings:</span><br><span class="line">            <span class="comment"># 在st时刻前正在开会的会议室，把结束的弹出来</span></span><br><span class="line">            <span class="keyword">while</span> using <span class="keyword">and</span> using[<span class="number">0</span>][<span class="number">0</span>]&lt;=st:</span><br><span class="line">                <span class="comment"># 首先将使用栈中的内容弹出来</span></span><br><span class="line">                <span class="comment"># 并且将结束时间放入idle中，表示可用任务队列</span></span><br><span class="line">                heappush(idle,heappop(using)[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(idle)==<span class="number">0</span>:</span><br><span class="line">                <span class="comment"># 如果当前没有可用的</span></span><br><span class="line">                <span class="comment"># 需要等到最近一个结束</span></span><br><span class="line">                e,i=heappop(using)</span><br><span class="line">                <span class="comment"># 补上时间</span></span><br><span class="line">                end+=e-st</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># 将当前空闲的弹出去(其实也是索引最小值)</span></span><br><span class="line">                <span class="comment"># 将最短时间的出堆</span></span><br><span class="line">                i=heappop(idle)</span><br><span class="line"></span><br><span class="line">            cnt[i]+=<span class="number">1</span></span><br><span class="line">            <span class="comment"># 将当前结束时间和索引加入最小堆中</span></span><br><span class="line">            <span class="comment"># 每次取都是最小(最近一个结束的)</span></span><br><span class="line">            heappush(using,(end,i))</span><br><span class="line"></span><br><span class="line">        ans=<span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i,c <span class="keyword">in</span> <span class="built_in">enumerate</span>(cnt):</span><br><span class="line">            <span class="keyword">if</span> c&gt;cnt[ans]:</span><br><span class="line">                ans=i</span><br><span class="line">        <span class="keyword">return</span> ans</span><br></pre></td></tr></table></figure>
<p>O(n+mlogn+mlogn)</p>
<p>建堆+排+插入堆</p>
<hr>
<h1>86 双赛</h1>
<blockquote>
<p>T3和T4很有意思</p>
</blockquote>
<h2 id="T2-v2">T2</h2>
<p><strong>带余除法</strong></p>
<p>当<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>&gt;</mo><mn>4</mn><mo separator="true">,</mo><mn>2</mn><mo>&lt;</mo><mi>n</mi><mo>−</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">n&gt;4,2&lt;n-2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8389em;vertical-align:-0.1944em;"></span><span class="mord">4</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">2</span></span></span></span>，下面的表达式一定成立</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>n</mi><mo>=</mo><mi>q</mi><mo>∗</mo><mi>b</mi><mo>+</mo><mi>r</mi><mo separator="true">,</mo><mn>0</mn><mo>&lt;</mo><mo>=</mo><mi>r</mi><mo>&lt;</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">n=q*b+r,0&lt;=r&lt;b
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6597em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">b</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8389em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">0</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&lt;=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">b</span></span></span></span></span></p>
<p>这题完全就是脑筋急转弯<br>
告诉你了，这玩意在<code>n-2</code>进制上必定为<code>12</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<hr>
<h2 id="T3-v2">T3</h2>
<p><img src="/2022/09/04/%E3%80%90LeetCode%E3%80%91309%E5%91%A8%E8%B5%9B&86%E5%8F%8C%E8%B5%9B/image-20220906175340017.png" alt="image-20220906175340017"></p>
<p>这题不难看出是位运算，难得是如何进行。</p>
<p>不是没有想过枚举，但是会不会有一种更加高效的手段拿来实现这个算法？很可惜，似乎是没有的。</p>
<p>所幸的是，位运算枚举还是挺快的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">maximumRows</span>(<span class="params">self, mat: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]], cols: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        位运算</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        枚举所有选择情况</span></span><br><span class="line"><span class="string">        实际上，二进制数就能表征所有的选择情况</span></span><br><span class="line"><span class="string">        二进制数还能用来表征更高位的数据</span></span><br><span class="line"><span class="string">        譬如之前的毒药和小鼠</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        ans=<span class="number">0</span></span><br><span class="line">        mask=[<span class="built_in">sum</span>(v&lt;&lt;j <span class="keyword">for</span> j,v <span class="keyword">in</span> <span class="built_in">enumerate</span>(row)) <span class="keyword">for</span> row <span class="keyword">in</span> mat]</span><br><span class="line">        <span class="comment"># 刚好就能够表示0-1覆盖情况</span></span><br><span class="line">        <span class="comment"># 例如：5-&gt; 101</span></span><br><span class="line">        <span class="comment"># 6-&gt;110</span></span><br><span class="line">        <span class="keyword">for</span> <span class="built_in">set</span> <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>&lt;&lt;<span class="built_in">len</span>(mat[<span class="number">0</span>])):</span><br><span class="line">            <span class="comment"># 这样就能表征所有的情况</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">set</span>.bit_count()!=cols:</span><br><span class="line">                <span class="comment"># 剪枝</span></span><br><span class="line">                <span class="comment"># 不满足列的情况就丢弃</span></span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="comment"># 某一行 and 选择列如果还等于他自己</span></span><br><span class="line">            <span class="comment"># 那就说明可以覆盖</span></span><br><span class="line">            <span class="comment"># 1的时候恰好是1 0的时候不用管他</span></span><br><span class="line">            cnt=<span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> row <span class="keyword">in</span> mask:</span><br><span class="line">                <span class="keyword">if</span> row &amp;<span class="built_in">set</span>==row:</span><br><span class="line">                    cnt+=<span class="number">1</span></span><br><span class="line">            ans=<span class="built_in">max</span>(ans,cnt)</span><br><span class="line">        <span class="keyword">return</span> ans </span><br><span class="line"></span><br><span class="line">            </span><br></pre></td></tr></table></figure>
<h2 id="T4-v2">T4</h2>
<img src="/2022/09/04/%E3%80%90LeetCode%E3%80%91309%E5%91%A8%E8%B5%9B&86%E5%8F%8C%E8%B5%9B/image-20220905204610760.png" alt="image-20220905204610760" style="zoom:50%;">
<p>这题的关键字：<strong>连续consecutive</strong></p>
<p>所以，双指针搭建滑动窗口不失为一种好的选择。</p>
<p>当然，这类似背包问题，是存在一个限制条件的。</p>
<p>我们可以用单调队列来处理这种情况，通过维护单调队列，及时清理无用数据，保证队首是最大元素的同时，考虑是否加入和剔除元素。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">maximumRobots</span>(<span class="params">self, chargeTimes: <span class="type">List</span>[<span class="built_in">int</span>], runningCosts: <span class="type">List</span>[<span class="built_in">int</span>], budget: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line"></span><br><span class="line">        ans=s=left=<span class="number">0</span></span><br><span class="line">        q=deque()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> right,(t,c) <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">zip</span>(chargeTimes,runningCosts)):</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 处理右端点</span></span><br><span class="line">            <span class="keyword">while</span> q <span class="keyword">and</span> t&gt;=chargeTimes[q[-<span class="number">1</span>]]:</span><br><span class="line">                <span class="comment"># 只要当前的时间大于队列的时间</span></span><br><span class="line">                <span class="comment"># 就要维护队列的单调性</span></span><br><span class="line">                q.pop()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 将这个端点加入</span></span><br><span class="line">            q.append(right)</span><br><span class="line">            s+=c <span class="comment"># 总的cost</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 处理左端点</span></span><br><span class="line">            <span class="keyword">while</span> q <span class="keyword">and</span> chargeTimes[q[<span class="number">0</span>]]+(right-left+<span class="number">1</span>)*s&gt;budget:</span><br><span class="line">                <span class="comment"># 太多了！ 最大的滚出去！</span></span><br><span class="line">                <span class="keyword">if</span> q[<span class="number">0</span>]==left:</span><br><span class="line">                    q.popleft()</span><br><span class="line">                s-=runningCosts[left]</span><br><span class="line">                <span class="comment"># 一直找啊找直到找到最大的那个</span></span><br><span class="line">                left+=<span class="number">1</span></span><br><span class="line">            <span class="comment"># 这样 超出区间的一个就是我们的一个连续的子序列了</span></span><br><span class="line">            <span class="comment"># 这样的方式能保证：</span></span><br><span class="line">            <span class="comment"># 如果后面加进来的值比较大</span></span><br><span class="line">            <span class="comment"># 我们可以直接剔除掉串</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 如果后面加进来的值比较小</span></span><br><span class="line">            <span class="comment"># 我们就无须对其进行维护</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 举个栗子</span></span><br><span class="line">            <span class="comment"># tar: 10</span></span><br><span class="line">            <span class="comment"># List: 4 3 1 2</span></span><br><span class="line">            <span class="comment"># q:4 3 1</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 插入2</span></span><br><span class="line">            <span class="comment"># 此时q: 4 3 2</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 发现超了</span></span><br><span class="line">            <span class="comment"># 我们就去掉最大的</span></span><br><span class="line">            <span class="comment"># 剩下的q: 3 2</span></span><br><span class="line">            <span class="comment"># 重新开始一段</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># tar:10</span></span><br><span class="line">            <span class="comment"># List: 1 3 4 2</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 插入2时:</span></span><br><span class="line">            <span class="comment"># q: 4</span></span><br><span class="line">            <span class="comment"># 插入2一定会炸</span></span><br><span class="line">            <span class="comment"># 那么我们就从4的位置开始新的子串</span></span><br><span class="line">            <span class="comment"># 直接定位到了最大的位置</span></span><br><span class="line">            <span class="comment"># 因为当x上溢</span></span><br><span class="line">            <span class="comment"># x+1一定上溢</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 而且，单调队列维护的是坐标索引</span></span><br><span class="line">            <span class="comment"># 方便我们定位</span></span><br><span class="line">            ans=<span class="built_in">max</span>(ans,right-left+<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> ans</span><br></pre></td></tr></table></figure>
<p>我们可以反思一下，什么时候可以用单调队列？</p>
<ul>
<li>我们每次不符合条件的弹出都是最值</li>
<li>维护一个最值，使其满足限制条件</li>
</ul>
<p>怎么使用单调队列？</p>
<ul>
<li>及时弹出无用元素</li>
</ul>
<p>在滑动窗口维护最值问题，可以考虑单调队列：</p>
<ul>
<li>判断队列单调性，不满足时，队尾出队</li>
<li>增大窗口，队尾入队，更新统计值</li>
<li>判断是否满足条件，不满足则缩小窗口，队首出队</li>
</ul>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 不想学辣 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 算法 </tag>
            
            <tag> LeetCode </tag>
            
            <tag> 总结 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[CFOP]]></title>
      <url>/2022/09/04/%E3%80%90cfop%E3%80%91%E9%AD%94%E6%96%B9/</url>
      <content type="html"><![CDATA[<h3 id="CFOP-F2L-F2L1">CFOP-F2L-F2L1</h3>
<p>(R U’ R’ U) y’ (R’ U2 R U’ U’) (R’ U R)</p>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 拾枝杂谈 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 魔方 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[脑科学の一些无用小知识]]></title>
      <url>/2022/09/04/%E3%80%90%E8%84%91%E7%A7%91%E5%AD%A6%E3%80%91%E8%84%91%E7%A7%91%E5%AD%A6%E3%81%AE%E4%B8%80%E4%BA%9B%E6%97%A0%E7%94%A8%E5%B0%8F%E7%9F%A5%E8%AF%86/</url>
      <content type="html"><![CDATA[<h1>脑科学の一些无用小知识</h1>
<hr>
<p>这篇文章的问世来源于<code>9/4</code>日的一些小遐想。</p>
<p>我感觉最近的大脑越来越不够用了。记忆东西也根本记不下来。于是乎，想去找到那么一点点的慰藉🌮 。</p>
<hr>
<h2 id="1️⃣-脑科学提升智力的方法">1️⃣ 脑科学提升智力的方法</h2>
<p>来自：<a href="https://www.bilibili.com/video/BV1PP4y157d5?spm_id_from=333.880.my_history.page.click&amp;vd_source=b6ddb37b0dc1af8da34b699b1daf8a16">学不会？做题做不出来？脑科学最强提升智力的方法！</a></p>
<p>视频中，up主根据音乐大佬的脑子和案例(尤其是莫扎特的训练方式)，得到了对于普通人来说，天赋一词并不存在。</p>
<p>而智商是可以通过<code>后天训练提升</code>的。关键在于<code>记忆</code>!</p>
<ul>
<li>单纯的拥有记忆并没有什么用。重要的是经常运用这些信息，来加强神经通路。</li>
<li>学习任何东西最好可以尽可能的调用更多的感受器。</li>
<li>尽量带有情绪进行学习。</li>
<li>尽可能接触不同事物。</li>
</ul>
<hr>
<h2 id="2️⃣-14种超简易的脑力增强法！一星期变聪明！">2️⃣ 14种超简易的脑力增强法！一星期变聪明！</h2>
<p>来自：<a href="https://www.bilibili.com/video/BV1U4411G7YP/?spm_id_from=333.788.recommend_more_video.-1&amp;vd_source=b6ddb37b0dc1af8da34b699b1daf8a16">14种超简易的脑力增强法！一星期变聪明！</a></p>
<p>视频直接提出了几种记忆力训练方法</p>
<ul>
<li>画一张地图</li>
<li>远离电子设备，多用纸笔</li>
<li>心酸</li>
<li>刺激味蕾</li>
<li>睡前回忆</li>
<li>参加新运动</li>
<li>参加手眼协调的活动</li>
<li>记电话号码</li>
<li>提高反应速度
<ul>
<li>预览</li>
<li>问题</li>
<li>重读</li>
<li>研究</li>
<li>测试</li>
</ul>
</li>
<li>出声读书</li>
<li>保留脑力</li>
<li>总结重点</li>
</ul>
<hr>
<h2 id="3️⃣-熬夜的危害">3️⃣ 熬夜的危害</h2>
<p>来自：</p>
<p>TED演讲：<a href="https://www.bilibili.com/video/BV1qx411d7XW/?spm_id_from=333.788.recommend_more_video.6&amp;vd_source=b6ddb37b0dc1af8da34b699b1daf8a16">睡眠到底有多重要，看完不敢熬夜了！</a></p>
<ul>
<li>影响生殖激素分泌，显老且生殖能力变差</li>
<li>影响记忆力和学习能力，比睡眠充足的人少<code>40%</code>~</li>
<li>影响心脑血管系统jis</li>
<li>影响免疫力和DNA活力，免疫力低<code>70%</code>！</li>
</ul>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 拾枝杂谈 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 脑科学 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[【海洋遥感】第一节课]]></title>
      <url>/2022/09/02/%E3%80%90%E6%B5%B7%E6%B4%8B%E9%81%A5%E6%84%9F%E3%80%91Unname/</url>
      <content type="html"><![CDATA[<h1>海洋遥感</h1>
<h1>第一章</h1>
<hr>
<h2 id="一、海洋遥感的意义">一、海洋遥感的意义</h2>
<p>1️⃣ 理解海洋及地球</p>
<p>2️⃣ 利用海洋和地球</p>
<ul>
<li>海洋是人类最大的资源宝库，是全球生命支持系统的基本组成部分。</li>
<li>海洋资源的重要性促使人们采用各类手段对其进行调查研究。</li>
</ul>
<p><strong>痛点🤕</strong></p>
<ul>
<li>传统海洋调查依赖于调查船沿设定航线设置的稀疏取样，虽然定位测量准确，但在规模、范围和频度上受限制。</li>
<li>海洋环境的<strong>进入性</strong>和<strong>可通达性</strong>较差</li>
<li>近海和海岸环境复杂多变，难以进行多变量同步控制观测</li>
<li>海岸环境变化周期长、信息量大，难以取得理想的可控制数据，在实时处理上也有着较大的困难。</li>
</ul>
<hr>
<p>海洋遥感具有大范围、实时同步、全天时、全天候多波段成像技术的优势可以快速地探测海洋表面各物理量的时空变化归规律。</p>
<p><strong>重要性</strong></p>
<ul>
<li>海洋科学或遥感科学的交叉学科</li>
<li>为海洋观测和研究提供了一个崭新的数据集，并开辟了新的考虑问题的视角</li>
<li>多传感器资料可推动海洋科学交叉学科研究的发展</li>
</ul>
<h2 id="二、海洋遥感的概念">二、海洋遥感的概念</h2>
<p><strong>基本概念</strong></p>
<p><strong>海洋遥感</strong> (Ocean Remote Sensing) 指以海洋及海岸带作为监测、研究对象，利用电磁波与大气和海洋的相互作用原理来观测和研究海洋的遥感技术。</p>
<p><strong>整体特点</strong></p>
<ul>
<li>不受地表、海面、天气和人为条件的性质，可以探测地理位置偏远、环境条件恶劣等不能直接进入的海区。</li>
<li>宏观特性可进行大面积同步测量，能够进行半球或全球探测。</li>
<li>可动态、长期的、周期性的对海洋现象进行监测</li>
<li>具有实时的或准实时的特征</li>
<li>多个探测器相配套</li>
<li>很显然，海洋遥感能够在不破坏当地环境下进行大面积的客观测量(没有人为干涉！)</li>
</ul>
<p><strong>具体特点</strong></p>
<blockquote>
<p>传感器设计方面</p>
</blockquote>
<p>光学传感器，带宽较窄，IFOV较大。微波波段应用较多(云层覆盖较多，微波数据比可见光和热红外能够取得的效果更好)。</p>
<blockquote>
<p>传感器定标与数据处理应用方面</p>
</blockquote>
<p>需要调查船、浮标、潜水器等仪器实测资料的支持。</p>
<blockquote>
<p>数据预处理方面</p>
</blockquote>
<p>更需要消除大气的干扰</p>
<blockquote>
<p>数据应用方面</p>
</blockquote>
<p>适用于海洋数值模型的检验与改进</p>
<p><strong>卫星类别</strong></p>
<p><strong>按传感方式</strong></p>
<ul>
<li>被动遥感</li>
<li>主动遥感</li>
</ul>
<p><strong>按使用目的</strong></p>
<ul>
<li>海洋水色卫星
<ul>
<li>主要探测海洋水色要素，如叶绿素浓度、悬浮泥沙含量、有色可溶有机物等，也可以用来获得浅海水下地形、海冰、海水污染及海流等游泳信息价值</li>
</ul>
</li>
<li>海洋地形卫星
<ul>
<li>主要用于探测海表面拓扑，即海平面高度的空间分布，此外，还可以探测海水、有效波高、海面风速和海流等</li>
</ul>
</li>
<li>海洋动力环境卫星
<ul>
<li>用于探测海洋动力环境要素，如海面风场、浪场、海冰等。</li>
</ul>
</li>
</ul>
<hr>
<p><strong>雷达高度计</strong></p>
<ul>
<li>用于测量海面高度、有效波高及风速等海洋基本要素</li>
<li>无线电系统射电反射比较时间差</li>
</ul>
<p><strong>微波散射计</strong></p>
<ul>
<li>用于全球风场观测</li>
<li>通过测量风引起的粗糙海面对微博的后向散射特征来推算风场</li>
</ul>
<p><strong>微波辐射计</strong></p>
<ul>
<li>主要用于获取全球海洋温度、海面风场、大气水蒸气含量、云中水含量、海冰和降雨量</li>
<li>微波辐射计接收辐亮度(亮温)，等同于辐射的黑体的温度。</li>
<li>辐亮度F=(海表面温度、盐度，海面粗糙度，波浪破碎产生的白冠和气泡)</li>
</ul>
<h2 id="三、海洋遥感的发展历程">三、海洋遥感的发展历程</h2>
<h3 id="🚂-四个主要阶段">🚂 四个主要阶段</h3>
<p><strong>起步阶段</strong></p>
<p><strong>探索阶段</strong></p>
<p>气象卫星和陆地卫星的探测器波段设置不同，还要遥感需要更多的频段和更高的精度。</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1978</mn></mrow><annotation encoding="application/x-tex">1978</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1978</span></span></span></span> NASA发射了三科海洋遥感卫星。<code>SeasatA</code>是第一颗海洋试验卫星，但由于电源故障，仅运行了<code>108</code>天</p>
<p>我国的海洋卫星</p>
<ul>
<li>1988 FY-1A 第一颗海洋卫星</li>
<li>2002 HY-1A 第一颗海洋水色卫星</li>
<li>2008 FY-3 极轨卫星</li>
</ul>
<h2 id="四、海洋遥感的研究内容">四、海洋遥感的研究内容</h2>
<ul>
<li>物理海洋学遥感</li>
<li>生物海洋学和化学海洋学遥感</li>
<li>海冰监测</li>
<li>海洋污染监测</li>
<li>目标识别</li>
</ul>
<p>1️⃣ 海表温度遥感</p>
<p>主要采用热和红外波段和微波波段的信息进行海表面温度的遥感反演。</p>
<p>2️⃣ 海水浑浊度</p>
<p>3️⃣ 海洋污染监测</p>
<hr>
<h2 id="五、相关数据、资料获取">五、相关数据、资料获取</h2>
<hr>
<h2 id="六、主流的海洋遥感大学和机构">六、主流的海洋遥感大学和机构</h2>
<hr>
<h1>第二章  海洋遥感原理与基础</h1>
<h2 id="一、与海洋遥感相关的基本概念">一、与海洋遥感相关的基本概念</h2>
<h3 id="海洋学上的专有名词">海洋学上的专有名词</h3>
<p><strong>海面状况</strong>： 海面粗糙度状况，与最大的海面波动高度有关。</p>
<p><strong>深水波</strong>： 水深大于波长<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mi mathvariant="normal">/</mi><mn>2</mn></mrow><annotation encoding="application/x-tex">1/2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1/2</span></span></span></span>的波动</p>
<p><strong>浅水波</strong>： 水深小于波长<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mi mathvariant="normal">/</mi><mn>2</mn></mrow><annotation encoding="application/x-tex">1/2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1/2</span></span></span></span>的波动(长波)</p>
<p><strong>波高H</strong>： 从波峰到波谷之间的铅直距离</p>
<p><strong>有效波高<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>H</mi><mrow><mn>1</mn><mi mathvariant="normal">/</mi><mn>3</mn></mrow></msub></mrow><annotation encoding="application/x-tex">H_{1/3}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0385em;vertical-align:-0.3552em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:-0.0813em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1/3</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3552em;"><span></span></span></span></span></span></span></span></span></span></strong>： 博陈列</p>
<p><strong>反射率</strong> 传感器发出电磁波后，在原位置上能接收到的电磁辐射功率与发出功率之比(盆子洒豆子，接到多少豆子)</p>
<p><strong>反照率</strong> 被反射的电磁辐射的总功率与发出功率之比</p>
<p><strong>表观反射率</strong> 大气顶层的反射率，辐射定标的结果之一</p>
<p><strong>均方根波高<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">h_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></strong></p>
<h2 id="二、电磁波与海水相互作用机制">二、电磁波与海水相互作用机制</h2>
<h2 id="三、海洋水体波谱特征">三、海洋水体波谱特征</h2>
<h2 id="四、遥感图像处理">四、遥感图像处理</h2>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 不想学辣 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 海洋遥感 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[研究生英语A]]></title>
      <url>/2022/09/01/%E3%80%90%E7%A0%94%E7%A9%B6%E7%94%9F%E8%8B%B1%E8%AF%ADA%E3%80%91A64%E7%8F%AD%E8%AF%BE%E7%A8%8B/</url>
      <content type="html"><![CDATA[<h1>研究生英语</h1>
<p>TextA 从宏观到微观</p>
<ul>
<li>文章主题-&gt;段落主题-&gt;语法分析</li>
<li>文章背景介绍</li>
<li>文本语法现象</li>
</ul>
<p>Begin 介绍</p>
<p>End 测试</p>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 不想学辣 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 英语 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[【Data Mining】Chapter 1. Introduction]]></title>
      <url>/2022/08/31/%E3%80%90Data%20Mining%E3%80%91Chapter%201.%20Introduction/</url>
      <content type="html"><![CDATA[<h2 id="1️⃣-What-is-Data-Mining">1️⃣ What is Data Mining?</h2>
<ul>
<li><strong>Data mining:</strong> 🌟 Discover valid, novel, useful, and understandable patterns in massive datasets.</li>
</ul>
<p><strong>Cross Disciplines</strong></p>
<ul>
<li>Databases</li>
<li>Machine learning</li>
<li>Statistics</li>
<li>Neural network</li>
<li>Parallel / Distributed computing</li>
</ul>
<hr>
<h2 id="2️⃣-Characteristics-of-Data-Mining">2️⃣ Characteristics of Data Mining</h2>
<ul>
<li>Massive dataset</li>
<li>Automatically searching for interesting patterns from historical data</li>
<li>Fast</li>
<li>Scalable</li>
<li>Update easily</li>
<li>Practical</li>
<li>Decision support</li>
</ul>
<hr>
<h2 id="3️⃣-The-main-tasks-of-Data-Mining">3️⃣ The main tasks of Data Mining</h2>
<ul>
<li>
<p>Clustering</p>
</li>
<li>
<p>Classification</p>
</li>
<li>
<p>Anomaly Detection</p>
</li>
<li>
<p>Association Rules</p>
</li>
<li>
<p>Social Analysis</p>
</li>
<li>
<p>Recommender Systems</p>
</li>
<li>
<p>Sequence Mining</p>
</li>
</ul>
<h3 id="🌬️-Association-Rule-Mining">🌬️ Association Rule Mining</h3>
<p>Detect sets of attributes or items that frequently co-occur in many database records and rules among them.</p>
<blockquote>
<p>关联规则挖掘，旨在寻找到经常同时出现在数据库记录和其中的规则中的属性或项集。</p>
</blockquote>
<hr>
<h3 id="🔥-Classification">🔥 Classification</h3>
<p>Build a model of classes on training dataset, and then, assign a new record to one of several predefined classes.</p>
<blockquote>
<p>一个简单的分类模型：决策树。</p>
<p>分类是在先验基础上(经验、样本)，对未定义的数据赋予新的属性。</p>
</blockquote>
<hr>
<h3 id="🍦-Clustering">🍦 Clustering</h3>
<p>Partition the dataset into groups such that elements in a group have lower inter-group similarity and higher intra-group similarity.</p>
<blockquote>
<p>聚类的核心在于对于无标签数据，通过模型将其划分为具有簇间差异最大、簇内差异最小的簇</p>
</blockquote>
<hr>
<h3 id="🐍-Anomaly-Detection">🐍 Anomaly Detection</h3>
<p><strong>Anomalies:</strong> 🌟 The set of objects are considerably dissimilar from the remaining of the data.</p>
<p>Give a set of <code>n</code> objects, and <code>k</code>, the number of expected anomalies, find the top <code>k</code> objects that are considerably dissimilar or inconsistent with the remaining data.</p>
<hr>
<h3 id="📘-Sequence-Mining">📘 Sequence Mining</h3>
<p>Given a set of sequences, find the complete set of frequent subsequences.</p>
<blockquote>
<p>给定一组序列，找到他的频繁子序列的完整集合</p>
</blockquote>
<hr>
<h2 id="4️⃣-The-kinds-of-Date">4️⃣ The kinds of Date</h2>
<ul>
<li>Relational Databases
<ul>
<li>说人话就是处理结构化数据，以关系表的形式存储</li>
</ul>
</li>
<li>Data Warehouses
<ul>
<li>数据仓库顾名思义，是⼀个很⼤的数据存储集合，出于企业的分析性报告和决策⽀持⽬的⽽创建，对多样的业务数据进⾏筛选与整合。</li>
</ul>
</li>
<li>Transactional Databases</li>
<li>Spatial Data</li>
<li>Time Series</li>
<li>Text Databases</li>
<li>Multimedia databases</li>
<li>Data Streams</li>
<li>Biomedical Data</li>
<li>World-Wide Web</li>
<li>Graph</li>
</ul>
<hr>
<h2 id="5️⃣-Knowledge-Discovery-Process">5️⃣ Knowledge Discovery Process</h2>
<img src="/2022/08/31/%E3%80%90Data%20Mining%E3%80%91Chapter%201.%20Introduction/image-20220831101945274.png" alt="image-20220831101945274" style="zoom:50%;">
<p>说人话就是：</p>
<p>从数据库中进行<code>数据清洗和聚合</code>，接着在数据仓库中进行<code>选择和变换</code>，通过<code>数据挖掘</code>，对得到的<code>模式进行评估</code>，最终得到可用的<code>知识</code>。</p>
<p><strong>Key Step🔑</strong></p>
<p>1️⃣ Learning the application domain</p>
<ul>
<li>relevant prior knowledge and goals of application</li>
</ul>
<p>2️⃣ Creating a target data resource</p>
<p>3️⃣ Data cleaning and preprocessing. (may take 60% of effort)</p>
<p>4️⃣ Data reduction and transformation</p>
<p>5️⃣ Choosing the mining algorithms to search for patterns of interest.</p>
<p>6️⃣ Pattern evaluation and knowledge presentation.</p>
<p>7️⃣ Use of discovered knowledge</p>
<blockquote>
<p>可以归纳为<strong>三个阶段</strong></p>
<ul>
<li>用户画像阶段</li>
<li>数据处理阶段</li>
<li>评估应用阶段</li>
</ul>
<p>用户画像阶段，需要学习用户相关领域的知识，创建我们的目标数据资源</p>
<p>数据处理阶段，需要进行数据预处理、数据降维和变换、数据挖掘这几个步骤，找到感兴趣的模式</p>
<p>评估应用阶段，则是将得到的模式进行评估，利用该模式对知识进行表达和运用</p>
</blockquote>
<hr>
<h2 id="6️⃣-Interesting-Patterns">6️⃣ Interesting Patterns</h2>
<p><strong>Measures</strong></p>
<p>🌟 A pattern is interesting if it is <code>easily understood</code> by humans, <code>valid</code> on new or test data with some degree of <code>certainly, potentially useful, novel,</code> or <code>validates some hypothesis</code> that a user seeks to confirm.</p>
<p>✏️ 如果一种模式“很容易被人类理解”，对新数据或测试数据“有效”，并具有某种程度的“肯定、潜在有用、新颖”或“验证用户试图确认的某些假设”，那么这种模式就是有趣的。</p>
<blockquote>
<p>Objective or Subjective</p>
</blockquote>
<p><strong>Objective</strong>: based on <code>statistics and structures of pattern</code>s, e.g., support, confidence, etc.</p>
<p><strong>Subjective</strong>: based on <code>user’s belief in the data</code>, e.g., unexpectedness, novelty, actionability, etc.</p>
<blockquote>
<p>all or only interesting patterns</p>
</blockquote>
<p><strong>All:</strong> Completeness</p>
<p><strong>Only:</strong> An optimization problem–challenging</p>
<ul>
<li>Can a data mining system find only the interesting patterns</li>
<li>approaches
<ul>
<li>First generate all the patterns and then filter out the uninteresting ones.</li>
<li>Guide and constrain the discovery process.</li>
</ul>
</li>
</ul>
<hr>
<h2 id="7️⃣-Research-Issues-in-Data-Mining">7️⃣ Research Issues in Data Mining</h2>
<ul>
<li>Mining methodology</li>
<li>User interaction</li>
<li>Applications and social impacts</li>
</ul>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 不想学辣 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 数据分析 </tag>
            
            <tag> 数据挖掘 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[LeetCode Hot100 详细题解]]></title>
      <url>/2022/08/30/%E3%80%90LeetCode%E3%80%91Hot100%E9%A2%98%E8%A7%A3/</url>
      <content type="html"><![CDATA[<h2 id="Hot-100-题解🔥">Hot 100 题解🔥</h2>
<h3 id="前言">前言</h3>
<p>最近打算开个新坑，也就是这个Hot 100。</p>
<p>做完这份题解后，我会对我做过的所有题里有意思的，值得一说的再写一份题解。</p>
<hr>
<p>这份题解并不按照顺序进行，而是根据🏷️进行排序。不定期更新，平均一天1~2T，有空的话会加更。</p>
<hr>
<h2 id="一、数组">一、数组</h2>
<p>1.1 <a href="https://leetcode.cn/problems/two-sum/">两数之和</a></p>
<p><strong>题干：</strong></p>
<p>Given an array of integers <code>nums</code> and an integer <code>target</code>, return <code>indices of the two numbers such that they add up to target</code>.</p>
<p>You may assume that each input would have <code>exactly one solution</code>, and you may not use the same element twice.</p>
<p>You can return the answer in any order.</p>
<p><strong>示例：</strong></p>
<blockquote>
<p>Input: nums = [2,7,11,15], target = 9<br>
Output: [0,1]<br>
Explanation: Because nums[0] + nums[1] == 9, we return [0, 1].</p>
</blockquote>
<blockquote>
<p>Input: nums = [3,2,4], target = 6<br>
Output: [1,2]</p>
</blockquote>
<p><strong>思路：</strong></p>
<p>介个题本身考察的是对数组的理解和对数据结构的应用，我们可以想到一种最简单的方式：暴力。</p>
<p>借助暴力搜索+集合去重的方式，很快就能得到需要的答案。但这样的时间复杂度为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n^2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>，远远超出预期。</p>
<p>亦或是思路二：先排好序，接着通过二分的方式找到另一个。这种方式有个好处，那就是不需要数组去重，遇到重复的跳过就行了。时间复杂度为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>l</mi><mi>o</mi><mi>g</mi><mi>n</mi><mo stretchy="false">)</mo><mo>+</mo><mi>O</mi><mo stretchy="false">(</mo><mi>l</mi><mi>o</mi><mi>g</mi><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(logn)+O(logn)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">n</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">n</span><span class="mclose">)</span></span></span></span>排序+二分。</p>
<p>但是还是不够快，思路三可以通过<code>hash</code>表的方式进行，为什么能想到<code>hash</code>表呢？首先，这个数组本身是无序的，排序需要花费一定的时间复杂度。而对于某一个数<code>i</code>来说，他的配对为<code>target-i</code>，我们关注的，如何在后一次遇到<code>target-i</code>时及时找到我们的<code>i</code>？<code>hash</code>表可以很快的实现这一点。而且不需要担心重复问题。</p>
<p><strong>实现：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">twoSum</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>], target: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        hashmap=&#123;&#125;</span><br><span class="line">        res=[]</span><br><span class="line">        <span class="keyword">for</span> i,num <span class="keyword">in</span> <span class="built_in">enumerate</span>(nums):</span><br><span class="line">            <span class="keyword">if</span> (j:=target-num) <span class="keyword">in</span> hashmap.keys():</span><br><span class="line">                <span class="keyword">return</span> [hashmap[j],i]</span><br><span class="line">            hashmap[num]=i</span><br><span class="line">        <span class="keyword">return</span> []</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="二、链表">二、链表</h2>
<p>2.1 <a href="https://leetcode.cn/problems/add-two-numbers/">Add Two Numbers</a></p>
<p>You are given two non-empty linked lists representing two non-negative integers. The digits are stored in <code>reverse order</code>, and each of their nodes contains a single digit. Add the two numbers and return the sum as a <code>linked list</code>.</p>
<p>You may assume the two numbers do not contain any leading zero, except the number 0 itself.</p>
<img src="/2022/08/30/%E3%80%90LeetCode%E3%80%91Hot100%E9%A2%98%E8%A7%A3/image-20220905223717946.png" alt="image-20220905223717946" style="zoom:50%;">
<p><strong>思路</strong></p>
<p>链表的逆序相加，需要同时遍历两个链表，而且重点是进位。</p>
<p>我们可以用一个哨兵<code>carryBit</code>存放。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">addTwoNumbers</span>(<span class="params">self, l1: <span class="type">Optional</span>[ListNode], l2: <span class="type">Optional</span>[ListNode]</span>) -&gt; <span class="type">Optional</span>[ListNode]:</span><br><span class="line">        <span class="comment"># 关键词 逆序 相加</span></span><br><span class="line">        cur,carryBit=ListNode(<span class="number">0</span>),<span class="number">0</span></span><br><span class="line">        dummy=cur</span><br><span class="line">        <span class="keyword">while</span> l1 <span class="keyword">or</span> l2:</span><br><span class="line">            carryBit=(val:=(l1.val <span class="keyword">if</span> l1 <span class="keyword">else</span> <span class="number">0</span>)+(l2.val <span class="keyword">if</span> l2 <span class="keyword">else</span> <span class="number">0</span>)+carryBit)//<span class="number">10</span></span><br><span class="line">            cur.<span class="built_in">next</span>=ListNode(val%<span class="number">10</span>)</span><br><span class="line">            cur=cur.<span class="built_in">next</span></span><br><span class="line">            <span class="keyword">if</span> l1: l1=l1.<span class="built_in">next</span></span><br><span class="line">            <span class="keyword">if</span> l2: l2=l2.<span class="built_in">next</span></span><br><span class="line">        <span class="keyword">if</span> carryBit:cur.<span class="built_in">next</span>=ListNode(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> dummy.<span class="built_in">next</span></span><br></pre></td></tr></table></figure>
<p>总体来说，这题考察的就是对链表的理解和对进位的理解，并没有什么难度。</p>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 不想学辣 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 算法 </tag>
            
            <tag> LeetCode </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[【遥感科学】第一章 遥感科学的发展]]></title>
      <url>/2022/08/30/%E3%80%90%E9%81%A5%E6%84%9F%E7%A7%91%E5%AD%A6%E3%80%91%E7%AC%AC%E4%B8%80%E7%AB%A0%20%E9%81%A5%E6%84%9F%E7%A7%91%E5%AD%A6%E7%9A%84%E5%8F%91%E5%B1%95/</url>
      <content type="html"><![CDATA[<h1>第一章 遥感科学的发展🌐</h1>
<hr>
<h2 id="一、遥感的起源与发展✈️">一、遥感的起源与发展✈️</h2>
<p>1️⃣ 得益于战争，遥感技术得到了大力的发展</p>
<p>2️⃣ 上世纪<code>60</code>年代，国际上第一次将<code>遥感技术</code>作为一项科学技术门类以来，其理论逐渐发展，不断完善，在军事、资环调查、环境与灾害监测方面展现了巨大的优势。</p>
<p>3️⃣ 目前，世界各国向空间发射<code>6000</code>多颗卫星，其中<code>1/3</code>是遥感卫星。</p>
<blockquote>
<p><strong>1962</strong>年，第一届国际环境遥感大会在美国密歇根大学召开，<strong>遥感Remote sening</strong>一词正式被提出</p>
<p><strong>1957</strong>年苏联发射第一颗人造卫星</p>
<p><strong>1958</strong>年美国发射人造卫星</p>
<p><strong>1959</strong>年美国启动科罗纳卫星侦查计划</p>
<p><strong>1960</strong>年美国发射第一颗气象卫星</p>
<p><strong>1970</strong>年中国发射第一颗东方红卫星</p>
</blockquote>
<hr>
<h2 id="二、遥感的基本概念">二、遥感的基本概念</h2>
<h3 id="遥感的定义">遥感的定义</h3>
<p>1️⃣ 广义上的遥感</p>
<p>​	泛指一切不接触物体而进行的远距离探测，包括对电磁场、力场、机械波等的探测。</p>
<p>2️⃣ 狭义上的遥感</p>
<p>​	利用传感器记录目标的电磁波特征，通过对数据的处理、综合分析，揭示物体的特征及其变化规律的综合性探测技术</p>
<p>他是以电磁波与地面物质相互作用为基础，来探测、分析和研究地球资源与环境，并揭示相关要素的空间分布特征与时空变化规律的一门新兴科学。</p>
<p><strong>遥</strong>：远距离，非接触</p>
<p><strong>感</strong>：通过某种仪器进行探测并感知被测量物体的形状、大小、状态、特征等</p>
<p><strong>遥感的特点</strong></p>
<ul>
<li>面状信息获取、覆盖范围大</li>
<li>时效性强</li>
<li>连续性</li>
<li>多维信息</li>
<li>生动、形象、直观</li>
<li>经济实惠</li>
</ul>
<hr>
<p><strong>电磁波谱</strong></p>
<p>将电磁波按波长(或频率)从小到大(从大到小)排列起来，就是电磁波谱。</p>
<p>自变量是 $\lambda $ （波长），而因变量是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi></mrow><annotation encoding="application/x-tex">I</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span></span></span></span> , 反射率，或者说信息量。</p>
<p>值得注意下，所谓的波段一直指的都是一个范围，表示光子能量的范围，例如我们的红光波段、蓝光波段、绿光波段 。</p>
<p><strong>谱</strong> 一个物理量随另一个物理量的变化情况(反射率在波长下的变化)</p>
<p><strong>遥感的基本物理基础</strong></p>
<p>任何物体都具有发射、反射和吸收电磁波的特性，物体与电磁波的相互作用，形成了物体的电磁波特性，这是遥感探测物体的基础、依据。不同类型的地物具有不同的波谱特征，这也是遥感识别地物的基础。</p>
<p>遥感得到的数据一般是不同波长下的反射波谱曲线。</p>
<p>而反射率曲线，一般受到<strong>尺度</strong>、<strong>纯度视场大小</strong>、<strong>环境条件</strong>、<strong>方向角度</strong>等因素的影响。</p>
<p>当电磁波与地物发生作用时，会导致选择性的反射，不同地物呈现出不同的特征。因而可以通过遥感数据反演地物。</p>
<p>地表接收能量也会导致升温，从而发射热辐射，被传感器接收后，就成了热红外遥感。</p>
<p>传感器接收后，会将信息量转化为图像上的灰度值。</p>
<hr>
<p><strong>波段</strong></p>
<p>一定的电磁波范围。(如TM波段1的波段范围是0.45 ~ 0.52μm，波段2是0.53~0.61μm等)</p>
<p><strong>波段与通道🍌</strong></p>
<p>对传感器而言，波段与通道是等价的。</p>
<p>对图像处理而言，我们是将波段放到通道中对图像进行渲染。</p>
<p><strong>全色图像</strong></p>
<p>全色图像也是黑白的，指的是可见光到近红外波谱范围里头，传感器获取的一个宽波谱图像。</p>
<p><strong>彩色合成</strong></p>
<p>将在红绿蓝波段获取的单波段图像分别赋予红色、绿色和蓝色，并将3个图像叠加到一起，称为彩色图像。</p>
<p><strong>假彩色合成</strong></p>
<p>合成图像时，所用的波段的光谱段和赋予的相应通道不相一致，合成出来的图像的颜色与实际地物颜色不一致。</p>
<hr>
<p><strong>定标</strong></p>
<p>输入输出模式映射，或者说，就是将输出数据的范围映射到一个统一的区间，以方便多数据操作。</p>
<hr>
<p><strong>地面遥感</strong></p>
<p><strong>航空遥感</strong></p>
<p><strong>航天遥感</strong></p>
<p>地面遥感是基础，而航空航天遥感一般用来反演地面地物，而其验证一般也依托于地面遥感。</p>
<p>航空遥感也可以作为地面与航天遥感的中间商。</p>
<hr>
<h3 id="遥感的分类">遥感的分类</h3>
<p><strong>按工作方式</strong></p>
<p><strong>主动遥感</strong> 由传感器主动发射电磁波并接受目标反射的回波信号，如(SAR&lt;微波&gt;,激光雷达LIDAR&lt;可见光波&gt;)</p>
<p><strong>被动遥感</strong> 传感器自身不发射电磁波，被动接收目标对自然辐射源的反射能量或其自身发射的能量。</p>
<p><strong>成像遥感</strong> 传感器接收的电磁辐射信号可以转换为图像。</p>
<p><strong>非成像遥感</strong> 传感器接收的电磁辐射信号不能转换为图像(如微博辐射计、高度计等</p>
<p><strong>按应用领域</strong></p>
<p>资源、环境、农业、林业、地质、城市、灾害、水文、海洋、军事等等</p>
<h3 id="分辨率">分辨率</h3>
<p><strong>空间分辨率</strong> 指(未经过重采样的)想冤案所代表的地面范围大小，一般来说是指遥感图像能分辨的地面物体的最小单元。</p>
<p><strong>意义</strong></p>
<ul>
<li>空间分辨率高，划分地物越细，识别地物空间细节能力越强</li>
<li>不一定空间分辨率越高越好，地物细节信息太多有时反而会影响主要信息的识别与提取，要根据应用的特定目的选择合适的空间分辨率，不同的研究目标、尺度需要相应的数据。</li>
<li>图像的可分辨程度，不完全取决于空间分辨率的具体值，而与目标的形状、大小，以及它与周围物体亮度、结构的相对差异有关，与北京的反差大小有关。</li>
</ul>
<p><strong>光谱分辨率</strong> 指传感器接收目标辐射的波谱时，能分辨的最小波长间隔。(单位<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>u</mi><mi>m</mi><mo separator="true">,</mo><mi>n</mi><mi>m</mi></mrow><annotation encoding="application/x-tex">um,nm</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">u</span><span class="mord mathnormal">m</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">nm</span></span></span></span>)</p>
<p>其含义通常包括</p>
<ul>
<li>波长间隔的大小</li>
<li>传感器波段数量的多少</li>
<li>各波段中心波长位置</li>
</ul>
<p><strong>意义</strong></p>
<p>光谱分辨率高则光谱信息丰富，可探测出不同地物在光谱上的细微变化，微小差异，提高辨识地物的能力和精度。</p>
<p><strong>时间分辨率</strong> 指对同一地点获取遥感数据所需的最小的时间间隔，即重访周期。</p>
<p>时间分辨率的大小，除了主要决定于飞行器的回归周期外，还与遥感探测器、遥感系统的设计等因素直接相关。</p>
<p><strong>意义</strong></p>
<p>用于动态监测、长时间序列分析，利用最合适时相的数据降低识别地物的难度，提高识别地物的精度。</p>
<p><strong>辐射分辨率</strong></p>
<p>指传感器接收波谱信号时能分辨的最小辐射度差，即分辨辐射差异的能力。</p>
<p>辐射分辨率反映探测器的灵敏度，可以通过数据的量化级体现，但不等于量化等级。</p>
<h3 id="早期中国遥感大事件">早期中国遥感大事件</h3>
<ul>
<li>中国遥感的摇篮：云南腾冲航空遥感实验 1978年开展了我国第一次大规模、多学科、综合性遥感应用试验</li>
<li>天津-渤海湾城市遥感实验</li>
<li>四川二滩水电站能源遥感实验</li>
</ul>
<p>以上三个被称为我国遥感事业起步的三大战役。</p>
<hr>
<p>我国第一颗商用卫星：吉林一号卫星(高分辨率遥感卫星)。由2015年10月7日，在酒泉卫星发射中心发射成功，一共有四颗卫星，标志着我国航天遥感领域商业化、产业化发展迈出重要一步。</p>
<p>bilibili视频卫星，央视频号等，都是跟长光卫星合作打造的商用卫星。</p>
<p>高景一号，2016年12月28日，太原发射中心。全色分辨率0.5m，多光谱分辨率2m，到了我国0.5m级商业遥感数据被国外垄断的现状。</p>
<hr>
<h2 id="四、遥感发展的趋势">四、遥感发展的趋势</h2>
<p>1️⃣ <strong>多层次立体观测</strong></p>
<ul>
<li>地面</li>
<li>航空</li>
<li>航天</li>
</ul>
<p>2️⃣ <strong>传感器</strong></p>
<ul>
<li>单一<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>→</mo></mrow><annotation encoding="application/x-tex">\to</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.3669em;"></span><span class="mrel">→</span></span></span></span>多传感器、多平台</li>
</ul>
<p>3️⃣ <strong>分辨率</strong></p>
<ul>
<li>分辨率不断提高</li>
</ul>
<p>4️⃣ <strong>全天候、全天时、全谱段</strong></p>
<ul>
<li>可见光/近红外、短波红外、热红外、微波</li>
</ul>
<p><strong>5️⃣ 静态观测、动态观测</strong></p>
<p>​	多时相、短周期</p>
<p><strong>6️⃣ 定性、定量</strong></p>
<ul>
<li>从定性到半定量，再到定量</li>
</ul>
<p><strong>7️⃣ 遥感平台小型化</strong></p>
<p><strong>8️⃣ 多源数据综合应用</strong></p>
<h3 id="北斗卫星导航">北斗卫星导航</h3>
<p><strong>1994-2020.6.23</strong>历时26年。</p>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 不想学辣 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 遥感科学 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[遥感科学]]></title>
      <url>/2022/08/30/%E3%80%90%E9%81%A5%E6%84%9F%E7%A7%91%E5%AD%A6%E3%80%91%E9%81%A5%E6%84%9F%E7%A7%91%E5%AD%A6A/</url>
      <content type="html"><![CDATA[<h1>遥感科学</h1>
<hr>
<h2 id="Lesson-1">Lesson 1</h2>
<blockquote>
<p>date 2022.8.30</p>
</blockquote>
<p><strong>姜小光老师</strong></p>
<ul>
<li><a href="mailto:xgjiang@ucas.ac.cn">xgjiang@ucas.ac.cn</a></li>
</ul>
<p><strong>参考教材</strong></p>
<p>《遥感应用分析原理与方法》赵英时等。</p>
<hr>
<h2 id="第一章-遥感科学的发展🏷️">第一章 遥感科学的发展🏷️</h2>
<h3 id="一、遥感的起源于发展">一、遥感的起源于发展</h3>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 不想学辣 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 遥感科学 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Data Mining]]></title>
      <url>/2022/08/29/%E3%80%90Data%20Mining%E3%80%91%E8%AF%BE%E7%A8%8B/</url>
      <content type="html"><![CDATA[<h1>Introduction</h1>
<hr>
<p>Tutor: LiuYing</p>
<p>Main Contents:</p>
<ul>
<li>
<p>Who’s LiuYing</p>
<ul>
<li>PKU CS</li>
<li>Northwest University of USA</li>
</ul>
</li>
<li>
<p>Scores</p>
<ul>
<li>30% daily work</li>
<li>40% group work</li>
<li>30% Final test</li>
</ul>
</li>
<li>
<p>How to study this class</p>
<ul>
<li>In English</li>
<li>Do it early</li>
<li>communicate with teach</li>
<li>enhance study ability</li>
</ul>
</li>
<li>
<p>the motivation of Data Mining.</p>
</li>
<li>
<p>Four space of Data Mining.</p>
<ul>
<li>Useful</li>
<li>Understandable</li>
<li>valid</li>
<li>novel</li>
</ul>
</li>
<li>
<p>Kaggle competition</p>
</li>
</ul>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 不想学辣 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 数据分析 </tag>
            
            <tag> 数据挖掘 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Ucas选课]]></title>
      <url>/2022/08/25/UCAS%E9%80%89%E8%AF%BE/</url>
      <content type="html"><![CDATA[<h1>UCAS选课</h1>
<hr>
<h2 id="一、选课方式">一、选课方式</h2>
<p>登录<a href="https://sep.ucas.ac.cn">选课系统</a></p>
<h2 id="二、选课要求">二、选课要求</h2>
<h3 id="公共必修课">公共必修课</h3>
<p>1.《硕士学位英语》与《博士学位英语》由外语系开设，选课要求见附件1。</p>
<p>2.《新时代中国特色社会主义理论与实践》（以下简称“中特”）以及《自然辩证法概论》（以下简称“自辩”）由马克思主义学院在秋季学期开设。每位同学选择1个“中特”和1个“自辩”班级。</p>
<p>3.《学术道德与学术写作规范》。研究生须选择通论和分论班级各1个，通论班级由公共政策与管理学院开设，分论班级由本院系开设，可在同一学年的不同学期分别修读通论和分论，学年末所有通论和分论班级均结课且上传成绩后再根据通论和分论的成绩计算总成绩。通论和分论均通过视为课程通过。</p>
<p>4.《工程伦理》为工程类研究生公共必修课，由工程科学学院开设。每位工程硕士须选择1个通论班级和3个分论班级，不可跨学期修读，若秋季选课但未通过，须在春季学期重新选课。</p>
<hr>
<h3 id="公共选修课">公共选修课</h3>
<p>1.公共政策与管理学院和马克思主义学院的核心课和普及课可以作为公共选修课，选课时学生须自行将课程属性设置为公共选修课，具体课程信息请查看附件2《两用课程信息表》。</p>
<p>2.体育类公选课由体育部开设，每位学生每学期<strong>限选1门</strong>。</p>
<p>3.“人文系列讲座”课程（1学分），学生全学年听满<strong>20学时及以</strong>上获得该课程学分。</p>
<hr>
<h3 id="专业课程">专业课程</h3>
<p>包括一级学科核心课、一级学科普及课、一级学科研讨课、专业核心课、专业普及课、专业研讨课和科学前沿讲座。</p>
<p>1.每位学术型研究生须在导师和培养单位的指导下，修读本专业所属<strong>一级学科核心课</strong>以及<strong>一级学科下各专业核心课</strong>不少于<strong>2</strong>门；只开设1门核心课的学科或专业，学生须修读该核心课；未开设核心课的学科或专业，学生按导师或培养单位的意见进行选课。</p>
<blockquote>
<p><strong>专业硕士按所在培养单位的培养方案要求修读包括核心课在内的所有专业课程。</strong></p>
</blockquote>
<p>2.研究生须选择本学科的专业类课程以及经导师和培养单位审核的相关学科的专业类课程作为专业学位课。</p>
<p>3.“科学前沿讲座”课程（1学分），学生全学年听满20学时及以上获得该课程学分。</p>
<p><strong>（四）选课学分要求</strong></p>
<p>本学期每人选课总学分<strong>不得低于10学分</strong>，不含人文系列讲座和科学前沿讲座。</p>
<hr>
<p><strong>关于我的选课</strong></p>
<img src="/2022/08/25/UCAS%E9%80%89%E8%AF%BE/image-20220825151103990.png" alt="image-20220825151103990" style="zoom:50%;">
<ul>
<li>中特✅</li>
<li>自辩✅</li>
<li>学术❎</li>
<li>工程❎</li>
<li>英语❎</li>
</ul>
<p><strong>学期时间</strong></p>
<img src="/2022/08/25/UCAS%E9%80%89%E8%AF%BE/image-20220825154410507.png" alt="image-20220825154410507" style="zoom: 33%;">
<p><strong>课程分类</strong></p>
<img src="/2022/08/25/UCAS%E9%80%89%E8%AF%BE/image-20220825154545951.png" alt="image-20220825154545951" style="zoom: 33%;">
<img src="/2022/08/25/UCAS%E9%80%89%E8%AF%BE/image-20220825154636639.png" alt="image-20220825154636639" style="zoom: 50%;">
<p><strong>学分分配</strong></p>
<img src="/2022/08/25/UCAS%E9%80%89%E8%AF%BE/image-20220825154654483.png" alt="image-20220825154654483" style="zoom:50%;">
<p><strong>必选课程</strong></p>
<img src="/2022/08/25/UCAS%E9%80%89%E8%AF%BE/image-20220825154918321.png" alt="image-20220825154918321" style="zoom:50%;">
<img src="/2022/08/25/UCAS%E9%80%89%E8%AF%BE/image-20220825154952112.png" alt="image-20220825154952112" style="zoom:50%;">
<p><strong>审核流程</strong></p>
<img src="/2022/08/25/UCAS%E9%80%89%E8%AF%BE/image-20220825155046073.png" alt="image-20220825155046073" style="zoom:50%;">
<hr>
<h2 id="现有课程"><strong>现有课程</strong></h2>
<p><strong>资环学院🌍</strong></p>
<p>1️⃣ 现代地图学</p>
<p>2️⃣ 现代自然地理学</p>
<p>3️⃣ 当代人文与经济地理学</p>
<p>4️⃣ 环境地学导论</p>
<p>5️⃣ <a href="https://jwxk.ucas.ac.cn/course/coursetime/222844">现代水文学与水资源学</a></p>
<p>6️⃣ <a href="https://jwxk.ucas.ac.cn/course/coursetime/222843">冰冻圈科学概论</a></p>
<p>7️⃣ <a href="https://jwxk.ucas.ac.cn/course/coursetime/223423">湖泊学概论</a></p>
<p>8️⃣ <a href="https://jwxk.ucas.ac.cn/course/coursetime/223424">湖泊沉积与环境</a></p>
<p>9️⃣ <a href="https://jwxk.ucas.ac.cn/course/coursetime/222847">产业与交通地理学</a></p>
<p>🔟 <a href="https://jwxk.ucas.ac.cn/course/coursetime/223486">旅游资源评价与利用</a></p>
<hr>
<p>1️⃣ <a href="https://jwxk.ucas.ac.cn/course/coursetime/222849">人口流动与城镇化讨论班</a></p>
<p>2️⃣<a href="https://jwxk.ucas.ac.cn/course/coursetime/222574">全球导航卫星系统原理与应用</a></p>
<p>3️⃣ <a href="https://jwxk.ucas.ac.cn/course/coursetime/222569">遥感物理</a></p>
<p>4️⃣ <a href="https://jwxk.ucas.ac.cn/course/coursetime/222852">高光谱遥感</a></p>
<p>5️⃣<a href="https://jwxk.ucas.ac.cn/course/coursetime/223118">资源经济学</a></p>
<p>6️⃣ 资源科学纲要</p>
<p>7️⃣ <a href="https://jwxk.ucas.ac.cn/course/coursetime/223120"> 资源生态学</a></p>
<p>8️⃣<a href="https://jwxk.ucas.ac.cn/course/coursetime/227257">环境与自然资源系统建模</a></p>
<p>9️⃣ <a href="https://jwxk.ucas.ac.cn/course/coursetime/222851">资源循环利用与生态经济</a></p>
<p>🔟 <a href="https://jwxk.ucas.ac.cn/course/coursetime/223400">自然与文化遗产</a></p>
<hr>
<p>1️⃣ <a href="https://jwxk.ucas.ac.cn/course/coursetime/222853">全球变化生态学</a></p>
<p>2️⃣<a href="https://jwxk.ucas.ac.cn/course/coursetime/222560">生态系统生态学A</a></p>
<p>4️⃣<a href="https://jwxk.ucas.ac.cn/course/coursetime/223389">景观与区域生态学</a></p>
<p>5️⃣ <a href="https://jwxk.ucas.ac.cn/course/coursetime/222854">环境规划与管理</a></p>
<p>6️⃣ <a href="https://jwxk.ucas.ac.cn/course/coursetime/222561">生态统计学——原理与实践</a></p>
<p>7️⃣ <a href="https://jwxk.ucas.ac.cn/course/coursetime/223509">植物生理生态学</a></p>
<p>8️⃣<a href="https://jwxk.ucas.ac.cn/course/coursetime/223125">土壤物理学</a></p>
<p>9️⃣<a href="https://jwxk.ucas.ac.cn/course/coursetime/223437">生态遥感原理、技术与方法</a></p>
<p>🔟 <a href="https://jwxk.ucas.ac.cn/course/coursetime/223439"> 环境变化的生态效应</a></p>
<hr>
<p>1️⃣ <a href="https://jwxk.ucas.ac.cn/course/coursetime/223644">生态信息学原理、方法和应用</a></p>
<p>2️⃣<a href="https://jwxk.ucas.ac.cn/course/coursetime/223643">大尺度宏观生态系统科学</a></p>
<p>4️⃣ <a href="https://jwxk.ucas.ac.cn/course/coursetime/222856">高原生态系统生态学</a></p>
<p>5️⃣ <a href="https://jwxk.ucas.ac.cn/course/coursetime/222588">恢复生态学前沿</a></p>
<p>6️⃣ <a href="https://jwxk.ucas.ac.cn/course/coursetime/222858">大气环境化学</a></p>
<p>7️⃣ <a href="https://jwxk.ucas.ac.cn/course/coursetime/222857">大气污染控制技术</a></p>
<p>8️⃣<a href="https://jwxk.ucas.ac.cn/course/coursetime/222859">大气污染监测技术</a></p>
<p>9️⃣ <a href="https://jwxk.ucas.ac.cn/course/coursetime/223126">环境土壤学</a></p>
<p>🔟 <a href="https://jwxk.ucas.ac.cn/course/coursetime/223127">环境修复与资源工程</a></p>
<hr>
<p>1️⃣ <a href="https://jwxk.ucas.ac.cn/course/coursetime/222862">现代环境分析</a></p>
<p>2️⃣<a href="https://jwxk.ucas.ac.cn/course/coursetime/222861">高等环境化学</a></p>
<p>4️⃣ 高等环境生物学</p>
<p>5️⃣ 环境分子毒理学</p>
<p>6️⃣ 环境毒理学研究方法</p>
<p>7️⃣ 环境污染控制化学</p>
<p>8️⃣ 纳米毒理学</p>
<p>9️⃣ 环境纳米科学与技术</p>
<p>🔟 环境影响评价</p>
<hr>
<p>1️⃣ 新型有机污染物前沿进展</p>
<p>2️⃣ 水质界面过程原理</p>
<p>4️⃣ 饮用水安全</p>
<p>5️⃣ 膜分离原理与技术</p>
<p>6️⃣ 工业废气控制过程技术与工程设计</p>
<p>7️⃣ 环境工程数学模型与Matlab应用</p>
<p>8️⃣ 高级废水生物处理工程</p>
<p>9️⃣ 水处理药剂与材料</p>
<hr>
<p><strong>电子学院⚡</strong></p>
<blockquote>
<p>与遥感相关的可选课程</p>
</blockquote>
<p>1️⃣ 微波遥感概论</p>
<p>2️⃣ 合成孔径雷达原理</p>
<p>4️⃣ 干涉合成孔径雷达技术</p>
<p>5️⃣ 大气遥感</p>
<p>6️⃣ 城市环境遥感</p>
<p>7️⃣ 现代雷达系统</p>
<hr>
<p><strong>目前已选课程(占用中🏷️ )</strong></p>
<table>
<thead>
<tr>
<th style="text-align:center">课程</th>
<th style="text-align:center">学分</th>
<th style="text-align:center">学时</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">遥感科学A</td>
<td style="text-align:center">4</td>
<td style="text-align:center">76</td>
</tr>
<tr>
<td style="text-align:center">海洋遥感</td>
<td style="text-align:center">2</td>
<td style="text-align:center">42</td>
</tr>
<tr>
<td style="text-align:center">热红外遥感</td>
<td style="text-align:center">2.5</td>
<td style="text-align:center">48</td>
</tr>
<tr>
<td style="text-align:center">模式识别</td>
<td style="text-align:center">2</td>
<td style="text-align:center">40</td>
</tr>
<tr>
<td style="text-align:center">数据挖掘</td>
<td style="text-align:center">2</td>
<td style="text-align:center">40</td>
</tr>
<tr>
<td style="text-align:center">图像处理</td>
<td style="text-align:center">2</td>
<td style="text-align:center">40</td>
</tr>
<tr>
<td style="text-align:center">区域可持续发展理论与实践</td>
<td style="text-align:center">3</td>
<td style="text-align:center">60</td>
</tr>
<tr>
<td style="text-align:center">高光谱遥感基础与数据处理</td>
<td style="text-align:center">4</td>
<td style="text-align:center">60</td>
</tr>
</tbody>
</table>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 琐碎日常 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 杂谈 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Python位运算]]></title>
      <url>/2022/08/23/%E3%80%90Python%E3%80%91%E4%BD%8D%E8%BF%90%E7%AE%97/</url>
      <content type="html"><![CDATA[<h2 id="运算符">运算符</h2>
<table>
<thead>
<tr>
<th style="text-align:center">符号</th>
<th style="text-align:center">意义</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">&amp;</td>
<td style="text-align:center">与，1&amp;1=1，其他情况为0</td>
</tr>
<tr>
<td style="text-align:center">|</td>
<td style="text-align:center">或，0|0=0，其他为1</td>
</tr>
<tr>
<td style="text-align:center">~</td>
<td style="text-align:center">逐位取反</td>
</tr>
<tr>
<td style="text-align:center">^</td>
<td style="text-align:center">异或，同0异1</td>
</tr>
<tr>
<td style="text-align:center">&lt;&lt;</td>
<td style="text-align:center">左移</td>
</tr>
<tr>
<td style="text-align:center">&gt;&gt;</td>
<td style="text-align:center">右移</td>
</tr>
</tbody>
</table>
<p>简单来看一下操作吧：</p>
<p><strong>倍乘</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="number">5</span>&lt;&lt;<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 10</span></span><br></pre></td></tr></table></figure>
<p>5: <code>101=1*4+0*2+1*</code></p>
<p>5&lt;&lt;1: <code>1010=1*8+0*4+1*2+0*1=2(1*4+0*2+1*1+0*1)=2(101)</code></p>
<p><strong>倍除</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="number">5</span>&gt;&gt;<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 2</span></span><br></pre></td></tr></table></figure>
<p><strong>奇数判断</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A&amp;<span class="number">1</span>==<span class="number">1</span>?</span><br></pre></td></tr></table></figure>
<p><strong>案例</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">coinChange</span>(<span class="params">self, coins, amount: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> amount:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="comment"># 将减法转换为除法进行运算</span></span><br><span class="line">        <span class="comment"># 一旦最低位为1，则说明找到解，停止运算</span></span><br><span class="line">        dp = <span class="number">1</span> &lt;&lt; amount</span><br><span class="line">        res = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> dp:</span><br><span class="line">            tmp = <span class="number">0</span></span><br><span class="line">            res += <span class="number">1</span></span><br><span class="line">            <span class="comment"># 每一轮运算计算一遍dp除以2**i得到的所有可能解</span></span><br><span class="line">            <span class="keyword">for</span> coin <span class="keyword">in</span> coins:</span><br><span class="line">                <span class="comment"># tmp用于存储运算的中间结果</span></span><br><span class="line">                <span class="comment"># dp &gt;&gt; coin 实际上是进行除法运算：dp//2**coin</span></span><br><span class="line">                <span class="comment"># 使用位运算“或”来保存全部除法运算结果中的‘1’，实现批量运算</span></span><br><span class="line">                <span class="comment"># ps:这也是二进制移位的一个神奇之处，大家可以手动模拟一下这个过程</span></span><br><span class="line">                tmp |= dp &gt;&gt; coin</span><br><span class="line">            <span class="comment"># 一旦末尾出现1，则返回结果</span></span><br><span class="line">            <span class="keyword">if</span> tmp &amp; <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">return</span> res</span><br><span class="line">            <span class="comment"># 将本轮运算的全部运算结果送入下一轮计算</span></span><br><span class="line">            dp = tmp</span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span></span><br></pre></td></tr></table></figure>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 不想学辣 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Python </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[常见词]]></title>
      <url>/2022/08/23/%E3%80%90%E8%8B%B1%E8%AF%AD%E3%80%91%E5%B8%B8%E8%A7%81%E8%AF%8D/</url>
      <content type="html"><![CDATA[<h2 id="8-23">8/23</h2>
<p><strong>expense</strong></p>
<ul>
<li>
<p>n. 花销，费用，支出</p>
</li>
<li>
<p>at the expense of … 以…为代价，在牺牲…的情况下</p>
</li>
</ul>
<p><strong>efficiency</strong></p>
<ul>
<li>n. 效率，效能</li>
<li>increase efficiency</li>
</ul>
<p><strong>establish</strong></p>
<ul>
<li>vt. 简历，创立，证实</li>
<li>establish a relationship</li>
<li>establish oneself 使自己立足</li>
</ul>
<p><strong>expand</strong></p>
<ul>
<li>vt. 扩充，扩大</li>
<li>vi. 详谈，详诉</li>
<li>expand the business</li>
</ul>
<p><strong>exact</strong></p>
<ul>
<li>adj. 精确的，严谨的，精密的</li>
<li>vt. 勒索，索取</li>
<li>your exact words 原话</li>
</ul>
<p><strong>effect</strong></p>
<ul>
<li>n. 影响，结果，特效，效果</li>
<li>v. 引起，使发生</li>
<li>a negative effect</li>
<li>in effect 实际上</li>
<li>take effect 见效</li>
<li>put sth into effect 实施，实行</li>
</ul>
<p><strong>examine</strong></p>
<ul>
<li>vt. 仔细研究，仔细检查，测试</li>
<li>examine data 剖析数据</li>
<li>examine sb on sth</li>
</ul>
<p><strong>efficient</strong></p>
<ul>
<li>adj. 效率高的</li>
<li>an efficient method</li>
</ul>
<p><strong>effective</strong></p>
<ul>
<li>adj. 有效的，实际的</li>
<li>effective power</li>
<li>an effective method</li>
</ul>
<p>He made an effective method, which is so efficient.</p>
<p><strong>exist</strong></p>
<ul>
<li>vi. 存在，生存</li>
</ul>
<p><strong>estate</strong></p>
<ul>
<li>n. 庄园，遗产</li>
<li>n. 住宅区，工业区</li>
<li>inherit the estate 继承遗产</li>
<li>a housing estate 住宅区</li>
</ul>
<p><strong>comprehension</strong></p>
<ul>
<li>n. 理解力</li>
</ul>
<p><strong>experience</strong></p>
<ul>
<li>n. 经历</li>
</ul>
<p><strong>experienced</strong></p>
<ul>
<li>adj. 经验丰富的</li>
</ul>
<p><strong>identify</strong></p>
<ul>
<li>vt. 认出，发现，识别</li>
<li>vt. 显示身份</li>
</ul>
<p><strong>intestine</strong></p>
<ul>
<li>n. 肠</li>
<li>adj. 内部的</li>
</ul>
<p><strong>thermal</strong></p>
<ul>
<li>adj. 热的</li>
</ul>
<hr>
<p><strong>performance</strong></p>
<ul>
<li>n. 表演，情况，<strong>执行</strong>，<strong>性能</strong></li>
<li>adj. 高性能的，性能卓越的 <strong>performance compute</strong></li>
</ul>
<p><strong>implement</strong></p>
<ul>
<li>v. 执行，贯彻</li>
<li>n. 工具，手段</li>
</ul>
<p><strong>concretely</strong></p>
<ul>
<li>adv. 具体地</li>
</ul>
<p><strong>creatively</strong></p>
<ul>
<li>adv. 创造性地</li>
</ul>
<p><strong>plagiarism</strong></p>
<ul>
<li>n. 剽窃</li>
</ul>
<p><strong>explosive</strong></p>
<ul>
<li>adj. 易爆的</li>
<li>n. 炸药</li>
</ul>
<p><strong>transaction</strong></p>
<ul>
<li>n. 交易，业务，公报</li>
</ul>
<p><strong>competitive pressure</strong></p>
<ul>
<li>竞争压力</li>
</ul>
<p><strong>starving for knowledge</strong></p>
<ul>
<li>渴望知识</li>
</ul>
<p><strong>starve</strong></p>
<ul>
<li>挨饿，需要，使极其缺乏</li>
</ul>
<p><strong>pattern</strong></p>
<ul>
<li>n. 模式</li>
</ul>
<p><strong>complexity</strong></p>
<ul>
<li>n. 复杂性</li>
<li>complexity of 复杂度</li>
</ul>
<p><strong>hypothesis</strong></p>
<ul>
<li>n. 假说</li>
</ul>
<p><strong>frequently</strong></p>
<ul>
<li>adv. 经常地</li>
</ul>
<p><strong>occur</strong></p>
<ul>
<li>v. 发生，存在，出现</li>
</ul>
<p><strong>promotional</strong></p>
<ul>
<li>adj. 促销的，推广的</li>
</ul>
<p><strong>assign</strong></p>
<ul>
<li>
<p>v. 分配，布置，转让，<strong>赋值</strong></p>
</li>
<li>
<p>assign a new record to one of  several predefined classes 将一条新记录分配给几个预定义类中的一个</p>
</li>
</ul>
<p><strong>bankrupt</strong></p>
<ul>
<li>adj. 破产的</li>
</ul>
<p><strong>profitability</strong></p>
<ul>
<li>n. 盈利能力</li>
</ul>
<p><strong>anomaly</strong></p>
<ul>
<li>n. 异常现象,离群点</li>
</ul>
<p><strong>citation</strong></p>
<ul>
<li>n. 引用，引语</li>
</ul>
<p><strong>domain</strong></p>
<ul>
<li>n. 领域,范围</li>
<li>domain experts 领域专家</li>
</ul>
<p><strong>temporal</strong></p>
<ul>
<li>adj. 时间的，世俗的</li>
<li>n. 世间万物，暂存的事物</li>
<li>spatio-temporal data 时空数据</li>
</ul>
<p><strong>decision makers</strong></p>
<ul>
<li>决策者</li>
</ul>
<p><strong>simulation</strong></p>
<ul>
<li>n. 模拟</li>
</ul>
<p><strong>disunderstand</strong></p>
<ul>
<li>不明白</li>
</ul>
<p><strong>incomprehension</strong></p>
<ul>
<li>不理解</li>
</ul>
<p><strong>unapprehensive</strong></p>
<ul>
<li>不理解的</li>
</ul>
<hr>
<p><strong>cross disciplines</strong></p>
<ul>
<li>跨学科</li>
</ul>
<p><strong>sophisticated</strong></p>
<ul>
<li>先进的，在行的</li>
</ul>
<p><strong>Scalable</strong></p>
<ul>
<li>可扩展的</li>
</ul>
<p><strong>Practical</strong></p>
<ul>
<li>切实可行的，真实的</li>
</ul>
<p><strong>partition</strong></p>
<ul>
<li>n. 隔墙，隔板，分裂，分治</li>
<li>v. 分割，分裂</li>
</ul>
<p><strong>considerably</strong></p>
<ul>
<li>adv. 非常，相当多地</li>
</ul>
<p><strong>heterogeneous</strong></p>
<ul>
<li>adj. 参差的，异质的</li>
<li>n. 异类</li>
</ul>
<p><strong>relevant</strong></p>
<ul>
<li>adj. 有关的</li>
</ul>
<p><strong>prior</strong></p>
<ul>
<li>adj. 先前的，先验的</li>
</ul>
<p><strong>invariant</strong></p>
<ul>
<li>adj. 不变的</li>
</ul>
<p><strong>optimization</strong></p>
<ul>
<li>优化</li>
</ul>
<hr>
<p><strong>axiomatic</strong></p>
<ul>
<li>adj. 公理的，自明的</li>
</ul>
<p><strong>blurry</strong></p>
<ul>
<li>adj. 模糊不清的</li>
</ul>
<p><strong>China-born</strong></p>
<ul>
<li>中国裔</li>
</ul>
<p><strong>as A put in B</strong></p>
<ul>
<li>正如A在B中说的</li>
</ul>
<p><strong>partly</strong></p>
<ul>
<li>adv. 部分地，在某种程度上</li>
</ul>
<p><strong>forged</strong></p>
<ul>
<li>adj. 锻造</li>
<li>v. 伪造，锻造</li>
</ul>
<p><strong>grocery</strong></p>
<ul>
<li>n. 食品杂货店</li>
</ul>
<p><strong>supervisor</strong></p>
<ul>
<li>导师</li>
</ul>
<p><strong>reflection</strong></p>
<ul>
<li>n. 反射，倒影，<strong>反思</strong>，反省，<strong>想法</strong></li>
</ul>
<p><strong>entangle with</strong></p>
<ul>
<li>交战、卷入、纠缠在一起</li>
</ul>
<p><strong>perspective</strong></p>
<ul>
<li>观点</li>
</ul>
<p><strong>instead</strong></p>
<ul>
<li>adv. 代替，顶替，<strong>反而</strong></li>
</ul>
<p><strong>notion</strong></p>
<ul>
<li>概念，想法</li>
</ul>
<hr>
<p><strong>fluctuate</strong></p>
<ul>
<li>波动，起伏不定</li>
</ul>
<p><strong>ambiguous</strong></p>
<ul>
<li>adj. 模棱两可的，不确定的</li>
</ul>
<p><strong>disconcerting</strong></p>
<ul>
<li>adj. 令人不安的，打扰人的</li>
</ul>
<p><strong>concert</strong></p>
<ul>
<li>n. 音乐会，一致，<strong>和谐</strong></li>
<li>v. 协调，<strong>共同协定</strong></li>
</ul>
<p><strong>essentially</strong></p>
<ul>
<li>adv. 本质上，根本上</li>
</ul>
<p><strong>self-contained</strong></p>
<ul>
<li>独立的，设备齐全的</li>
</ul>
<p><strong>inherently</strong></p>
<ul>
<li>adv. 内在的，固有的</li>
</ul>
<p><strong>rational</strong></p>
<ul>
<li>理性的</li>
</ul>
<p><strong>mind-bound</strong></p>
<ul>
<li>思想受到限制</li>
</ul>
<p><strong>skepticism</strong></p>
<ul>
<li>n. 怀疑态度，怀疑论</li>
</ul>
<p><strong>particular puzzle</strong></p>
<ul>
<li>特定的难题</li>
</ul>
<p><strong>decreed</strong></p>
<ul>
<li>adj. 任命的</li>
<li>v. 颁布法令(decree)</li>
</ul>
<p><strong>discern</strong></p>
<ul>
<li>v.(艰难地或努力地)看出，察觉，了解，辨识，<strong>分辨</strong></li>
</ul>
<p><strong>trade-off</strong></p>
<ul>
<li>n. <strong>平衡</strong>，协调，<strong>让步</strong></li>
</ul>
<p><strong>fickly</strong></p>
<ul>
<li>adj. 浮躁的，异变的，变化无常的</li>
</ul>
<p><strong>erratic</strong></p>
<ul>
<li>adj. 不稳定的，难以预测的</li>
<li>n. 漂泊无定的人</li>
</ul>
<p><strong>constitution</strong></p>
<ul>
<li>宪法，章程，体格</li>
</ul>
<p><strong>detach</strong></p>
<ul>
<li>v. 拆下，分离，脱离，分派</li>
</ul>
<p><strong>coherent</strong></p>
<ul>
<li>adj. 有条理的，<strong>连贯的</strong>，相干的，易于理解的</li>
</ul>
<p><strong>contemplative</strong></p>
<ul>
<li>adj. 沉思的，冥想的</li>
<li>n. 宗教思想家</li>
</ul>
<hr>
<p><strong>respected professor</strong></p>
<ul>
<li>令人尊敬的教授</li>
</ul>
<p><strong>identify as</strong></p>
<ul>
<li>把…视为</li>
</ul>
<p><strong>mind and matter</strong></p>
<ul>
<li>精神和物质</li>
</ul>
<p><strong>separate</strong></p>
<ul>
<li>分离</li>
</ul>
<p><strong>tend to proceed from the assumption</strong></p>
<ul>
<li>tend to 倾向于</li>
<li>proceed from 出发</li>
<li>assumption 假设</li>
<li>proceed v. 开展行动，来自，前往; n. 收入，收益</li>
</ul>
<p><strong>a sharp distinction</strong></p>
<ul>
<li>一个明显的区别</li>
</ul>
<p><strong>simple lives inside the skull</strong></p>
<ul>
<li>这个simple表示简单</li>
<li>但是可以引申为： 仅仅，只</li>
</ul>
<p><strong>recall</strong></p>
<ul>
<li>回想起，召回，收回</li>
<li>记忆力，记性，召回，撤销</li>
</ul>
<p><strong>confine</strong></p>
<ul>
<li>限制，局限</li>
<li>边界，限制</li>
</ul>
<p><strong>irrespective</strong></p>
<ul>
<li>adj. 不顾</li>
</ul>
<p><strong>respective</strong></p>
<ul>
<li>adj. 各自的，分别的</li>
</ul>
<p><strong>experimental</strong></p>
<ul>
<li>实验的</li>
</ul>
<p><strong>but even then</strong></p>
<ul>
<li>即使这样</li>
</ul>
<p><strong>presume</strong></p>
<ul>
<li>假设，摄像，料想</li>
</ul>
<p><strong>enquiry</strong></p>
<ul>
<li>n. 查询，询问</li>
</ul>
<p><strong>over time</strong></p>
<ul>
<li>超时</li>
<li>随时间过去</li>
</ul>
<p><strong>assaulted</strong></p>
<ul>
<li>武力攻击，袭击，解决</li>
</ul>
<p><strong>witness</strong></p>
<ul>
<li>目击者</li>
<li>目睹，见证</li>
</ul>
<p><strong>experiment</strong></p>
<ul>
<li>实验</li>
</ul>
<p><strong>epileptic</strong></p>
<ul>
<li>癫痫病</li>
</ul>
<p><strong>billow</strong></p>
<ul>
<li>n. 巨浪</li>
<li>v. 翻腾</li>
</ul>
<p><strong>distress</strong></p>
<ul>
<li>n. 忧虑，悲伤，贫困</li>
<li>v. 使悲伤，使忧虑</li>
</ul>
<p><strong>diffusion</strong></p>
<ul>
<li>n. 扩散，传播</li>
</ul>
<p><strong>dilute</strong></p>
<ul>
<li>v. 稀释，冲淡，削弱，降低</li>
<li>adj. 稀释了的，淡化了的</li>
</ul>
<hr>
<p><strong>numerical</strong></p>
<ul>
<li>adj. 数字的，用数字表示的</li>
</ul>
<p><strong>wipe away</strong></p>
<ul>
<li>擦去</li>
</ul>
<p><strong>vital contextual</strong></p>
<ul>
<li>vital 至关重要</li>
<li>contextual <strong>上下文</strong></li>
<li>至关重要的上下文</li>
</ul>
<p><strong>backdrop</strong></p>
<ul>
<li>幕布，背景</li>
<li>位于…后面</li>
</ul>
<p><strong>domestic dispute</strong></p>
<ul>
<li>内部争端</li>
<li>家庭暴力</li>
</ul>
<p><strong>reluctant</strong></p>
<ul>
<li>adj. 勉强的，不情愿的</li>
</ul>
<p><strong>more over</strong></p>
<ul>
<li>adv. 此外，而且</li>
</ul>
<p><strong>is there a way of</strong></p>
<ul>
<li>有方法吗</li>
</ul>
<p><strong>reconcile</strong></p>
<ul>
<li>v. 协调，和解</li>
</ul>
<p><strong>in ward</strong></p>
<ul>
<li>内心的，精神的</li>
<li>内向，想自己</li>
<li>内部，心脏</li>
</ul>
<p><strong>the answer lay in dialogue</strong></p>
<ul>
<li>the answer lay in 答案就在</li>
<li>dialogue 对话中</li>
</ul>
<p><strong>evaluate</strong></p>
<ul>
<li>评估，评价，估值</li>
</ul>
<p><strong>existence</strong></p>
<ul>
<li>存在，生活</li>
</ul>
<p><strong>luminous</strong></p>
<ul>
<li>夜光的，光亮的，发光的</li>
</ul>
<p><strong>struggle to summary your thought</strong></p>
<ul>
<li>struggle to <strong>努力</strong></li>
<li>summary 总结</li>
<li>努力总结你的想法</li>
</ul>
<p><strong>vivify</strong></p>
<ul>
<li>使生动，活跃</li>
</ul>
<p><strong>uncover</strong></p>
<ul>
<li>揭露，发现，发掘，挖出</li>
</ul>
<p><strong>conceive</strong></p>
<ul>
<li>构思，摄像，怀孕</li>
</ul>
<p><strong>depict as</strong></p>
<ul>
<li>描写成</li>
</ul>
<p><strong>by contrast</strong></p>
<ul>
<li>相比之下</li>
</ul>
<p><strong>emphasise</strong></p>
<ul>
<li>强调</li>
</ul>
<p><strong>scaffolding</strong></p>
<ul>
<li>脚手架</li>
</ul>
<hr>
<p><strong>a grimmer example</strong></p>
<ul>
<li>更严峻(残酷)的栗子</li>
</ul>
<p><strong>solitary confinement in prisons</strong></p>
<ul>
<li>solitary <strong>独自的</strong></li>
<li>监狱中的单独监禁</li>
</ul>
<p><strong>introspection</strong></p>
<ul>
<li>内省，反省</li>
</ul>
<p><strong>dissolve</strong></p>
<ul>
<li>解散，消失，溶解</li>
<li>淡出</li>
</ul>
<p><strong>punish</strong></p>
<ul>
<li>处罚，自责</li>
</ul>
<p><strong>anxiety</strong></p>
<ul>
<li>焦虑</li>
</ul>
<p><strong>insomnia</strong></p>
<ul>
<li>失眠</li>
</ul>
<p><strong>inadequacy</strong></p>
<ul>
<li>不充分，不足，缺乏信心</li>
</ul>
<p><strong>distorted</strong></p>
<ul>
<li>变形的，扭曲的</li>
<li>使变形，扭曲，曲解</li>
</ul>
<p><strong>deprived</strong></p>
<ul>
<li>贫困的</li>
<li><strong>剥夺</strong></li>
</ul>
<p><strong>embody</strong></p>
<ul>
<li>具体表现，体现，收录，包括，代表</li>
</ul>
<p><strong>phase</strong></p>
<ul>
<li>阶段，时期</li>
</ul>
<p><strong>but for the most part</strong></p>
<ul>
<li>在大多数情况下</li>
</ul>
<hr>
<p><strong>consummate</strong></p>
<ul>
<li>完成，实现</li>
</ul>
<p><strong>bystander</strong></p>
<ul>
<li>局外人，旁观者</li>
</ul>
<p><strong>purport</strong></p>
<ul>
<li>声称</li>
</ul>
<p><strong>inscribe</strong></p>
<ul>
<li>雕刻，印写</li>
</ul>
<p><strong>contour</strong></p>
<ul>
<li>轮廓，外形</li>
</ul>
<p><strong>inform</strong></p>
<ul>
<li>影响</li>
</ul>
<p><strong>forge</strong></p>
<ul>
<li>形成，缔造</li>
</ul>
<p><strong>crucible</strong></p>
<ul>
<li>坩埚，熔炉</li>
</ul>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 不想学辣 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 英语 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[LeetCode 百题留念]]></title>
      <url>/2022/08/22/%E3%80%90LeetCode%E3%80%91%E7%99%BE%E9%A2%98%E7%95%99%E5%BF%B5/</url>
      <content type="html"><![CDATA[<h2 id="后日谈♎">后日谈♎</h2>
<p>不知不觉已经参加在LeetCode上刷了一百题啦！！！</p>
<p>该成就于2022/8/22达成！</p>
<img src="/2022/08/22/%E3%80%90LeetCode%E3%80%91%E7%99%BE%E9%A2%98%E7%95%99%E5%BF%B5/image-20220822222053312.png" alt="image-20220822222053312" style="zoom:50%;">
<img src="/2022/08/22/%E3%80%90LeetCode%E3%80%91%E7%99%BE%E9%A2%98%E7%95%99%E5%BF%B5/image-20220822222105104.png" alt="image-20220822222105104" style="zoom:50%;">
<p>用时27天！平均每天3.74T!!!</p>
<img src="/2022/08/22/%E3%80%90LeetCode%E3%80%91%E7%99%BE%E9%A2%98%E7%95%99%E5%BF%B5/image-20220822222204107.png" alt="image-20220822222204107" style="zoom:50%;">
<p>中等题继上次60题后与简单分庭抗礼后，这一次实现了反超！！想不到，你这个萌新还是实力派！</p>
<hr>
<p>目前的大部分题型已经刷过啦！</p>
<p>包括热门tag</p>
<ul>
<li>bfs</li>
<li>dfs</li>
<li>并查集</li>
<li>二分</li>
<li>hash</li>
<li>bst</li>
<li>无向图</li>
<li>数学</li>
<li>dp</li>
<li>递归</li>
<li>迭代</li>
</ul>
<p>但还是有一些处于知识盲区，包括但不限于：</p>
<ul>
<li>有向图</li>
<li>路径分析</li>
<li>线段树</li>
<li>平衡树</li>
<li>红黑树</li>
<li>B+树</li>
<li>优先队列</li>
<li>堆</li>
<li>状态转移</li>
</ul>
<hr>
<p>周赛目前也是参加了三场！</p>
<ul>
<li>84场双赛 2372/4575 48.2%</li>
<li>85双赛 1681/4193 60%</li>
<li>307场周赛 2436/7064 65.5%</li>
</ul>
<p>总体而言，还是有所进步的！！</p>
<hr>
<p>最近也学了些黑科技：</p>
<ul>
<li>倒序并查集</li>
<li>查分数组</li>
<li>回溯构造</li>
<li>拓扑排序</li>
<li>图问题</li>
</ul>
<hr>
<p>希望两百把的时候，能过T3吧！目前的计划是：</p>
<ul>
<li>周赛+双赛</li>
<li>每日一题</li>
<li>LeetCode75 II</li>
</ul>
<p>满足以上条件，我会对目前做过的所有题进行复盘！(一天大概10道)</p>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 不想学辣 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 算法 </tag>
            
            <tag> LeetCode </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[数据分析实例--随机抽取微信接龙人员]]></title>
      <url>/2022/08/22/%E3%80%90%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E3%80%91%E5%AE%9E%E4%BE%8B%E9%9A%8F%E6%9C%BA%E9%80%89%E5%8F%96%E5%BE%AE%E4%BF%A1%E6%8E%A5%E9%BE%99%E7%9A%84%E4%BA%BA%E6%95%B0/</url>
      <content type="html"><![CDATA[<h2 id="案例-v2">案例</h2>
<p>数据分析，要求从微信接龙中随机抽取<code>35</code>名选手参加毕业典礼。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">solve</span>(<span class="params">s:<span class="built_in">str</span>,k:<span class="built_in">int</span>=<span class="number">35</span></span>)-&gt;<span class="literal">None</span>:</span><br><span class="line"></span><br><span class="line">    hashmap=defaultdict(<span class="built_in">str</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(s) <span class="keyword">as</span> f:</span><br><span class="line">        nameList=f.readlines()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> nameList:</span><br><span class="line">        hashmap[val[<span class="number">0</span>]]=(val:=i.split(<span class="string">&quot;.&quot;</span>))[<span class="number">1</span>].strip(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> random.sample(<span class="built_in">range</span>(<span class="number">1</span>,(l:=<span class="built_in">len</span>(hashmap))+<span class="number">1</span>),l-k <span class="keyword">if</span> l&gt;k <span class="keyword">else</span> <span class="number">0</span>):</span><br><span class="line">        <span class="built_in">print</span>(hashmap[<span class="built_in">str</span>(i)])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">solve(<span class="string">r&quot;C:\Users\lenovo\Desktop\新建 XLS 工作表.txt&quot;</span>)</span><br></pre></td></tr></table></figure>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 不想学辣 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 数据分析 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Collections.deque()详解]]></title>
      <url>/2022/08/22/%E3%80%90Python%E3%80%91deque()%E8%AF%A6%E8%A7%A3/</url>
      <content type="html"><![CDATA[<h1>deque()</h1>
<p>deque是栈和队列的一种广义实现，deque是&quot;double-end queue&quot;的简称；deque支持线程安全、有效内存地以近似<code>O(1)</code>的性能在deque的两端插入和删除元素，尽管list也支持相似的操作，但是它主要在固定长度操作上的优化，从而在<code>pop(0)</code>和<code>insert(0,v)</code>（会改变数据的位置和大小）上有<code>O(n</code>)的时间复杂度。</p>
<p><strong>常用方法：</strong></p>
<h2 id="append">append()</h2>
<p>从右端添加元素（<code>与list同</code>）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">st = <span class="string">&quot;abcd&quot;</span></span><br><span class="line">list1 = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">dst = deque(st)</span><br><span class="line">dlist1 = deque(list1)</span><br><span class="line">dst.append(<span class="number">4</span>)</span><br><span class="line">dlist1.append(<span class="string">&quot;k&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(dst)</span><br><span class="line"><span class="built_in">print</span>(dlist1)</span><br><span class="line"><span class="comment">#结果：</span></span><br><span class="line"><span class="comment">#deque([&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;d&#x27;, 4])</span></span><br><span class="line"><span class="comment">#deque([0, 1, 2, 3, &#x27;k&#x27;])</span></span><br></pre></td></tr></table></figure>
<h2 id="appendleft">appendleft()</h2>
<p>从左端添加元素</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">st = <span class="string">&quot;abcd&quot;</span></span><br><span class="line">list1 = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">dst = deque(st)</span><br><span class="line">dlist1 = deque(list1)</span><br><span class="line">dst.appendleft(<span class="number">4</span>)</span><br><span class="line">dlist1.appendleft(<span class="string">&quot;k&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(dst)</span><br><span class="line"><span class="built_in">print</span>(dlist1)</span><br><span class="line"><span class="comment">#结果：</span></span><br><span class="line"><span class="comment">#deque([4, &#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;d&#x27;])</span></span><br><span class="line"><span class="comment">#deque([&#x27;k&#x27;, 0, 1, 2, 3])</span></span><br></pre></td></tr></table></figure>
<h2 id="extend">extend()</h2>
<p>从右端逐个添加可迭代对象（<code>与list同</code>）<br>
Python中的可迭代对象有：列表、元组、字典、字符串</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> deque</span><br><span class="line">ex = (<span class="number">1</span>, <span class="string">&quot;h&quot;</span>, <span class="number">3</span>)</span><br><span class="line">st = <span class="string">&quot;abcd&quot;</span></span><br><span class="line">list1 = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">dst = deque(st)</span><br><span class="line">dlist1 = deque(list1)</span><br><span class="line">dst.extend(ex)</span><br><span class="line">dlist1.extend(ex)</span><br><span class="line"><span class="built_in">print</span>(dst)</span><br><span class="line"><span class="built_in">print</span>(dlist1)</span><br><span class="line"><span class="comment">#结果：</span></span><br><span class="line"><span class="comment">#deque([&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;d&#x27;, 1, &#x27;h&#x27;, 3])</span></span><br><span class="line"><span class="comment">#deque([0, 1, 2, 3, 1, &#x27;h&#x27;, 3])</span></span><br></pre></td></tr></table></figure>
<h2 id="extendleft">extendleft()</h2>
<p>从左端逐个添加可迭代对象</p>
<h2 id="pop">pop()</h2>
<p>移除列表中的一个元素（默认最右端的一个元素），并且返回该元素的值（<code>与list同</code>），如果没有元素，将会报出IndexError</p>
<h2 id="popleft">popleft()</h2>
<p>移除列表中的一个元素（默认最左端的一个元素），并且返回该元素的值，如果没有元素，将会报出IndexError</p>
<h2 id="count">count()</h2>
<p>统计队列中的元素个数（<code>与list同</code>）</p>
<h2 id="insert-index-obj">insert(index,obj)</h2>
<p>在指定位置插入元素（<code>与list同</code>）</p>
<h2 id="rotate-n">rotate(n)</h2>
<p>rotate(n)， 从右侧反转n步，如果n为负数，则从左侧反转。<br>
d.rotate(1) 等于 d.appendleft(d.pop())</p>
<h2 id="clear">clear()</h2>
<p>将deque中的元素全部删除，最后长度为0</p>
<h2 id="remove">remove()</h2>
<p>移除第一次出现的元素，如果没有找到，报出ValueError</p>
<h2 id="maxlen">maxlen</h2>
<p>只读的属性，deque限定的最大长度，如果无，就返回None。<br>
当限制长度的deque增加超过限制数的项时, 另一边的项会<code>自动删除</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">st = <span class="string">&quot;abbcd&quot;</span></span><br><span class="line">dq = deque（）</span><br><span class="line">dq.append(st)</span><br></pre></td></tr></table></figure>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 不想学辣 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Python </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Python map函数(类)详解]]></title>
      <url>/2022/08/20/%E3%80%90Python%E3%80%91map%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3/</url>
      <content type="html"><![CDATA[<h2 id="理论">理论</h2>
<p><code>map()</code>函数是<code>Python</code>的内置函数，会根据提供的函数参数，对传入的序列数据进行映射。</p>
<p>所以，<code>map()</code>函数也称<code>映射函数</code>。</p>
<p>在<code>Python</code>中，<code>map</code>是一个类，有着迭代方法，能够返回对应值。平时也能充当着函数使用：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="built_in">list</span>(<span class="built_in">map</span>(<span class="keyword">lambda</span> x:x[<span class="number">0</span>],[[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]])))</span><br><span class="line"></span><br><span class="line"><span class="comment"># [1, 3]</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">data=[[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]]</span><br><span class="line">A=<span class="built_in">map</span>(<span class="keyword">lambda</span> x:x[<span class="number">0</span>],data)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(data)):</span><br><span class="line">    <span class="built_in">print</span>(A.__next__())</span><br><span class="line"><span class="comment"># 1</span></span><br><span class="line"><span class="comment"># 3</span></span><br></pre></td></tr></table></figure>
<h3 id="格式">格式</h3>
<p>最常见的格式为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">map</span>(function,iterables,...)-&gt;<span class="built_in">map</span></span><br></pre></td></tr></table></figure>
<p><strong>Input</strong></p>
<ul>
<li>function: 映射函数</li>
<li>iterables: 可迭代序列</li>
</ul>
<p><strong>Output</strong></p>
<ul>
<li>一个可迭代对象</li>
</ul>
<hr>
<h2 id="实践">实践</h2>
<p>我们来进行一个简单的尝试！</p>
<p><strong>实例一</strong></p>
<p>设计一个函数，将两个数组<code>A</code>和<code>B</code>中的元素加起来。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">Add</span>(<span class="params">x,y</span>):</span><br><span class="line">    n,m=<span class="built_in">len</span>(x),<span class="built_in">len</span>(y)</span><br><span class="line">    <span class="keyword">if</span> n&gt;m:</span><br><span class="line">        n,m=m,n</span><br><span class="line">        x,y=y,x</span><br><span class="line">    new=[i <span class="keyword">for</span> i <span class="keyword">in</span> y]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        new[i]+=x[i]</span><br><span class="line">    <span class="keyword">return</span> new</span><br><span class="line"></span><br><span class="line">A=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>]</span><br><span class="line">B=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]</span><br><span class="line"><span class="built_in">print</span>(Add(A,B))</span><br><span class="line"></span><br><span class="line"><span class="comment"># [2, 4, 6, 8, 10, 12, 7, 8]</span></span><br></pre></td></tr></table></figure>
<p>那如果对格式输入不那么严格，又想比较简便地实现操作，我们可以通过<code>map</code>+<code>lambda</code>表达式的方式，对输入的元素进行一一映射。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="built_in">list</span>(<span class="built_in">map</span>(<span class="keyword">lambda</span> x,y:x+y,A,B)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># [2, 4, 6, 8, 10, 12]</span></span><br></pre></td></tr></table></figure>
<p>此时，第一个参数是一个映射(函数),第二，第三个参数则是输入的可迭代对象。<code>map</code>会自动的<code>依次取出</code>可迭代对象中的每个元素，通过映射输出。我们可以通过<code>map.__next__()</code>控制获取每一个元素，或是直接将返回的迭代对象转化为<code>list</code>获取全部元素。</p>
<p><code>map</code>能够确保数据的最小截断，也就是满足两个或多个可迭代对象进行的最小长度。比如上文提到的，<code>A</code>数组的长度是高于<code>B</code>数组的，但由于<code>map</code>对象的特性，返回值只保留到<code>B</code>的长度。</p>
<hr>
<p>是不是学会了！那我们再来看一题。</p>
<p>将一个元组对象转化为一个列表。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">A=((<span class="number">7</span>),(<span class="number">7</span>),(<span class="number">7</span>),(<span class="number">7</span>),(<span class="number">7</span>),(<span class="number">7</span>),(<span class="number">7</span>),(<span class="number">8</span>))</span><br><span class="line"><span class="built_in">print</span>([[i] <span class="keyword">for</span> i <span class="keyword">in</span> A])</span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">list</span>,A)))</span><br></pre></td></tr></table></figure>
<hr>
<p><strong>实例二</strong></p>
<blockquote>
<p>出自LC417太平洋大西洋水流问题</p>
</blockquote>
<p>有一个 m × n 的矩形岛屿，与 太平洋 和 大西洋 相邻。 “太平洋” 处于大陆的左边界和上边界，而 “大西洋” 处于大陆的右边界和下边界。</p>
<p>这个岛被分割成一个由若干方形单元格组成的网格。给定一个 m x n 的整数矩阵 heights ， heights<code>[r][c]</code>表示坐标 (r, c) 上单元格 高于海平面的高度 。</p>
<p>岛上雨水较多，如果相邻单元格的高度 小于或等于 当前单元格的高度，雨水可以直接向北、南、东、西流向相邻单元格。水可以从海洋附近的任何单元格流入海洋。</p>
<p>返回网格坐标 result 的 2D 列表 ，其中 result[i] = [ri, ci] 表示雨水从单元格 (ri, ci) 流动 既可流向太平洋也可流向大西洋 。</p>
<img src="https://assets.leetcode.com/uploads/2021/06/08/waterflow-grid.jpg" style="zoom:50%;">
<blockquote>
<p>输入: heights = [[1,2,2,3,5],[3,2,3,4,4],[2,4,5,3,1],[6,7,1,4,5],[5,1,1,2,4]]<br>
输出: [[0,4],[1,3],[1,4],[2,2],[3,0],[3,1],[4,0]]</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">pacificAtlantic</span>(<span class="params">self, heights: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]</span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span><br><span class="line">        m,n=<span class="built_in">len</span>(heights),<span class="built_in">len</span>(heights[<span class="number">0</span>])</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">search</span>(<span class="params">start</span>):</span><br><span class="line">            visitSet=<span class="built_in">set</span>()</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">def</span> <span class="title function_">dfs</span>(<span class="params">x,y</span>):</span><br><span class="line">                <span class="keyword">if</span> (x,y) <span class="keyword">in</span> visitSet:</span><br><span class="line">                    <span class="keyword">return</span> </span><br><span class="line">                val=heights[x][y]</span><br><span class="line">                visitSet.add((x,y))</span><br><span class="line">                <span class="keyword">for</span> i,j <span class="keyword">in</span> [[x+<span class="number">1</span>,y],[x-<span class="number">1</span>,y],[x,y-<span class="number">1</span>],[x,y+<span class="number">1</span>]]:</span><br><span class="line">                    <span class="keyword">if</span> <span class="number">0</span>&lt;=i&lt;m <span class="keyword">and</span> <span class="number">0</span>&lt;=j&lt;n <span class="keyword">and</span> heights[i][j]&gt;=val:</span><br><span class="line">                        dfs(i,j)</span><br><span class="line">                        </span><br><span class="line">            <span class="keyword">for</span> i,j <span class="keyword">in</span> start:</span><br><span class="line">                dfs(i,j)</span><br><span class="line">            <span class="keyword">return</span> visitSet </span><br><span class="line">        </span><br><span class="line">        pacificSet=[(<span class="number">0</span>,i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n)]+[(i,<span class="number">0</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(m)]</span><br><span class="line">        altanticSet=[(m-<span class="number">1</span>,i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n)]+[(i,n-<span class="number">1</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(m)]</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">list</span>,search(pacificSet)&amp;search(altanticSet)))</span><br></pre></td></tr></table></figure>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 不想学辣 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Python </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[一些改善记忆力的小tips]]></title>
      <url>/2022/08/18/%E3%80%90%E6%9D%82%E8%B0%88%E3%80%91%E4%B8%80%E4%BA%9B%E6%94%B9%E5%96%84%E8%AE%B0%E5%BF%86%E5%8A%9B%E7%9A%84%E5%B0%8Ftips/</url>
      <content type="html"><![CDATA[<blockquote>
<p><strong>从保障神经系统的健康的角度出发</strong></p>
</blockquote>
<h2 id="饮食">饮食</h2>
<p><a href="https://www.zhihu.com/search?q=%E9%A5%B1%E5%92%8C%E8%84%82%E8%82%AA&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A81809350%7D">饱和脂肪</a>不利于脑子的保养!类似的食物有：</p>
<ul>
<li>奶油</li>
<li>肥猪肉</li>
<li>动物皮</li>
<li>火腿</li>
<li>培根</li>
<li>油炸食品</li>
<li>高点</li>
<li>西点</li>
</ul>
<p>好吃的食物可能都会让你变笨！！！</p>
<p>而不饱和脂肪酸的食物有：</p>
<ul>
<li>坚果</li>
<li>鱼</li>
<li>植物种子</li>
<li>蔬菜</li>
<li>水果
<ul>
<li>🍊</li>
<li>🍎</li>
</ul>
</li>
</ul>
<p>吃夜宵会影响记忆力。养成深夜吃零食的习惯可能会导致大脑学习和记忆能力的缺失</p>
<hr>
<blockquote>
<p><strong>从让神经元之间联系的活性突触数量增加的角度出发</strong></p>
</blockquote>
<h2 id="睡眠">睡眠</h2>
<p>当我们进入深度睡眠时，大脑神经元会长出新的突触，并加强神经元之间的联系，从而巩固和加强记忆</p>
<p>午休以10-15min为好，不要超过90min</p>
<p>不管你什么时候开始睡觉，一定要在每天的同一时间起床。这样才能在一定程度上保证生物钟正常运作。</p>
<h2 id="运动">运动</h2>
<p>有氧运动！！！</p>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 琐碎日常 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> hexo </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[人生的一些小建议~]]></title>
      <url>/2022/08/15/%E3%80%90%E6%9D%82%E8%B0%88%E3%80%91%E4%BA%BA%E7%94%9F%E7%9A%84%E5%B0%8F%E5%BB%BA%E8%AE%AE/</url>
      <content type="html"><![CDATA[<p>🌈</p>
<p>永远不要把时间放在没必要的争论上，尤其是两个不同层次的人，完全没有争论的必要，不如花些时间提升自我。</p>
<p>🖲️</p>
<p>把每天当做最后一天来过！</p>
<p>😲</p>
<p>顺，不妄喜；逆，不惶馁；安，不奢逸；危，不惊惧；胸有惊雷而面如平湖者，可拜上将军。</p>
<p>😦</p>
<p>不要害怕交涉，不要害怕表达，把每一次表达都当做一次魂游戏来打！这次不行了，就算死掉了，下次重开一条命再来</p>
<p>🇶🇦</p>
<p>一定要提前做好规划,提前进行复盘！</p>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 琐碎日常 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 碎碎念 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[常用英语积累]]></title>
      <url>/2022/08/15/%E3%80%90%E8%8B%B1%E8%AF%AD%E3%80%91%E8%AE%BA%E6%96%87%E5%B8%B8%E7%94%A8%E7%9A%84%E8%AF%8D%E8%AF%AD/</url>
      <content type="html"><![CDATA[<p>Contrasting suitability and ambition in regional carbon mitigation.</p>
<p>区域碳减排适宜性和雄心的对比。</p>
<hr>
<p>spend … (in) doing</p>
<p>🌟 I spend time studying.</p>
<p>🌟 I spend a lot energy playing.</p>
<p>spend … on sth.</p>
<p>🌟 I spend time on this book.</p>
<hr>
<p>be doom to failure.</p>
<p>失败</p>
<hr>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 不想学辣 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 英语 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Unit6 情态动词与虚拟语气]]></title>
      <url>/2022/08/15/%E3%80%90%E8%8B%B1%E8%AF%AD%E3%80%91Unit6%20%E6%83%85%E6%80%81%E5%8A%A8%E8%AF%8D%E5%92%8C%E8%99%9A%E6%8B%9F%E8%AF%AD%E6%B0%94/</url>
      <content type="html"><![CDATA[<h2 id="第一章-情态动词">第一章  情态动词</h2>
<p>📖 情态动词就是表示情绪和态度的动词，虽然也叫做动词啦，但必须作为<code>实义动词</code>的小跟班而存在。</p>
<p>🍓 情态动词没有人称的变化，不需要考虑三单</p>
<p>📏 结构: 情态动词+动词原形</p>
<h3 id="常见的情态动词">常见的情态动词</h3>
<table>
<thead>
<tr>
<th style="text-align:center">Can</th>
<th style="text-align:center">Could</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">may</td>
<td style="text-align:center">might</td>
</tr>
<tr>
<td style="text-align:center">should</td>
<td style="text-align:center">would</td>
</tr>
<tr>
<td style="text-align:center">ought to</td>
<td style="text-align:center">must</td>
</tr>
<tr>
<td style="text-align:center">have to</td>
<td style="text-align:center">need</td>
</tr>
<tr>
<td style="text-align:center">dare</td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
<hr>
<h4 id="🍎-Can-Could">🍎 <strong>Can Could</strong></h4>
<p>1️⃣ 表能力</p>
<p>🌟 I believe I can fly.</p>
<p>🌟 She could skate before she broke her leg.</p>
<hr>
<p>2️⃣ 表请求、允许</p>
<p>🌟 Can you give me 10 bucks?</p>
<p>表示请求时，<code>could</code>比<code>can</code>更加礼貌和委婉</p>
<hr>
<p>3️⃣ 表猜测</p>
<p>🌟 Can it be true?</p>
<p>🌟 It can’t be true.</p>
<p>啊值得注意的是，can’t表示不太可能，而不是不可能</p>
<hr>
<p>4️⃣ 虚拟语气</p>
<p>在虚拟语气中，我们用<code>could</code>而不用<code>can</code> !</p>
<p><code>could have done</code>表示和过去的事情相反，也就是<code>本可以做到，却没做</code>，有惋惜、遗憾之情</p>
<p>🌟 You could have told her the truth.</p>
<p>🌟 You couldn’t have told her the truth.</p>
<hr>
<p>5️⃣ <strong>Can</strong>与<strong>be able to</strong></p>
<p><code>be able to</code>适用于各个时态，而且<code>在一定的条件(金钱、资源、机会下)做成某事</code>，用的是<code>be able to</code></p>
<p>🌟 He didn’t agree with me at first but I was able to persuade him.</p>
<hr>
<h4 id="🍎-may-might">🍎 <strong>may</strong> <strong>might</strong></h4>
<p>1️⃣ 表请求、允许</p>
<p>🌟 You may not take my stuffed animal.</p>
<p>⭐ May I take the book?</p>
<p>🌟 Yes, you may. / Yes, you can. / No, you can’t. / I’m afraid not. / You’d better not.</p>
<p>在委婉程度上，<code>might</code>会更高一些</p>
<hr>
<p>2️⃣ 表示猜测可能性</p>
<p>🌟 He may be at home. ( 50 percent )</p>
<p>🌟 He might be at home. ( 30 percent )</p>
<p>包括对过去的推测：</p>
<p>🌟 He <code>might have given</code> you more help, even though he was very busy.</p>
<hr>
<p>3️⃣ 虚拟语气</p>
<p>用<code>might</code>不用<code>may</code></p>
<p><strong>might have done</strong> 表示 <strong>本可以做，却没有做</strong> 有责怪的意思。</p>
<p>🌟 She <strong>might have had</strong> her hair cut by an experienced hairdresser.</p>
<hr>
<h4 id="🍎-should-ought-to"><strong>🍎 should  ought to</strong></h4>
<p>1️⃣ 表义务，应该</p>
<p><code>should</code> 常用于一般情况；<code>ought to</code> 则更多用于特殊情况。</p>
<p>🌟 We should respect the old.</p>
<p>🌟 We ought to take good care of the old man. He has no family.</p>
<hr>
<p>2️⃣ 表推测</p>
<p>强度排序！</p>
<p>🏷️ <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mi>u</mi><mi>s</mi><mi>t</mi><mo>&gt;</mo><mi>o</mi><mi>u</mi><mi>g</mi><mi>h</mi><mi>t</mi><mtext> </mtext><mi>t</mi><mi>o</mi><mo>&gt;</mo><mi>s</mi><mi>h</mi><mi>o</mi><mi>u</mi><mi>l</mi><mi>d</mi></mrow><annotation encoding="application/x-tex">must&gt;ought\ to&gt;should</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6542em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">m</span><span class="mord mathnormal">u</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">ug</span><span class="mord mathnormal">h</span><span class="mord mathnormal">t</span><span class="mspace"> </span><span class="mord mathnormal">t</span><span class="mord mathnormal">o</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">h</span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">d</span></span></span></span></p>
<hr>
<p>3️⃣ 虚拟语气</p>
<p>本不该做某事，却做了。</p>
<p>⭐ <strong>shouldn’t have done</strong></p>
<p>⭐ <strong>oughtn’t to have done</strong></p>
<p>🌟 Australia <strong>shouldn’t have bamboozled</strong> British into traveling there when the whole country has been “on fire” for months.</p>
<p>🖊️ 澳大利亚本不应该忽悠英国人去那儿旅游；整个澳洲“火烧”了几个月。</p>
<p>⭐ <strong>should have done</strong></p>
<p>⭐ <strong>ought to have done</strong></p>
<p>🌟 Australia should have spent the advertising expenses in controlling the wildfires.</p>
<p>🖊️ 澳大利亚本应该把广告费用在控制山火上。</p>
<hr>
<h4 id="🍎-must">🍎 <strong>must</strong></h4>
<p>1️⃣ 表示必须</p>
<p>🔈 Must I cheer up?</p>
<p>✏️ Yes, you must.</p>
<p>✏️ No, you needn’t. / No, you don’t have to.</p>
<hr>
<p>2️⃣ 表推测</p>
<p>🌟 The Gods must be crazy.</p>
<p>🔈 <strong>must have done</strong> 表示过去肯定做过</p>
<p>🌟 I must have done something good.</p>
<hr>
<h4 id="🍎-need">🍎 <strong>need</strong></h4>
<p>1️⃣ 情态动词</p>
<p>必须，需要。</p>
<p>🌟 If you want anything, you need only ask.</p>
<hr>
<p>2️⃣ 实义动词</p>
<p>此时一般跟<code>to</code>连在一起！<code>need to do sth.</code>表示有义务或责任做某事。</p>
<p>🌟 You need to eat more.</p>
<p>🌟 I need to take my dog out for a walk every day.</p>
<hr>
<p>3️⃣ 虚拟语气</p>
<p>needn’t have done 本不必要做，却做了</p>
<p>🌟 You needn’t have said that.</p>
<hr>
<h4 id="🍎-dare">🍎 <strong>dare</strong></h4>
<p>1️⃣ 情态动词</p>
<p>多用于否定句、疑问句。意思是：<code>敢吗</code></p>
<p>🌟 I dare not  move!</p>
<p>🌟 Dare you answer me when I call your name?</p>
<p>🌟 I wonder whether he dare tell the truth.</p>
<hr>
<p>2️⃣ 实义动词</p>
<p>此时，需要考虑人称与时态，跟<code>need</code>一样，常常跟<code>to</code>连用。</p>
<p>🌟 She <strong>dares to</strong> use the F-word in front of the kids!</p>
<p>在否定句和疑问句中，可以不带<code>to</code></p>
<p>🌟 He <strong>didn’t dare (to)</strong> tell her his feelings.</p>
<hr>
<h2 id="第二章-虚拟语气">第二章  虚拟语气</h2>
<p>🏷️ 跟事实相反的语法现象，就叫做虚拟语气。</p>
<h3 id="一、if引导的虚拟语气">一、if引导的虚拟语气</h3>
<table>
<thead>
<tr>
<th style="text-align:center">If从句</th>
<th style="text-align:center">主句</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">一般过去时 did</td>
<td style="text-align:center">would / should do</td>
</tr>
</tbody>
</table>
<p>🌟 If I had 1 million dollars, I would build a school.</p>
<p>🌟 If I were you, I should ask him out.</p>
<p>✏️ 如果我是你，我就约他出去了</p>
<p>🌟 If I were 17, I would not make my school life miserable.</p>
<p>🐽 值得注意的是，<code>should</code>在这里并没有情态动词中<code>应该</code>的意思，而是<code>shall</code>的过去时。一般用于第一人称做主语。</p>
<p>🐷 如果<code>if</code>从句带有<code>be</code>动词，不需要考虑人称和单复数啦，直接<code>were</code>!</p>
<blockquote>
<p>我们可以发现，虚拟语气在表达与现在的事实相反时，用的全是过去时。可以理解为两个平行时空的交错点在现在之前~</p>
</blockquote>
<hr>
<h4 id="🍎-与过去事实相反">🍎 与过去事实相反</h4>
<table>
<thead>
<tr>
<th style="text-align:center">If 从句</th>
<th style="text-align:center">主句</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">过去完成时 had done</td>
<td style="text-align:center">would / should have done</td>
</tr>
</tbody>
</table>
<p>🌟 If his father hadn’t interfered, we would have been married.</p>
<p>🌟 If Dad had kept a healthy lifestyle, he would not have had a heart disease.</p>
<blockquote>
<p>诶嘿，这个时间点还在过去之前，所以要用过去完成时~</p>
</blockquote>
<hr>
<h4 id="🍎-与将来事实相反">🍎 与将来事实相反</h4>
<table>
<thead>
<tr>
<th style="text-align:center">If 从句</th>
<th style="text-align:center">主句</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">一般过去时 did</td>
<td style="text-align:center">would / should do</td>
</tr>
<tr>
<td style="text-align:center">were to do</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">should do</td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
<p>🌟 If you <strong>were to see</strong> someone in the office, you career would be ruined.</p>
<p>🌟 If it <strong>should rain</strong> tomorrow, my road test would be doomed to failure.</p>
<p>🌟 If my neighbor <strong>walked</strong> his dog this evening, I should ask him to mop my porch.</p>
<p>如何理解将来相反呢？你说它还没发生呀，咋相反捏？别急，这是带有较强的<strong>主观判断</strong>的✔️ ！</p>
<p>也就是说，用上了带有将来虚拟语气的<code>if从句</code>，那么主句的事情很可能不会发生！而如果觉得主句很有可能发生，那么就用普通的<code>if</code>引导的条件状语从句好啦！区别在于主将从现！</p>
<p>🔈 If I were to get up early, I would spend my time studying.</p>
<p>✏️ If I get up early, I will spend my time on English.</p>
<blockquote>
<p>注意将来的时间点还是在过去哦(强行解释ing)</p>
</blockquote>
<h3 id="二、if从句倒装">二、if从句倒装</h3>
<p>有个十分抽象的栗子：</p>
<img src="/2022/08/15/%E3%80%90%E8%8B%B1%E8%AF%AD%E3%80%91Unit6%20%E6%83%85%E6%80%81%E5%8A%A8%E8%AF%8D%E5%92%8C%E8%99%9A%E6%8B%9F%E8%AF%AD%E6%B0%94/image-20220816005222979.png" alt="image-20220816005222979" style="zoom:50%;">
<p>把三种情况提前，也就是把<code>我梳头</code>提前</p>
<hr>
<h4 id="🌏-现在相反">🌏 现在相反</h4>
<p>🔈 If  I were you, I should ask him out.</p>
<p>➡️ Were I you, I should ask him out.</p>
<p><strong>结构</strong></p>
<ul>
<li>去掉<code>if</code></li>
<li><code>were</code>提前</li>
<li>其他照搬</li>
</ul>
<hr>
<h4 id="🌍-过去相反">🌍 过去相反</h4>
<p>🔈 If they hadn’t argued, the woman wouldn’t have died.</p>
<p>➡️ Had they not argued, the woman wouldn’t have died.</p>
<p><strong>结构</strong></p>
<ul>
<li>去掉<code>if</code></li>
<li><code>had</code>提前</li>
<li>其他照搬， <code>not</code>不缩写</li>
</ul>
<hr>
<h4 id="🌎-将来相反">🌎 将来相反</h4>
<p>🔈 If it should rain tomorrow, my road test would be doomed to failure.<br>
➡️ Should it rain tomorrow, my road test would be doomed to failure.</p>
<p><strong>结构</strong></p>
<ul>
<li>去掉<code>if</code></li>
<li><code>should</code>提前</li>
<li>其他照搬， <code>not</code>不缩写</li>
</ul>
<blockquote>
<p>呐呐呐，啥时候要倒装呀！</p>
<p>当然是把<code>if</code>省略的情况啦！</p>
</blockquote>
<p>倒装是将信息重点后移，一般强调主语。</p>
<hr>
<h3 id="三、虚拟语气动词">三、虚拟语气动词</h3>
<p>要是遇上以下这几个大佬做谓语，后面的宾语从句必须小心翼翼地用上虚拟语气！</p>
<table>
<thead>
<tr>
<th style="text-align:center">类型</th>
<th style="text-align:center">动词</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">表建议</td>
<td style="text-align:center">advise, suggest, propose, recommend</td>
</tr>
<tr>
<td style="text-align:center">表要求/请求</td>
<td style="text-align:center">insist, demand, request, urge</td>
</tr>
<tr>
<td style="text-align:center">表愿望</td>
<td style="text-align:center">wish, desire, prefer</td>
</tr>
<tr>
<td style="text-align:center">表命令</td>
<td style="text-align:center">order, command, direct</td>
</tr>
<tr>
<td style="text-align:center">表决定</td>
<td style="text-align:center">decide, determine, resolve</td>
</tr>
</tbody>
</table>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 不想学辣 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 英语 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Java入门]]></title>
      <url>/2022/08/15/%E3%80%90Java%E3%80%91Java%E5%85%A5%E9%97%A8%E8%AF%A6%E8%A7%A3/</url>
      <content type="html"><![CDATA[<h1>第一章  Java简介</h1>
<hr>
<h2 id="一、概述">一、概述</h2>
<h3 id="1-1-Java简介">1.1 Java简介</h3>
<p>Java语言是美国<strong>Sun(Stanford University Netword)<strong>在</strong>1995</strong>推出的计算机语言。</p>
<p>Java之父：詹姆斯·高斯林（James Gosling)。</p>
<img src="/2022/08/15/%E3%80%90Java%E3%80%91Java%E5%85%A5%E9%97%A8%E8%AF%A6%E8%A7%A3/image-20220524231710965.png" alt="image-20220524231710965" style="zoom:50%;">
<p>2009年Oracle收购Sun公司，Java隶属于甲骨文公司。</p>
<h3 id="二、Java语言跨平台原理">二、Java语言跨平台原理</h3>
<p>此处的平台指的是<strong>操作系统</strong>，Java程序能够在任意操作系统上执行。</p>
<p>Java通过**JVM(Java Virtual Machine)**实现跨平台间的操作。JVM是一种抽象化的计算机，通过在实际的计算机上仿真模拟各类计算机功能来实现。</p>
<img src="/2022/08/15/%E3%80%90Java%E3%80%91Java%E5%85%A5%E9%97%A8%E8%AF%A6%E8%A7%A3/image-20220524232447360.png" alt="image-20220524232447360" style="zoom:50%;">
<h3 id="三、JRE与JDK">三、JRE与JDK</h3>
<p>JRE(Java Runtime Environment)是Java运行时环境，包含JVM和运行时所需要的核心类库。</p>
<p>JDK(Java Development Kit)是Java程序开发工具包，包含JRE和开发人员使用的工具。包括编译工具(javac.exe)和运行工具(java.exe)。</p>
<img src="/2022/08/15/%E3%80%90Java%E3%80%91Java%E5%85%A5%E9%97%A8%E8%AF%A6%E8%A7%A3/image-20220524232926702.png" alt="image-20220524232926702" style="zoom:50%;">
<h3 id="四、Java开发流程">四、Java开发流程</h3>
<p>开发一个Java程序，需要以下三个步骤：</p>
<ul>
<li>编写程序</li>
<li>编译程序</li>
<li>运行程序</li>
</ul>
<p>我们新建一个<strong>HelloWorld.java</strong>文件：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HelloWorld</span>&#123;</span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span>&#123;</span><br><span class="line">		System.out.println(<span class="string">&quot;HelloWorld&quot;</span>);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在运行前，我们需要先编译下，在CMD中输入：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">javac HelloWorld.java</span><br></pre></td></tr></table></figure>
<p>此时我们发现，出现了编译文件<code>HelloWorld.class</code></p>
<p>再执行运行任务：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">java HelloWorld</span><br><span class="line"></span><br><span class="line">&#x27;&#x27;&#x27;</span><br><span class="line">out:</span><br><span class="line">HelloWorld</span><br><span class="line">&#x27;&#x27;&#x27;</span><br></pre></td></tr></table></figure>
<p>此时可能出现以下错误：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Hellow.java:1: 错误: 类 HelloWorld 是公共的, 应在名为 HelloWorld.java 的文件中声明</span><br></pre></td></tr></table></figure>
<p>这是由于系统声明的class名称与文件名称不相同所导致的。</p>
<p>Java程序中最基本的组成单位是类，代码的执行是从main方法开始的。</p>
<hr>
<h1>第二章  基础语法</h1>
<hr>
<h2 id="一、注释">一、注释</h2>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 单行注释</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* 多行注释 */</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/** 文档注释 **/</span></span><br></pre></td></tr></table></figure>
<hr>
<h2 id="二、关键字">二、关键字</h2>
<p>具有<strong>特定含义</strong>的单词。关键字全部小写。目前Java中一共有53个关键字(2个保留字)。</p>
<h3 id="2-1-保留关键字：">2.1 保留关键字：</h3>
<ul>
<li>const:常量</li>
<li>goto:转到</li>
</ul>
<h3 id="2-2-访问修饰符">2.2 访问修饰符</h3>
<ul>
<li>public:公用，可跨包</li>
<li>protected:受保护的，当前包内可用</li>
<li>private:私有的，当前类可用</li>
</ul>
<h3 id="2-3-OOP关键字">2.3 OOP关键字</h3>
<ul>
<li>class:类，类名需要与文件名相同</li>
<li>interface:接口，接口一般提供方法但不实现</li>
<li>abstract:抽象，介于类与接口中，可以有也可以没有实现的方法体</li>
<li>implemenst:实现，用于类或接口，实现接口</li>
<li>extends:继承，用于类继承类</li>
<li>new:新建一个类</li>
</ul>
<h3 id="2-4-包的关键字">2.4 包的关键字</h3>
<ul>
<li>import:引入包</li>
<li>package:定义包</li>
</ul>
<h3 id="2-5-数据类型">2.5 数据类型</h3>
<ul>
<li>byte:字节型，8bit</li>
<li>char:字节型，16bit</li>
<li>boolean:布尔型</li>
<li>short:短整型，16bit</li>
<li>int:整型，32bit</li>
<li>float:浮点型，32bit</li>
<li>long:长整型，64bit</li>
<li>double:双精度，64bit</li>
<li>void:无返回值</li>
<li>null:空值</li>
<li>true:真</li>
<li>false:假</li>
</ul>
<h3 id="2-6-条件循环-流程控制">2.6 条件循环(流程控制)</h3>
<ul>
<li>if</li>
<li>else</li>
<li>while</li>
<li>for</li>
<li>switch</li>
<li>case</li>
<li>do</li>
<li>break</li>
<li>continue</li>
<li>return</li>
<li>instanceof:实例检测,判断左边对象是否是右边的实例</li>
</ul>
<h3 id="2-7-修饰方法">2.7 修饰方法</h3>
<ul>
<li>static:静态</li>
<li>super:调用父类的方法</li>
<li>this:当前类父类的对象</li>
<li>native:本地</li>
<li>strictfp:严格</li>
<li>synchronized:线程，同步</li>
<li>transient:短暂</li>
<li>volatile:易失</li>
</ul>
<h3 id="2-8-错误处理">2.8 错误处理</h3>
<ul>
<li>catch</li>
<li>try</li>
<li>finally</li>
<li>throw</li>
</ul>
<h3 id="2-9-其他">2.9 其他</h3>
<ul>
<li>enum:枚举</li>
<li>assert:断言</li>
</ul>
<hr>
<h2 id="三、常量">三、常量</h2>
<p>在程序中保持不变的量，称为常量。</p>
<p>在Java中，常量可分为六类：</p>
<ul>
<li>字符串常量</li>
<li>整数常量</li>
<li>小数常量</li>
<li>字符常量</li>
<li>布尔常量</li>
<li>空常量</li>
</ul>
<hr>
<h2 id="四、变量">四、变量</h2>
<p>与常量相对，能够在程序中发生改变的量，称为变量。</p>
<blockquote>
<p>Java提供的显示的访问权限修饰符有3种,分别是:私有(private)、保护(protected)和公 共(public)。除此之外,还有一种默认的访问权限:friendly,它并不是Java的关键字,只有当变量前面没有写明任何访问权限修饰符时,就 默认以friendly作为访问权限。</p>
</blockquote>
<h3 id="4-1-变量定义">4.1 变量定义</h3>
<p>格式：<code>数据类型 变量名=变量值；</code></p>
<p>面对<code>long</code>变量数据越界，可以在数据后添加一个<code>L</code>。</p>
<p>而Java默认小数类型为<code>double</code>，使用<code>float</code>关键字时，为防止不兼容，需要添加<code>F</code>。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">long</span> l=<span class="number">100000000L</span>;</span><br><span class="line"><span class="type">float</span> f=<span class="number">13.14F</span>;</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="五、数据类型">五、数据类型</h2>
<h3 id="5-1-计算机存储单元">5.1 计算机存储单元</h3>
<p>计算机存储设备的最小信息单元叫&quot;位(bit)“，我们又称之为“比特位”，通常用小写的字母“b”表示，而计算机中最小的存储单元叫“字节(byte)”，通常用大写字母&quot;B&quot;表示，字节是由连续的8个位组成。</p>
<h3 id="5-2-数据类型">5.2 数据类型</h3>
<p>Java是强类型语言，每一种数据都必须有明确的数据类型，不同的数据类型也分配了不同的内存空间。所以其表示的数据大小是不一致的。</p>
<img src="/2022/08/15/%E3%80%90Java%E3%80%91Java%E5%85%A5%E9%97%A8%E8%AF%A6%E8%A7%A3/image-20220525123222411.png" alt="image-20220525123222411" style="zoom:50%;">
<hr>
<h2 id="六、标识符">六、标识符</h2>
<p>所谓标识符，就是给类、方法、变量等起名字的符号。</p>
<p><strong>规则</strong></p>
<ul>
<li>由数字、字母、下划线_和美元符$组成</li>
<li>不能以数字开头</li>
<li>不能是关键字</li>
<li>区分大小写</li>
</ul>
<p><strong>约定</strong></p>
<p><strong>小驼峰</strong>：方法、变量</p>
<ul>
<li>标识符是一个单词时，首字母小写</li>
<li>标识符由多个单词组成，第一个单词字母小写，其他首字母大写</li>
</ul>
<p><strong>大驼峰</strong>：类</p>
<ul>
<li>标识符是一个单词时，首字母大写</li>
<li>标识符由多个单词组成，首字母全部大写</li>
</ul>
<hr>
<h2 id="七、类型转换">七、类型转换</h2>
<h3 id="7-1-类型转换分类">7.1 类型转换分类</h3>
<ul>
<li>自动类型转换</li>
<li>强制类型转换</li>
</ul>
<h3 id="7-2-自动类型转换">7.2 自动类型转换</h3>
<p>把一个表示数据范围小的数值或变量赋值给一个表示数据范围大的变量时，可以实现自动范围转换：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">double</span> d=<span class="number">10</span></span><br></pre></td></tr></table></figure>
<p><img src="/2022/08/15/%E3%80%90Java%E3%80%91Java%E5%85%A5%E9%97%A8%E8%AF%A6%E8%A7%A3/image-20220525130806831.png" alt="image-20220525130806831"></p>
<h3 id="7-3-强制类型转换">7.3 强制类型转换</h3>
<p>将数据范围大的转换为范围小的</p>
<ul>
<li>格式：<code>目标数据类型 变量名=(目标数据类型)值或变量</code></li>
<li>范例：<code>int k=(int)88.88</code></li>
</ul>
<hr>
<h1>第三章  运算符</h1>
<hr>
<h2 id="一、算数运算符">一、算数运算符</h2>
<h3 id="1-1-运算符与表达式">1.1 运算符与表达式</h3>
<ul>
<li>运算符：对常量或变量进行操作的符号</li>
<li>表达式：用运算符把常量或变量连接起来符合java语法规范的句子</li>
</ul>
<h3 id="1-2-算数运算符">1.2 算数运算符</h3>
<ul>
<li><code>+</code></li>
<li><code>-</code></li>
<li><code>*</code></li>
<li><code>/</code></li>
<li><code>%</code></li>
</ul>
<p>除法得到的是商，取余得到的是余数。整数相除只能得到整数，要得到小数必须有浮点数的参与。</p>
<p>当字符型与数字类型做加法时，会将字符转为ASCII码进行运算。</p>
<ul>
<li>byte类型、short类型和char类型都将被提升到int类型</li>
</ul>
<p>字符串型做加操作时，做的是字符拼接。(只要是字符串在前，那就是字符拼接)。例如：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;a&quot;</span>+<span class="number">1</span>+<span class="number">2</span></span><br><span class="line">--&gt;<span class="string">&quot;a12&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="number">1</span>+<span class="number">2</span>+<span class="string">&quot;a&quot;</span>:</span><br><span class="line">--&gt;<span class="string">&quot;3a&quot;</span></span><br></pre></td></tr></table></figure>
<hr>
<h2 id="二、赋值运算符">二、赋值运算符</h2>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> i=<span class="number">10</span>;</span><br><span class="line"></span><br><span class="line">i+=<span class="number">20</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注意，+=操作带有一个强制类型转换</span></span><br><span class="line"><span class="type">short</span> a=<span class="number">10</span>;</span><br><span class="line">a=a+<span class="number">20</span>；<span class="comment">// 此时右边是int类型,会报错</span></span><br><span class="line">a=(<span class="type">short</span>)(a+<span class="number">20</span>); <span class="comment">// 不会报错</span></span><br><span class="line">a+=<span class="number">20</span>; <span class="comment">// 不会报错</span></span><br></pre></td></tr></table></figure>
<ul>
<li><code>+=</code></li>
<li><code>-=</code></li>
<li><code>*=</code></li>
<li><code>/=</code></li>
<li><code>%=</code></li>
</ul>
<hr>
<h2 id="三、自增自减运算符">三、自增自减运算符</h2>
<ul>
<li><code>++</code></li>
<li><code>--</code></li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 单独使用时二者相等</span></span><br><span class="line">++i;</span><br><span class="line">i++;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 参与操作时，先参与操作后自加：</span></span><br><span class="line"><span class="type">int</span> i=<span class="number">10</span>;</span><br><span class="line"><span class="type">int</span> j=i++;</span><br><span class="line">---&gt; j: <span class="number">10</span> ; i: <span class="number">11</span></span><br><span class="line">    </span><br><span class="line"><span class="comment">// ++放前时，先进行自增:</span></span><br><span class="line"><span class="type">int</span> j=++i;</span><br><span class="line">---&gt; j: <span class="number">11</span> ; i: <span class="number">11</span></span><br></pre></td></tr></table></figure>
<hr>
<h2 id="四、关系运算符">四、关系运算符</h2>
<ul>
<li><code>==</code></li>
<li><code>!=</code></li>
<li><code>&gt;</code></li>
<li><code>&gt;=</code></li>
<li><code>&lt;</code></li>
<li><code>&lt;=</code></li>
</ul>
<hr>
<h2 id="五、逻辑运算符">五、逻辑运算符</h2>
<p>逻辑运算符是用来连接关系表达式的运算符。</p>
<ul>
<li><code>&amp;</code>逻辑与 有false则false</li>
<li><code>|</code>逻辑或 有true则true</li>
<li><code>^</code>逻辑异或 相同false不同true</li>
<li><code>!</code>逻辑非</li>
</ul>
<p><strong>短路逻辑运算符</strong></p>
<ul>
<li><code>&amp;&amp;</code>短路与</li>
<li><code>||</code>短路或</li>
</ul>
<p>逻辑与<code>&amp;</code>，无论左边真假，右边都要执行</p>
<p>短路与<code>&amp;&amp;</code>，若左边为假，则右边不执行</p>
<p>逻辑或<code>|</code>，无论真假，都要执行</p>
<p>短路或<code>||</code>，左边为真，则右边不执行</p>
<hr>
<h2 id="六、三元运算符">六、三元运算符</h2>
<p><strong>格式</strong>：<code>关系表达式?表达式1:表达式2;</code></p>
<p><strong>范例</strong>：<code>a&gt;b?a:b;</code></p>
<p>先计算关系表达式的值，若为<code>true</code>,表达式1的值就是运算结果；</p>
<p>若为<code>false</code>，表达式2的值就是运算结果。</p>
<p>数据输入(Scanner包):</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Scanner;</span><br><span class="line">Scanner sc=<span class="keyword">new</span> <span class="title class_">Scanner</span>(System.in);</span><br><span class="line"><span class="type">int</span> i=sc.nextInt();</span><br></pre></td></tr></table></figure>
<hr>
<h1>第四章  控制语句</h1>
<hr>
<p>流程控制语句可分为三大类：</p>
<ul>
<li>顺序结构</li>
<li>分支结构</li>
<li>循环结构</li>
</ul>
<h2 id="一、顺序结构">一、顺序结构</h2>
<p>作为基本的流程控制结构，顺序结构从上往下依次执行语序。</p>
<hr>
<h2 id="二、分支结构">二、分支结构</h2>
<h3 id="2-1-if-结构">2.1 if 结构</h3>
<p><strong>格式</strong>：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (关系表达式)&#123;</span><br><span class="line">	语句体;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="2-2-if…else-结构">2.2 if…else 结构</h3>
<p><strong>格式</strong>：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span>(关系表达式)&#123;</span><br><span class="line">	语句体<span class="number">1</span>;</span><br><span class="line">&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">	语句体<span class="number">2</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="2-3-if…else…if-结构">2.3 if…else…if 结构</h3>
<p><strong>格式</strong>：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span>(关系表达式<span class="number">1</span>)&#123;</span><br><span class="line">	语句体<span class="number">1</span>;</span><br><span class="line">&#125;<span class="keyword">else</span> <span class="keyword">if</span>(关系表达式<span class="number">2</span>)&#123;</span><br><span class="line">	语句体<span class="number">2</span>;</span><br><span class="line">&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">	语句体n;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="2-4-Switch结构">2.4 Switch结构</h3>
<p><strong>格式</strong>：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">switch</span>(表达式)&#123;</span><br><span class="line">	<span class="keyword">case</span> 值<span class="number">1</span>:</span><br><span class="line">		语句体<span class="number">1</span>;</span><br><span class="line">		<span class="keyword">break</span>;</span><br><span class="line">	<span class="keyword">case</span> 值<span class="number">2</span>:</span><br><span class="line">		语句体<span class="number">2</span>;</span><br><span class="line">		<span class="keyword">break</span>;</span><br><span class="line">	...</span><br><span class="line">	<span class="keyword">default</span>:</span><br><span class="line">		语句体n;</span><br><span class="line">		<span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>值得注意的是，当<code>case</code>语句块中没有<code>break</code>时，将继续执行下一次的<code>case</code>：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">switch</span>(a)&#123;</span><br><span class="line">	<span class="keyword">case</span> <span class="number">1</span>:</span><br><span class="line">	<span class="keyword">case</span> <span class="number">2</span>:</span><br><span class="line">	<span class="keyword">case</span> <span class="number">3</span>:</span><br><span class="line">		System.out.println(<span class="string">&quot;HELLO&quot;</span>);</span><br><span class="line">		<span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="三、循环结构">三、循环结构</h2>
<p>循环结构由四个部分构成：</p>
<ul>
<li>初始化语句</li>
<li>条件判断语句</li>
<li>循环体语句</li>
<li>条件控制语句</li>
</ul>
<h3 id="3-1-for循环">3.1 for循环</h3>
<p><strong>格式</strong>：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (初始化语句;条件判断语句;条件控制语句)&#123;</span><br><span class="line">	循环体语句;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="3-2-while循环">3.2 while循环</h3>
<p><strong>格式</strong>：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span>(条件判断语句)&#123;</span><br><span class="line">	循环体语句;</span><br><span class="line">	条件控制语句;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="3-3-do-…-while-循环">3.3 do … while 循环</h3>
<p><strong>格式</strong>：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">do</span>&#123;</span><br><span class="line">	循环体语句;</span><br><span class="line">	条件控制语句;</span><br><span class="line">&#125;<span class="number">0</span></span><br><span class="line"><span class="keyword">while</span>(条件判断语句)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<hr>
<h2 id="四、跳转语句">四、跳转语句</h2>
<ul>
<li>continue</li>
<li>break</li>
</ul>
<hr>
<h2 id="随机数Random">随机数Random</h2>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Random;</span><br><span class="line">Random r=<span class="keyword">new</span> <span class="title class_">Random</span>();</span><br><span class="line"><span class="type">int</span> num=r.nextInt(<span class="number">10</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 0-9</span></span><br></pre></td></tr></table></figure>
<hr>
<h2 id="IDEA">IDEA</h2>
<p><strong>快速生成语句</strong></p>
<ul>
<li>快速生成main方法：<code>psvm</code></li>
<li>快速生成输出语句：<code>sout</code></li>
</ul>
<p><strong>内容辅助键</strong></p>
<ul>
<li><code>Ctrl+Alt+space</code>(内容提示，代码补全)</li>
</ul>
<p><strong>快捷键</strong></p>
<ul>
<li>
<p>注释</p>
<ul>
<li>单行：<code>ctrl+/</code> 再来一次是取消</li>
<li>多行：<code>ctrl+shift+/</code> 再来一次是取消</li>
</ul>
</li>
<li>
<p>格式化</p>
<ul>
<li><code>ctrl+alt+L</code></li>
</ul>
</li>
</ul>
<hr>
<h1>第五章  数组</h1>
<hr>
<h2 id="一、数组定义格式">一、数组定义格式</h2>
<p><strong>格式一</strong>：</p>
<ul>
<li><code>数据类型[] 变量名</code></li>
<li>范例: <code>int[] arr</code></li>
<li>定义了一个int类型的数组，数组名是arr</li>
</ul>
<p><strong>格式二</strong>:</p>
<ul>
<li><code>数据类型 变量名[]</code></li>
<li>范例:<code>int arr[]</code></li>
<li>定义了一个int类型的变量，变量名是arr数组</li>
</ul>
<hr>
<h2 id="二、数组初始化">二、数组初始化</h2>
<p>Java中的数组必须先初始化，然后才能使用。</p>
<p>所谓初始化，就是为数组中的数组元素分配内存空间，并为每个数组元素赋值。</p>
<h3 id="2-1-动态初始化">2.1  动态初始化</h3>
<p>在初始化时，指定数组长度，由系统为数组动态分配初始值</p>
<p>例如:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span>[] arr=<span class="keyword">new</span> <span class="title class_">int</span>[<span class="number">3</span>];</span><br></pre></td></tr></table></figure>
<h3 id="2-2-静态初始化">2.2  静态初始化</h3>
<p>指定数组的初始值，由系统决定长度。</p>
<p>例如：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span>[] arr = <span class="keyword">new</span> <span class="title class_">int</span>[] &#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>&#125;;</span><br><span class="line"><span class="comment">// 或者</span></span><br><span class="line"><span class="type">int</span>[] arr = &#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>&#125;;</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="三、数组元素访问">三、数组元素访问</h2>
<h3 id="3-1-数组元素访问">3.1  数组元素访问</h3>
<p>格式：<code>数组名[索引]</code></p>
<p>索引用于访问数组中的数据使用，<code>数组名[索引]</code>等同于变量名，是一种特殊的变量名。</p>
<ul>
<li>索引从0开始</li>
<li>索引是连续的</li>
<li>索引每次递增1</li>
</ul>
<hr>
<h2 id="四、内存分配">四、内存分配</h2>
<h3 id="4-1-Java中内存分配">4.1 Java中内存分配</h3>
<p>Java为了提高效率，给每种类型的数据都分配了空间。数组在初始化时，会为存储空间添加默认值：</p>
<ul>
<li>整数：0</li>
<li>浮点：0.0</li>
<li>布尔：false</li>
<li>字符：空字符</li>
<li>引用：null</li>
</ul>
<p>Java中的内存可分为两种，栈内存和堆内存。</p>
<p>栈内存：存储局部变量，定义在方法中的变量，使用完毕，立即消失。</p>
<p>堆内存：存储new出来的内容(实体、对象)，数组在初始化时会为期添加默认值。当使用完毕时，会在垃圾回收期空闲时被回收。</p>
<img src="/2022/08/15/%E3%80%90Java%E3%80%91Java%E5%85%A5%E9%97%A8%E8%AF%A6%E8%A7%A3/image-20220527233055693.png" alt="image-20220527233055693" style="zoom:50%;">
<h3 id="4-2-数组内存图">4.2  数组内存图</h3>
<img src="/2022/08/15/%E3%80%90Java%E3%80%91Java%E5%85%A5%E9%97%A8%E8%AF%A6%E8%A7%A3/image-20220527233316829.png" alt="image-20220527233316829" style="zoom:50%;">
<p>当两个数组指向相同的栈内存时，牵一而动全身。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span>[] arr1=arr;</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="五、常见问题">五、常见问题</h2>
<ul>
<li>索引越界</li>
<li>空指针异常</li>
</ul>
<hr>
<h2 id="六、数组常见操作">六、数组常见操作</h2>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 遍历数组</span></span><br><span class="line"><span class="type">int</span>[] arr =&#123;<span class="number">11</span>,<span class="number">12</span>,<span class="number">13</span>&#125;;</span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;<span class="number">3</span>;i++)&#123;</span><br><span class="line">	System.out.println(arr[i]);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 获取数组元素数量</span></span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;arr.length;i++)&#123;</span><br><span class="line">    System.out.println(arr[i]);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 获取最值</span></span><br><span class="line"><span class="type">int</span> max=arr[<span class="number">0</span>];</span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;arr.length;i++)&#123;</span><br><span class="line">    <span class="keyword">if</span>(max&lt;arr[i])&#123;</span><br><span class="line">        max=arr[i];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 翻转</span></span><br><span class="line"><span class="type">int</span>[] arr=&#123;<span class="number">11</span>,<span class="number">22</span>,<span class="number">33</span>,<span class="number">44</span>,<span class="number">55</span>,<span class="number">66</span>&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> start=<span class="number">0</span>,end=arr.length-<span class="number">1</span>;start&lt;=end;start++,end--)&#123;</span><br><span class="line">    <span class="type">int</span> temp=arr[start];</span><br><span class="line">    arr[start]=arr[end];</span><br><span class="line">    arr[end]=temp;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<h1>第六章  方法</h1>
<hr>
<h2 id="一、方法概述">一、方法概述</h2>
<p>方法是将具有独立功能的代码块组织成一个整体，使之能够完成特定任务的代码集。</p>
<ul>
<li>方法必须先创建才可使用，该过程称为方法定义</li>
<li>方法创建后不是直接运行的，需要手动使用后才执行，该过程称为方法调用</li>
</ul>
<p><strong>定义方法</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 格式</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> 方法名()&#123;</span><br><span class="line">    <span class="comment">// 方法体</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>调用方法</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 格式</span></span><br><span class="line">方法名();</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="二、带参数的方法">二、带参数的方法</h2>
<p><strong>定义方法与调用</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 格式</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> 方法名(参数)&#123;...&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 范例</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">isNumber</span><span class="params">(<span class="type">int</span> number)</span>&#123;...&#125;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">getMax</span><span class="params">(<span class="type">int</span> number1,<span class="type">int</span> number2)</span>&#123;...&#125;</span><br><span class="line"></span><br><span class="line">isNumber(<span class="number">5</span>);</span><br><span class="line">getMax(<span class="number">6</span>,<span class="number">7</span>);</span><br></pre></td></tr></table></figure>
<h3 id="形参与实参">形参与实参</h3>
<p><strong>形参</strong></p>
<ul>
<li>方法定义中的参数</li>
<li>等同于变量定义格式</li>
</ul>
<p><strong>实参</strong></p>
<ul>
<li>方法调用中的参数</li>
<li>等同于使用变量或常量</li>
</ul>
<hr>
<h2 id="三、带返回值的方法">三、带返回值的方法</h2>
<p><strong>定义方法与调用</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 格式</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> 数据类型 方法名(参数)&#123;</span><br><span class="line">	<span class="keyword">return</span> 数据;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 范例</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="type">int</span> <span class="title function_">getMax</span><span class="params">(<span class="type">int</span> n1,<span class="type">int</span> n2)</span>&#123;</span><br><span class="line">    <span class="keyword">return</span> n1&gt;n2?n1:n2;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">a=getMax(<span class="number">5</span>,<span class="number">6</span>);</span><br></pre></td></tr></table></figure>
<p><strong>注意事项</strong></p>
<ul>
<li>方法不能嵌套定义</li>
<li><code>void</code>表示无返回值，可以省略<code>return</code>，也可以不省略，但后面不能加数据。</li>
</ul>
<hr>
<h2 id="四、方法重载">四、方法重载</h2>
<p>方法重载指同一个类中定义的多个方法之间的关系，满足下列条件的多个方法互相构成重载。</p>
<ul>
<li>多个方法在同一个类中</li>
<li>多个方法具有相同的方法名</li>
<li>多个方法的参数不同，类型不同或数量不同</li>
</ul>
<p>重载仅针对参数进行识别，与返回值无关。</p>
<p><strong>示例</strong></p>
<p>设计一个兼容整数类型的比较方法。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="type">boolean</span> <span class="title function_">compare</span><span class="params">(<span class="type">int</span> a,<span class="type">int</span> b)</span>&#123;</span><br><span class="line">	<span class="keyword">return</span> a==b;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="type">boolean</span> <span class="title function_">compare</span><span class="params">(<span class="type">short</span> a,<span class="type">short</span> b)</span>&#123;</span><br><span class="line">	<span class="keyword">return</span> a==b;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="type">boolean</span> <span class="title function_">compare</span><span class="params">(<span class="type">byte</span> a,<span class="type">byte</span> b)</span>&#123;</span><br><span class="line">	<span class="keyword">return</span> a==b;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="type">boolean</span> <span class="title function_">compare</span><span class="params">(<span class="type">long</span> a,<span class="type">long</span> b)</span>&#123;</span><br><span class="line">	<span class="keyword">return</span> a==b;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">compare(<span class="number">1</span>,<span class="number">2</span>);</span><br><span class="line">compare(<span class="type">short</span>(<span class="number">1</span>),<span class="type">short</span>(<span class="number">2</span>));</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="五、方法参数传递">五、方法参数传递</h2>
<p>基本类型的参数，各个方法是隔开进行的(作用域)，所以形参并不会影响实参的值。</p>
<img src="/2022/08/15/%E3%80%90Java%E3%80%91Java%E5%85%A5%E9%97%A8%E8%AF%A6%E8%A7%A3/image-20220528132130223.png" alt="image-20220528132130223" style="zoom:50%;">
<p>对于引用参数，由于传进去了堆内存，所以修改时会在堆内存里修改，形参传递的是堆地址。</p>
<p><img src="/2022/08/15/%E3%80%90Java%E3%80%91Java%E5%85%A5%E9%97%A8%E8%AF%A6%E8%A7%A3/image-20220528132800842.png" alt="image-20220528132800842"></p>
<hr>
<p><strong>Debug</strong>：是供程序员使用的程序调试工具，它可用于查看程序的执行流程，也可以用于追踪程序执行过程来调试程序。</p>
<p>Debug调试又称断点调试，断点本质上是一个标记，告诉我们从哪里开始查看。</p>
<hr>
<h1>第七章  类和对象</h1>
<hr>
<h2 id="一、类和对象">一、类和对象</h2>
<p><strong>对象</strong>：客观存在的实体。</p>
<p><strong>类</strong>：类是对显示生活中一类具有共同属性和行为的事物的抽象。</p>
<p><strong>特点</strong>：</p>
<ul>
<li>类是对象的数据类型</li>
<li>类是具有相同属性和行为的一组对象的集合</li>
</ul>
<p>在Java程序中，类是基本组成单位，它将确定对象会拥有的属性和行为。</p>
<p><strong>类的组成</strong>：属性和行为</p>
<ul>
<li>属性：通过成员变量来体现</li>
<li>行为：通过行为方法来体现</li>
</ul>
<p><strong>类的定义</strong>：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> class 类名&#123;</span><br><span class="line">	<span class="comment">// 成员变量</span></span><br><span class="line">	变量<span class="number">1</span>的数据类型 变量<span class="number">1</span>;</span><br><span class="line">	变量<span class="number">2</span>的数据类型 变量<span class="number">2</span>;</span><br><span class="line">	...</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 成员方法</span></span><br><span class="line">	方法<span class="number">1</span>;</span><br><span class="line">	方法<span class="number">2</span>;</span><br><span class="line">	...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 案例</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Phone</span>&#123;</span><br><span class="line">    <span class="comment">// 成员变量</span></span><br><span class="line">    String brand;</span><br><span class="line">    <span class="type">int</span> price;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 成员方法</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">call</span><span class="params">()</span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;Calling&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>创建并使用对象</strong>：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 创建对象</span></span><br><span class="line">Phone p=<span class="keyword">new</span> <span class="title class_">Phone</span>();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 调用成员变量</span></span><br><span class="line">p.brand; <span class="comment">// 会得到默认值哦</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 调用成员方法</span></span><br><span class="line">p.call();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 赋值</span></span><br><span class="line">p.brand=<span class="string">&quot;OPPO&quot;</span>;</span><br><span class="line">p.price=<span class="number">3000</span>;</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="二、对象内存图">二、对象内存图</h2>
<img src="/2022/08/15/%E3%80%90Java%E3%80%91Java%E5%85%A5%E9%97%A8%E8%AF%A6%E8%A7%A3/image-20220529005813465.png" alt="image-20220529005813465" style="zoom:50%;">
<p>在申请对象时，会在栈内存中创建一个地址，作为引用类型，对象地址会指向堆内存中存储的方法和成员变量。</p>
<img src="/2022/08/15/%E3%80%90Java%E3%80%91Java%E5%85%A5%E9%97%A8%E8%AF%A6%E8%A7%A3/image-20220529010535860.png" alt="image-20220529010535860" style="zoom:50%;">
<img src="/2022/08/15/%E3%80%90Java%E3%80%91Java%E5%85%A5%E9%97%A8%E8%AF%A6%E8%A7%A3/image-20220529010803689.png" alt="image-20220529010803689" style="zoom:50%;">
<hr>
<h2 id="三、成员变量和局部变量">三、成员变量和局部变量</h2>
<p><strong>成员变量</strong>：在类中方法外的变量</p>
<p><strong>局部变量</strong>：在类中方法中的变量</p>
<table>
<thead>
<tr>
<th style="text-align:center">区别</th>
<th style="text-align:center">成员变量</th>
<th style="text-align:center">局部变量</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">类中位置不同</td>
<td style="text-align:center">类中方法外</td>
<td style="text-align:center">方法内或方法声明上</td>
</tr>
<tr>
<td style="text-align:center">内存中位置不同</td>
<td style="text-align:center">堆内存</td>
<td style="text-align:center">栈内存</td>
</tr>
<tr>
<td style="text-align:center">生命周期不同</td>
<td style="text-align:center">随对象存在而存在，随对象的消失而消失</td>
<td style="text-align:center">随方法的调用而存在</td>
</tr>
<tr>
<td style="text-align:center">初始化值不同</td>
<td style="text-align:center">有默认初始值</td>
<td style="text-align:center">无默认初始值，必须先定义</td>
</tr>
</tbody>
</table>
<hr>
<h2 id="四、封装">四、封装</h2>
<h3 id="4-1-private关键字">4.1  private关键字</h3>
<ul>
<li>是一个权限修饰符</li>
<li>可以修饰成员(成员变量和成员方法)</li>
<li>作用是保护成员不被别的类使用，被<code>private</code>修饰的成员只在本类中才能访问。</li>
</ul>
<p>针对被<code>private</code>修饰的成员变量，如果需要被别的类使用，则需要提供相应的操作</p>
<ul>
<li><code>get 变量名()</code>方法，用于获取成员变量的名称，方法用<code>public</code>修饰</li>
<li><code>set 变量名(参数)</code>方法，用于设置成员变量的值，方法用<code>public</code>修饰</li>
</ul>
<p>例如：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Student</span>&#123;</span><br><span class="line">	String name;</span><br><span class="line">	<span class="keyword">private</span> age;</span><br><span class="line">	</span><br><span class="line">	<span class="keyword">public</span> <span class="title function_">getAge</span><span class="params">()</span>&#123;</span><br><span class="line">		<span class="keyword">return</span> age;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="keyword">public</span> <span class="title function_">setAge</span><span class="params">(<span class="type">int</span> a)</span>&#123;</span><br><span class="line">		age=a;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="4-2-this关键字">4.2  this关键字</h3>
<p><code>this</code>修饰的变量用于指代成员变量。</p>
<ul>
<li>方法的形参如果与成员变量同名，不带this修饰的变量指的是形参，而不是成员变量</li>
<li>方法的形参没有与成员变量同名，不带this修饰的变量指的是成员变量</li>
</ul>
<p><code>this</code>就是栈内存地址本身哦。</p>
<h3 id="4-3-封装">4.3  封装</h3>
<p><strong>概述</strong></p>
<ul>
<li>封装是面向对象三大特征之一</li>
<li>是面向对象编程语言对客观世界的模拟，客观世界成员变量都是隐藏在对象内部的，外界是无法直接操作的</li>
</ul>
<p><strong>原则</strong></p>
<ul>
<li>将类的某些信息隐藏在类内部，不允许外部程序直接访问。而是提供对应的接口。</li>
</ul>
<p><strong>好处</strong></p>
<ul>
<li>控制了成员变量的操作，提高了代码的安全性</li>
<li>提供了代码的复用性</li>
</ul>
<hr>
<h3 id="五、构造方法">五、构造方法</h3>
<p>构造方法是一种特殊的方法，用于创建对象。</p>
<p>例如：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Student</span>()&#123;</span><br><span class="line">	</span><br><span class="line">	<span class="keyword">public</span> <span class="title function_">Student</span><span class="params">()</span>&#123;</span><br><span class="line">		System.out.println(<span class="string">&quot;hi&quot;</span>);</span><br><span class="line">	&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">Student</span><span class="params">(<span class="type">int</span> a)</span>&#123;</span><br><span class="line">        System.out.println(a);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>当一个类没有构造方法时，系统会自动给一个无参的构造方法。</p>
<p><strong>标准类</strong></p>
<ul>
<li>成员变量
<ul>
<li>使用<code>private</code>修饰</li>
</ul>
</li>
<li>构造方法
<ul>
<li>提供一个无参构造方法</li>
<li>提供一个或多个带参构造方法</li>
</ul>
</li>
<li>成员方法
<ul>
<li>提供每个成员变量的set、get方法</li>
<li>提供显示对象信息的show方法</li>
</ul>
</li>
<li>创建对象并为其成员变量赋值的两种方法</li>
</ul>
<hr>
<h1>第八章  字符串</h1>
<hr>
<h2 id="一、API">一、API</h2>
<p>API(Application Programming Interface)应用程序编程接口</p>
<p>Java API：在JDK中提供各种功能的Java类，这些类将底层的实现封装起来了，我们不需要关心这些类是如何实现的，只需要学习这些类是如何使用即可。</p>
<hr>
<h2 id="二、String">二、String</h2>
<p>String类在<code>java.lang</code>包下，使用时不需要额外导入。</p>
<p>String类代表字符串，Java程序中所有字符串文字都被实现为此类的实例。</p>
<p><strong>特点</strong></p>
<ul>
<li>字符串不可变</li>
<li>字符串可被共享</li>
<li>字符串底层是字节数组</li>
</ul>
<p>通过<code>new</code>创建的字符串对象，每次<code>new</code>都会申请一个内存空间，虽然内容相同，但结果不同。</p>
<p>通过<code>&quot;&quot;</code>方式创建的字符串对象，只要字典序相同，无论程序中代码出现几次，JVM都只会建立一个String对象，并在字符串池中维护。</p>
<p><strong>字符串的比较</strong></p>
<p>使用<code>==</code>做比较：</p>
<ul>
<li>基本类型：比较数据值是否相同</li>
<li>引用类型：比较地址值是否相同</li>
</ul>
<p>字符串是对象，如果用<code>==</code>则是比较地址。为了比较内容，需要一个新的方法来实现：<code>equals()</code></p>
<p><code>public boolean equals(Object anObject)</code>:将此字符串与指定对象比较</p>
<p><code>s1.equals(s2)</code></p>
<p><strong>案例一  登录系统</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        String username=<span class="string">&quot;UCAS&quot;</span>;</span><br><span class="line">        String password=<span class="string">&quot;Hello&quot;</span>;</span><br><span class="line">        Scanner sc=<span class="keyword">new</span> <span class="title class_">Scanner</span>(System.in);</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;<span class="number">3</span>;i++) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;请输入用户名&quot;</span>);</span><br><span class="line">            <span class="type">String</span> <span class="variable">name</span> <span class="operator">=</span> sc.nextLine();</span><br><span class="line"></span><br><span class="line">            System.out.println(<span class="string">&quot;请输入密码&quot;</span>);</span><br><span class="line">            <span class="type">String</span> <span class="variable">pass</span> <span class="operator">=</span> sc.nextLine();</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (name.equals(username) &amp;&amp; pass.equals(password)) &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;登录成功&quot;</span>);</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">if</span>(<span class="number">2</span>-i==<span class="number">0</span>)&#123;</span><br><span class="line">                    System.out.println(<span class="string">&quot;您的账号已被锁定&quot;</span>);    </span><br><span class="line">                &#125;</span><br><span class="line">                System.out.println(<span class="string">&quot;登录失败&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p><strong>案例二  遍历字符串</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Scanner sc=<span class="keyword">new</span> <span class="title class_">Scanner</span>(System.in);</span><br><span class="line">      System.out.println(<span class="string">&quot;请输入一个字符串&quot;</span>);</span><br><span class="line">      String line=sc.nextLine();</span><br><span class="line">      <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;line.length();i++)&#123;</span><br><span class="line">      	<span class="comment">// 通过charAt(idx)获取索引位置的字符</span></span><br><span class="line">          System.out.println(line.charAt(i));</span><br><span class="line">      &#125;</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="三、StringBuilderimage-20220529095929563">三、StringBuilder<img src="/2022/08/15/%E3%80%90Java%E3%80%91Java%E5%85%A5%E9%97%A8%E8%AF%A6%E8%A7%A3/image-20220529095929563.png" alt="image-20220529095929563"></h2>
<p>若对字符串进行拼接，每次拼接都会构建一个新的String对象，即耗时又浪费内存。</p>
<p>StringBuilder是一个可变的字符串类，可以有效处理上述问题。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 创建空白可变</span></span><br><span class="line">StringBuilder sb=<span class="keyword">new</span> <span class="title class_">StringBuilder</span>();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建内容可变</span></span><br><span class="line">StringBuilder sb1=<span class="keyword">new</span> <span class="title class_">StringBuilder</span>(<span class="string">&quot;hello&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 添加数据 返回数据本身</span></span><br><span class="line">sb.append(<span class="string">&quot;hello&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 转换</span></span><br><span class="line">sb.toString();</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 反转</span></span><br><span class="line">sb.reverse();</span><br></pre></td></tr></table></figure>
<p><strong>案例</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span>[] arr=&#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>&#125;;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title function_">arrayToString</span><span class="params">(<span class="type">int</span>[] arr)</span>&#123;</span><br><span class="line">	StringBuilder sb= <span class="keyword">new</span> <span class="title class_">StringBuilder</span>();</span><br><span class="line">	sb.append(<span class="string">&quot;[&quot;</span>);</span><br><span class="line">	<span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;arr.length;i++)&#123;</span><br><span class="line">		<span class="keyword">if</span>(i== arr.length-<span class="number">1</span>)&#123;</span><br><span class="line">			sb.append(arr[i]);</span><br><span class="line">		&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">			sb.append(arr[i]).append(<span class="string">&quot;,&quot;</span>);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	sb.append(<span class="string">&quot;]&quot;</span>);</span><br><span class="line">	String s=sb.toString();</span><br><span class="line">	<span class="keyword">return</span> s;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<h1>第九章  集合</h1>
<hr>
<h2 id="一、集合基础">一、集合基础</h2>
<p>集合是一种提供可变存储空间的存储模型类，存储的数据容量可以发生改变。</p>
<p><strong>ArrayList&lt;E&gt;</strong></p>
<table>
<thead>
<tr>
<th style="text-align:center">方法名</th>
<th style="text-align:center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">public ArrayList()</td>
<td style="text-align:center">创建一个新的集合对象</td>
</tr>
<tr>
<td style="text-align:center">public boolean add(E e)</td>
<td style="text-align:center">追加到末尾</td>
</tr>
<tr>
<td style="text-align:center">public void add(int index,E element)</td>
<td style="text-align:center">在指定位置插入元素</td>
</tr>
<tr>
<td style="text-align:center">public boolean remove(Object o)</td>
<td style="text-align:center">删除指定元素</td>
</tr>
<tr>
<td style="text-align:center">public E remove(int index)</td>
<td style="text-align:center">删除指定位置元素，返回被删除元素</td>
</tr>
<tr>
<td style="text-align:center">public E set(int index,E element)</td>
<td style="text-align:center">修改指定元素，返回被修改元素</td>
</tr>
<tr>
<td style="text-align:center">public E get(int index)</td>
<td style="text-align:center">返回指定索引处元素</td>
</tr>
<tr>
<td style="text-align:center">public int size()</td>
<td style="text-align:center">返回集合中的元素个数</td>
</tr>
</tbody>
</table>
<p><strong>案例一</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 存储字符串并遍历</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 创建集合对象</span></span><br><span class="line">    ArrayList&lt;String&gt; array = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;String&gt;();</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 添加字符串对象</span></span><br><span class="line">    array.add(<span class="string">&quot;Y&quot;</span>);</span><br><span class="line">    array.add(<span class="string">&quot;ou&quot;</span>);</span><br><span class="line">    array.add(<span class="string">&quot;Bui&quot;</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 遍历集合</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;array.size();i++)&#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">s</span> <span class="operator">=</span> array.get(i);</span><br><span class="line">        System.out.println(s);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>案例二</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Student类</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Student</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> age;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">Student</span><span class="params">()</span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">Student</span><span class="params">(String name,<span class="type">int</span> age)</span>&#123;</span><br><span class="line">        <span class="built_in">this</span>.name=name;</span><br><span class="line">        <span class="built_in">this</span>.age=age;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setName</span><span class="params">(String name)</span>&#123;</span><br><span class="line">        <span class="built_in">this</span>.name=name;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setAge</span><span class="params">(<span class="type">int</span> age)</span>&#123;</span><br><span class="line">        <span class="built_in">this</span>.age=age;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getName</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">this</span>.name;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getAge</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> age;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 集合操作</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Test</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] arg)</span>&#123;</span><br><span class="line">        <span class="comment">// 创建集合对象</span></span><br><span class="line">        ArrayList&lt;Student&gt; array= <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;Student&gt;();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 添加到集合</span></span><br><span class="line">        addStudent(array);</span><br><span class="line">        addStudent(array);</span><br><span class="line">        addStudent(array);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;array.size();i++)&#123;</span><br><span class="line">            Student s= array.get(i);</span><br><span class="line">            System.out.println(s.getName()+<span class="string">&quot;,&quot;</span>+s.getAge());</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">addStudent</span><span class="params">(ArrayList&lt;Student&gt; array)</span>&#123;</span><br><span class="line">        Scanner sc=<span class="keyword">new</span> <span class="title class_">Scanner</span>(System.in);</span><br><span class="line">        System.out.println(<span class="string">&quot;Student&#x27;s name&quot;</span>);</span><br><span class="line"></span><br><span class="line">        String name=sc.nextLine();</span><br><span class="line">        System.out.println(<span class="string">&quot;Student&#x27;s age&quot;</span>);</span><br><span class="line">        <span class="type">int</span> age=sc.nextInt();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建学生对象</span></span><br><span class="line">        <span class="type">Student</span> <span class="variable">s</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Student</span>();</span><br><span class="line">        s.setName(name);</span><br><span class="line">        s.setAge(age);</span><br><span class="line">        array.add(s);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<h1>第十章  面向对象</h1>
<hr>
<h2 id="一、继承">一、继承</h2>
<h3 id="1-1-继承概述">1.1 继承概述</h3>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 格式</span></span><br><span class="line"><span class="keyword">public</span> class 子类名 extends 父类名&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 范例</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">children</span> <span class="keyword">extends</span> <span class="title class_">parents</span>&#123;&#125;</span><br></pre></td></tr></table></figure>
<p>父类也称基类、超类，子类也称派生类。</p>
<p>子类可以有父类的内容和自己独特的内容。</p>
<h3 id="1-2-继承的好处和弊端">1.2  继承的好处和弊端</h3>
<p><strong>好处</strong></p>
<ul>
<li>提高了代码的复用性</li>
<li>提高了代码的可维护性</li>
</ul>
<p><strong>弊端</strong></p>
<ul>
<li>增加了类的耦合性，削弱了子类的独立性</li>
</ul>
<h3 id="1-3-继承中变量的访问特点">1.3  继承中变量的访问特点</h3>
<p>在子类方法中访问一个变量</p>
<ul>
<li>子类局部范围找</li>
<li>子类成员范围找</li>
<li>父类成员范围找</li>
<li>报错</li>
</ul>
<h3 id="1-4-Super">1.4  Super</h3>
<p>与<code>this</code>关键字差不多，<code>super</code>关键字用于在子类中调用父类的成员和方法。</p>
<table>
<thead>
<tr>
<th style="text-align:center">关键字</th>
<th style="text-align:center">访问成员变量</th>
<th style="text-align:center">访问构造方法</th>
<th style="text-align:center">访问成员方法</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">this</td>
<td style="text-align:center">this.成员</td>
<td style="text-align:center">this(…)</td>
<td style="text-align:center">this.方法</td>
</tr>
<tr>
<td style="text-align:center">super</td>
<td style="text-align:center">super.成员</td>
<td style="text-align:center">super(…)</td>
<td style="text-align:center">super.方法</td>
</tr>
</tbody>
</table>
<h3 id="1-5-构造方法">1.5  构造方法</h3>
<p>子类中所有的构造方法都会默认访问父类中无参的构造方法。因而，在子类进行初始化之前，一定要先完成父类数据的初始化。</p>
<p>在每个子类构造方法的第一条语句默认都是<code>super()</code></p>
<p>面对带参的父类，要么用<code>super()</code>显示调用，要么在父类中构建个无参方法。当调用构造方法时，父类将会被置入堆内存。</p>
<h3 id="1-6-方法重写">1.6  方法重写</h3>
<p>方法重写概述</p>
<ul>
<li>子类中出现了和父类中一模一样的方法声明</li>
<li>注意区分重载和重写</li>
</ul>
<p>例如</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Phone</span>&#123;</span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">call</span><span class="params">(String name)</span>&#123;</span><br><span class="line">		System.out.println(name);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">XiaoMi</span> <span class="keyword">extends</span> <span class="title class_">Phone</span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Override</span> </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">call</span><span class="params">(String name)</span>&#123;</span><br><span class="line">        System.out,println(<span class="string">&quot;H&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>@Override</p>
<ul>
<li>是一个注解</li>
<li>可以帮我们检查重写方法声明的正确性</li>
</ul>
<p><strong>注意事项</strong></p>
<ul>
<li>方法重写不能重写私有方法</li>
<li>重写方法访问权限不能低于父类</li>
<li>Java中不能多类继承，但可以多层继承</li>
</ul>
<hr>
<h2 id="二、包与修饰符">二、包与修饰符</h2>
<h3 id="2-1-包">2.1  包</h3>
<p>在Java中，包就是文件夹，用于对类进行分级管理。</p>
<p><strong>格式</strong></p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mi>a</mi><mi>c</mi><mi>k</mi><mi>a</mi><mi>g</mi><mi>e</mi><mtext> 包名</mtext><mn>1.</mn><mtext>包名</mtext><mn>2</mn></mrow><annotation encoding="application/x-tex">package\ 包名1.包名2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal">a</span><span class="mord mathnormal">c</span><span class="mord mathnormal">ka</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">e</span><span class="mspace"> </span><span class="mord cjk_fallback">包名</span><span class="mord">1.</span><span class="mord cjk_fallback">包名</span><span class="mord">2</span></span></span></span></p>
<p>在程序中使用<code>package</code>文件夹，会将<code>class</code>放到对应的文件夹下。</p>
<p><strong>导入</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> 包<span class="number">1</span>;</span><br></pre></td></tr></table></figure>
<h3 id="2-2-修饰符">2.2  修饰符</h3>
<p><strong>权限修饰符</strong></p>
<table>
<thead>
<tr>
<th style="text-align:center">修饰符</th>
<th style="text-align:center">同一类</th>
<th style="text-align:center">同一包子类无关类</th>
<th style="text-align:center">不同包子类</th>
<th style="text-align:center">不同包无关类</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">private</td>
<td style="text-align:center">1</td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">默认</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">protected</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">public</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
</tr>
</tbody>
</table>
<p><strong>状态修饰符</strong></p>
<p><code>final</code>关键字可用于修饰成员方法、成员变量、类。</p>
<p><strong>特点</strong></p>
<ul>
<li>修饰方法：表示该方法为最终方法，不能被重写</li>
<li>修饰变量：表示该变量时常量，不能被再次赋值</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">void</span> <span class="title function_">find</span><span class="params">()</span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="type">int</span> pig;</span><br></pre></td></tr></table></figure>
<p>当修饰变量时基本类型，则数据值不能发生改变。</p>
<p>当修饰变量为引用类型，则数据地址值不能改变，但内容可变。</p>
<p><code>static</code>关键字可以修饰成员方法和变量。</p>
<p><strong>特点</strong></p>
<ul>
<li>被类所有对象共享
<ul>
<li>也是判断是否能能够使用静态关键字的条件</li>
</ul>
</li>
<li>可通过类名调用，也可以通过对象名调用</li>
</ul>
<p>非静态成员方法：</p>
<ul>
<li>能够访问静态和非静态的变量和方法</li>
</ul>
<p>静态成员方法：</p>
<ul>
<li>只能访问静态成员方法和变量</li>
</ul>
<hr>
<h2 id="三、-多态">三、 多态</h2>
<h3 id="3-1-概述">3.1  概述</h3>
<p>同一个对象，在不同时刻表现出来的不同形态。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// cat类可以生成cat对象或是animal对象</span></span><br><span class="line"><span class="type">cat</span> <span class="variable">c</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">cat</span>();</span><br><span class="line"><span class="comment">// 父类引用指向子类对象</span></span><br><span class="line"><span class="type">animal</span> <span class="variable">c</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">cat</span>();</span><br></pre></td></tr></table></figure>
<p>多态的前提和体现：</p>
<ul>
<li>有继承/实现关系</li>
<li>有方法重写</li>
<li>有父类引用指向子类对象</li>
</ul>
<h3 id="3-2-成员访问特点">3.2  成员访问特点</h3>
<p>成员变量：编译和执行看左边，即最终接收到多态对象的类型。</p>
<p>成员方法：编译看左边，执行看右边，即生成对象的类型。</p>
<p>究其原因是成员方法有重写，而成员变量没有。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Animal</span>&#123;</span><br><span class="line">	<span class="type">int</span> age=<span class="number">40</span>;</span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">eat</span><span class="params">()</span>&#123;</span><br><span class="line">		System.out.println(<span class="string">&quot;吃饭&quot;</span>);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">cat</span> extend Animal&#123;</span><br><span class="line">	<span class="type">int</span> age=<span class="number">20</span>;</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">eat</span><span class="params">()</span>&#123;</span><br><span class="line">		System.out.println(<span class="string">&quot;猫&quot;</span>);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Animal a= <span class="keyword">new</span> <span class="title class_">cat</span>();</span><br><span class="line">System.out.println(a.age); <span class="comment">// 40</span></span><br><span class="line">a.eat(); <span class="comment">// 猫</span></span><br></pre></td></tr></table></figure>
<h3 id="3-3-多态的好处和弊端">3.3  多态的好处和弊端</h3>
<p>好处：在声明方法时，在父类型里声明，但是在子类型里定义具体实现，参与操作。提高了程序的扩展性</p>
<p>弊端：不能使用子类特有的方法</p>
<h3 id="3-4-多态中的转型">3.4  多态中的转型</h3>
<p>目的：访问子类中的特有方法</p>
<p>操作：强转(向下转型)</p>
<hr>
<h2 id="四、-抽象类">四、 抽象类</h2>
<h3 id="4-1-概述">4.1  概述</h3>
<p>一个没有方法体的方法应定义为抽象方法，而含有抽象方法的类必须定义为抽象类。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">class</span> <span class="title class_">Animal</span>()&#123;</span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title function_">eat</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>抽象类并不能创建一个实例对象。</p>
<h3 id="4-2-抽象类的特点">4.2  抽象类的特点</h3>
<ul>
<li>抽象类和抽象方法必须使用<code>abstract</code>关键词修饰</li>
<li>抽象类中不一定有抽象方法，有抽象方法的类一定是抽象类</li>
<li>抽象类不能实例化</li>
<li>抽象类的子类要么重写抽象类中的所有抽象方法，要么是抽象类</li>
</ul>
<h3 id="4-3-抽象类的成员特点">4.3  抽象类的成员特点</h3>
<ul>
<li>成员变量
<ul>
<li>可以是变量</li>
<li>也可以是常量</li>
</ul>
</li>
<li>构造方法
<ul>
<li>有构造方法，但不能实例化，用于子类访问父类数据的初始化</li>
</ul>
</li>
<li>成员方法
<ul>
<li>可以有抽象方法：限制成员必须完成某些动作</li>
<li>也可以有非抽象方法：提高代码复用性</li>
</ul>
</li>
</ul>
<hr>
<h2 id="5、-接口">5、 接口</h2>
<h3 id="5-1-概述">5.1  概述</h3>
<p>接口是一种公共的规范标准，只要符合规范，那么大家都可以通用。Java中的接口更多的体现在对行为的抽象。</p>
<h3 id="5-2-接口的特点">5.2  接口的特点</h3>
<ul>
<li>
<p>接口用关键字<code>interface</code>修饰</p>
<ul>
<li>
<pre><code class="language-java">public interface 接口名&#123;&#125;
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+ 类实现接口用`implements`表示</span><br><span class="line"></span><br><span class="line">  + ```java</span><br><span class="line">    public class 类名 implements 接口名&#123;&#125;</span><br></pre></td></tr></table></figure>

</code></pre>
</li>
</ul>
</li>
<li>
<p>接口不能实例化</p>
</li>
<li>
<p>接口的实现类</p>
<ul>
<li>要么重写接口中的所有抽象方法</li>
<li>要么是抽象类</li>
</ul>
</li>
</ul>
<h3 id="5-3-接口的成员特点">5.3  接口的成员特点</h3>
<ul>
<li>成员变量
<ul>
<li>只能是常量</li>
<li>默认修饰符：<code>public static final</code></li>
</ul>
</li>
<li>构造方法
<ul>
<li>接口没有构造方法，因为接口主要是对行为进行抽象的，是有具体存在</li>
<li>一个类如果没有父类，默认继承自<code>Object</code>类</li>
</ul>
</li>
<li>成员方法
<ul>
<li>只能是抽象方法</li>
</ul>
</li>
</ul>
<h3 id="5-4-类和接口的关系">5.4  类和接口的关系</h3>
<ul>
<li>
<p>类和类</p>
<ul>
<li>继承关系，只能单继承但可以多层继承</li>
</ul>
</li>
<li>
<p>类和接口</p>
<ul>
<li>实现关系，可以单实现或是多实现，或是继承实现</li>
</ul>
</li>
<li>
<p>接口和接口</p>
<ul>
<li>继承关系，可以单继承也可以多继承</li>
</ul>
</li>
</ul>
<h3 id="5-5-抽象类和接口的区别">5.5  抽象类和接口的区别</h3>
<ul>
<li>成员区别</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:center">抽象类</th>
<th style="text-align:center">接口</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">变量，常量</td>
<td style="text-align:center">常量</td>
</tr>
<tr>
<td style="text-align:center">有构造方法</td>
<td style="text-align:center">无构造方法</td>
</tr>
<tr>
<td style="text-align:center">有抽象或非抽象方法</td>
<td style="text-align:center">只有抽象方法</td>
</tr>
</tbody>
</table>
<ul>
<li>关系区别
<ul>
<li>见3.4</li>
</ul>
</li>
</ul>
<p><strong>案例</strong></p>
<ul>
<li>定义一个门对象，有<code>open</code>和<code>close</code>两个动作</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 抽象类</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">class</span> <span class="title class_">Door</span>&#123;</span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title function_">open</span><span class="params">()</span>;</span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 接口</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">Door</span>&#123;</span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">open</span><span class="params">()</span>;</span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 不想学辣 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
            <tag> 编程语言 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Unit5 三大从句]]></title>
      <url>/2022/08/10/%E3%80%90%E8%8B%B1%E8%AF%AD%E3%80%91Unit5%20%E4%B8%89%E5%A4%A7%E4%BB%8E%E5%8F%A5/</url>
      <content type="html"><![CDATA[<h2 id="三大从句">三大从句</h2>
<p>根据性质与类型，从句可分为以下三大类：</p>
<ul>
<li>名词性从句</li>
<li>定语从句</li>
<li>状语从句</li>
</ul>
<hr>
<p><strong>名词性从句</strong></p>
<p>在句子中充当名词，是较为常见的从句。如主语、表语、宾语、同位语从句等。</p>
<p><strong>定语从句</strong></p>
<p>在复合句中起到定语的作用，用于修饰名词词性结构，其最显眼的特征就是<code>先行词</code>和<code>关系词</code>。先行词(中心词)即为被修饰的对象，关系词则是起到引导定语从句的作用。</p>
<p><strong>状语从句</strong></p>
<p>状语从句在复合句中起到状语作用，格外需要注意九大状语从句的引导词。</p>
<hr>
<h2 id="一、名词性从句">一、名词性从句</h2>
<p>顾名思义啦，名词性从句指在句子中起到相当于名词的从句，按照类型可细化为四大类型：</p>
<ul>
<li>主语从句</li>
<li>宾语从句</li>
<li>表语从句</li>
<li>同位语从句</li>
</ul>
<blockquote>
<p>举个栗子~</p>
</blockquote>
<p>🌟 What she said is wrong.  主</p>
<p>🌟 I said that she was wrong.  宾</p>
<p>🌟 I am who I am.  表</p>
<p>🌟 The news that he will come back is true. 同</p>
<h3 id="纵览全局">纵览全局</h3>
<img src="https://pic2.zhimg.com/80/v2-a2c2a851cd3cc67d38953cc1660146fd_1440w.jpg" style="zoom:50%;">
<h3 id="一、名词性从句的连接词">一、名词性从句的连接词</h3>
<p>引导名词性从句的连接词有三种，<code>单纯连词</code>，<code>连接代词</code>，<code>连接副词</code></p>
<p><strong>单纯连词</strong></p>
<p><code>that/whether/if</code>在句中不充当任何成分，只起到连接从句的功能。<code>that</code>没有实际含义，<code>whether/if</code>有是否的意义。</p>
<p>🌟 That housing price will go up is certain.</p>
<p>🌟 Whether you win or not doesn’t matter.</p>
<p><strong>连接代词</strong></p>
<p>除却引导从句外，连接代词还具有指代的特性。主要有<code>who/whom/whose/what</code>等，具有具体的含义。</p>
<p>🌟 What doesn’t kill you only makes you stronger.</p>
<p>🌟 I am who I am.</p>
<p>🌟 What worries us is who let out the secret,</p>
<p><strong>连接副词</strong></p>
<p>具有副词的特点，可以做状语，有具体的含义，不能被省略。例如:<code>when/where/how/why</code>等</p>
<p>🌟 When the meeting will begin is unknown.</p>
<p>🌟 I don’t know how I can please him.</p>
<p>🌟 This is where the accident happened.</p>
<hr>
<h3 id="二、主语从句">二、主语从句</h3>
<p>主语从句（subject clause）,顾名思义就是利用一个从句来代替主语。</p>
<p>例如：That he finished writing the composition in such a short time surprised us .</p>
<p>这句话的结构就是最基础的：主＋谓＋宾</p>
<ul>
<li>
<p>主语：That he finished writing the composition in such a short time</p>
</li>
<li>
<p>谓语：Surprised</p>
</li>
<li>
<p>宾语：us</p>
</li>
</ul>
<p><strong>连接词</strong></p>
<table>
<thead>
<tr>
<th style="text-align:center">从属连词</th>
<th style="text-align:center">连接代词</th>
<th style="text-align:center">连接副词</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">that</td>
<td style="text-align:center">who</td>
<td style="text-align:center">when</td>
</tr>
<tr>
<td style="text-align:center">whether</td>
<td style="text-align:center">whoever</td>
<td style="text-align:center">where</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">whom</td>
<td style="text-align:center">how</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">whose</td>
<td style="text-align:center">why</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">what</td>
<td style="text-align:center">whenever</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">whatever</td>
<td style="text-align:center">wherever</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">which</td>
<td style="text-align:center">however</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">whichever</td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
<p>主语从句中的<code>that</code>虽然没有实际意义，但不可以进行省略。</p>
<p><strong>注意点</strong></p>
<blockquote>
<p>从句的语态不受到主句时态影响</p>
</blockquote>
<p>⭐ Who will be our monitor hasn’t been decided yet.</p>
<blockquote>
<p>主句大部分情况是三单，但what引导的主语从句视情况而定</p>
</blockquote>
<p>⭐ What caused the accident remains unknown.</p>
<p>⭐ What we need are good doctors.</p>
<blockquote>
<p>主语从句放在句首表示&quot;是否&quot;的时候，不能用<code>if</code>，只能用<code>whether</code></p>
</blockquote>
<p>⭐ Whether Mary really heard him is really doubtful.</p>
<blockquote>
<p>为了防止句子<code>头重脚轻</code>，往往将形式主语<code>it</code>放在句首，而真正的主语放在句末</p>
</blockquote>
<p>⭐ That he will win the match is certain. --&gt;  It is certain that he will win the match.</p>
<p>⭐ What caused the accident is still a mystery. --&gt; It is still a mystery what caused the accident.</p>
<hr>
<p>📌<strong>主语从句不可位于句首的五种情况</strong></p>
<ol>
<li><code>if</code>引导的主语从句</li>
</ol>
<p>✅ It is uncertain if he will leave for Beijing tomorrow.</p>
<p>❌ If he will leave for Beijing tomorrow is uncertain.</p>
<hr>
<ol start="2">
<li><code>It is said, (reported)...</code>结构</li>
</ol>
<p>✅ It is said that President Jingo will visit our school next week.</p>
<p>❌ That President jin will visit our school next week is said.</p>
<hr>
<ol start="3">
<li><code>It happens, ... , It occurs ... </code>结构</li>
</ol>
<p>✅ It occurred to him that he failed in the examination.</p>
<hr>
<ol start="4">
<li><code>It doesn't matter how/whether</code>结构</li>
</ol>
<p>✅ It doesn’t matter whether he is wrong or not.</p>
<hr>
<ol start="5">
<li>含主语从句的复合句是疑问句时，主语从句不可以提前</li>
</ol>
<p>✅ Is it likely that it will rain in the evening?</p>
<p>❌ It that will rain in the evening likely?</p>
<img src="/2022/08/10/%E3%80%90%E8%8B%B1%E8%AF%AD%E3%80%91Unit5%20%E4%B8%89%E5%A4%A7%E4%BB%8E%E5%8F%A5/image-20220812225919955.png" alt="image-20220812225919955" style="zoom:50%;">
<hr>
<h3 id="三、宾语从句">三、宾语从句</h3>
<p><strong>定义</strong></p>
<p>名词性从句均是异曲同工。即宾语从句就是利用一个从句来代替宾语。</p>
<p>例如：I think (that) you should tell the truth.</p>
<ul>
<li>
<p>主语：I</p>
</li>
<li>
<p>谓语：think</p>
</li>
<li>
<p>宾语：（that）you should tell the truth</p>
</li>
</ul>
<p><strong>连接词</strong></p>
<p>同上文</p>
<p><strong>时态</strong></p>
<p>🏓主句为现在时，将来时，完成时，从句可以使用任何时态</p>
<p>🌟 I know he lives here.</p>
<p>🌟 I know he lived here ten years ago.</p>
<hr>
<p>🍍主句为过去时，从句需要对应某种过去时态</p>
<p>🌟 I knew he lived here.</p>
<p>🌟 I saw he talking with her mother.</p>
<hr>
<p>🍎遇到客观真理时，用现在时</p>
<p>🌟 The teacher said that earth travels around the sun.</p>
<hr>
<p><strong>注意点</strong></p>
<p>🍏 宾语从句中<code>That</code>不可以省略的情况</p>
<p>1️⃣ 宾语从句的主语是非谓语动词</p>
<p>🌟 He think that learning English is very hard.</p>
<p>2️⃣ 从句的主语是<code>this</code>或<code>that</code>的时候</p>
<p>🌟 She said that would lead her win.</p>
<p>3️⃣ 有两个或以上的宾语从句，第二个<code>that</code>不能省略</p>
<p>🌟 I believe (that) you have done your best and that things will get better.</p>
<p>4️⃣ <code>it</code>做形式宾语，此时<code>that</code>引导的宾语从句<code>that</code>不可以省略</p>
<p>🌟 I thought it strange that Amy didn’t came up yesterday.</p>
<p>5️⃣ 双宾语时，<code>that</code>引导的从句做直接宾语，<code>that</code>不可以省略。</p>
<p>🌟 My foreign friend tell me that Chinese is one of the most difficult language to learn.</p>
<hr>
<p>🔱 四种只能用<code>whether</code>的情况</p>
<p>1️⃣ <code>or...not</code></p>
<p>2️⃣ 有介词</p>
<p>3️⃣ 后接<code>to do</code></p>
<p>4️⃣ 做主语，只用<code>whether</code></p>
<img src="/2022/08/10/%E3%80%90%E8%8B%B1%E8%AF%AD%E3%80%91Unit5%20%E4%B8%89%E5%A4%A7%E4%BB%8E%E5%8F%A5/image-20220812234810736.png" alt="image-20220812234810736" style="zoom:50%;">
<hr>
<h3 id="四、表语从句">四、表语从句</h3>
<p><strong>定义</strong></p>
<p>名词性从句均是异曲同工。即表语从句就是利用一个从句来代替表语。</p>
<p>众所周知，表语谓语系动词（be 动词及感官动词）之后，所以一般结构为主语+系动词+表语从句</p>
<p>例如：The trouble is that he has lost a lot of money.</p>
<ul>
<li>
<p>主语：the trouble</p>
</li>
<li>
<p>谓语: is</p>
</li>
<li>
<p>表语: that he has lost a lot of money.</p>
</li>
</ul>
<p><strong>连接词</strong></p>
<p>在从属连词上，多了<code>as though</code>和<code>as if</code></p>
<p><strong>时态</strong></p>
<p>同主语从句，时态不受主句影响</p>
<p><strong>注意点</strong></p>
<p>只能用<code>whether</code>代替<code>if</code>引导</p>
<hr>
<h3 id="五、同位语从句">五、同位语从句</h3>
<p><strong>定义</strong></p>
<p>同位语，按字面意思理解，就是与同位语前面的那个名词具有相同地位的成分. 即同位语通常紧跟在名词、代词后面,进一步说明、解释它的情况</p>
<p>例如 :</p>
<p>🌟 He my brother is a superstar.</p>
<p>他，即我的哥哥，是个明星(my brother是he的同位语)</p>
<p>🌟 We both can do it.</p>
<p>我们，两个人，都可以做(both就是we的同位语)</p>
<p>🌟 Where is you classmate tom.</p>
<p>你的同学汤姆在哪里（tom 是classmate的同位语）</p>
<p>同位语从句，就是用一个句子来做同位语成分，通常跟在一些特定的名词之后。这些名词有：</p>
<ul>
<li>hope</li>
<li>wish</li>
<li>fact</li>
<li>answer</li>
<li>problem</li>
<li>new</li>
<li>belief</li>
<li>idea</li>
<li>promise</li>
<li>suggestion</li>
<li>order</li>
<li>conclusion</li>
<li>information</li>
<li>though</li>
</ul>
<p>这些名词的名义都很抽象，指代不明确，所以往往跟一个同位语从句来解释这些名词的具体内涵。比如：</p>
<p>🌟 The fact that she didn’t like me really hurts me.</p>
<p>主语：The fact</p>
<p>谓语： really hurts</p>
<p>同位语：that she didn’t like me</p>
<p>宾语：me</p>
<p>不知道大家发现没有，不管是同位语还是同位语从句，他们都是起到解释说明的功能，不是关键的句子成分。所以即使他们被去除，也不会影响句子的完整性。</p>
<hr>
<p><strong>连接词</strong></p>
<p>同上</p>
<p><strong>时态</strong></p>
<p>同主语从句</p>
<p><strong>注意点</strong></p>
<p>1️⃣ 定语（从句）是对其先行词的修饰，属于形容词范畴。而同位语（从句）是对其前面的抽象名词进行解释说明，属于名词范畴。</p>
<p>2️⃣ 引导词that在同位语从句中只起连接作用，不做任何成分。That在定语从句中属于关系代词，充当句子成分。</p>
<p>3️⃣ 当when,where,why,how 等连接副词连接时，虽然在句中充当成分，但前面没有与其意义相当的先行词！</p>
<p>🌟 He will never forget the days when he lived with his grandparents.</p>
<p>🌙 He has no idea when the meeting will be held.</p>
<hr>
<h2 id="二、定语从句">二、定语从句</h2>
<h3 id="一、定义">一、定义</h3>
<p>一个句子跟在一个名词或代词后，对这个名词（代词）进行修饰限定的句子就叫定语从句，被修饰的名词或代词叫先行词，引导定语从句的词叫关系词。定语从句也可以叫做形容词词性从句。</p>
<p>📏 定语从句结构=<code>先行词</code>+<code>关系词</code>+<code>从句</code></p>
<p>🏛️ <strong>分类</strong>:</p>
<p>​	1️⃣限制性定语从句</p>
<p>​	2️⃣非限制性定语从句</p>
<p>💫 <strong>区别</strong></p>
<ul>
<li>限制性定语从句是先行词不可缺少的部分，去掉从句后，主句意思不明显，所以称为限制性啦 <s>(限制你删除)</s></li>
</ul>
<p>🌟 A man who doesn’t learn from others can’t achieve much.</p>
<p>此时，主语<code>A man</code>指的是一类人，定语从句不能去掉，要不然区间就变成了怪怪的一个人了！</p>
<ul>
<li>非限制性定语从句仅仅是对修饰的词做进一步的说明，而没有深入的解释或是补充，去掉并不影响意思，且非限一般以逗号形式与主句分割。</li>
</ul>
<p>🌟 Finally we visited the Three Gorges Dam, which is the greatest key water control project in the world at present.</p>
<ul>
<li>此外，非限还能对整个主句进行修饰嘞✌️,此时一般用三单</li>
</ul>
<p>🌟 The traffic of this city is quite bad, which is know to every.</p>
<h3 id="二、关系词">二、关系词</h3>
<p>关系词就是引导词的官方说法啦，用来开启一个从句(火车头🚆）</p>
<p><strong>关系代词</strong></p>
<table>
<thead>
<tr>
<th style="text-align:center">引导词</th>
<th style="text-align:center">代替</th>
<th style="text-align:center">用于</th>
<th style="text-align:center">成分</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">that</td>
<td style="text-align:center">人/物</td>
<td style="text-align:center">限制</td>
<td style="text-align:center">主、宾、表</td>
</tr>
<tr>
<td style="text-align:center">which</td>
<td style="text-align:center">物</td>
<td style="text-align:center">Both</td>
<td style="text-align:center">主、宾、表</td>
</tr>
<tr>
<td style="text-align:center">who</td>
<td style="text-align:center">人</td>
<td style="text-align:center">Both</td>
<td style="text-align:center">主、宾、表</td>
</tr>
<tr>
<td style="text-align:center">whom</td>
<td style="text-align:center">人</td>
<td style="text-align:center">Both</td>
<td style="text-align:center">宾、表</td>
</tr>
<tr>
<td style="text-align:center">whose</td>
<td style="text-align:center">人</td>
<td style="text-align:center">Both</td>
<td style="text-align:center">定语</td>
</tr>
<tr>
<td style="text-align:center">as</td>
<td style="text-align:center">人/物</td>
<td style="text-align:center">Both</td>
<td style="text-align:center">主、宾、表</td>
</tr>
</tbody>
</table>
<hr>
<blockquote>
<p>By the way, 我的，你的，这类的词，是做定语哦</p>
</blockquote>
<p><strong>关系副词</strong></p>
<table>
<thead>
<tr>
<th style="text-align:center">引导词</th>
<th style="text-align:center">代替</th>
<th style="text-align:center">用于</th>
<th style="text-align:center">成分</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">when</td>
<td style="text-align:center">时间</td>
<td style="text-align:center">Both</td>
<td style="text-align:center">时间状语</td>
</tr>
<tr>
<td style="text-align:center">where</td>
<td style="text-align:center">地点</td>
<td style="text-align:center">Both</td>
<td style="text-align:center">地点状语</td>
</tr>
<tr>
<td style="text-align:center">why</td>
<td style="text-align:center">原因</td>
<td style="text-align:center">限制</td>
<td style="text-align:center">原因状语</td>
</tr>
</tbody>
</table>
<hr>
<blockquote>
<p>下面我们来看看关系代词引导的定语从句</p>
</blockquote>
<p>🍎 关系代词<code>who/whom</code></p>
<p>指代人，分别做主语和宾语~</p>
<p>🌟 The man who lives in that house is my uncle.</p>
<p>🌟 The girl whom the teacher often praises is our monitor.</p>
<hr>
<p>🍇 关系代词<code>which</code></p>
<p>关系代词<code>which</code>指物，在定语从句做主语或宾语~</p>
<p>🌟 The book which cost me a lot of money is very interesting.</p>
<hr>
<p>🍏 关系代词<code>that</code></p>
<p><code>that</code>只能用于限制性从句，可以指物指人，用于进一步的解释说明。</p>
<p>🌟 The bag that lies on the ground is hers.</p>
<p>🌟 The old man that I visited yesterday is my teacher.</p>
<hr>
<p>📘 关系代词<code>whose</code></p>
<p>这个关系词捏，一般可以用<code>of whom/ of which</code>的结构进行替代</p>
<p>🌟 Do you know the doctor, whose son is a doctor too?</p>
<p>➡️ Do you konw the doctor, the son of whom is a doctor too?</p>
<p>➡️ Do you konw the doctor, of whom the son is a doctor too?</p>
<hr>
<p>🚙 <code>as</code>引导的定语从句</p>
<p>1️⃣ <code>as</code>引导的限制性定语从句</p>
<p>通常要跟<code>such, the same, as</code>进行搭配，构成固定搭配。</p>
<p>🌟 He is not such a fool as he looks.</p>
<p>🌟 He rides as expensive a bike as he can afford.</p>
<p>2️⃣ <code>as</code>引导的非限制定语从句</p>
<p>一般这时候，代替整个主句~</p>
<p>我们常见的就有<code>as we all know, aas it is known, as it is , as it said above, as is usual</code>等等啦。</p>
<p>🌟 As is known to the United States, Mark Twain is a great writer.</p>
<p>🌟 As we all know, the earth is round.</p>
<p>🌟 He is absorbed in work, as he often was.</p>
<hr>
<blockquote>
<p>我们再来看看关系副词引导的定语从句</p>
</blockquote>
<p>🏷️ 关系副词<code>when/where</code></p>
<p>当先行词是时间或地点名词，在从句中充当时间状语或地点状语，相当于&quot;介词+which&quot;</p>
<p>🌟 October 1, 1949 was the day when (=on which) the People’s Republic of China was founded.</p>
<p>🌟 This is the school where (=in which) I studied a few years ago.</p>
<p>那啥，<code>where</code>有时还可以于抽象名词后引导定语从句，常见的抽象名词有：</p>
<ul>
<li>point</li>
<li>degree</li>
<li>stage</li>
<li>position</li>
<li>case</li>
<li>condition</li>
</ul>
<p>🌟 We have reached a point where a change is needed.</p>
<p>🌟 He got into a situation where it is hard to decide what is right and wrong.</p>
<hr>
<p>🚗 关系副词<code>why</code></p>
<p>只能用于引导限制性定语从句哦，先行词只有<code>reason</code>，充当原因状语，相当于<code>for which</code></p>
<p>🌟 Do you know the reason why (=for which) he is not here now?</p>
<hr>
<p>✈️ 关系代词<code>which</code>和<code>that</code>的区别</p>
<p>🌵 只能用<code>that</code>的情况</p>
<ul>
<li>
<p>先行词是不定代词，或者被<code>every, any, all, some, no, little, few, much</code>等修饰</p>
</li>
<li>
<p>先行词被序数词、形容词最高级、the only, the very, the last等修饰</p>
</li>
<li>
<p>先行词有人有物</p>
</li>
<li>
<p>疑问词是<code>who</code>或者<code>which</code></p>
</li>
</ul>
<p>🍰 只用<code>which</code></p>
<ul>
<li>在非限制性定语从句中只能使用关系代词<code>which</code></li>
<li>&quot;介词+关系代词&quot;引导的定语从句中，只能使用关系词<code>which</code>不能使用<code>that</code></li>
</ul>
<hr>
<h3 id="注意点-v2">注意点</h3>
<p>1️⃣ 定语从句的谓语动词需要跟先行词的人称和数保持一致！</p>
<p>🌟 Tom is one of the boys who are from the USA.</p>
<p>🌟 Tom is the only boy that is from the USA.</p>
<p>⭐ I, who am in Australia, feel proud of being a Chinese.</p>
<p>2️⃣ that和why只能引导限制，而what不能在定语从句中充当引导词</p>
<p>3️⃣ 限制性从句中，关系代词做动词宾语或介词宾语放在句末的时候，是可以进行省略的。而非限制性则不能进行省略。</p>
<p>🌟 Is there anything [ ( that ) you wanted ]?</p>
<p>🌟 Who is the man, whom you were talking to?</p>
<p>4️⃣ 用关系代词还是关系副词，取决于关系词在定语从句中充当的作用。</p>
<p>5️⃣ 以<code>the way</code>为先行词的限制性定语从句通常由<code>in which</code>和<code>that</code>引导，而且通常可以省略</p>
<hr>
<h2 id="三、状语从句">三、状语从句</h2>
<p>今天我们来talk about状语从句~</p>
<p><strong>啥是状语从句</strong></p>
<p>⚓ 当然是在复合句中充当状语的从句啦！</p>
<p><strong>有虾米用</strong></p>
<p>⚓ 用来修饰谓语、非谓语动词、定语、状语或者整个句子！换句话说，就是<code>增加信息量</code>!</p>
<p>⚓ 当然啦，脱离了状语从句的主句也能成活，且意思不受影响~</p>
<p><strong>结构捏</strong></p>
<p>⚓ 状语从句一般由<strong>连词</strong>引导，也可以由<strong>词组</strong>引导，可以放在任何位置~</p>
<p>⚓ 不失一般性，放在句首或句中时，通常用逗号隔开，而句末一般不用。</p>
<p>🌟 连词+状语从句 , 主句</p>
<p>🌟 主句 , 连词+状语从句</p>
<p><strong>分类捏</strong></p>
<p>根据状语从句所蕴含的信息，可以分为九大类！</p>
<table>
<thead>
<tr>
<th style="text-align:center">类型</th>
<th style="text-align:center">连词 or 词组</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">时间状语从句</td>
<td style="text-align:center">when, while, as, before, after, since, until, as soon as. etc.</td>
</tr>
<tr>
<td style="text-align:center">地点状语从句</td>
<td style="text-align:center">where, wherever</td>
</tr>
<tr>
<td style="text-align:center">原因状语从句</td>
<td style="text-align:center">because, since, as</td>
</tr>
<tr>
<td style="text-align:center">结果状语从句</td>
<td style="text-align:center">so…that, such…that</td>
</tr>
<tr>
<td style="text-align:center">❤️</td>
<td style="text-align:center">🥀</td>
</tr>
<tr>
<td style="text-align:center">目的状语从句</td>
<td style="text-align:center">so that, in order that</td>
</tr>
<tr>
<td style="text-align:center">条件状语从句</td>
<td style="text-align:center">if, unless, as long as</td>
</tr>
<tr>
<td style="text-align:center">方式状语从句</td>
<td style="text-align:center">as, as if/though, the way</td>
</tr>
<tr>
<td style="text-align:center">💙</td>
<td style="text-align:center">📘</td>
</tr>
<tr>
<td style="text-align:center">让步状语从句</td>
<td style="text-align:center">though, although, even if/ though.</td>
</tr>
<tr>
<td style="text-align:center">比较状语从句</td>
<td style="text-align:center">as…as, 比较级+than</td>
</tr>
</tbody>
</table>
<hr>
<blockquote>
<p>时间状语从句</p>
</blockquote>
<p>用来告诉你主句<code>发生的时间</code>！引导词包括：</p>
<p>🏷️ 当…的时候: <code>when, while, as</code></p>
<p>🏷️ …发生前/后: <code>before, after</code></p>
<p>🏷️ 一…就…(类似触发器~): <code>as soon as, no sooner...than..., hardly...when...</code></p>
<p>🏷️ 自从: <code>since</code></p>
<p>🏷️ 直到: <code>until</code></p>
<hr>
<p>🍎 <strong>when, while, as</strong></p>
<p><strong>when</strong>：像你身边人畜无害的朋友，既可以跟<code>瞬间性动词</code>（词组）<em>go to bed</em> 玩在一起，也可以和<code>延续性动词</code> <em>drink</em> 做朋友。</p>
<p>例如！</p>
<p>🌟 When Dad was drinking Coke, Mom went to bed.</p>
<p>🌟 Dad was drinking Coke when Mom went to bed.</p>
<p>固定搭配<code>be about to do sth. when...</code> 表示<code>正要做某事，这时</code></p>
<p>🌟 Mon was about to fall asleep when Dad gave a loud burp.</p>
<hr>
<p><strong>while</strong>：这个词，有点像你身边比较高冷的那种人，基本只跟<code>延续性动词</code>（如 drink）一起玩，而且常常是进行时。</p>
<p>🌟 While Dad was drinking Coke, Mom went to bed.</p>
<hr>
<p><strong>as</strong>：朋友圈也比较固定，后面跟延续性动词（如 drink）。as 强调主、从句两个动作<strong>同时发生</strong></p>
<p>🌟 As Dad was drinking Coke, he saw Mom go to the bedroom.</p>
<hr>
<p>🍎  <strong>until, not…until</strong></p>
<p>until，单独一个词相当于 till，是“直到……”的意思。</p>
<p>那么，not…until 直译过来就是“不做某事，直到……”。这样讲话费劲啊，我们再捋捋通顺：“直到……才……”。</p>
<p>🌟 I watched TV until Mom came home.</p>
<p>🌟 I didn’t watch TV until Mom came home.</p>
<p>我们看两个栗子!</p>
<p>1）我爱你，至死不渝。from《唐顿庄园》</p>
<p>💌 I will love you, until the last breath leaves my body.</p>
<p>2）直到放弃你，我才能爱你。from《纯真年代》</p>
<p>💌 I can’t love you until I give you up.</p>
<hr>
<p>🍎 <strong>as soon as</strong></p>
<p>“一……就……”，遵循<code>主将从现</code>哦！</p>
<p>🌟 I will call you as soon as I arrive.</p>
<p><strong>升级版</strong> <strong>no sooner … than …</strong></p>
<p>遵循主句过去完成，从句一般过去！</p>
<p>意思是：刚做完A，就去做B啦</p>
<p>所以A的时态相当于说话点的过去！而且A是完成了的，所以是过去完成时！</p>
<p>该句型描述的动作一般都发生在过去哦。</p>
<p>🌟 Dad had no sooner finished dinner than he took a Coke from the fridge.</p>
<hr>
<blockquote>
<p>条件状语从句</p>
</blockquote>
<p>条件状语从句表示满足某个条件<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span>，事件<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> 才会发生!</p>
<p><strong>引导词</strong></p>
<ul>
<li>if</li>
<li>unless</li>
</ul>
<p>🍎 <strong>if</strong></p>
<p>if适用于主将从现</p>
<p>🌟 If you jump, I will jump.</p>
<p>🍎 <strong>unless</strong></p>
<p><code>unless</code>与<code>if</code>反着来，表示除非~</p>
<p>🌟 Unless you jump, I won’t jump.</p>
<p>🌟 If you don’t jump, I won’t jump.</p>
<hr>
<blockquote>
<p>原因状语从句</p>
</blockquote>
<p>告诉你事情 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span> 发生的原因！通常由<code>because, since, as</code> 引导，气场上逐渐减弱~</p>
<p>🍎 <strong>because</strong></p>
<p><code>because</code>表示直接原因，能够回答<code>why</code>的提问。一般情况下，提问方是不知道原因的。</p>
<p>⭐ Why do you hate her?</p>
<p>🌟 Because her dog always shits at my door.</p>
<p>🔔 注意注意！<code>because</code>不能和<code>so</code>一起用！</p>
<hr>
<p>🍎 <strong>since</strong></p>
<p><code>since</code>一般放在句首，一般可以表示为<code>既然</code>，带点小傲娇</p>
<p>既然你诚心诚意的发问啦，我就告诉你为什么吧~</p>
<p>🌟 Since you asked in good faith, I will tell you why~</p>
<hr>
<p>🍎 <strong>as</strong></p>
<p><code>as</code>可以表示<code>由于</code>，意思和语境是最弱也是最不正式的哦</p>
<p>🌟 As Mom gets angry, we had better go outside for a while.</p>
<hr>
<blockquote>
<p>结果状语从句！</p>
</blockquote>
<p>告诉你事件<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span> 带来的结果！</p>
<p>一般来说，用<code>so...that..., such...that...</code>引导啦，可以意为：<code>如此，以至于</code></p>
<p>🌟 D&amp;G is <strong>so</strong> stupid <strong>that</strong> it <strong>took</strong> “hacked accounts” <strong>as</strong> an excuse.</p>
<p><code>so</code>后面跟形容词，<code>such</code>后面跟人或物~</p>
<p>❗ The baby is <strong>so cute</strong> that Wong likes her.</p>
<p>❗ She is <strong>such a cute baby</strong> that Wong likes her.</p>
<p>当然，遇到<code>many, much, little, few</code>这类不定形容词修饰的时候，只能用<code>so</code></p>
<p>🇱🇦 so many people, so much money</p>
<hr>
<blockquote>
<p>目的状语从句！</p>
</blockquote>
<p>告诉你做事件<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span> 是为了啥！</p>
<p>一般用<code>so that, in order that</code>引导，可以理解为<code>为了，以便</code></p>
<p>🏷️ <code>so that</code>和<code>in order that</code>用法相同</p>
<p>🌟 I got up early <strong>so that / in order that</strong> I could catch the early flight.</p>
<p>我们做个对比(跟结果状语<code>so...that</code>)</p>
<p>☀️ I got up early <strong>so that</strong> I could catch the early flight.</p>
<p>🌙 I got up <strong>so</strong> early <strong>that</strong> I felt drowsy in the afternoon.</p>
<p>可以从以下三个方面进行区分哦</p>
<p>1️⃣ 看意思。早起是为了赶飞机，但结果可能是一整天精神萎靡，让人看着像二傻子。</p>
<p>2️⃣ 结果状语从句的 so…that 大多数情况下分开写，目的状语从句的 so that 则当做固定搭配来记；</p>
<p>3️⃣ <strong>目的状语从句一般带情态动词 can/ could, may/ might等。</strong></p>
<hr>
<blockquote>
<p>让步状语从句</p>
</blockquote>
<p>告诉你某事即使退一万步讲会怎样，通常由 <code>although, though, even though</code> 等引导，可以理解为<code>尽管……</code>，<code>即使……</code>。</p>
<p>🌟 Although Mom has a hot temper, Dad loves her very much.</p>
<p>❗ <code>although</code>和<code>but</code>也不能用在一个句子里！</p>
<p>❗ <code>although</code>比<code>though</code>更加的正式，而<code>though</code>可以做副词，意思是<code>然鹅</code>，阔以放在句末~</p>
<p>🌟 I got up early, I didn’t catch the early flight, though.</p>
<hr>
<blockquote>
<p>比较状语从句</p>
</blockquote>
<p>告诉你<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span> 和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> 一样，或者<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span> 比<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> 更怎样。通常由<code>as + 形容词/ 副词 + as…</code>，<code>比较级 + than…</code>等引导。</p>
<p>🌟 My sister eats <strong>twice</strong> <strong>as much as</strong> I do.</p>
<p>🏷️ 第二个<code>as</code>引导比较状语从句。第一个<code>as</code>是<code>as...as...</code>结构，意为<code>和...一样</code></p>
<hr>
<blockquote>
<p>方式状语从句</p>
</blockquote>
<p>告诉你动作以什么方式展开，常常由 as, as if/ though, the way 引导。</p>
<p>🌟 When in Rome, do <strong>as</strong> the Romans do.<br>
🏷️ 入乡随俗。</p>
<p>🌟 Treat people <strong>the way</strong> you want to be treated.<br>
🏷️ 用你希望别人对待你的方式去对待别人。</p>
<hr>
<blockquote>
<p>地点状语从句</p>
</blockquote>
<p>告诉你动作在哪里发生（可以是抽象意义），常由 <code>where</code> 等来引导。</p>
<p>🌟 <strong>Where</strong> there is a will, there is a way.<br>
🏷️ 有志者事竟成。</p>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 不想学辣 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 英语 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[LeetCode 算法题归档]]></title>
      <url>/2022/08/06/%E3%80%90LeetCode%E3%80%91%20%E5%88%B7%E9%A2%98%E5%BD%92%E6%A1%A3/</url>
      <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>呼呼呼</p>
<p>这是我的刷题统计~</p>
<p>每周对这些题进行简单的复盘！</p>
<hr>
<h2 id="分组">分组</h2>
<blockquote>
<p>难度🌟=3⭐  🌙=3🌟 ☀️=3🌙 思维题♦️</p>
</blockquote>
<p><strong>前缀和</strong></p>
<table>
<thead>
<tr>
<th style="text-align:center">题号</th>
<th style="text-align:center">名称</th>
<th style="text-align:center">难度</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">724</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/find-pivot-index/">寻找数组的中心下标</a></td>
<td style="text-align:center">⭐⭐</td>
</tr>
<tr>
<td style="text-align:center">1403</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/minimum-subsequence-in-non-increasing-order/">非递增最小子序列</a></td>
<td style="text-align:center">⭐⭐</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
<hr>
<p><strong>模拟</strong></p>
<table>
<thead>
<tr>
<th style="text-align:center">题号</th>
<th style="text-align:center">名称</th>
<th style="text-align:center">难度</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">592</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/fraction-addition-and-subtraction/">分数加减运算</a></td>
<td style="text-align:center">🌟🌟</td>
</tr>
<tr>
<td style="text-align:center">622</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/design-circular-queue/">设计循环队列</a></td>
<td style="text-align:center">🌟🌟</td>
</tr>
<tr>
<td style="text-align:center">1374</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/generate-a-string-with-characters-that-have-odd-counts/">生成每个字符都是奇数个的字符串</a></td>
<td style="text-align:center">⭐</td>
</tr>
<tr>
<td style="text-align:center">2365</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/task-scheduler-ii/">任务调度器II</a></td>
<td style="text-align:center">🌙⭐</td>
</tr>
<tr>
<td style="text-align:center">636</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/exclusive-time-of-functions/">函数的独占时间</a></td>
<td style="text-align:center">🌙</td>
</tr>
<tr>
<td style="text-align:center">640</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/solve-the-equation/">求解方程</a></td>
<td style="text-align:center">🌙</td>
</tr>
<tr>
<td style="text-align:center">1706</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/where-will-the-ball-fall/">球会落在哪</a></td>
<td style="text-align:center">🌙</td>
</tr>
<tr>
<td style="text-align:center">202</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/happy-number/">快乐数</a></td>
<td style="text-align:center">🌙</td>
</tr>
<tr>
<td style="text-align:center">54</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/spiral-matrix/">螺旋矩阵</a></td>
<td style="text-align:center">🌔</td>
</tr>
<tr>
<td style="text-align:center">59</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/spiral-matrix-ii/">螺旋矩阵II</a></td>
<td style="text-align:center">🌟🌟</td>
</tr>
<tr>
<td style="text-align:center">885</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/spiral-matrix-iii/">螺旋矩阵III</a></td>
<td style="text-align:center">🌙🌙</td>
</tr>
<tr>
<td style="text-align:center">2326</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/spiral-matrix-iv/">螺旋矩阵IV</a></td>
<td style="text-align:center">🌙</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
<hr>
<p><strong>字符串</strong></p>
<table>
<thead>
<tr>
<th style="text-align:center">题号</th>
<th style="text-align:center">名称</th>
<th style="text-align:center">难度</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">205</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/isomorphic-strings/">同构字符串</a></td>
<td style="text-align:center">⭐</td>
</tr>
<tr>
<td style="text-align:center">392</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/is-subsequence/">判断子序列</a></td>
<td style="text-align:center">🌙</td>
</tr>
<tr>
<td style="text-align:center">409</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/longest-palindrome/">最长回文串</a></td>
<td style="text-align:center">⭐</td>
</tr>
<tr>
<td style="text-align:center">1408</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/string-matching-in-an-array/">数组字符串匹配</a></td>
<td style="text-align:center">⭐</td>
</tr>
<tr>
<td style="text-align:center">761</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/special-binary-string/">特殊的二进制序列</a></td>
<td style="text-align:center">☀️</td>
</tr>
<tr>
<td style="text-align:center">299</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/bulls-and-cows/">猜数字</a></td>
<td style="text-align:center">🌟</td>
</tr>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/two-sum/">两数之和</a></td>
<td style="text-align:center">⭐</td>
</tr>
<tr>
<td style="text-align:center">1417</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/reformat-the-string/">重新格式化字符串</a></td>
<td style="text-align:center">🌟</td>
</tr>
</tbody>
</table>
<hr>
<p><strong>数组</strong></p>
<table>
<thead>
<tr>
<th style="text-align:center">题号</th>
<th style="text-align:center">名称</th>
<th style="text-align:center">难度</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1480</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/running-sum-of-1d-array/">一维数组的动态和</a></td>
<td style="text-align:center">⭐</td>
</tr>
<tr>
<td style="text-align:center">1331</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/rank-transform-of-an-array/">数组序号转换</a></td>
<td style="text-align:center">⭐⭐</td>
</tr>
<tr>
<td style="text-align:center">121</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/best-time-to-buy-and-sell-stock/">买股票的最佳时机</a></td>
<td style="text-align:center">🌟</td>
</tr>
<tr>
<td style="text-align:center">622</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/design-circular-queue/">设计循环队列</a></td>
<td style="text-align:center">🌟🌟</td>
</tr>
<tr>
<td style="text-align:center">899</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/orderly-queue/">有序队列</a></td>
<td style="text-align:center">♦️</td>
</tr>
<tr>
<td style="text-align:center">2363</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/merge-similar-items/">合并相似的物品</a></td>
<td style="text-align:center">⭐</td>
</tr>
<tr>
<td style="text-align:center">2364</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/count-number-of-bad-pairs/">统计坏数对的数目</a></td>
<td style="text-align:center">🌙</td>
</tr>
<tr>
<td style="text-align:center">2366</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/minimum-replacements-to-sort-the-array/">将数组排序的最小替换次数</a></td>
<td style="text-align:center">☀️</td>
</tr>
<tr>
<td style="text-align:center">2367</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/number-of-arithmetic-triplets/">算数三元组的数量</a></td>
<td style="text-align:center">⭐</td>
</tr>
<tr>
<td style="text-align:center">1413</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/minimum-value-to-get-positive-step-by-step-sum/">逐步求和得到正数的最小值</a></td>
<td style="text-align:center">🌟</td>
</tr>
<tr>
<td style="text-align:center">394</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/decode-string/">字符串解码</a></td>
<td style="text-align:center">🌙⭐</td>
</tr>
<tr>
<td style="text-align:center">844</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/backspace-string-compare/">比较退格字符串</a></td>
<td style="text-align:center">⭐⭐</td>
</tr>
<tr>
<td style="text-align:center">692</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/top-k-frequent-words/">前k个高频单词</a></td>
<td style="text-align:center">🌟🌟</td>
</tr>
<tr>
<td style="text-align:center">1282</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/reformat-the-string/">用户分组</a></td>
<td style="text-align:center">🌟🌟</td>
</tr>
</tbody>
</table>
<hr>
<p><strong>动态规划</strong></p>
<table>
<thead>
<tr>
<th style="text-align:center">题号</th>
<th style="text-align:center">名称</th>
<th style="text-align:center">难度</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">392</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/is-subsequence/">判断子序列</a></td>
<td style="text-align:center">🌙</td>
</tr>
<tr>
<td style="text-align:center">121</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/best-time-to-buy-and-sell-stock/">买股票的最佳时机</a></td>
<td style="text-align:center">⭐</td>
</tr>
<tr>
<td style="text-align:center">70</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/climbing-stairs/">爬楼梯</a></td>
<td style="text-align:center">⭐</td>
</tr>
<tr>
<td style="text-align:center">509</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/fibonacci-number/">斐波那契数列</a></td>
<td style="text-align:center">⭐</td>
</tr>
<tr>
<td style="text-align:center">746</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/min-cost-climbing-stairs/">花费最小爬楼梯</a></td>
<td style="text-align:center">⭐⭐</td>
</tr>
<tr>
<td style="text-align:center">62</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/unique-paths/">不同路径</a></td>
<td style="text-align:center">⭐⭐</td>
</tr>
<tr>
<td style="text-align:center">2369</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/check-if-there-is-a-valid-partition-for-the-array/">检查数组是否存在有效划分</a></td>
<td style="text-align:center">🌙</td>
</tr>
<tr>
<td style="text-align:center">2370</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/longest-ideal-subsequence/submissions/">最长理想子序列</a></td>
<td style="text-align:center">🌟🌟</td>
</tr>
</tbody>
</table>
<hr>
<p><strong>数学</strong></p>
<table>
<thead>
<tr>
<th style="text-align:center">题号</th>
<th style="text-align:center">名称</th>
<th style="text-align:center">难度</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">593</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/valid-square/">有效正方形</a></td>
<td style="text-align:center">♦️</td>
</tr>
<tr>
<td style="text-align:center">70</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/climbing-stairs/">爬楼梯</a></td>
<td style="text-align:center">♦️</td>
</tr>
<tr>
<td style="text-align:center">509</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/fibonacci-number/">斐波那契数列</a></td>
<td style="text-align:center">♦️</td>
</tr>
</tbody>
</table>
<hr>
<p><strong>并查集+DFP+BFS（图)</strong></p>
<table>
<thead>
<tr>
<th style="text-align:center">题号</th>
<th style="text-align:center">名称</th>
<th style="text-align:center">难度</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">547</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/number-of-provinces/">省份数量</a></td>
<td style="text-align:center">🌟🌟</td>
</tr>
<tr>
<td style="text-align:center">952</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/largest-component-size-by-common-factor/">按公因数计算最大组件大小</a></td>
<td style="text-align:center">☀️</td>
</tr>
<tr>
<td style="text-align:center">733</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/flood-fill/">图像渲染</a></td>
<td style="text-align:center">🌟</td>
</tr>
<tr>
<td style="text-align:center">200</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/number-of-islands/">岛屿数量</a></td>
<td style="text-align:center">🌟🌟</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
<hr>
<p><strong>链表</strong></p>
<table>
<thead>
<tr>
<th style="text-align:center">题号</th>
<th style="text-align:center">名称</th>
<th style="text-align:center">难度</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">21</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/merge-two-sorted-lists/">合并有序链表</a></td>
<td style="text-align:center">⭐</td>
</tr>
<tr>
<td style="text-align:center">206</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/reverse-linked-list/">反转链表</a></td>
<td style="text-align:center">⭐⭐</td>
</tr>
<tr>
<td style="text-align:center">876</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/middle-of-the-linked-list/">链表中间节点</a></td>
<td style="text-align:center">⭐</td>
</tr>
<tr>
<td style="text-align:center">142</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/linked-list-cycle-ii/">环形链表 II</a></td>
<td style="text-align:center">⭐⭐</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
<hr>
<p><strong>树</strong></p>
<table>
<thead>
<tr>
<th style="text-align:center">题号</th>
<th style="text-align:center">名称</th>
<th style="text-align:center">难度</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1161</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/maximum-level-sum-of-a-binary-tree/">最大层内元素和</a></td>
<td style="text-align:center">⭐⭐</td>
</tr>
<tr>
<td style="text-align:center">623</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/add-one-row-to-tree/">在二叉树中增加一行</a></td>
<td style="text-align:center">🌙</td>
</tr>
<tr>
<td style="text-align:center">589</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/n-ary-tree-preorder-traversal/">N叉树的前序遍历</a></td>
<td style="text-align:center">⭐</td>
</tr>
<tr>
<td style="text-align:center">102</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/binary-tree-level-order-traversal/">二叉树的层序遍历</a></td>
<td style="text-align:center">⭐</td>
</tr>
<tr>
<td style="text-align:center">235</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/lowest-common-ancestor-of-a-binary-search-tree/">二叉搜索树最近公共祖先</a></td>
<td style="text-align:center">⭐⭐</td>
</tr>
<tr>
<td style="text-align:center">98</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/validate-binary-search-tree/">验证二叉搜索树</a></td>
<td style="text-align:center">🌙</td>
</tr>
<tr>
<td style="text-align:center">2368</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/reachable-nodes-with-restrictions/">受限制条件下可达到的节点数</a></td>
<td style="text-align:center">🌙⭐</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
<hr>
<p><strong>二分法</strong></p>
<table>
<thead>
<tr>
<th style="text-align:center">题号</th>
<th style="text-align:center">名称</th>
<th style="text-align:center">难度</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">704</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/binary-search/">二分查找</a></td>
<td style="text-align:center">⭐</td>
</tr>
<tr>
<td style="text-align:center">278</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/first-bad-version/">第一个错误版本</a></td>
<td style="text-align:center">⭐</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
<hr>
<p><strong>滑动窗口+双指针</strong></p>
<table>
<thead>
<tr>
<th style="text-align:center">题号</th>
<th style="text-align:center">名称</th>
<th style="text-align:center">难度</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">424</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/binary-search/">替换后的最长重复字符</a></td>
<td style="text-align:center">🌙</td>
</tr>
<tr>
<td style="text-align:center">438</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/find-all-anagrams-in-a-string/">找到字符串中所有字母异位值</a></td>
<td style="text-align:center">🌙</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
<hr>
<p><strong>优先队列+堆</strong></p>
<table>
<thead>
<tr>
<th style="text-align:center">题号</th>
<th style="text-align:center">名称</th>
<th style="text-align:center">难度</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1046</td>
<td style="text-align:center"><a href="https://leetcode.cn/problems/last-stone-weight/">最后一块石头的重量</a></td>
<td style="text-align:center">🌟</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 不想学辣 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 算法 </tag>
            
            <tag> LeetCode </tag>
            
            <tag> 总结 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Python中:=符号的用法]]></title>
      <url>/2022/08/06/%E3%80%90Python%E3%80%91%20=%E7%AC%A6%E5%8F%B7/</url>
      <content type="html"><![CDATA[<blockquote>
<p>是不是经常看到:=符号而又百思不得其解呢</p>
</blockquote>
<h2 id="栗子">栗子</h2>
<p>话不多说，我们直接上例子!</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">a=<span class="number">321</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line"><span class="built_in">print</span>(v:=a)</span><br><span class="line"><span class="built_in">print</span>(v)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">321</span></span><br><span class="line"><span class="string">321</span></span><br><span class="line"><span class="string">321</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>对数字有着某种规律的话，对其他类型是否有效呢?</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 再来看一个简单的栗子</span></span><br><span class="line">a=<span class="built_in">input</span>() <span class="comment"># &quot;abcd&quot;</span></span><br><span class="line"><span class="built_in">print</span>(v:=a)</span><br><span class="line"><span class="built_in">print</span>(v)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">abcd</span></span><br><span class="line"><span class="string">abcd</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>从上述的两个栗子我们可以发现，<code>:=</code>符号的作用是在表达式内获取变量值并赋给新变量。</p>
<p>好像他的返回值也挺有意思的？我们进一步观察:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">a=<span class="number">7</span></span><br><span class="line"><span class="built_in">print</span>(V:=(a+<span class="number">2</span>))</span><br><span class="line"><span class="built_in">print</span>(V)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">9</span></span><br><span class="line"><span class="string">9</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>没错了，不但能够将表达式的值赋给变量，还能够再向上返回这个值。</p>
<h2 id="总结">总结</h2>
<p><code>:=</code>符号不能单独作为一个语句使用，一般是嵌套在函数内部，用于中间层获取返回值。</p>
<p>可以类似于A给B打电话，C偷听了他们的内容，并且记下来了。此时A和B依旧在正常通话。</p>
<p>其实就是个<code>语法糖</code>一样的东西啦</p>
<h2 id="案例">案例</h2>
<p>数据分析，要求从微信接龙中随机抽取<code>35</code>名选手参加毕业典礼。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">solve</span>(<span class="params">s:<span class="built_in">str</span>,k:<span class="built_in">int</span>=<span class="number">35</span></span>)-&gt;<span class="literal">None</span>:</span><br><span class="line"></span><br><span class="line">    hashmap=defaultdict(<span class="built_in">str</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(s) <span class="keyword">as</span> f:</span><br><span class="line">        nameList=f.readlines()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> nameList:</span><br><span class="line">        hashmap[val[<span class="number">0</span>]]=(val:=i.split(<span class="string">&quot;.&quot;</span>))[<span class="number">1</span>].strip(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> random.sample(<span class="built_in">range</span>(<span class="number">1</span>,(l:=<span class="built_in">len</span>(hashmap))+<span class="number">1</span>),l-k <span class="keyword">if</span> l&gt;k <span class="keyword">else</span> <span class="number">0</span>):</span><br><span class="line">        <span class="built_in">print</span>(hashmap[<span class="built_in">str</span>(i)])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">solve(<span class="string">r&quot;C:\Users\lenovo\Desktop\新建 XLS 工作表.txt&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>我们来做个小练习吧~</p>
<hr>
<h2 id="练习题">练习题</h2>
<p>给定一个单词列表 <code>words</code>和一个整数 <code>k </code>，返回前<code>k</code>个出现次数最多的单词。</p>
<p>返回的答案应该按单词出现频率由高到低排序。如果不同的单词有相同出现频率， 按<code>字典顺序</code> 排序。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">topKFrequent</span>(<span class="params">self, words: <span class="type">List</span>[<span class="built_in">str</span>], k: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">str</span>]:</span><br><span class="line">        <span class="comment"># 先获取到一个单词hash表 Counter(words)</span></span><br><span class="line">        <span class="comment"># 题目所给的需要进行的排序优先度为： 数量&gt;字典序</span></span><br><span class="line">        <span class="comment"># 我们可以考虑采用sorted函数，通过关键词 key=lambda x:(数量,字典序) 进行排序</span></span><br><span class="line">        <span class="comment"># 当然，数量是从小到大，而字典序是从大到小，这里需要控制</span></span><br><span class="line">        <span class="comment"># 所以最终的语句为:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">sorted</span>((cnt:=Counter(words)).keys(),key=<span class="keyword">lambda</span> x:(-cnt[x],x))[:k]</span><br></pre></td></tr></table></figure>
<p>这个语句等价于：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">topKFrequent</span>(<span class="params">self, words, k: <span class="built_in">int</span></span>):</span><br><span class="line">        cnt=Counter(words)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">sorted</span>(cnt.keys(),key=<span class="keyword">lambda</span> x:(-cnt[x],x))[:k]</span><br></pre></td></tr></table></figure>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 不想学辣 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Python </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[【二】语态、倒装、强调、省略]]></title>
      <url>/2022/08/04/%E3%80%90%E8%8B%B1%E8%AF%AD%E3%80%91%E8%A2%AB%E5%8A%A8%E5%BC%BA%E8%B0%83%E5%80%92%E8%A3%85%E7%9C%81%E7%95%A5/</url>
      <content type="html"><![CDATA[<h2 id="被动语态">被动语态</h2>
<p>与主动语态相对，被动语态将焦点放在<code>动作的承受者</code>上。</p>
<img src="/2022/08/04/%E3%80%90%E8%8B%B1%E8%AF%AD%E3%80%91%E8%A2%AB%E5%8A%A8%E5%BC%BA%E8%B0%83%E5%80%92%E8%A3%85%E7%9C%81%E7%95%A5/image-20220804152517953.png" alt="image-20220804152517953" style="zoom: 50%;">
<blockquote>
<p>构成: &lt;承受者&gt; be + 过去分词 + （by + &lt;动作执行者&gt;）</p>
</blockquote>
<p><strong>例句</strong></p>
<ul>
<li>His bicycle was stolen.</li>
<li>The building has been built in 2000.</li>
</ul>
<blockquote>
<p>注意啦，被动语态只有主语没有宾语，by xxx 是动作的承接者，作状语</p>
</blockquote>
<h3 id="什么时候需要使用被动语态呢？">什么时候需要使用被动语态呢？</h3>
<ol>
<li>不知道动作的执行者，或是没有必要知道
<ul>
<li>Paper is made from wood.</li>
<li>He was wounded in the fight.</li>
<li>Electricity is used to run machines.</li>
</ul>
</li>
<li>需要强调动作的对象时
<ul>
<li>Calculator can’t be used in the maths exam.</li>
<li>He was awarded first prize in that contest.</li>
</ul>
</li>
<li>让语气婉转，或是刻意隐藏信息
<ul>
<li>The construction of the new lab must be completed by the end of next month.</li>
</ul>
</li>
</ol>
<h3 id="被动语态的结构">被动语态的结构</h3>
<ul>
<li>一般现在时: be + p. p 及物动词的过去分词</li>
<li>一般过去时: was / were + p. p</li>
<li>一般将来时: shall / will be + p. p</li>
<li>现在完成时: have / has been + p. p</li>
<li>现在进行时: be + being + p. p</li>
<li>过去将来时: should / would be + p. p</li>
<li>情态动词: 情态动词 + be + p. p</li>
</ul>
<h3 id="如何将主动变成被动呢？">如何将主动变成被动呢？</h3>
<ol>
<li>从句子的意义上看，找出<code>被完成</code>的事物
<ul>
<li>主动: People speak English in many countries.</li>
<li>被动: English is spoken by People in many countries.</li>
</ul>
</li>
<li>从语法的角度看，把<code>宾语</code>改成主语
<ul>
<li>主动: Xiao Liu has invited you to a lunch party.</li>
<li>被动: You has been invited to a lunch party by Xiao Liu.</li>
</ul>
</li>
</ol>
<h3 id="特殊情况">特殊情况</h3>
<p>在主动变成被动时，需要留意以下几个特殊情况：</p>
<ol>
<li>含双宾语的主动变成被动时，有两种方法：
<ol>
<li>间接宾语变成主语，直接宾语保持不变</li>
<li>直接宾语变位主语，间接宾语用<code>to</code>或<code>for</code>引导</li>
</ol>
</li>
</ol>
<p>例如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">He told us a story.</span><br><span class="line"></span><br><span class="line"><span class="comment"># type 1</span></span><br><span class="line">We were told a story (by him).</span><br><span class="line"></span><br><span class="line"><span class="comment"># type 2</span></span><br><span class="line">A story was told to us (by him).</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>短语动词的被动需要视作一个整体，不能省去动词后的介词或副词</li>
<li>省略的to变成被动时需要补上</li>
<li>动词不定式的被动语态为<code>to be ＋过去分词</code></li>
<li>以疑问代词开头的疑问句转换成被动句时要注意词序：应将主动句中的疑问代词改为介词by的宾语，但仍然放在句子开头</li>
</ol>
<p>例如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Who has broken the cup?</span><br><span class="line"></span><br><span class="line">By Whom has the cup been broken?</span><br></pre></td></tr></table></figure>
<img src="/2022/08/04/%E3%80%90%E8%8B%B1%E8%AF%AD%E3%80%91%E8%A2%AB%E5%8A%A8%E5%BC%BA%E8%B0%83%E5%80%92%E8%A3%85%E7%9C%81%E7%95%A5/image-20220804205826411.png" alt="image-20220804205826411" style="zoom:50%;">
<hr>
<h2 id="倒装句">倒装句</h2>
<p>倒装句作为英语的一种修辞手法，可以用来强调<code>主语</code>。一般呢，常见于书面用语。</p>
<p>比如：</p>
<ul>
<li>你吃<code>胡萝卜</code>了吗？</li>
<li>吃胡萝卜了吗，<code>你</code>？</li>
</ul>
<h3 id="一、完全倒装">一、完全倒装</h3>
<p>完全倒装的谓语动词完全放在主语前了，一般情况下，用于副词/介词短语在句首的倒装，和主语补语的倒装。</p>
<p><strong>地点副词在句首的倒装</strong></p>
<p>关键词: <code>here</code>，<code>there</code></p>
<p>例句: There <code>goes</code> the last bus.</p>
<p><strong>时间副词在句首的倒装</strong></p>
<p>关键词: <code>now</code>，<code>then</code></p>
<p>例句: Now <code>comes</code> the wolf’s turn.</p>
<p><strong>表运动方向在句首的倒装</strong></p>
<p>关键词: <code>in</code>，<code>out</code>，<code>up</code>，<code>down</code>，<code>away</code></p>
<p>例句: Up drive the car on the road.</p>
<p><strong>表语的倒装</strong></p>
<p>关键词：形容词、分词、介词短语、<code>such</code></p>
<p>例句：Seated on the ground is a group of rabbits.</p>
<p>Such were the wolf’s trick.</p>
<hr>
<h3 id="二、部分倒装">二、部分倒装</h3>
<p>分离助动词和谓语动词，将助动词提前。</p>
<p>主要用在：</p>
<ul>
<li>句首有否定意义时</li>
<li>句首有<code>only</code>时</li>
<li><code>if...should...</code>构成虚拟语气时</li>
<li>固定句型</li>
</ul>
<p><strong>句首有否定意义的倒装</strong></p>
<p>Never befor have I eaten such a delicious carrot.</p>
<p><strong>句首有Only的倒装</strong></p>
<p>Only in this way can we grow delicious carrots.</p>
<p>Only then did the rabbit meet the wolf.</p>
<p><strong>if…should…构成虚拟的倒装</strong></p>
<p>正常语序：If I should win the lottery, I would buy a huge pile of carrots.</p>
<p>倒装: Shoud I win the lottery, I would buy a huge pile of carrots.</p>
<p><strong>固定句型</strong></p>
<p>so do I.</p>
<p>neither/nor can the wolf.</p>
<hr>
<h3 id="三、形式倒装">三、形式倒装</h3>
<p>形式倒装仅仅是将强调内容提前，而不对谓语动词和助动词进行修改。</p>
<p>主要有如下情况：</p>
<ul>
<li>感叹句</li>
<li>比较句 the more the more</li>
<li>however whatever 引导让步状语从旧</li>
<li>as though 引导让步状语从句</li>
</ul>
<p><strong>感叹句</strong></p>
<p>What a delicious carrot it is!</p>
<p><strong>比较句</strong></p>
<p>The more carrots you eat, the healthier you become.</p>
<p><strong>让步状语</strong></p>
<p>However long this video is, you should watch it till the end.</p>
<p>Much as he likes the carrot, he doesn’t want to eat it.</p>
<img src="/2022/08/04/%E3%80%90%E8%8B%B1%E8%AF%AD%E3%80%91%E8%A2%AB%E5%8A%A8%E5%BC%BA%E8%B0%83%E5%80%92%E8%A3%85%E7%9C%81%E7%95%A5/image-20220804221342215.png" alt="image-20220804221342215" style="zoom:50%;">
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 不想学辣 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 英语 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[【一】 句子成分]]></title>
      <url>/2022/08/03/%E3%80%90%E8%8B%B1%E8%AF%AD%E3%80%91%E5%8F%A5%E5%AD%90%E6%88%90%E5%88%86/</url>
      <content type="html"><![CDATA[<h2 id="句子成分">句子成分</h2>
<hr>
<h3 id="简单句">简单句</h3>
<p>语句中的最小单元是<code>简单句</code>(simple sentences)，而简单句的构成如下：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>主</mtext><msubsup><mtext>语</mtext><mrow><mi>s</mi><mi>u</mi><mi>b</mi><mi>j</mi><mi>e</mi><mi>c</mi><mi>t</mi></mrow><mrow><mtext>人</mtext><mi mathvariant="normal">/</mi><mtext>物</mtext></mrow></msubsup><mo>+</mo><mtext>谓</mtext><msub><mtext>语</mtext><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi><mi>i</mi><mi>c</mi><mi>a</mi><mi>t</mi><mi>e</mi></mrow></msub></mrow><annotation encoding="application/x-tex">主语^{人/物}_{subject}+谓语_{predicate}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.4822em;vertical-align:-0.4374em;"></span><span class="mord cjk_fallback">主</span><span class="mord"><span class="mord cjk_fallback">语</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em;"><span style="top:-2.3987em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">bj</span><span class="mord mathnormal mtight">ec</span><span class="mord mathnormal mtight">t</span></span></span></span><span style="top:-3.2198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord cjk_fallback mtight">人</span><span class="mord mtight">/</span><span class="mord cjk_fallback mtight">物</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4374em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord cjk_fallback">谓</span><span class="mord"><span class="mord cjk_fallback">语</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">re</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span></p>
<p>谓语的核心是谓语动词，但谓语并不等同于谓语动词哦。</p>
<blockquote>
<p>句子成分和词性并没有一一对应的哦</p>
</blockquote>
<p><img src="/2022/08/03/%E3%80%90%E8%8B%B1%E8%AF%AD%E3%80%91%E5%8F%A5%E5%AD%90%E6%88%90%E5%88%86/image-20220803232917051.png" alt="image-20220803232917051"></p>
<p>我们来梳理一下~</p>
<p>英语的语法与中文不同，遵循严格的格式，其中最基本的单元就是<code>主语+谓语</code>构成的简单句。主语是一个工人，谓语就是工人手上的镰刀和锄头。有时候，工人会拿着锄头去割稻子，稻子就是锄头的施力对象，也就是<code>宾语</code>。有时候，稻子染上了白化病，这个白化让稻子变白了，白色便是稻子的修饰颜色，换句话说，叫做<code>定语</code>，它作为一层<code>外壳</code>固定在了宾语上。那这个稻子是水稻还是旱稻呢？工人告诉我们，是水稻。水稻，就是对稻子进行进一步的补充，叫做<code>宾语补足语</code>。中午，工人卖力地砍着稻子，而中午和卖力，就是<code>状语</code>，状语让句子有了无限的可能。</p>
<p>我们对状语、定语、表语的概念可以做个简单的区分：</p>
<p>表语最简单，只用来修饰或说明主语。而定语，一般只套在名词或代词上，作为挂件让其功能更加完善。状语就牛逼多啦，副词、形容词、动词、全句，他都能进行修饰，甚至是传递时间、地点、原因、目的、结果、方式、程度等，这些对句子加以完善的成分都是状语。(反正排除法啦，看起来怪怪的算在状语头上)</p>
<h3 id="复合句">复合句</h3>
<p>两个简单句中间的元素，叫做<code>连词</code>，例如<code>and</code>、<code>or</code>、<code>then</code>等等~连词的作用是连接两个简单句！</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>A</mi><mtext> </mtext><mi>a</mi><mi>n</mi><mi>d</mi><mtext> </mtext><mi>B</mi><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">A\ and \ B.
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">A</span><span class="mspace"> </span><span class="mord mathnormal">an</span><span class="mord mathnormal">d</span><span class="mspace"> </span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mord">.</span></span></span></span></span></p>
<h3 id="复杂句">复杂句</h3>
<p>而当某个简单句充当另一个简单句的句子成分时，我们也就叫复杂句或者<code>主从复合句</code>，被充当的称为<code>主句</code>，充当的称为<code>从句</code>。例如：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>H</mi><mi>e</mi><mtext> </mtext><mi>i</mi><mi>s</mi><mtext> </mtext><mi>a</mi><mtext> </mtext><mi>m</mi><mi>a</mi><mi>n</mi><mtext> </mtext><mi>w</mi><mi>h</mi><mi>o</mi><mtext> </mtext><mi>l</mi><mi>i</mi><mi>k</mi><mi>e</mi><mi>s</mi><mtext> </mtext><mi>p</mi><mi>l</mi><mi>a</mi><mi>y</mi><mtext> </mtext><mi>g</mi><mi>a</mi><mi>m</mi><mi>e</mi><mi>s</mi><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">He\ is \ a\ man\ who\ likes\ play\ games. 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">He</span><span class="mspace"> </span><span class="mord mathnormal">i</span><span class="mord mathnormal">s</span><span class="mspace"> </span><span class="mord mathnormal">a</span><span class="mspace"> </span><span class="mord mathnormal">man</span><span class="mspace"> </span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord mathnormal">h</span><span class="mord mathnormal">o</span><span class="mspace"> </span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal" style="margin-right:0.03148em;">ik</span><span class="mord mathnormal">es</span><span class="mspace"> </span><span class="mord mathnormal" style="margin-right:0.01968em;">pl</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace"> </span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">am</span><span class="mord mathnormal">es</span><span class="mord">.</span></span></span></span></span></p>
<hr>
<h2 id="句子分类">句子分类</h2>
<p><img src="/2022/08/03/%E3%80%90%E8%8B%B1%E8%AF%AD%E3%80%91%E5%8F%A5%E5%AD%90%E6%88%90%E5%88%86/image-20220804000032303.png" alt="image-20220804000032303"></p>
<hr>
<h3 id="一些感想">一些感想</h3>
<p>就像图像有着最小单元，句子也有着属于它的最小单位，这就是 <s>你的工人爷爷</s> 简单句!</p>
<p>从简单句的结构来看，句子能够拆解成八大块，分别是主谓宾、定状补、同位语、插入语，谓语未必是动词，动词也未必是谓语，但谓语动词是可以独立做谓语的。</p>
<p>多个简单句集成了复合句，复合句根据组合方式是拼接还是嵌套，分为了复合句和复杂句。</p>
<p>根据句子本身的含义，又能分成四大天王：陈述、疑问、祈使、感叹；其中能力最强的疑问句，手下居然还有四大天王！分别是一般疑问、反义疑问句、特殊疑问、选择疑问！</p>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 不想学辣 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 英语 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[伪代码]]></title>
      <url>/2022/08/03/%E3%80%90%E7%A7%91%E7%A0%94%E3%80%91%E4%BC%AA%E4%BB%A3%E7%A0%81/</url>
      <content type="html"><![CDATA[<h1>伪代码教程</h1>
<hr>
<blockquote>
<p>起一篇伪代码基础教程</p>
</blockquote>
<p>伪代码(Pseudo code)是一种介于<code>计算机语言</code>和<code>自然语言</code>间的文字和符号，是表达算法的简单而有效的方法。伪代码不需要关注底层是如何实现的，本身就是算法框架的逻辑模型。</p>
<h2 id="一、赋值语句">一、赋值语句</h2>
<p>赋值号<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>←</mo><mi>B</mi></mrow><annotation encoding="application/x-tex">A\leftarrow B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span>，表示将<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span>的内容传递给<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span>，相当于：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>=</mo><mi>B</mi></mrow><annotation encoding="application/x-tex">A=B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span></p>
<h2 id="二、输入输出">二、输入输出</h2>
<p><strong>输入</strong></p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi><mi>n</mi><mi>p</mi><mi>u</mi><mi>t</mi><mo>:</mo><mtext> </mtext><mi>i</mi><mi>n</mi><mi>p</mi><mi>u</mi><mi>t</mi><mtext> </mtext><mi>p</mi><mi>a</mi><mi>r</mi><mi>a</mi><mi>m</mi><mi>e</mi><mi>t</mi><mi>e</mi><mi>r</mi><mi>s</mi><mtext> </mtext><mi>A</mi><mo separator="true">,</mo><mi>B</mi><mo separator="true">,</mo><mi>C</mi></mrow><annotation encoding="application/x-tex">Input:\ input\ parameters\ A,B,C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal">n</span><span class="mord mathnormal">p</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">:</span><span class="mspace"> </span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">in</span><span class="mord mathnormal">p</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mspace"> </span><span class="mord mathnormal">p</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">am</span><span class="mord mathnormal">e</span><span class="mord mathnormal">t</span><span class="mord mathnormal">ers</span><span class="mspace"> </span><span class="mord mathnormal">A</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span></p>
<p><strong>输出</strong></p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mi>u</mi><mi>t</mi><mi>p</mi><mi>u</mi><mi>t</mi><mo>:</mo><mtext> </mtext><mi>o</mi><mi>u</mi><mi>t</mi><mi>p</mi><mi>u</mi><mi>t</mi><mtext> </mtext><mi>r</mi><mi>e</mi><mi>s</mi><mi>u</mi><mi>l</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">Output:\ output \ result</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mord mathnormal">u</span><span class="mord mathnormal">tp</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">:</span><span class="mspace"> </span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">tp</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mspace"> </span><span class="mord mathnormal">res</span><span class="mord mathnormal">u</span><span class="mord mathnormal">lt</span></span></span></span></p>
<h2 id="三、条件语句">三、条件语句</h2>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>I</mi><mi>f</mi><mtext> </mtext><mi>A</mi><mtext> </mtext><mi>t</mi><mi>h</mi><mi>e</mi><mi>n</mi><mtext> </mtext><mi>B</mi><mspace linebreak="newline"></mspace><mi>E</mi><mi>l</mi><mi>s</mi><mi>e</mi><mtext> </mtext><mi>C</mi><mspace linebreak="newline"></mspace><mi>E</mi><mi>n</mi><mi>d</mi><mtext> </mtext><mi>i</mi><mi>f</mi></mrow><annotation encoding="application/x-tex">If\ A \ then \ B
\\
Else \ C
\\
End\ if
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mspace"> </span><span class="mord mathnormal">A</span><span class="mspace"> </span><span class="mord mathnormal">t</span><span class="mord mathnormal">h</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mspace"> </span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">El</span><span class="mord mathnormal">se</span><span class="mspace"> </span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mord mathnormal">n</span><span class="mord mathnormal">d</span><span class="mspace"> </span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span></span></span></span></span></p>
<h2 id="四、循环语句">四、循环语句</h2>
<h3 id="4-1-for循环">4.1 for循环</h3>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>f</mi><mi>o</mi><mi>r</mi><mtext> </mtext><mi>i</mi><mo>=</mo><mn>1</mn><mo>→</mo><mi>i</mi><mo>=</mo><mi>N</mi><mtext> </mtext><mi>d</mi><mi>o</mi><mspace linebreak="newline"></mspace><mi>e</mi><mi>n</mi><mi>d</mi><mtext> </mtext><mi>f</mi><mi>o</mi><mi>r</mi></mrow><annotation encoding="application/x-tex">for\ i=1\rightarrow i=N\ do\\
end \ for
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal" style="margin-right:0.02778em;">or</span><span class="mspace"> </span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mspace"> </span><span class="mord mathnormal">d</span><span class="mord mathnormal">o</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord mathnormal">d</span><span class="mspace"> </span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal" style="margin-right:0.02778em;">or</span></span></span></span></span></p>
<h3 id="4-2-while循环">4.2 while循环</h3>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>W</mi><mi>h</mi><mi>i</mi><mi>l</mi><mi>e</mi><mtext> </mtext><mi>A</mi><mspace linebreak="newline"></mspace><mi>Y</mi><mi>o</mi><mi>u</mi><mi>r</mi><mtext> </mtext><mi>s</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>e</mi><mi>n</mi><mi>c</mi><mi>e</mi><mi>s</mi><mspace linebreak="newline"></mspace><mi>E</mi><mi>n</mi><mi>d</mi><mtext> </mtext><mi>w</mi><mi>h</mi><mi>i</mi><mi>l</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">While \ A
\\
Your\ sentences
\\
End \ while
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">Whi</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">e</span><span class="mspace"> </span><span class="mord mathnormal">A</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mspace"> </span><span class="mord mathnormal">se</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord mathnormal">ces</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mord mathnormal">n</span><span class="mord mathnormal">d</span><span class="mspace"> </span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord mathnormal">hi</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">e</span></span></span></span></span></p>
<hr>
<p>一个简单的<code>栗子</code>🔶</p>
<p><img src="/2022/08/03/%E3%80%90%E7%A7%91%E7%A0%94%E3%80%91%E4%BC%AA%E4%BB%A3%E7%A0%81/image-20220803174851918.png" alt="image-20220803174851918"></p>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 不想学辣 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 编程 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[【数论】欧式筛]]></title>
      <url>/2022/08/03/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E6%AC%A7%E6%8B%89%E7%AD%9B/</url>
      <content type="html"><![CDATA[<p>总所周知，质数(prime number)又称素数，除了<code>1</code>和<code>自身</code>外，不能被其他的自然数整除。</p>
<p>那么我们今天就来看看一个简单的寻找素数的算法，欧拉筛。欧拉筛是在埃氏筛的基础上做了一定的改进，大幅降低时间复杂度。</p>
<h2 id="欧拉筛">欧拉筛</h2>
<p><strong>输入</strong></p>
<ul>
<li>区间范围n</li>
</ul>
<p><strong>输出</strong></p>
<ul>
<li>素数列表</li>
</ul>
<p><strong>思想</strong></p>
<ul>
<li>通过打表的方式，构建素数表，这张表包含了<code>n</code>个元素，包括素数和合数</li>
<li>素数是无法通过其他素数相乘得到的，利用这一原理，可以将所有能够被素数相乘得到的值设置为合数</li>
</ul>
<p><strong>过程</strong></p>
<ul>
<li>创建一个大小为<code>n</code>的列表<code>isPrime</code>，元素值代表是否为素数。</li>
<li>创建一个新的可变列表<code>prime</code>，元素值代表素数</li>
<li>遍历<code>isPrime</code>，若元素值为<code>1</code>，则将其加入<code>prime</code>列表。</li>
<li>将该元素与<code>prime</code>中的所有素数相乘：
<ul>
<li>若该元素为素数，那么会遍历<code>prime</code>列表，得到的结果是最小素数相乘的合数</li>
<li>若该元素为合数，那么将为其添加新的最小质数，直到遇到初始质数。(同样也是最小质数相乘)</li>
</ul>
</li>
</ul>
<p><strong>算法</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">n=<span class="built_in">int</span>(<span class="number">1e5</span>+<span class="number">1</span>)</span><br><span class="line">prime=[]</span><br><span class="line">isPrime=[<span class="number">1</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n+<span class="number">1</span>)]</span><br><span class="line"><span class="comment"># 欧拉筛构建1-n的所有质数</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>,n+<span class="number">1</span>):</span><br><span class="line">    <span class="keyword">if</span> isPrime[i]==<span class="number">1</span>:</span><br><span class="line">        <span class="comment"># 质数加入队列</span></span><br><span class="line">        prime.append(i)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 删除质数集构成的合数</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(prime)):</span><br><span class="line">        <span class="keyword">if</span> prime[j]*i&lt;n:</span><br><span class="line">            <span class="comment"># 合数去掉了</span></span><br><span class="line">            isPrime[prime[j]*i]=<span class="number">0</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="comment"># 通过最小质数来构建即可</span></span><br><span class="line">        <span class="keyword">if</span> i%prime[j]==<span class="number">0</span>:</span><br><span class="line">            <span class="comment"># 当然第一次遇到还是要乘上去的，这样才会倍增</span></span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"><span class="built_in">print</span>(prime)</span><br></pre></td></tr></table></figure>
<p><strong>复杂度</strong></p>
<p>时间复杂度约等于<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(N)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mclose">)</span></span></span></span>，它只对每个元素遍历一次。</p>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 不想学辣 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 算法 </tag>
            
            <tag> 数学 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[记忆学入门]]></title>
      <url>/2022/08/03/%E3%80%90%E8%AE%B0%E5%BF%86%E5%AD%A6%E3%80%91%E8%AE%B0%E5%BF%86%E5%AD%A6%E5%85%A5%E9%97%A8/</url>
      <content type="html"><![CDATA[<h1>记忆学入门</h1>
<hr>
<h2 id="Lesson-1-记忆术入门">Lesson 1  记忆术入门</h2>
<blockquote>
<p>爱因斯坦曾说，如果让他花一个小时解决问题，那么92%的时间用来认知问题，而解决问题只需要8%的时间。</p>
</blockquote>
<p>一个好的框架，比漫无目的的遍历好得多。</p>
<p>我们先来看看记忆的框架，总所周知，影响主动记忆的四个重要因子为：</p>
<ul>
<li>注意力</li>
<li>兴趣</li>
<li>自信心</li>
<li>好方法</li>
</ul>
<p>通过不断的训练，能够将<code>注意力</code>迅速集中在感<code>兴趣</code>的区域，形成正反馈后，增强<code>自信心</code>。当然，训练是离不开<code>好方法</code>的。</p>
<h3 id="万能记忆公式">万能记忆公式</h3>
<ul>
<li>用她去了解她</li>
<li>用你去理解她</li>
<li>用记忆法刻意记忆她</li>
</ul>
<p>参悟本源，吸收归纳，烙印神魂。</p>
<p><strong>记忆法</strong>的灵魂在于<strong>参与感</strong>！</p>
<p>细说的话，记忆法可以归纳为四步学习法：</p>
<img src="/2022/08/03/%E3%80%90%E8%AE%B0%E5%BF%86%E5%AD%A6%E3%80%91%E8%AE%B0%E5%BF%86%E5%AD%A6%E5%85%A5%E9%97%A8/image-20220803002451441.png" alt="image-20220803002451441" style="zoom: 50%;">
<p><strong>例题</strong></p>
<img src="/2022/08/03/%E3%80%90%E8%AE%B0%E5%BF%86%E5%AD%A6%E3%80%91%E8%AE%B0%E5%BF%86%E5%AD%A6%E5%85%A5%E9%97%A8/image-20220803003611995.png" alt="image-20220803003611995" style="zoom:33%;">
<p>摄取信息：</p>
<p>​	这是一段概念性文字描述。我们试着去理解其中的内容，也就是什么是生产力，怎么样算生产力？敲代码，打猎，生活，财米油盐是不是都是生产力？那么，生产力作为一种力，肯定不能凭空产生呀，需要借助什么来实现呢？</p>
<p>处理信息：</p>
<ul>
<li>化简为繁
<ul>
<li>关键字：生产力、征服自然、改造自然、物质生活能力</li>
<li>关键字：劳动者、生产工具、劳动对象</li>
</ul>
</li>
</ul>
<p>存储信息：</p>
<ul>
<li>理解知识信息</li>
<li>关键词转化为图像记忆</li>
<li>运用四大记忆方法记忆(联想、绘图、数字、宫殿)</li>
<li>创建回忆线索点</li>
<li>多次复习</li>
</ul>
<p><strong>简单的记忆宫殿练习</strong></p>
<img src="/2022/08/03/%E3%80%90%E8%AE%B0%E5%BF%86%E5%AD%A6%E3%80%91%E8%AE%B0%E5%BF%86%E5%AD%A6%E5%85%A5%E9%97%A8/image-20220803005534833.png" alt="image-20220803005534833" style="zoom:33%;">
<img src="/2022/08/03/%E3%80%90%E8%AE%B0%E5%BF%86%E5%AD%A6%E3%80%91%E8%AE%B0%E5%BF%86%E5%AD%A6%E5%85%A5%E9%97%A8/image-20220803005552438.png" alt="image-20220803005552438" style="zoom: 25%;">
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">59 23 07 81 64 06 28 62 08 99</span><br></pre></td></tr></table></figure>
<img src="/2022/08/03/%E3%80%90%E8%AE%B0%E5%BF%86%E5%AD%A6%E3%80%91%E8%AE%B0%E5%BF%86%E5%AD%A6%E5%85%A5%E9%97%A8/image-20220803005705359.png" alt="image-20220803005705359" style="zoom: 33%;">
<img src="/2022/08/03/%E3%80%90%E8%AE%B0%E5%BF%86%E5%AD%A6%E3%80%91%E8%AE%B0%E5%BF%86%E5%AD%A6%E5%85%A5%E9%97%A8/image-20220803005724860.png" alt="image-20220803005724860" style="zoom:33%;">
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">86 28 03 48 25 34 21 17 06 79</span><br></pre></td></tr></table></figure>
<h3 id="总结">总结</h3>
<p>好的记忆力跟信息的输入输出相关，如何保证信息高效的输入呢？那就需要专注力，而专注力能够通过兴趣提升，不断的正反馈能够增强自信，自信也能提高专注力。当然，好的方法也必不可少。</p>
<p>我们在承载信息的时候，首先要明确的就是信息的形态、核心，是概念还是理论，是方法还是综述。掌握信息的核心本质，理解其中的思想，也就是<code>用她去了解她</code>。接下来，我们就可以通过构建自己的脑回路，将这个信息以自己的想法进行输出，这部分至关重要，也就是<code>用你去理解她</code>，我们可以借助关键字、化简成图的方式，结合记忆法进行辅助记忆。</p>
<p>当然，存储的信息一定要打下锚点，不然飘到什么地方去了就很难找了不是吗。</p>
<p>常复盘，这也是关键。</p>
<hr>
<h2 id="Lesson-2-注意力">Lesson 2  注意力</h2>
<p>增强注意力的关键，还是需要<code>参与感</code>，也就是一定的<code>兴趣</code>，兴致勃勃地研究，直到未知的内容显现出来。</p>
<blockquote>
<p>可以通过找茬游戏训练！</p>
</blockquote>
<p>注意力训练：</p>
<ul>
<li>保持腹式呼吸</li>
<li>眼睛自然睁大</li>
<li>不要眨眼，盯着黑点看，直到黑点阴影全部变成白色</li>
<li>一次时间约两分钟</li>
</ul>
<img src="/2022/08/03/%E3%80%90%E8%AE%B0%E5%BF%86%E5%AD%A6%E3%80%91%E8%AE%B0%E5%BF%86%E5%AD%A6%E5%85%A5%E9%97%A8/image-20220803153409835.png" alt="image-20220803153409835" style="zoom:50%;">
<p><strong>思考</strong></p>
<p>注意力受制于我们的意志力，注意力在哪种下因，记忆力在哪收下果。</p>
<p>我们需要关注自己的思维波动，及时的把思想拉回锚点。做一做注意力训练也是件好事。</p>
<hr>
<h2 id="Lesson-3-数字编码">Lesson 3  数字编码</h2>
<p>啊下面是一些数字编码，内容实在是太多了，就放到另外的网页了。<a href="https://www.renrendoc.com/paper/88829238.html">https://www.renrendoc.com/paper/88829238.html</a></p>
<p><strong>type 1</strong></p>
<table>
<thead>
<tr>
<th style="text-align:center">0</th>
<th style="text-align:center">1</th>
<th style="text-align:center">2</th>
<th style="text-align:center">3</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">呼啦圈</td>
<td style="text-align:center">蜡烛</td>
<td style="text-align:center">天鹅</td>
<td style="text-align:center">耳朵</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:center">5</td>
<td style="text-align:center">6</td>
<td style="text-align:center">7</td>
</tr>
<tr>
<td style="text-align:center">旗子</td>
<td style="text-align:center">钩子</td>
<td style="text-align:center">汤勺</td>
<td style="text-align:center">镰刀</td>
</tr>
<tr>
<td style="text-align:center">8</td>
<td style="text-align:center">9</td>
<td style="text-align:center">10</td>
<td style="text-align:center">11</td>
</tr>
<tr>
<td style="text-align:center">葫芦</td>
<td style="text-align:center">哨子</td>
<td style="text-align:center">石头</td>
<td style="text-align:center">梯子</td>
</tr>
<tr>
<td style="text-align:center">12</td>
<td style="text-align:center">13</td>
<td style="text-align:center">14</td>
<td style="text-align:center">15</td>
</tr>
<tr>
<td style="text-align:center">椅儿</td>
<td style="text-align:center">医生</td>
<td style="text-align:center">钥匙</td>
<td style="text-align:center">鹦鹉</td>
</tr>
<tr>
<td style="text-align:center">16</td>
<td style="text-align:center">17</td>
<td style="text-align:center">18</td>
<td style="text-align:center">19</td>
</tr>
<tr>
<td style="text-align:center">石榴</td>
<td style="text-align:center">仪器</td>
<td style="text-align:center">糖葫芦</td>
<td style="text-align:center">狮鹫</td>
</tr>
<tr>
<td style="text-align:center">20</td>
<td style="text-align:center">21</td>
<td style="text-align:center">22</td>
<td style="text-align:center">23</td>
</tr>
<tr>
<td style="text-align:center">香烟</td>
<td style="text-align:center">鳄鱼</td>
<td style="text-align:center">22娘</td>
<td style="text-align:center">和尚</td>
</tr>
<tr>
<td style="text-align:center">24</td>
<td style="text-align:center">25</td>
<td style="text-align:center">26</td>
<td style="text-align:center">27</td>
</tr>
<tr>
<td style="text-align:center">闹钟</td>
<td style="text-align:center">二胡</td>
<td style="text-align:center">河流</td>
<td style="text-align:center">耳机</td>
</tr>
<tr>
<td style="text-align:center">28</td>
<td style="text-align:center">29</td>
<td style="text-align:center">30</td>
<td style="text-align:center">31</td>
</tr>
<tr>
<td style="text-align:center">恶霸</td>
<td style="text-align:center">恶球</td>
<td style="text-align:center">三轮车</td>
<td style="text-align:center">鲨鱼</td>
</tr>
</tbody>
</table>
<hr>
<p><strong>type 2</strong></p>
<table>
<thead>
<tr>
<th style="text-align:center">32</th>
<th style="text-align:center">33</th>
<th style="text-align:center">34</th>
<th style="text-align:center">35</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">扇儿</td>
<td style="text-align:center">三三娘</td>
<td style="text-align:center">三丝</td>
<td style="text-align:center">珊瑚</td>
</tr>
<tr>
<td style="text-align:center">36</td>
<td style="text-align:center">37</td>
<td style="text-align:center">38</td>
<td style="text-align:center">39</td>
</tr>
<tr>
<td style="text-align:center">山路</td>
<td style="text-align:center">山鸡</td>
<td style="text-align:center">妇女</td>
<td style="text-align:center">山丘</td>
</tr>
<tr>
<td style="text-align:center">40</td>
<td style="text-align:center">41</td>
<td style="text-align:center">42</td>
<td style="text-align:center">43</td>
</tr>
<tr>
<td style="text-align:center">司令</td>
<td style="text-align:center">蜥蜴</td>
<td style="text-align:center">柿儿</td>
<td style="text-align:center">尸山</td>
</tr>
<tr>
<td style="text-align:center">44</td>
<td style="text-align:center">45</td>
<td style="text-align:center">46</td>
<td style="text-align:center">47</td>
</tr>
<tr>
<td style="text-align:center">蛇</td>
<td style="text-align:center">师傅</td>
<td style="text-align:center">饲料</td>
<td style="text-align:center">司机</td>
</tr>
<tr>
<td style="text-align:center">48</td>
<td style="text-align:center">49</td>
<td style="text-align:center">50</td>
<td style="text-align:center">51</td>
</tr>
<tr>
<td style="text-align:center">石板</td>
<td style="text-align:center">火眼金睛</td>
<td style="text-align:center">五菱宏光</td>
<td style="text-align:center">工人</td>
</tr>
<tr>
<td style="text-align:center">52</td>
<td style="text-align:center">53</td>
<td style="text-align:center">54</td>
<td style="text-align:center">55</td>
</tr>
<tr>
<td style="text-align:center">孤儿</td>
<td style="text-align:center">五年高考</td>
<td style="text-align:center">青年</td>
<td style="text-align:center">托马斯</td>
</tr>
<tr>
<td style="text-align:center">56</td>
<td style="text-align:center">57</td>
<td style="text-align:center">58</td>
<td style="text-align:center">59</td>
</tr>
<tr>
<td style="text-align:center">蜗牛</td>
<td style="text-align:center">武器</td>
<td style="text-align:center">尾巴</td>
<td style="text-align:center">蜈蚣</td>
</tr>
</tbody>
</table>
<hr>
<p><strong>type 3</strong></p>
<table>
<thead>
<tr>
<th style="text-align:center">60</th>
<th style="text-align:center">61</th>
<th style="text-align:center">62</th>
<th style="text-align:center">63</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">榴莲</td>
<td style="text-align:center">儿童</td>
<td style="text-align:center">牛儿</td>
<td style="text-align:center">流沙</td>
</tr>
<tr>
<td style="text-align:center">64</td>
<td style="text-align:center">65</td>
<td style="text-align:center">66</td>
<td style="text-align:center">67</td>
</tr>
<tr>
<td style="text-align:center">螺丝</td>
<td style="text-align:center">尿壶</td>
<td style="text-align:center">溜溜球</td>
<td style="text-align:center">流星</td>
</tr>
<tr>
<td style="text-align:center">68</td>
<td style="text-align:center">69</td>
<td style="text-align:center">70</td>
<td style="text-align:center">71</td>
</tr>
<tr>
<td style="text-align:center">喇叭</td>
<td style="text-align:center">太极</td>
<td style="text-align:center">麒麟</td>
<td style="text-align:center">机翼</td>
</tr>
<tr>
<td style="text-align:center">72</td>
<td style="text-align:center">73</td>
<td style="text-align:center">74</td>
<td style="text-align:center">75</td>
</tr>
<tr>
<td style="text-align:center">企鹅</td>
<td style="text-align:center">花旗参</td>
<td style="text-align:center">骑士</td>
<td style="text-align:center">媳妇</td>
</tr>
<tr>
<td style="text-align:center">76</td>
<td style="text-align:center">77</td>
<td style="text-align:center">78</td>
<td style="text-align:center">79</td>
</tr>
<tr>
<td style="text-align:center">汽油</td>
<td style="text-align:center">七七</td>
<td style="text-align:center">青蛙</td>
<td style="text-align:center">气球</td>
</tr>
<tr>
<td style="text-align:center">80</td>
<td style="text-align:center">81</td>
<td style="text-align:center">82</td>
<td style="text-align:center">83</td>
</tr>
<tr>
<td style="text-align:center">霸凌</td>
<td style="text-align:center">白蚁</td>
<td style="text-align:center">巴尔</td>
<td style="text-align:center">芭蕉扇</td>
</tr>
<tr>
<td style="text-align:center">84</td>
<td style="text-align:center">85</td>
<td style="text-align:center">86</td>
<td style="text-align:center">87</td>
</tr>
<tr>
<td style="text-align:center">宝宝巴士</td>
<td style="text-align:center">吧务</td>
<td style="text-align:center">八路</td>
<td style="text-align:center">白起</td>
</tr>
</tbody>
</table>
<hr>
<p><strong>type 4</strong></p>
<table>
<thead>
<tr>
<th style="text-align:center">88</th>
<th style="text-align:center">89</th>
<th style="text-align:center">90</th>
<th style="text-align:center">91</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">爸爸</td>
<td style="text-align:center">芭蕉</td>
<td style="text-align:center">酒瓶</td>
<td style="text-align:center">秋衣</td>
</tr>
<tr>
<td style="text-align:center">92</td>
<td style="text-align:center">93</td>
<td style="text-align:center">94</td>
<td style="text-align:center">95</td>
</tr>
<tr>
<td style="text-align:center">球儿</td>
<td style="text-align:center">旧伞</td>
<td style="text-align:center">旧誓</td>
<td style="text-align:center">酒壶</td>
</tr>
<tr>
<td style="text-align:center">96</td>
<td style="text-align:center">97</td>
<td style="text-align:center">98</td>
<td style="text-align:center">99</td>
</tr>
<tr>
<td style="text-align:center">蝴蝶</td>
<td style="text-align:center">酒气</td>
<td style="text-align:center">酒吧</td>
<td style="text-align:center">舅舅</td>
</tr>
<tr>
<td style="text-align:center">100</td>
<td style="text-align:center">00</td>
<td style="text-align:center">01</td>
<td style="text-align:center">02</td>
</tr>
<tr>
<td style="text-align:center">💯</td>
<td style="text-align:center">望远镜</td>
<td style="text-align:center">小树</td>
<td style="text-align:center">铃儿</td>
</tr>
<tr>
<td style="text-align:center">03</td>
<td style="text-align:center">04</td>
<td style="text-align:center">05</td>
<td style="text-align:center">06</td>
</tr>
<tr>
<td style="text-align:center">灵山</td>
<td style="text-align:center">奥迪</td>
<td style="text-align:center">老虎</td>
<td style="text-align:center">手枪</td>
</tr>
<tr>
<td style="text-align:center">07</td>
<td style="text-align:center">08</td>
<td style="text-align:center">09</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">007</td>
<td style="text-align:center">溜冰鞋</td>
<td style="text-align:center">猫</td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
<hr>
<h2 id="Lesson-4-文字转换">Lesson 4 文字转换</h2>
<p>奇奇怪怪的文字编码~</p>
<p>主要就是<code>带动感官，积极想象</code>！</p>
<hr>
<h2 id="Lesson-5-联想配对记忆四大方法">Lesson 5 联想配对记忆四大方法</h2>
<p>嗨，咱今天就来介绍这四大联想法：</p>
<ul>
<li>主动出击</li>
<li>媒婆牵线</li>
<li>夸张搞笑</li>
<li>双剑合璧</li>
</ul>
<img src="/2022/08/03/%E3%80%90%E8%AE%B0%E5%BF%86%E5%AD%A6%E3%80%91%E8%AE%B0%E5%BF%86%E5%AD%A6%E5%85%A5%E9%97%A8/image-20220806222931152.png" alt="image-20220806222931152" style="zoom:33%;">
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 拾枝杂谈 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 记忆术 </tag>
            
            <tag> 朝花夕拾 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[快速图像颜色风格迁移]]></title>
      <url>/2022/08/01/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E5%BF%AB%E9%80%9F%E5%9B%BE%E5%83%8F%E9%A2%9C%E8%89%B2%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/</url>
      <content type="html"><![CDATA[<h1>快速图像颜色迁移</h1>
<hr>
<p>传统的图像颜色迁移是通过计算目标图像和源图像的颜色直方图，优化二者之间的差值，从而实现不更改内容，完成颜色的迁移。其核心在于如何找到颜色间的关系映射。一般情况的研究会现将RGB空间转化为更复杂、对色彩的支持度更佳的其他色彩空间，如HSV、Lab等。为了获取匹配规则，一般需要对图像进行色彩信息统计，可以是局部特征统计，也可以是全局。一般的特征统计计算的是色彩直方图信息，局部特征提取可以通过聚类来实现，或者是特征部分如角点、边缘、背景、Blob等。考虑到色彩之间存在语义信息，也会对不同色彩之间进行权重修正或是不同语义采用不同的算法来计算两幅图像之间的差异。</p>
<p>Reinhard提出的算法(2001)步骤大致如下：</p>
<ul>
<li>
<p>输入目标图像和源图像</p>
</li>
<li>
<p>将源图像和目标图像转化到Lab颜色空间，Lab颜色空间模拟感知均匀性，其中颜色量的微小变化会产生颜色重要性的相对变化。Lab空间在模仿人类如何解释颜色上做的比RGB更好</p>
</li>
<li>
<p>分离源图像和目标图像的通道</p>
</li>
<li>
<p>计算图像每个通道的平均值和标准差</p>
</li>
<li>
<p>利用标准差做缩放</p>
</li>
<li>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>I</mi><mrow><mi>n</mi><mi>e</mi><mi>w</mi></mrow></msub><mo>=</mo><mo stretchy="false">(</mo><msub><mi>I</mi><mrow><mi>t</mi><mi>a</mi><mi>r</mi><mi>g</mi><mi>e</mi><mi>t</mi></mrow></msub><mo>−</mo><mi>M</mi><mi>E</mi><mi>A</mi><msub><mi>N</mi><mrow><mi>t</mi><mi>a</mi><mi>r</mi><mi>g</mi><mi>e</mi><mi>t</mi></mrow></msub><mo stretchy="false">)</mo><mo>∗</mo><mfrac><mrow><mi>S</mi><mi>T</mi><msub><mi>D</mi><mrow><mi>t</mi><mi>a</mi><mi>r</mi><mi>g</mi><mi>e</mi><mi>t</mi></mrow></msub></mrow><mrow><mi>S</mi><mi>T</mi><msub><mi>D</mi><mrow><mi>s</mi><mi>o</mi><mi>u</mi><mi>r</mi><mi>c</mi><mi>e</mi></mrow></msub></mrow></mfrac><mo>+</mo><mo stretchy="false">(</mo><mi>M</mi><mi>E</mi><mi>A</mi><msub><mi>N</mi><mrow><mi>s</mi><mi>o</mi><mi>u</mi><mi>r</mi><mi>c</mi><mi>e</mi></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">I_{new}=(I_{target}-MEAN_{target})*\frac{STD_{target}}{STD_{source}}+(MEAN_{source})
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">ME</span><span class="mord mathnormal">A</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:2.1963em;vertical-align:-0.836em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3603em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">ST</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">so</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">rce</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">ST</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.836em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05764em;">ME</span><span class="mord mathnormal">A</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">so</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">rce</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
</li>
<li>
<p>裁剪输出范围至[0,255]</p>
</li>
<li>
<p>融合通道并转回RGB空间</p>
</li>
</ul>
<hr>
<h3 id="实现代码">实现代码</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getImageStatistic</span>(<span class="params">img</span>):</span><br><span class="line">    <span class="comment"># 获取通道的统计信息</span></span><br><span class="line">    <span class="comment"># 相当于img[...,0]...</span></span><br><span class="line">    l,a,b=cv2.split(img)</span><br><span class="line">    lM,lS=l.mean(),l.std()</span><br><span class="line">    aM,aS=a.mean(),a.std()</span><br><span class="line">    bM,bS=b.mean(),b.std()</span><br><span class="line">    <span class="keyword">return</span> [lM,lS,aM,aS,bM,bS]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">colorTransfer</span>(<span class="params">source,target,needmask=<span class="literal">False</span></span>):</span><br><span class="line">    <span class="keyword">if</span> needmask:</span><br><span class="line">        mask,edge=changeBackColor(target)</span><br><span class="line">        <span class="comment"># # 边缘需要提取下</span></span><br><span class="line">        <span class="comment"># target_edge=cv2.bitwise_and(target,target,mask=edge)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 通道转化</span></span><br><span class="line">    source=cv2.cvtColor(source,cv2.COLOR_BGR2LAB).astype(<span class="string">&quot;float32&quot;</span>)</span><br><span class="line">    target=cv2.cvtColor(target,cv2.COLOR_BGR2LAB).astype(<span class="string">&quot;float32&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 分离通道并获取统计信息</span></span><br><span class="line">    source_list=getImageStatistic(source)</span><br><span class="line">    target_list=getImageStatistic(target)</span><br><span class="line">    <span class="comment"># 缩放图像</span></span><br><span class="line">    LAB=[i <span class="keyword">for</span> i <span class="keyword">in</span> cv2.split(target)]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">        LAB[i]=np.clip((LAB[i]-target_list[i*<span class="number">2</span>])*(target_list[i*<span class="number">2</span>+<span class="number">1</span>]/source_list[i*<span class="number">2</span>+<span class="number">1</span>])+source_list[i*<span class="number">2</span>],<span class="number">0</span>,<span class="number">255</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 合并通道</span></span><br><span class="line">    new=cv2.merge(LAB)</span><br><span class="line">    <span class="comment"># 转回RGB并使用8位无符号整形</span></span><br><span class="line">    new=cv2.cvtColor(new.astype(<span class="string">&quot;uint8&quot;</span>),cv2.COLOR_Lab2BGR)</span><br><span class="line">    <span class="comment"># 获取掩膜区域外的数据</span></span><br><span class="line">    cv2.imshow(<span class="string">&quot;new&quot;</span>,new)</span><br><span class="line">    <span class="keyword">if</span> needmask:</span><br><span class="line">        new=cv2.bitwise_and(new,new,mask=mask) <span class="comment"># 在掩膜范围内做按位与</span></span><br><span class="line">        <span class="comment"># 掩膜白色相当于逻辑1，黑色相当于逻辑0</span></span><br><span class="line">        <span class="comment"># 在白色部分也就是逻辑1部分进行运算，其他部分不参与运算</span></span><br><span class="line">        <span class="comment"># 替换黑色</span></span><br><span class="line">        new[mask==<span class="number">0</span>]=np.array([<span class="number">255</span>,<span class="number">255</span>,<span class="number">255</span>])</span><br><span class="line">        <span class="comment"># new[edge!=0]=np.array([0,0,0])</span></span><br><span class="line">    <span class="keyword">return</span> new</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">changeBackColor</span>(<span class="params">img</span>):</span><br><span class="line">    <span class="comment"># 如何修正背景色？</span></span><br><span class="line">    <span class="comment"># 可以选择边界提取算法来做</span></span><br><span class="line">    <span class="comment"># 也可以选择腐蚀+高斯算法</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取边界</span></span><br><span class="line">    upper = np.array([<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>])</span><br><span class="line">    lower = np.array([<span class="number">200</span>, <span class="number">80</span>, <span class="number">180</span>])</span><br><span class="line">    mask = cv2.inRange(img, lower, upper)  <span class="comment"># 在区域内就是255，否则是0</span></span><br><span class="line">    <span class="comment"># 腐蚀</span></span><br><span class="line">    erode=cv2.erode(mask,kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(<span class="number">3</span>, <span class="number">3</span>))</span><br><span class="line">,iterations=<span class="number">10</span>) <span class="comment"># 分离连接</span></span><br><span class="line">    <span class="comment"># 膨胀</span></span><br><span class="line">    dilate=cv2.dilate(erode,kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(<span class="number">3</span>, <span class="number">3</span>))</span><br><span class="line">,iterations=<span class="number">10</span>) <span class="comment"># 孤岛填充</span></span><br><span class="line">    <span class="comment"># 黑色是需要剔除的，所以要按位取反</span></span><br><span class="line">    mask = cv2.bitwise_not(mask, mask)</span><br><span class="line">    cv2.imshow(<span class="string">&quot;mask&quot;</span>, mask)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 高斯滤波去除噪声</span></span><br><span class="line">    blurred = cv2.GaussianBlur(img, (<span class="number">3</span>, <span class="number">3</span>), <span class="number">0</span>)</span><br><span class="line">    gray = cv2.cvtColor(blurred, cv2.COLOR_BGR2GRAY)</span><br><span class="line">    <span class="comment"># X Gradient  cv.CV_16SC1所对应的数据类型必须是整型</span></span><br><span class="line">    <span class="comment"># 获取两个方向梯度</span></span><br><span class="line">    xgrad = cv2.Sobel(gray, cv2.CV_16SC1, <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">    <span class="comment"># Y Gradient</span></span><br><span class="line">    ygrad = cv2.Sobel(gray, cv2.CV_16SC1, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">    <span class="comment"># edge，50、150分别是低阈值和高阈值</span></span><br><span class="line">    edge_output = cv2.Canny(xgrad, ygrad, <span class="number">50</span>, <span class="number">150</span>)</span><br><span class="line">    cv2.imshow(<span class="string">&quot;edge&quot;</span>, edge_output)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> mask,edge_output</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    tar=cv2.imread(<span class="string">r&quot;C:\Users\lenovo\Desktop\gif\img\04.jpg&quot;</span>)</span><br><span class="line">    src=cv2.imread(<span class="string">r&quot;C:\Users\lenovo\Desktop\gif\img\02.jpg&quot;</span>)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        cv2.imshow(<span class="string">&#x27;src&#x27;</span>,src)</span><br><span class="line">        cv2.imshow(<span class="string">&#x27;tar&#x27;</span>,tar)</span><br><span class="line">        new=colorTransfer(src,tar,<span class="literal">True</span>)</span><br><span class="line">        cv2.imshow(<span class="string">&#x27;result&#x27;</span>,new)</span><br><span class="line">        cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">        cv2.destroyAllWindows()</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Your path is error&quot;</span>)</span><br><span class="line">    new = colorTransfer(src, tar)</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="结果展示">结果展示</h3>
<p><strong>迁移图像</strong></p>
<img src="/2022/08/01/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E5%BF%AB%E9%80%9F%E5%9B%BE%E5%83%8F%E9%A2%9C%E8%89%B2%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/image-20220316140830023.png" alt="image-20220316140830023" style="zoom:23%;">
<p><strong>目标图像</strong></p>
<img src="/2022/08/01/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E5%BF%AB%E9%80%9F%E5%9B%BE%E5%83%8F%E9%A2%9C%E8%89%B2%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/image-20220316140740207.png" alt="image-20220316140740207" style="zoom:25%;">
<p><strong>结果图像</strong></p>
<img src="/2022/08/01/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E5%BF%AB%E9%80%9F%E5%9B%BE%E5%83%8F%E9%A2%9C%E8%89%B2%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/image-20220316140653641.png" alt="image-20220316140653641" style="zoom: 25%;">
<hr>
<p><strong>专题地图迁移</strong></p>
<img src="/2022/08/01/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E5%BF%AB%E9%80%9F%E5%9B%BE%E5%83%8F%E9%A2%9C%E8%89%B2%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/image-20220316140830023.png" alt="image-20220316140830023" style="zoom:18%;">
<img src="/2022/08/01/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E5%BF%AB%E9%80%9F%E5%9B%BE%E5%83%8F%E9%A2%9C%E8%89%B2%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/image-20220316153242319.png" alt="image-20220316153242319" style="zoom:25%;">
<img src="/2022/08/01/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E5%BF%AB%E9%80%9F%E5%9B%BE%E5%83%8F%E9%A2%9C%E8%89%B2%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/image-20220316153256467.png" alt="image-20220316153256467" style="zoom:25%;">
<img src="/2022/08/01/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E5%BF%AB%E9%80%9F%E5%9B%BE%E5%83%8F%E9%A2%9C%E8%89%B2%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/image-20220316153214690.png" alt="image-20220316153214690" style="zoom:25%;">
<hr>
<h1>图像风格迁移</h1>
<hr>
<p>图像风格迁移顾名思义，就是将别的图像的风格迁移到内容图像上去。这一思想一经提出，无论是学术界还是艺术界，都伸出了橄榄枝。</p>
<p>图像风格迁移又能分成固定风格固定内容的普通迁移和固定风格不限内容的快速迁移。</p>
<h2 id="固定风格固定内容的迁移">固定风格固定内容的迁移</h2>
<p>该思想最早是由图宾根大学的研究学者提出，核心在于将图片作为可训练的变量，通过不断优化图片的像素值，降低其与内容图片的内容差异，并降低其与风格图片的差异。</p>
<img src="/2022/08/01/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E5%BF%AB%E9%80%9F%E5%9B%BE%E5%83%8F%E9%A2%9C%E8%89%B2%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/image-20220308095531724.png" alt="image-20220308095531724" style="zoom:50%;">
<img src="/2022/08/01/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E5%BF%AB%E9%80%9F%E5%9B%BE%E5%83%8F%E9%A2%9C%E8%89%B2%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/image-20220308101448500.png" alt="image-20220308101448500" style="zoom:50%;">
<p>在该研究中，通过提取VGG16网络的第0、5、10、19、28层卷积层作为需要比对的风格特征。而21层则是需要比对的内容特征。</p>
<p>在21层也就是<code>conv4_2</code>层上，计算特征映射的相似性作为图像的内容损失：</p>
<img src="/2022/08/01/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E5%BF%AB%E9%80%9F%E5%9B%BE%E5%83%8F%E9%A2%9C%E8%89%B2%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/image-20220308095837322.png" alt="image-20220308095837322" style="zoom:50%;">
<p>其中<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi></mrow><annotation encoding="application/x-tex">l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span></span></span></span>表示特征映射的层数，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi></mrow><annotation encoding="application/x-tex">F</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span></span></span></span>和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span>是目标图像和内容图像在对应卷积层输出的特征向量。</p>
<p>损失函数求导后是这个样：</p>
<img src="/2022/08/01/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E5%BF%AB%E9%80%9F%E5%9B%BE%E5%83%8F%E9%A2%9C%E8%89%B2%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/image-20220308101335734.png" alt="image-20220308101335734" style="zoom:50%;">
<p>一般来说，目标图像可以是噪声，也可以是初始图像的副本。为了方便训练，一般选用副本。</p>
<p>图像的风格损失主要是通过Gram矩阵进行计算的。Gram矩阵通过计算特征映射，将其转为列向量，在用该列向量乘以其转置获得，能够更好的表示图片的风格。(风格是一种潜在的整体特征，而Gram矩阵能够提取这种特征)</p>
<p>运作方法如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 假设A是个数据，shape为[batch,deep,heigh,width]</span></span><br><span class="line">A=torch.Tensor(<span class="number">1</span>,<span class="number">21</span>,<span class="number">300</span>,<span class="number">300</span>)</span><br><span class="line"><span class="comment"># 获取其列向量</span></span><br><span class="line"><span class="comment"># 相当于把内容融合了</span></span><br><span class="line">A=A.view(<span class="number">1</span>,<span class="number">21</span>,<span class="number">300</span>*<span class="number">300</span>)</span><br><span class="line"><span class="comment"># 最后计算Gram矩阵</span></span><br><span class="line">gram=torch.mm(A,A.t())</span><br></pre></td></tr></table></figure>
<p>风格损失呢，可以这样去评估</p>
<p><img src="/2022/08/01/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E5%BF%AB%E9%80%9F%E5%9B%BE%E5%83%8F%E9%A2%9C%E8%89%B2%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/image-20220308101608605.png" alt="image-20220308101608605"></p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>N</mi><mi>l</mi></msub></mrow><annotation encoding="application/x-tex">N_l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>M</mi><mi>l</mi></msub></mrow><annotation encoding="application/x-tex">M_l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>对应特征映射的宽高</p>
<p><img src="/2022/08/01/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E5%BF%AB%E9%80%9F%E5%9B%BE%E5%83%8F%E9%A2%9C%E8%89%B2%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/image-20220308101659514.png" alt="image-20220308101659514"></p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mi>l</mi></msub></mrow><annotation encoding="application/x-tex">w_l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>表示每层的权重</p>
<p>求偏导后是这样</p>
<img src="/2022/08/01/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E5%BF%AB%E9%80%9F%E5%9B%BE%E5%83%8F%E9%A2%9C%E8%89%B2%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/image-20220308101851552.png" alt="image-20220308101851552" style="zoom:50%;">
<img src="/2022/08/01/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E5%BF%AB%E9%80%9F%E5%9B%BE%E5%83%8F%E9%A2%9C%E8%89%B2%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/image-20220308101743233.png" alt="image-20220308101743233" style="zoom:50%;">
<p>总损失则是由内容损失和风格损失加权得到。</p>
<hr>
<h3 id="实现代码-v2">实现代码</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> models</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> hiddenlayer <span class="keyword">as</span> hl</span><br><span class="line"><span class="keyword">from</span> skimage.io <span class="keyword">import</span> imread</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用VGG19网络构建特征</span></span><br><span class="line">vgg19=models.vgg19(pretrained=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 不需要网络分类器，只用卷积层和池化层</span></span><br><span class="line">vgg=vgg19.features</span><br><span class="line"><span class="comment"># 设置显卡</span></span><br><span class="line">device=torch.device(<span class="string">&quot;cuda:0&quot;</span>)</span><br><span class="line"><span class="comment"># 将VGG19的特征提取网络权重冻结，训练不进行更新</span></span><br><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> vgg.parameters():</span><br><span class="line">    param.requires_grad_(<span class="literal">False</span>)</span><br><span class="line">vgg=vgg.to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义图像读取函数，将图像进行相应转化</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_image</span>(<span class="params">img_path,max_size=<span class="number">400</span>,shape=<span class="literal">None</span></span>):</span><br><span class="line">    image=Image.<span class="built_in">open</span>(img_path).convert(<span class="string">&quot;RGB&quot;</span>)</span><br><span class="line">    size=max_size <span class="keyword">if</span> <span class="built_in">max</span>(image.size)&gt;max_size <span class="keyword">else</span> <span class="built_in">max</span>(image.size)</span><br><span class="line">    <span class="comment"># 指定尺寸需要转化</span></span><br><span class="line">    <span class="keyword">if</span> shape <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        size=shape</span><br><span class="line">    <span class="comment"># 进行图像数据转化</span></span><br><span class="line">    in_transform=transforms.Compose(</span><br><span class="line">        [transforms.Resize(size),</span><br><span class="line">         transforms.ToTensor(),</span><br><span class="line">         transforms.Normalize((<span class="number">0.485</span>,<span class="number">0.456</span>,<span class="number">0.406</span>),(<span class="number">0.229</span>,<span class="number">0.224</span>,<span class="number">0.225</span>))]</span><br><span class="line">    )</span><br><span class="line">    <span class="comment"># 使用RGB通道，并升维到[b,c,h,w]</span></span><br><span class="line">    image=in_transform(image)[:<span class="number">3</span>,...].unsqueeze(dim=<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> image.to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义可视化图像函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">im_convert</span>(<span class="params">tensor</span>):</span><br><span class="line">    <span class="comment"># [1,c,h,w]-&gt;[c,h,w]</span></span><br><span class="line">    image=tensor.data.cpu().numpy().squeeze()</span><br><span class="line">    <span class="comment"># [c,h,w]-&gt;[h,w,c]</span></span><br><span class="line">    image=image.transpose(<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># 逆标准化</span></span><br><span class="line">    image=image*np.array((<span class="number">0.229</span>,<span class="number">0.224</span>,<span class="number">0.225</span>))+np.array((<span class="number">0.485</span>,<span class="number">0.456</span>,<span class="number">0.406</span>))</span><br><span class="line">    <span class="comment"># 裁剪图片到[0,1]</span></span><br><span class="line">    image=image.clip(<span class="number">0</span>,<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> image</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 读取内容和风格图像</span></span><br><span class="line">content=load_image(<span class="string">r&quot;C:\Users\lenovo\Desktop\新建文件夹\图片\03.jpg&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;content shape:&quot;</span>,content.shape)</span><br><span class="line"></span><br><span class="line">style=load_image(<span class="string">r&quot;C:\Users\lenovo\Desktop\新建文件夹\渲染\03.jpg&quot;</span>,shape=content.shape[-<span class="number">2</span>:])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Style&#x27;shape:&quot;</span>,style.shape)</span><br><span class="line"></span><br><span class="line">fig,(ax1,ax2) = plt.subplots(<span class="number">1</span>,<span class="number">2</span>,figsize=(<span class="number">12</span>,<span class="number">5</span>))</span><br><span class="line">ax1.imshow(im_convert(content))</span><br><span class="line">ax1.set_title(<span class="string">&quot;Content&quot;</span>)</span><br><span class="line">ax2.imshow(im_convert(style))</span><br><span class="line">ax2.set_title(<span class="string">&quot;Style&quot;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义函数，获取图像在网络上指定层的输出</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_features</span>(<span class="params">image,model,layers=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="comment"># 获取指定layer的输出</span></span><br><span class="line">    <span class="comment"># lyaers参数指定需要用于图像内容和样式表示的图层</span></span><br><span class="line">    <span class="comment"># 没有指定就使用默认的层</span></span><br><span class="line">    <span class="keyword">if</span> layers <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        layers=&#123;</span><br><span class="line">            <span class="string">&#x27;0&#x27;</span>:<span class="string">&#x27;conv1_1&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;5&#x27;</span>:<span class="string">&#x27;conv2_1&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;10&#x27;</span>:<span class="string">&#x27;conv3_1&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;19&#x27;</span>:<span class="string">&#x27;conv4_1&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;21&#x27;</span>:<span class="string">&#x27;conv4_2&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;28&#x27;</span>:<span class="string">&#x27;conv5_1&#x27;</span>,</span><br><span class="line">        &#125;</span><br><span class="line">    <span class="comment"># 获取的每层特征保存到字典中</span></span><br><span class="line">    features=&#123;&#125;</span><br><span class="line">    x=image</span><br><span class="line">    <span class="keyword">for</span> name,layer <span class="keyword">in</span> model._modules.items():</span><br><span class="line">        <span class="comment"># 从第一层开始获取图像特征</span></span><br><span class="line">        x=layer(x)</span><br><span class="line">        <span class="comment"># 如果是指定层的特征就保存</span></span><br><span class="line">        <span class="keyword">if</span> name <span class="keyword">in</span> layers:</span><br><span class="line">            features[layers[name]]=x</span><br><span class="line">    <span class="keyword">return</span> features</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 通过Gram矩阵来评价两幅图像是否具有相同风格</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gram_matrix</span>(<span class="params">tensor</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    Gram矩阵表示图像的风格特征，在保证内容的情况下，进行风格传输</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    _,d,h,w=tensor.size()</span><br><span class="line">    <span class="comment"># 改变维度为(深度,高*宽)</span></span><br><span class="line">    tensor=tensor.view(d,h*w)</span><br><span class="line">    <span class="comment"># 计算gram矩阵</span></span><br><span class="line">    gram=torch.mm(tensor,tensor.t())</span><br><span class="line">    <span class="keyword">return</span> gram</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算第一次训练之前的内容特征和风格特征</span></span><br><span class="line">content_features=get_features(content,vgg)</span><br><span class="line">style_features=get_features(style,vgg)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算每层的Gram矩阵,用于表示风格</span></span><br><span class="line">style_grams=&#123;layer:gram_matrix(style_features[layer]) <span class="keyword">for</span> layer <span class="keyword">in</span> style_features&#125;</span><br><span class="line"><span class="comment"># 使用内容图像的副本创建一个目标图像，训练时对目标图像进行调整</span></span><br><span class="line">target=content.clone().requires_grad_(<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义每个样式层的权重</span></span><br><span class="line">style_weights=&#123;<span class="string">&#x27;conv1_1&#x27;</span>:<span class="number">1.</span>,</span><br><span class="line">               <span class="string">&#x27;conv2_1&#x27;</span>:<span class="number">0.75</span>,</span><br><span class="line">               <span class="string">&#x27;conv3_1&#x27;</span>:<span class="number">0.2</span>,</span><br><span class="line">               <span class="string">&#x27;conv4_1&#x27;</span>:<span class="number">0.2</span>,</span><br><span class="line">               <span class="string">&#x27;conv5_1&#x27;</span>:<span class="number">0.2</span>&#125;</span><br><span class="line"></span><br><span class="line">alpha=<span class="number">1</span></span><br><span class="line">beta=<span class="number">1e6</span></span><br><span class="line"></span><br><span class="line">content_weight=alpha</span><br><span class="line">style_weight=beta</span><br><span class="line"></span><br><span class="line"><span class="comment"># conv4 2用于度量图像内容相似性</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 每1000次迭代输出一个中间结果</span></span><br><span class="line">show_every=<span class="number">1000</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存损失</span></span><br><span class="line">total_loss_all=[]</span><br><span class="line">content_loss_all=[]</span><br><span class="line">style_loss_all=[]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用Adam优化器</span></span><br><span class="line">optimizer=optim.Adam([target],lr=<span class="number">0.0003</span>)</span><br><span class="line">step=<span class="number">50000</span></span><br><span class="line">t0=time.time()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,step+<span class="number">1</span>):</span><br><span class="line">    <span class="comment"># 获取图像特征</span></span><br><span class="line">    target_features=get_features(target,vgg)</span><br><span class="line">    <span class="comment"># 计算内容损失</span></span><br><span class="line">    content_loss=torch.mean((target_features[<span class="string">&#x27;conv4_2&#x27;</span>]-content_features[<span class="string">&#x27;conv4_2&#x27;</span>])**<span class="number">2</span>)</span><br><span class="line">    <span class="comment"># 计算风格损失</span></span><br><span class="line">    style_loss=<span class="number">0</span></span><br><span class="line">    <span class="comment"># 把每个层的Gram矩阵相加</span></span><br><span class="line">    <span class="keyword">for</span> layer <span class="keyword">in</span> style_weights:</span><br><span class="line">        <span class="comment"># 计算要生成的图像风格表示</span></span><br><span class="line">        target_feature=target_features[layer]</span><br><span class="line">        <span class="comment"># [d,h*w]</span></span><br><span class="line">        target_gram=gram_matrix(target_feature)</span><br><span class="line">        _,d,h,w=target_feature.shape</span><br><span class="line">        <span class="comment"># 获得风格在每层的Gram矩阵</span></span><br><span class="line">        style_gram=style_grams[layer]</span><br><span class="line">        <span class="comment"># 计算损失</span></span><br><span class="line">        layer_style_loss=style_weights[layer]*torch.mean((target_gram-style_gram)**<span class="number">2</span>)</span><br><span class="line">        <span class="comment"># 累加计算风格差异</span></span><br><span class="line">        <span class="comment"># 每个像素点</span></span><br><span class="line">        style_loss+=layer_style_loss/(d*h*w)</span><br><span class="line">    <span class="comment"># 总损失等于风格损失加上内容损失</span></span><br><span class="line">    total_loss=content_weight*content_loss+style_weight*style_loss</span><br><span class="line">    <span class="comment"># 保留三种损失大小</span></span><br><span class="line">    content_loss_all.append(content_loss.item())</span><br><span class="line">    style_loss_all.append(style_loss.item())</span><br><span class="line">    total_loss_all.append(total_loss.item())</span><br><span class="line">    <span class="comment"># 更新需要生成的图像</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    total_loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line">    <span class="comment"># 输出show_ecvery次数厚度图像</span></span><br><span class="line">    <span class="keyword">if</span> i%show_every==<span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Total loss&quot;</span>,total_loss.item())</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Use time: &quot;</span>,(time.time()-t0)/<span class="number">3600</span>,<span class="string">&quot;hour&quot;</span>)</span><br><span class="line">        newim=im_convert(target)</span><br><span class="line">        plt.imshow(newim)</span><br><span class="line">        plt.title(<span class="string">&quot;Iteration: &quot;</span>+<span class="built_in">str</span>(i)+<span class="string">&quot;times&quot;</span>)</span><br><span class="line">        plt.show()</span><br><span class="line">        <span class="comment"># 保存图片</span></span><br><span class="line">        result=Image.fromarray((newim*<span class="number">255</span>).astype(np.uint8))</span><br><span class="line">        result.save(<span class="string">r&quot;C:\Users\lenovo\Desktop\新建文件夹\结果\Map_Result&quot;</span>+<span class="built_in">str</span>(i)+<span class="string">&quot;.bmp&quot;</span>)</span><br><span class="line">        </span><br><span class="line"><span class="comment"># 结果可视化</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>,<span class="number">4</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">plt.plot(total_loss_all,<span class="string">&#x27;r&#x27;</span>,label=<span class="string">&#x27;total_loss&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.title(<span class="string">&quot;total loss&quot;</span>)</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">plt.plot(content_loss_all,<span class="string">&#x27;g-&#x27;</span>,label=<span class="string">&quot;content_loss&quot;</span>)</span><br><span class="line">plt.plot(style_loss_all,<span class="string">&#x27;b-.&#x27;</span>,label=<span class="string">&quot;style_loss&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.title(<span class="string">&quot;Content and Style loss&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="结果展示-v2">结果展示</h3>
<p><strong>内容图片</strong></p>
<img src="/2022/08/01/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E5%BF%AB%E9%80%9F%E5%9B%BE%E5%83%8F%E9%A2%9C%E8%89%B2%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/02.png" style="zoom:25%;">
<p><strong>风格图片</strong></p>
<img src="/2022/08/01/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E5%BF%AB%E9%80%9F%E5%9B%BE%E5%83%8F%E9%A2%9C%E8%89%B2%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/image-20220316140830023.png" alt="image-20220316140830023" style="zoom:10%;">
<p><strong>渲染图片</strong></p>
<h1>对抗生成网络</h1>
<hr>
<h2 id="GAN">GAN</h2>
<p>GAN的核心在于生成器和判别器的勾心斗角。</p>
<img src="/2022/08/01/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E5%BF%AB%E9%80%9F%E5%9B%BE%E5%83%8F%E9%A2%9C%E8%89%B2%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/image-20220317194554644.png" alt="image-20220317194554644" style="zoom:50%;">
<p><strong>BCELOSS</strong></p>
<p>如何去评估模型的效果？对于判别器来说，会出现正负值，我们先将其映射到[0,1]区间，接着根据信息熵的计算公式来得到损失函数：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi><mo stretchy="false">(</mo><mi>o</mi><mo separator="true">,</mo><mi>t</mi><mo stretchy="false">)</mo><mo>=</mo><mo>−</mo><mn>1</mn><mi mathvariant="normal">/</mi><mi>n</mi><munder><mo>∑</mo><mi>i</mi></munder><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">[</mo><mi>i</mi><mo stretchy="false">]</mo><mo>∗</mo><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><mi>o</mi><mo stretchy="false">[</mo><mi>i</mi><mo stretchy="false">]</mo><mo stretchy="false">)</mo><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>t</mi><mo stretchy="false">[</mo><mi>i</mi><mo stretchy="false">]</mo><mo stretchy="false">)</mo><mo>∗</mo><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>o</mi><mo stretchy="false">[</mo><mi>i</mi><mo stretchy="false">]</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">loss(o,t)=-1/n\sum_{i}(t[i]*log(o[i])+(1-t[i])*log(1-o[i]))
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">oss</span><span class="mopen">(</span><span class="mord mathnormal">o</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">t</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.3277em;vertical-align:-1.2777em;"></span><span class="mord">−</span><span class="mord">1/</span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">t</span><span class="mopen">[</span><span class="mord mathnormal">i</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathnormal">o</span><span class="mopen">[</span><span class="mord mathnormal">i</span><span class="mclose">])</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">t</span><span class="mopen">[</span><span class="mord mathnormal">i</span><span class="mclose">])</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">o</span><span class="mopen">[</span><span class="mord mathnormal">i</span><span class="mclose">]))</span></span></span></span></span></p>
<h3 id="实现代码-v3">实现代码</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">from</span> torchvision.utils <span class="keyword">import</span> save_image</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建文件夹，用来存放数据</span></span><br><span class="line">os.makedirs(<span class="string">&quot;images&quot;</span>,exist_ok=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建全局参数</span></span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">&quot;--n_epochs&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">100</span>, <span class="built_in">help</span>=<span class="string">&quot;number of epochs of training&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--batch_size&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">128</span>, <span class="built_in">help</span>=<span class="string">&quot;size of the batches&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--lr&quot;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.0002</span>, <span class="built_in">help</span>=<span class="string">&quot;adam: learning rate&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--b1&quot;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.5</span>, <span class="built_in">help</span>=<span class="string">&quot;adam: decay of first order momentum of gradient&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--b2&quot;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.999</span>, <span class="built_in">help</span>=<span class="string">&quot;adam: decay of first order momentum of gradient&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--n_cpu&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">8</span>, <span class="built_in">help</span>=<span class="string">&quot;number of cpu threads to use during batch generation&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--latent_dim&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">100</span>, <span class="built_in">help</span>=<span class="string">&quot;dimensionality of the latent space&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--img_size&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">28</span>, <span class="built_in">help</span>=<span class="string">&quot;size of each image dimension&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--channels&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">1</span>, <span class="built_in">help</span>=<span class="string">&quot;number of image channels&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--sample_interval&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">400</span>, <span class="built_in">help</span>=<span class="string">&quot;interval betwen image samples&quot;</span>)</span><br><span class="line">opt = parser.parse_args()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 图像形状 : (c,h,w)</span></span><br><span class="line">img_shape=(opt.channels,opt.img_size,opt.img_size)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 是否调用GPU</span></span><br><span class="line">cuda=<span class="literal">True</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成器</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Generator</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 生成器要做的就是把随机噪声转化为图像像素</span></span><br><span class="line">        <span class="built_in">super</span>(Generator, self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">block</span>(<span class="params">in_feat,out_feat,normalize=<span class="literal">True</span></span>):</span><br><span class="line">            <span class="comment"># in: 初始化随机噪声</span></span><br><span class="line">            <span class="comment"># out: 指定神经元输出</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 做个最简单的全连接</span></span><br><span class="line">            layers=[nn.Linear(in_feat,out_feat)]</span><br><span class="line">            <span class="keyword">if</span> normalize:</span><br><span class="line">                <span class="comment"># batch初始化</span></span><br><span class="line">                layers.append(nn.BatchNorm1d(out_feat,<span class="number">0.8</span>))</span><br><span class="line">            <span class="comment"># leakrelu激活函数</span></span><br><span class="line">            layers.append(nn.LeakyReLU(<span class="number">0.2</span>,inplace=<span class="literal">True</span>))</span><br><span class="line">            <span class="keyword">return</span> layers</span><br><span class="line"></span><br><span class="line">        self.model=nn.Sequential(</span><br><span class="line">            *block(opt.latent_dim,<span class="number">128</span>,normalize=<span class="literal">False</span>),</span><br><span class="line">            *block(<span class="number">128</span>, <span class="number">256</span>),</span><br><span class="line">            *block(<span class="number">256</span>, <span class="number">512</span>),</span><br><span class="line">            *block(<span class="number">512</span>, <span class="number">1024</span>),</span><br><span class="line">            <span class="comment"># 转化到图像大小</span></span><br><span class="line">            <span class="comment"># 即: c*h*w</span></span><br><span class="line">            nn.Linear(<span class="number">1024</span>, <span class="built_in">int</span>(np.prod(img_shape))),</span><br><span class="line">            nn.Tanh()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,z</span>):</span><br><span class="line">        <span class="comment"># 生成fake图像</span></span><br><span class="line">        img=self.model(z)</span><br><span class="line">        <span class="comment"># 将展平的scalar变成图像格式</span></span><br><span class="line">        img=img.view(img.size(<span class="number">0</span>),*img_shape)</span><br><span class="line">        <span class="keyword">return</span> img</span><br><span class="line"></span><br><span class="line"><span class="comment"># 判别器</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Discriminator</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Discriminator, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.model=nn.Sequential(</span><br><span class="line">            <span class="comment"># 判别器要做的就是识别图像状态</span></span><br><span class="line">            nn.Linear(<span class="built_in">int</span>(np.prod(img_shape)),<span class="number">512</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>,inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">512</span>,<span class="number">256</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>,inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">256</span>,<span class="number">1</span>),</span><br><span class="line">            <span class="comment"># 需要映射到01</span></span><br><span class="line">            nn.Sigmoid()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,img</span>):</span><br><span class="line">        img_flat=img.view(img.size(<span class="number">0</span>),-<span class="number">1</span>)</span><br><span class="line">        validity=self.model(img_flat)</span><br><span class="line">        <span class="keyword">return</span> validity</span><br><span class="line"></span><br><span class="line"><span class="comment"># 损失函数</span></span><br><span class="line"><span class="comment"># 用的是BCEloss</span></span><br><span class="line"><span class="comment"># 即计算样本正确识别信息熵</span></span><br><span class="line">loss=torch.nn.BCELoss()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建生成器</span></span><br><span class="line">gen=Generator()</span><br><span class="line">dis=Discriminator()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> cuda:</span><br><span class="line">    gen.cuda()</span><br><span class="line">    dis.cuda()</span><br><span class="line">    loss.cuda()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建MNIST数据集</span></span><br><span class="line">os.makedirs(<span class="string">&quot;./data/mnist&quot;</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line">dataloader = DataLoader(</span><br><span class="line">    datasets.MNIST(</span><br><span class="line">        <span class="string">&quot;./data/mnist&quot;</span>,</span><br><span class="line">        train=<span class="literal">True</span>,</span><br><span class="line">        download=<span class="literal">True</span>,</span><br><span class="line">        transform=transforms.Compose(</span><br><span class="line">            [transforms.Resize(opt.img_size),</span><br><span class="line">             transforms.ToTensor(),</span><br><span class="line">             transforms.Normalize([<span class="number">0.5</span>], [<span class="number">0.5</span>])]</span><br><span class="line">        ),</span><br><span class="line">    ),</span><br><span class="line">    batch_size=opt.batch_size,</span><br><span class="line">    shuffle=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义优化器</span></span><br><span class="line">opt_G=torch.optim.Adam(gen.parameters(),lr=opt.lr,betas=(opt.b1, opt.b2))</span><br><span class="line">opt_D=torch.optim.Adam(dis.parameters(),lr=opt.lr,betas=(opt.b1, opt.b2))</span><br><span class="line"></span><br><span class="line">Tensor=torch.cuda.FloatTensor <span class="keyword">if</span> cuda <span class="keyword">else</span> torch.FloatTensor</span><br><span class="line"></span><br><span class="line"><span class="comment"># -------</span></span><br><span class="line"><span class="comment">#   训练</span></span><br><span class="line"><span class="comment"># -------</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(opt.n_epochs):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i,(imgs,_) <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line">        <span class="comment"># 验证数据表</span></span><br><span class="line">        valid=Variable(Tensor(imgs.size(<span class="number">0</span>),<span class="number">1</span>).fill_(<span class="number">1.0</span>),requires_grad=<span class="literal">False</span>)</span><br><span class="line">        fake=Variable(Tensor(imgs.size(<span class="number">0</span>),<span class="number">1</span>).fill_(<span class="number">0.0</span>),requires_grad=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 真实影像</span></span><br><span class="line">        real_imgs=Variable(imgs.<span class="built_in">type</span>(Tensor))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># ----------</span></span><br><span class="line">        <span class="comment">#  训练生成器</span></span><br><span class="line">        <span class="comment"># ----------</span></span><br><span class="line">        opt_G.zero_grad()</span><br><span class="line">        <span class="comment"># 创建随机噪声</span></span><br><span class="line">        z=Variable(Tensor(np.random.normal(<span class="number">0</span>,<span class="number">1</span>,(imgs.shape[<span class="number">0</span>],opt.latent_dim)))) <span class="comment"># imgs:(128,1,28,28) z:(128,100)</span></span><br><span class="line">        <span class="comment"># 生成batch图片</span></span><br><span class="line">        gen_imgs=gen(z)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算生成器能够骗过判别器的能力</span></span><br><span class="line">        g_loss = loss(dis(gen_imgs), valid)</span><br><span class="line"></span><br><span class="line">        g_loss.backward()</span><br><span class="line">        opt_G.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># ---------------------</span></span><br><span class="line">        <span class="comment">#  训练判别器</span></span><br><span class="line">        <span class="comment"># ---------------------</span></span><br><span class="line"></span><br><span class="line">        opt_D.zero_grad()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算判别器对真实数据的敏感度</span></span><br><span class="line">        real_loss = loss(dis(real_imgs), valid)</span><br><span class="line">        <span class="comment"># 计算判别器识别虚假数据的敏感度</span></span><br><span class="line">        fake_loss = loss(dis(gen_imgs.detach()), fake)</span><br><span class="line"></span><br><span class="line">        d_loss = (real_loss + fake_loss) / <span class="number">2</span></span><br><span class="line"></span><br><span class="line">        d_loss.backward()</span><br><span class="line">        opt_D.step()</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(</span><br><span class="line">            <span class="string">&quot;[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]&quot;</span></span><br><span class="line">            % (epoch, opt.n_epochs, i, <span class="built_in">len</span>(dataloader), d_loss.item(), g_loss.item())</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        batches_done = epoch * <span class="built_in">len</span>(dataloader) + i</span><br><span class="line">        <span class="keyword">if</span> batches_done % opt.sample_interval == <span class="number">0</span>:</span><br><span class="line">            save_image(gen_imgs.data[:<span class="number">25</span>], <span class="string">&quot;images/%d.png&quot;</span> % batches_done, nrow=<span class="number">5</span>, normalize=<span class="literal">True</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="结果展示-v3">结果展示</h3>
<p><img src="/2022/08/01/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E5%BF%AB%E9%80%9F%E5%9B%BE%E5%83%8F%E9%A2%9C%E8%89%B2%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/image-20220318011258706.png" alt="image-20220318011258706"></p>
<p>训练生成的图像已经能够以假乱真了。</p>
<hr>
<h2 id="CyCleGAN">CyCleGAN</h2>
<p>CycleGAN区别于其他网络，不需要图像配对(Paired)即可对目标图像进行风格与颜色的迁移。</p>
<p><strong>CycleGAN能做什么？</strong></p>
<p><img src="/2022/08/01/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E5%BF%AB%E9%80%9F%E5%9B%BE%E5%83%8F%E9%A2%9C%E8%89%B2%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/horse2zebra.gif" alt="horse2zebra"></p>
<p><strong>CycleGAN网络架构</strong></p>
<p>循环架构能够保证生成的图像与源图像有关系，要不然只要是![img](file:///C:\Users\lenovo\AppData\Local\Temp\SGPicFaceTpBq\22660\22F3ACEB.png)就可以了。<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>G</mi><mrow><mi>A</mi><mi>B</mi></mrow></msub></mrow><annotation encoding="application/x-tex">G_{AB}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">A</span><span class="mord mathnormal mtight" style="margin-right:0.05017em;">B</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>用于将源图像生成目标图像，该目标图像进入判别器与真时图像进行比对。同时，为了保证图像间的关联，还需要通过<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>G</mi><mrow><mi>B</mi><mi>A</mi></mrow></msub></mrow><annotation encoding="application/x-tex">G_{BA}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05017em;">B</span><span class="mord mathnormal mtight">A</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>网络将目标图像还原至与源图像相似的图像，并衡量最后结果与源图像的相似程度。</p>
<img src="/2022/08/01/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E5%BF%AB%E9%80%9F%E5%9B%BE%E5%83%8F%E9%A2%9C%E8%89%B2%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/image-20220318085558382.png" alt="image-20220318085558382" style="zoom:33%;">
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>G</mi><mrow><mi>B</mi><mi>A</mi></mrow></msub></mrow><annotation encoding="application/x-tex">G_{BA}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05017em;">B</span><span class="mord mathnormal mtight">A</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>在其中也有着非常重要的作用，同样需要经过训练。</p>
<img src="/2022/08/01/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E5%BF%AB%E9%80%9F%E5%9B%BE%E5%83%8F%E9%A2%9C%E8%89%B2%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/image-20220318090444399.png" alt="image-20220318090444399" style="zoom:33%;">
<p>在整体网络架构中，通过颠倒目标图像与源图像的方式，能够对循环生成器进行训练。</p>
<p><strong>损失函数</strong></p>
<ul>
<li>生成器损失</li>
<li>判别器损失</li>
<li>循环损失</li>
<li>映射损失(将生成图像再通过生成器，看二次生成与一次生成的差别)</li>
</ul>
<h3 id="重点代码详解">重点代码详解</h3>
<h3 id="结果展示-v4">结果展示</h3>
<p>样本类A示例</p>
<img src="/2022/08/01/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E5%BF%AB%E9%80%9F%E5%9B%BE%E5%83%8F%E9%A2%9C%E8%89%B2%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/264_A.jpg" alt="image-20220318012102085" style="zoom: 50%;">
<p>样本类B示例</p>
<img src="/2022/08/01/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E5%BF%AB%E9%80%9F%E5%9B%BE%E5%83%8F%E9%A2%9C%E8%89%B2%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/264_B.jpg" alt="image-20220318012123535" style="zoom: 50%;">
<p>生成器结果示例</p>
<img src="/2022/08/01/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E5%BF%AB%E9%80%9F%E5%9B%BE%E5%83%8F%E9%A2%9C%E8%89%B2%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/1002_A_fake.png" alt="image-20220318012123535" style="zoom: 110%;">
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 不想学辣 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 图像处理 </tag>
            
            <tag> 机器视觉 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[PointNet网络]]></title>
      <url>/2022/08/01/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91PointNet%E7%BD%91%E7%BB%9C/</url>
      <content type="html"><![CDATA[<h1>PointNet网络详解</h1>
<hr>
<h2 id="一、点云数据的特点">一、点云数据的特点</h2>
<ul>
<li>无序性</li>
<li>近密远疏</li>
<li>非结构化数据</li>
<li>局部结构语义</li>
</ul>
<h2 id="二、PointNet">二、PointNet</h2>
<h3 id="2-1-PointNet思想">2.1  PointNet思想</h3>
<p>传统的卷积神经网络是对图像像素进行卷积，如果在不同方向将点云数据进行投影，再利用卷积神经网络也能实现分割，但是算法复杂且效果不好。PointNet考虑的是直接输入点云数据，实现一个端到端的网络。</p>
<p>但是点云数据不同于图像数据，首先是点具有<strong>置换不变性</strong>，即交换任意点之间的位置，不会对整体造成影响(不考虑回波和辐射强度时)。</p>
<p>PointNet需要满足这种不变性，即:</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>x</mi><mi>n</mi></msub><mo stretchy="false">)</mo><mo>≡</mo><mi>f</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>π</mi><mn>1</mn></mrow></msub><mo separator="true">,</mo><msub><mi>x</mi><mrow><mi>π</mi><mn>2</mn></mrow></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>x</mi><mrow><mi>π</mi><mi>n</mi></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(x_1,x_2,...,x_n)\equiv f(x_{\pi1},x_{\pi2},...,x_{\pi n})
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≡</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">π</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">π</span><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">πn</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
<p>其实有很多种方式能满足这种不变性，PointNet采用了最大池化(max函数)来实现。但是该方法太过一刀切了，会丢失很多的信息。为了确保信息量，PointNet采用升维的方式，构建更多的隐含信息。</p>
<p>最简单的就是通过全连接层或者卷积进行特征提取。</p>
<img src="/2022/08/01/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91PointNet%E7%BD%91%E7%BB%9C/image-20220328001047560.png" alt="image-20220328001047560" style="zoom:33%;">
<p>其网络架构如下：</p>
<img src="/2022/08/01/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91PointNet%E7%BD%91%E7%BB%9C/image-20220328124916753.png" alt="image-20220328124916753" style="zoom: 33%;">
<p>大致流程为：</p>
<ul>
<li>输入一个包含n个点云的集合，表示为<code>n*3</code>的<code>tensor</code>，三个维度分别对应<code>xyz</code>坐标。</li>
<li>输入的数据一般需要跟一个<code>T-Net</code>学习到的转移矩阵相乘来对其，这样保证了模型的对特定空间转换的不变性。</li>
<li>最终利用<code>maxpooling</code>在各个维度上操作得到全局特征。</li>
</ul>
<p>对于分类工作，是将输入数据先做一个数据增强，然后利用多层感知机进行升维，在获取到1024维的信息之后，采用最大池化获取全局信息。接着在对这1024维进行降维到k维，进行分类。</p>
<p>而针对分割任务，则是将全局高维信息与64维的低维信息融合(等于64维后面直接黏上1024维)后做降维。</p>
<h3 id="2-2-PointNet实现">2.2  PointNet实现</h3>
<p>本文代码参考自：<a href="https://link.zhihu.com/?target=https%3A//github.com/yanx27/Pointnet_Pointnet2_pytorch">https://link.zhihu.com/?target=https%3A//github.com/yanx27/Pointnet_Pointnet2_pytorch</a>.</p>
<h4 id="2-2-1-T-Net">2.2.1  <strong>T-Net</strong></h4>
<p>T-Net是用来模拟模型对特定空间转换的不变性，在原文中给出了如下的解释：<em>The semantic labeling of a point cloud has to be invariant if the point cloud undergoes certain geometric transformations, such as rigid transformation. We therefore expect that the learnt representation by our point set is invariant to these transformations.</em></p>
<p>本质上是做了<strong>刚体变换</strong>(Rigid Transformation)，即变换前后两点间距离仍保持不变。具体原理可以参考<a href="https://www.cnblogs.com/xinxue/archive/2017/09/28/7513192.html">文章</a>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">STN3d</span>(nn.Module):</span><br><span class="line">    <span class="comment"># T-Net在三维情况下</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,channel</span>):</span><br><span class="line">        <span class="built_in">super</span>(STN3d, self).__init__()</span><br><span class="line">        self.conv1=nn.Conv1d(channel,<span class="number">64</span>,<span class="number">1</span>)</span><br><span class="line">        self.conv2=nn.Conv1d(<span class="number">64</span>,<span class="number">128</span>,<span class="number">1</span>)</span><br><span class="line">        self.conv3=nn.Conv1d(<span class="number">128</span>,<span class="number">1024</span>,<span class="number">1</span>)</span><br><span class="line">        self.fc1=nn.Linear(<span class="number">1024</span>,<span class="number">512</span>)</span><br><span class="line">        self.fc2=nn.Linear(<span class="number">512</span>,<span class="number">256</span>)</span><br><span class="line">        <span class="comment"># 这里的9是3*3变换来的</span></span><br><span class="line">        self.fc3=nn.Linear(<span class="number">256</span>,<span class="number">9</span>)</span><br><span class="line">        self.relu=nn.ReLU()</span><br><span class="line"></span><br><span class="line">        self.bn1=nn.BatchNorm1d(<span class="number">64</span>)</span><br><span class="line">        self.bn2=nn.BatchNorm1d(<span class="number">128</span>)</span><br><span class="line">        self.bn3=nn.BatchNorm1d(<span class="number">1024</span>)</span><br><span class="line">        self.bn4=nn.BatchNorm1d(<span class="number">512</span>)</span><br><span class="line">        self.bn5=nn.BatchNorm1d(<span class="number">256</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        batchsize=x.size(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 开始获取高维数据</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># shape: [ batch , num , 3 ]</span></span><br><span class="line">        x=F.relu(self.bn1(self.conv1(x)))</span><br><span class="line">        <span class="comment"># shape: [ batch , num , 64 ]</span></span><br><span class="line">        x=F.relu(self.bn2(self.conv2(x)))</span><br><span class="line">        <span class="comment"># shape: [ batch , num , 128 ]</span></span><br><span class="line">        x=F.relu(self.bn3(self.conv3(x)))</span><br><span class="line">        <span class="comment"># shape: [ batch , num , 1024 ]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 最大池化获取全局信息</span></span><br><span class="line">        x=torch.<span class="built_in">max</span>(x,<span class="number">2</span>,keepdim=<span class="literal">True</span>)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 展平做线性层</span></span><br><span class="line">        x=x.view(-<span class="number">1</span>,<span class="number">1024</span>)</span><br><span class="line">        <span class="comment"># shape: [ 1, 1024 ]</span></span><br><span class="line">        x=F.relu(self.bn4(self.fc1(x)))</span><br><span class="line">        <span class="comment"># shape: [ 1, 512 ]</span></span><br><span class="line">        x=F.relu(self.bn5(self.fc2(x)))</span><br><span class="line">        <span class="comment"># shape: [ 1, 256 ]</span></span><br><span class="line">        x=self.fc3(x)</span><br><span class="line">        <span class="comment"># shape: [ 1, 9 ]</span></span><br><span class="line">        <span class="comment"># 原本的三维xyz变换到了9维(3*3)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 关于iden，这东西就是一个eyes矩阵，本质上相当于给变换的结果加上input本身</span></span><br><span class="line">        iden=Variable(torch.from_numpy(np.array([<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>]).astype(np.float32)))\</span><br><span class="line">            .view(<span class="number">1</span>,<span class="number">9</span>).repeat(batchsize,<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># shape: [ batch , 9 ]</span></span><br><span class="line">        <span class="keyword">if</span> x.is_cuda:</span><br><span class="line">            iden=iden.cuda()</span><br><span class="line"></span><br><span class="line">        x+=iden</span><br><span class="line">        <span class="comment"># 转换成[ batch , 3 , 3 ]的矩阵进行输出</span></span><br><span class="line">        <span class="comment"># 该矩阵用于对原始向量做刚体变换</span></span><br><span class="line">        x=x.view(-<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<img src="/2022/08/01/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91PointNet%E7%BD%91%E7%BB%9C/image-20220328200404491.png" alt="image-20220328200404491" style="zoom:50%;">
<p><code>T-Net</code>就相当于一个微型网络，能够获得一个用于变换的数据，且该数据是能自适应的。</p>
<p>输入数据如果是一个<code>3*1000</code>的点云，得到的网络结构如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">----------------------------------------------------------------</span><br><span class="line">        Layer (<span class="built_in">type</span>)               Output Shape         Param <span class="comment">#</span></span><br><span class="line">================================================================</span><br><span class="line">            Conv1d-<span class="number">1</span>             [-<span class="number">1</span>, <span class="number">64</span>, <span class="number">1000</span>]             <span class="number">256</span></span><br><span class="line">       BatchNorm1d-<span class="number">2</span>             [-<span class="number">1</span>, <span class="number">64</span>, <span class="number">1000</span>]             <span class="number">128</span></span><br><span class="line">            Conv1d-<span class="number">3</span>            [-<span class="number">1</span>, <span class="number">128</span>, <span class="number">1000</span>]           <span class="number">8</span>,<span class="number">320</span></span><br><span class="line">       BatchNorm1d-<span class="number">4</span>            [-<span class="number">1</span>, <span class="number">128</span>, <span class="number">1000</span>]             <span class="number">256</span></span><br><span class="line">            Conv1d-<span class="number">5</span>           [-<span class="number">1</span>, <span class="number">1024</span>, <span class="number">1000</span>]         <span class="number">132</span>,096</span><br><span class="line">       BatchNorm1d-<span class="number">6</span>           [-<span class="number">1</span>, <span class="number">1024</span>, <span class="number">1000</span>]           <span class="number">2</span>,048</span><br><span class="line">            Linear-<span class="number">7</span>                  [-<span class="number">1</span>, <span class="number">512</span>]         <span class="number">524</span>,<span class="number">800</span></span><br><span class="line">       BatchNorm1d-<span class="number">8</span>                  [-<span class="number">1</span>, <span class="number">512</span>]           <span class="number">1</span>,024</span><br><span class="line">            Linear-<span class="number">9</span>                  [-<span class="number">1</span>, <span class="number">256</span>]         <span class="number">131</span>,<span class="number">328</span></span><br><span class="line">      BatchNorm1d-<span class="number">10</span>                  [-<span class="number">1</span>, <span class="number">256</span>]             <span class="number">512</span></span><br><span class="line">           Linear-<span class="number">11</span>                    [-<span class="number">1</span>, <span class="number">9</span>]           <span class="number">2</span>,<span class="number">313</span></span><br><span class="line">================================================================</span><br><span class="line">Total params: <span class="number">803</span>,081</span><br><span class="line">Trainable params: <span class="number">803</span>,081</span><br><span class="line">Non-trainable params: <span class="number">0</span></span><br><span class="line">----------------------------------------------------------------</span><br><span class="line">Input size (MB): <span class="number">0.01</span></span><br><span class="line">Forward/backward <span class="keyword">pass</span> size (MB): <span class="number">18.57</span></span><br><span class="line">Params size (MB): <span class="number">3.06</span></span><br><span class="line">Estimated Total Size (MB): <span class="number">21.64</span></span><br><span class="line">----------------------------------------------------------------</span><br></pre></td></tr></table></figure>
<p>扩展到<code>k</code>维，则是表示如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">STNkd</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, k=<span class="number">64</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(STNkd, self).__init__()</span><br><span class="line">        self.conv1 = torch.nn.Conv1d(k, <span class="number">64</span>, <span class="number">1</span>)</span><br><span class="line">        self.conv2 = torch.nn.Conv1d(<span class="number">64</span>, <span class="number">128</span>, <span class="number">1</span>)</span><br><span class="line">        self.conv3 = torch.nn.Conv1d(<span class="number">128</span>, <span class="number">1024</span>, <span class="number">1</span>)</span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">1024</span>, <span class="number">512</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">512</span>, <span class="number">256</span>)</span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">256</span>, k * k)</span><br><span class="line">        self.relu = nn.ReLU()</span><br><span class="line"></span><br><span class="line">        self.bn1 = nn.BatchNorm1d(<span class="number">64</span>)</span><br><span class="line">        self.bn2 = nn.BatchNorm1d(<span class="number">128</span>)</span><br><span class="line">        self.bn3 = nn.BatchNorm1d(<span class="number">1024</span>)</span><br><span class="line">        self.bn4 = nn.BatchNorm1d(<span class="number">512</span>)</span><br><span class="line">        self.bn5 = nn.BatchNorm1d(<span class="number">256</span>)</span><br><span class="line"></span><br><span class="line">        self.k = k</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        batchsize = x.size()[<span class="number">0</span>]</span><br><span class="line">        x = F.relu(self.bn1(self.conv1(x)))</span><br><span class="line">        x = F.relu(self.bn2(self.conv2(x)))</span><br><span class="line">        x = F.relu(self.bn3(self.conv3(x)))</span><br><span class="line">        x = torch.<span class="built_in">max</span>(x, <span class="number">2</span>, keepdim=<span class="literal">True</span>)[<span class="number">0</span>]</span><br><span class="line">        x = x.view(-<span class="number">1</span>, <span class="number">1024</span>)</span><br><span class="line"></span><br><span class="line">        x = F.relu(self.bn4(self.fc1(x)))</span><br><span class="line">        x = F.relu(self.bn5(self.fc2(x)))</span><br><span class="line">        x = self.fc3(x)</span><br><span class="line"></span><br><span class="line">        iden = Variable(torch.from_numpy(np.eye(self.k).flatten().astype(np.float32))).view(<span class="number">1</span>, self.k * self.k).repeat(</span><br><span class="line">            batchsize, <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> x.is_cuda:</span><br><span class="line">            iden = iden.cuda()</span><br><span class="line">        x = x + iden</span><br><span class="line">        x = x.view(-<span class="number">1</span>, self.k, self.k)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<p><img src="/2022/08/01/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91PointNet%E7%BD%91%E7%BB%9C/image-20220328200431913.png" alt="image-20220328200431913"></p>
<h4 id="2-2-2-PointNet">2.2.2  <strong>PointNet</strong></h4>
<p>实现起来也相对简单，与<code>T-Net</code>的差别其实不大。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PointNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,global_feat=<span class="literal">True</span>,feature_transform=<span class="literal">False</span>,channel=<span class="number">3</span></span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param global_feat: 是否返回全局特征,该值为False的时候会返回拼接的信息</span></span><br><span class="line"><span class="string">        :param feature_transform: 要素转换阶段，是否要进行要素转换</span></span><br><span class="line"><span class="string">        :param channel: 输入数据的维度，默认是只含有xyz坐标</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        self.stn=STN3d(channel)</span><br><span class="line">        self.conv1 = torch.nn.Conv1d(channel, <span class="number">64</span>, <span class="number">1</span>)</span><br><span class="line">        self.conv2 = torch.nn.Conv1d(<span class="number">64</span>, <span class="number">128</span>, <span class="number">1</span>)</span><br><span class="line">        self.conv3 = torch.nn.Conv1d(<span class="number">128</span>, <span class="number">1024</span>, <span class="number">1</span>)</span><br><span class="line">        self.bn1 = nn.BatchNorm1d(<span class="number">64</span>)</span><br><span class="line">        self.bn2 = nn.BatchNorm1d(<span class="number">128</span>)</span><br><span class="line">        self.bn3 = nn.BatchNorm1d(<span class="number">1024</span>)</span><br><span class="line">        self.global_feat=global_feat</span><br><span class="line">        self.feature_transform=feature_transform</span><br><span class="line">        <span class="keyword">if</span> self.feature_transform:</span><br><span class="line">            self.fstn=STNkd(k=<span class="number">64</span>)</span><br><span class="line">        </span><br><span class="line">        self.mlp1=nn.Linear(<span class="number">1024</span>,<span class="number">128</span>)</span><br><span class="line">        self.mlp2=nn.Linear(<span class="number">128</span>,<span class="number">64</span>)</span><br><span class="line">        self.mlp3=nn.Linear(<span class="number">64</span>,n)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        B, D, N=x.size() <span class="comment"># batch , deep , num</span></span><br><span class="line">        trans=self.stn(x) <span class="comment"># return : shape: [ b , 3 , 3 ]</span></span><br><span class="line">        x=x.transpose(<span class="number">2</span>,<span class="number">1</span>) <span class="comment"># [ b , num , deep ]</span></span><br><span class="line">        <span class="keyword">if</span> D&gt;<span class="number">3</span>:</span><br><span class="line">            <span class="comment"># 此时需要分割要素</span></span><br><span class="line">            <span class="comment"># 我们做刚体变换的只有位置数据</span></span><br><span class="line">            x,feature=x.split(<span class="number">3</span>,dim=<span class="number">2</span>)</span><br><span class="line">        <span class="comment"># 此时做矩阵乘法，bmm这个方法一定要三维才能进行</span></span><br><span class="line">        <span class="comment"># 相当于[x&#x27;,y&#x27;,z&#x27;]+[x,y,z]</span></span><br><span class="line">        <span class="comment"># [x&#x27;,y&#x27;,z&#x27;]来自于trans矩阵的变换</span></span><br><span class="line">        x=torch.bmm(x,trans) <span class="comment"># [ num , deep ] * [ deep , deep ]-&gt; [ num , deep ]</span></span><br><span class="line">        <span class="keyword">if</span> D&gt;<span class="number">3</span>:</span><br><span class="line">            x=torch.cat([x,feature],dim=<span class="number">2</span>)</span><br><span class="line">        x.transpose(<span class="number">2</span>,<span class="number">1</span>) <span class="comment"># [ b , d , n ]</span></span><br><span class="line"></span><br><span class="line">        x=F.relu(self.bn1(self.conv1(x)))</span><br><span class="line">        <span class="comment"># 64个特征时是否需要做feature_transform</span></span><br><span class="line">        <span class="keyword">if</span> self.feature_transform:</span><br><span class="line">            trans_feat=self.fstn(x)</span><br><span class="line">            x=x.transpose(<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">            x=torch.bmm(x,trans_feat)</span><br><span class="line">            x=x.transpose(<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            trans_feat=<span class="literal">None</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 此时若是处理分割任务，则将该部分(64维特征)作为拼接项</span></span><br><span class="line">        pointfeat=x</span><br><span class="line">        <span class="comment"># 接着进行卷积</span></span><br><span class="line">        x=F.relu(self.bn2(self.conv2(x)))</span><br><span class="line">        x=self.bn3(self.conv3(x))</span><br><span class="line">        x=torch.argmax(x,<span class="number">2</span>,keepdim=<span class="literal">True</span>)[<span class="number">0</span>]</span><br><span class="line">        x=x.view(-<span class="number">1</span>,<span class="number">1024</span>)</span><br><span class="line">        <span class="keyword">if</span> self.global_feat:</span><br><span class="line">            <span class="comment"># 分类任务</span></span><br><span class="line">            <span class="comment"># trans是input_transform的3*3矩阵</span></span><br><span class="line">            <span class="comment"># trans是feature_transform的64*64矩阵</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 为了方便演示，在编码器上加上了解码器的工作</span></span><br><span class="line">            <span class="comment"># 实际上没有下面三行</span></span><br><span class="line">            x=F.relu(self.bn2(self.mlp1(x)))</span><br><span class="line">            x=F.relu(self.bn1(self.mlp2(x)))</span><br><span class="line">            x=self.mlp3(x)</span><br><span class="line">            <span class="keyword">return</span> x,trans,trans_feat</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 分割任务，需要将全局信息黏贴到中间层信息中</span></span><br><span class="line">            x=x.view(-<span class="number">1</span>,<span class="number">1024</span>,<span class="number">1</span>).repeat(<span class="number">1</span>,<span class="number">1</span>,N)</span><br><span class="line">            <span class="keyword">return</span> torch.cat([x,pointfeat],<span class="number">1</span>),trans,trans_feat</span><br></pre></td></tr></table></figure>
<p>论文中提到，64*64维的矩阵很难优化，但作者发现如果该矩阵约等于正交矩阵，优化就会容易很多。根据正交矩阵的性质：正交矩阵乘以转置等于单位矩阵，作者额外增加了损失函数。</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>L</mi><mrow><mi>r</mi><mi>e</mi><mi>g</mi></mrow></msub><mo>=</mo><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><mi>I</mi><mo>−</mo><mi>A</mi><msup><mi>A</mi><mi>T</mi></msup><mi mathvariant="normal">∣</mi><msubsup><mi mathvariant="normal">∣</mi><mi>F</mi><mn>2</mn></msubsup></mrow><annotation encoding="application/x-tex">L_{reg}=||I-AA^T||^2_F
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">re</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∣∣</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1413em;vertical-align:-0.25em;"></span><span class="mord mathnormal">A</span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord">∣</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">F</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span></span></p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span>是通过<code>T-Net</code>得到的<code>64*64</code>对齐矩阵，在本部分中，作者给出的损失函数代码为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">feature_transform_reguliarzer</span>(<span class="params">trans</span>):</span><br><span class="line">    <span class="comment"># 定义损失规则</span></span><br><span class="line">    d = trans.size()[<span class="number">1</span>] <span class="comment"># deep</span></span><br><span class="line">    I = torch.eye(d)[<span class="literal">None</span>, :, :] <span class="comment"># [ 1 , deep , deep ]</span></span><br><span class="line">    <span class="keyword">if</span> trans.is_cuda:</span><br><span class="line">        I = I.cuda()</span><br><span class="line">    loss = torch.mean(torch.norm(torch.bmm(trans, trans.transpose(<span class="number">2</span>, <span class="number">1</span>) - I), dim=(<span class="number">1</span>, <span class="number">2</span>)))</span><br><span class="line">    <span class="comment"># 虽然但是...按照公式写应该是</span></span><br><span class="line">    <span class="comment">#  loss = torch.mean(torch.norm(torch.bmm(trans, trans.transpose(2, 1))- I, dim=(1, 2)))</span></span><br><span class="line">    <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure>
<p>话说F范数就是对向量的所有元素平方求和再开方，本质上是向量模的度量。如果向量内的数据都是无量纲的，那么开不开方影响就不大了。</p>
<p>我们可以查看下网络的结构。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">----------------------------------------------------------------</span><br><span class="line">        Layer (<span class="built_in">type</span>)               Output Shape         Param <span class="comment">#</span></span><br><span class="line">================================================================</span><br><span class="line">            Conv1d-<span class="number">1</span>             [-<span class="number">1</span>, <span class="number">64</span>, <span class="number">1000</span>]             <span class="number">256</span></span><br><span class="line">       BatchNorm1d-<span class="number">2</span>             [-<span class="number">1</span>, <span class="number">64</span>, <span class="number">1000</span>]             <span class="number">128</span></span><br><span class="line">            Conv1d-<span class="number">3</span>            [-<span class="number">1</span>, <span class="number">128</span>, <span class="number">1000</span>]           <span class="number">8</span>,<span class="number">320</span></span><br><span class="line">       BatchNorm1d-<span class="number">4</span>            [-<span class="number">1</span>, <span class="number">128</span>, <span class="number">1000</span>]             <span class="number">256</span></span><br><span class="line">            Conv1d-<span class="number">5</span>           [-<span class="number">1</span>, <span class="number">1024</span>, <span class="number">1000</span>]         <span class="number">132</span>,096</span><br><span class="line">       BatchNorm1d-<span class="number">6</span>           [-<span class="number">1</span>, <span class="number">1024</span>, <span class="number">1000</span>]           <span class="number">2</span>,048</span><br><span class="line">            Linear-<span class="number">7</span>                  [-<span class="number">1</span>, <span class="number">512</span>]         <span class="number">524</span>,<span class="number">800</span></span><br><span class="line">       BatchNorm1d-<span class="number">8</span>                  [-<span class="number">1</span>, <span class="number">512</span>]           <span class="number">1</span>,024</span><br><span class="line">            Linear-<span class="number">9</span>                  [-<span class="number">1</span>, <span class="number">256</span>]         <span class="number">131</span>,<span class="number">328</span></span><br><span class="line">      BatchNorm1d-<span class="number">10</span>                  [-<span class="number">1</span>, <span class="number">256</span>]             <span class="number">512</span></span><br><span class="line">           Linear-<span class="number">11</span>                    [-<span class="number">1</span>, <span class="number">9</span>]           <span class="number">2</span>,<span class="number">313</span></span><br><span class="line">            STN3d-<span class="number">12</span>                 [-<span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>]               <span class="number">0</span></span><br><span class="line">           Conv1d-<span class="number">13</span>             [-<span class="number">1</span>, <span class="number">64</span>, <span class="number">1000</span>]             <span class="number">256</span></span><br><span class="line">      BatchNorm1d-<span class="number">14</span>             [-<span class="number">1</span>, <span class="number">64</span>, <span class="number">1000</span>]             <span class="number">128</span></span><br><span class="line">           Conv1d-<span class="number">15</span>            [-<span class="number">1</span>, <span class="number">128</span>, <span class="number">1000</span>]           <span class="number">8</span>,<span class="number">320</span></span><br><span class="line">      BatchNorm1d-<span class="number">16</span>            [-<span class="number">1</span>, <span class="number">128</span>, <span class="number">1000</span>]             <span class="number">256</span></span><br><span class="line">           Conv1d-<span class="number">17</span>           [-<span class="number">1</span>, <span class="number">1024</span>, <span class="number">1000</span>]         <span class="number">132</span>,096</span><br><span class="line">      BatchNorm1d-<span class="number">18</span>           [-<span class="number">1</span>, <span class="number">1024</span>, <span class="number">1000</span>]           <span class="number">2</span>,048</span><br><span class="line">================================================================</span><br><span class="line">Total params: <span class="number">946</span>,<span class="number">185</span></span><br><span class="line">Trainable params: <span class="number">946</span>,<span class="number">185</span></span><br><span class="line">Non-trainable params: <span class="number">0</span></span><br><span class="line">----------------------------------------------------------------</span><br><span class="line">Input size (MB): <span class="number">0.01</span></span><br><span class="line">Forward/backward <span class="keyword">pass</span> size (MB): <span class="number">37.12</span></span><br><span class="line">Params size (MB): <span class="number">3.61</span></span><br><span class="line">Estimated Total Size (MB): <span class="number">40.74</span></span><br><span class="line">----------------------------------------------------------------</span><br></pre></td></tr></table></figure>
<h4 id="2-2-3-数据加载">2.2.3  <strong>数据加载</strong></h4>
<p>这里我们随便测试下数据，加载器就随便写写了</p>
<p>注意Model是刚刚定义的模型文件夹，pointnet是写PointNet的.py文件</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.utils.data <span class="keyword">as</span> Data</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> Model <span class="keyword">import</span> pointnet</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure>
<p>我们就单独取一个类试试</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">path=<span class="string">r&quot;.modelnet40_normal_resampled\car\\&quot;</span></span><br><span class="line">file_list=os.listdir(path)</span><br></pre></td></tr></table></figure>
<p>接着定义数据读取方法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义一个数据读取类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PCDataset</span>(Data.Dataset):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,file_list</span>):</span><br><span class="line">        self.file_list=file_list</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(path + file_list[idx]) <span class="keyword">as</span> f:</span><br><span class="line">            data = f.readlines()</span><br><span class="line">        data = [i.split(<span class="string">&quot;\n&quot;</span>)[<span class="number">0</span>].split(<span class="string">&quot;,&quot;</span>) <span class="keyword">for</span> i <span class="keyword">in</span> data]</span><br><span class="line">        data=np.array(data,dtype=<span class="built_in">float</span>)</span><br><span class="line">        <span class="keyword">return</span> data,<span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.file_list)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读入数据</span></span><br><span class="line">Dataset=PCDataset(file_list)</span><br><span class="line">train_loader=Data.DataLoader(</span><br><span class="line">    dataset=Dataset,</span><br><span class="line">    shuffle=<span class="literal">True</span>,</span><br><span class="line">    batch_size=<span class="number">9</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>网络搭建</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构建PointNet</span></span><br><span class="line">pn=pointnet.PointNet(<span class="number">3</span>)</span><br><span class="line">criterion=nn.NLLLoss()</span><br><span class="line">optimizer=torch.optim.Adam(pn.parameters(),lr=<span class="number">0.0003</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 简单测试下</span></span><br><span class="line">loss_list=[]</span><br><span class="line">acc_list=[]</span><br><span class="line"></span><br><span class="line">device=torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">pn.to(device)</span><br><span class="line">criterion.to(device)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> step,(bx,by) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">    bx,by=bx.to(device),by.to(device)</span><br><span class="line">    out = pn(bx.to(torch.float32))[<span class="number">0</span>]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Result&#x27;s Size&quot;</span>, out.shape)</span><br><span class="line">    out = F.softmax(out, dim=<span class="number">1</span>)</span><br><span class="line">    pre_lab = torch.argmax(out, dim=<span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;class&quot;</span>, pre_lab)</span><br><span class="line">    <span class="built_in">print</span>(by)</span><br><span class="line">    loss = criterion(out, by)</span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line">    loss_list.append(loss.item())</span><br><span class="line">    acc_list.append(accuracy_score(pre_lab,by))</span><br></pre></td></tr></table></figure>
<p>结果可视化</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">12</span>,<span class="number">8</span>))</span><br><span class="line">plt.plot(<span class="built_in">range</span>(<span class="built_in">len</span>(train_loader)),loss_list,<span class="string">&quot;ro-&quot;</span>,label=<span class="string">&quot;loss&quot;</span>)</span><br><span class="line">plt.plot(<span class="built_in">range</span>(<span class="built_in">len</span>(train_loader)),acc_list,<span class="string">&quot;bs-&quot;</span>,label=<span class="string">&quot;acc&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<img src="/2022/08/01/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91PointNet%E7%BD%91%E7%BB%9C/image-20220329152205605.png" alt="image-20220329152205605" style="zoom: 33%;">
<p>损失函数出现负值是因为用的函数是NLLoss，然后小batch的训练其实没多大意义，这里只是测试下。</p>
<h3 id="2-3-PointNet缺点">2.3  PointNet缺点</h3>
<ul>
<li>PointNet与当下主流网络不符，只是做了全局信息的融合，并没有考虑到局部的语义</li>
<li>点对之间的特征关系并没有考虑</li>
</ul>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 不想学辣 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 神经网络 </tag>
            
            <tag> 点云 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[PointNet++网络]]></title>
      <url>/2022/08/01/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91PointNet-%E7%BD%91%E7%BB%9C/</url>
      <content type="html"><![CDATA[<h1>PointNet++网络详解</h1>
<hr>
<h2 id="一、PointNet-改进思想">一、PointNet++改进思想</h2>
<p>关于PointNet可以参考前一篇<a href="https://blog.csdn.net/qq_45957458/article/details/123822694?spm=1001.2014.3001.5502">文档</a>。</p>
<p>前文中已经提到，PointNet并没有做局部特征提取，而是通过最大池化层获取全局的信息。这与当前主流的网络不符。在CNN中，有着感受野的概念，通过不断卷积获得的高维特征点对应着低层的一个区域。而在PointNet中，则没有这种局部特征融合的机制。</p>
<p>针对PointNet的不足，PointNet++应运而生。</p>
<p>PointNet++相较于PointNet，主要有以下几个改进项：</p>
<ul>
<li>针对点云图点对数量的不规则，采用<strong>最远点采样</strong>选取其中的<code>N</code>个点，既能保证每个数据能够有相同的形状，也能让其尽可能保留多的信息量。</li>
<li>通过构建球形搜索区域，获取子区域的点对，实现局部特征提取</li>
<li>提取多尺度特征，对不同子区域的特征进行提取与聚合。</li>
<li>提出基于距离差值的分层特征传播算法，将局部特征上采样传播给在特征融合过程中丢失的点中。</li>
</ul>
<p>下面我们针对这些改进项进行一些比较细致的分析。</p>
<p>注：<strong>B</strong>表示batch；<strong>N</strong>表示num；<strong>C</strong>和<strong>D</strong>都表示特征维度(C是xyz)。</p>
<img src="/2022/08/01/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91PointNet-%E7%BD%91%E7%BB%9C/image-20220401131840067.png" alt="image-20220401131840067" style="zoom: 33%;">
<hr>
<h2 id="二、最远点采样FPS算法">二、最远点采样FPS算法</h2>
<p>最远点采样能够对全局点进行采样，在保证每个点云数据具有相同的点数量的同时，尽可能保留更多的信息量。</p>
<p>其中的<strong>输入</strong>为：</p>
<ul>
<li>xyz: 点云坐标数据，shape为 [B,N,3]</li>
<li>npoint: 需要提取的点云数量</li>
</ul>
<p><strong>输出</strong>为：</p>
<ul>
<li>centroid: 点云中心点<strong>索引</strong>，shape为 [B,npoint]</li>
</ul>
<p>FPS(Farthest Point Sample)的核心思想如下：</p>
<ul>
<li>对输入的每一批点云分别<strong>构建簇中心</strong></li>
<li>构建<strong>距离矩阵</strong>，用于每次最远距迭代</li>
<li>在点云中随机选择一个点作为簇初始点</li>
<li>选择与该簇距离最远的点，加入簇，并将该点作为下一次迭代的点</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">farthest_point_sample</span>(<span class="params">xyz,npoint</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Input:</span></span><br><span class="line"><span class="string">        xyz: pointcloud data, [B, N, 3]</span></span><br><span class="line"><span class="string">        npoint: number of samples</span></span><br><span class="line"><span class="string">    Return:</span></span><br><span class="line"><span class="string">        centroids: sampled pointcloud index, [B, npoint]</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    device = xyz.device</span><br><span class="line">    B, N, C = xyz.shape</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 构建中心簇 ， 大小为: [ batch , npoint ]</span></span><br><span class="line">    centroids=torch.zeros(B,npoint,dtype=torch.long).to(device)</span><br><span class="line">    <span class="comment"># 构建距离矩阵</span></span><br><span class="line">    distance=torch.ones(B,N).to(device)*<span class="number">1e10</span></span><br><span class="line">    <span class="comment"># 对batch细分</span></span><br><span class="line">    batch_indices=torch.arange(B,dtype=torch.long).to(device)</span><br><span class="line">    <span class="comment"># 最远点初始化 随机选择一个点</span></span><br><span class="line">    farthest=torch.randint(<span class="number">0</span>,N,(B,),dtype=torch.long).to(device)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(npoint):</span><br><span class="line">        centroids[:,i]=farthest</span><br><span class="line">        <span class="comment"># 获取当前采样点坐标值</span></span><br><span class="line">        centroid=xyz[batch_indices,farthest,:].view(B,<span class="number">1</span>,<span class="number">3</span>)</span><br><span class="line">        <span class="comment"># 计算当前点与其他点的距离</span></span><br><span class="line">        dist=torch.<span class="built_in">sum</span>((xyz-centroid)**<span class="number">2</span>,-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 获取满足条件的逻辑矩阵</span></span><br><span class="line">        mask=dist&lt;distance</span><br><span class="line">        <span class="comment"># 选择距离最近的点来更新距离</span></span><br><span class="line">        distance[mask]=dist[mask]</span><br><span class="line">        farthest=torch.<span class="built_in">max</span>(distance,-<span class="number">1</span>)[<span class="number">1</span>] <span class="comment"># 获得最远点的索引</span></span><br><span class="line">    <span class="keyword">return</span> centroid</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>关于距离更新算法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取满足条件的逻辑矩阵</span></span><br><span class="line">mask=dist&lt;distance</span><br><span class="line"><span class="comment"># 选择距离最近的点来更新距离</span></span><br><span class="line">distance[mask]=dist[mask]</span><br><span class="line">farthest=torch.<span class="built_in">max</span>(distance,-<span class="number">1</span>)[<span class="number">1</span>] <span class="comment"># 获得最远点的索引</span></span><br></pre></td></tr></table></figure>
<p>在初始化的时候，我们将<code>distance</code>初始化为<code>1e10</code>，那么在第一次更新时，就会将所有点距离进行更新。</p>
<p>且计算是会将自身计算进去的(自己到自己的距离是0)，所以每更新一次矩阵，都有一个点的距离被更新为0。</p>
<p><code>distance</code>在这里的作用，就相当于一个记录表，用来记录每次的状态变化。这样，每有一个点被加入，就有有一个0值被寻得，说明该点已经被使用，不再参与更新。</p>
<hr>
<h2 id="三、局部特征提取算法">三、局部特征提取算法</h2>
<p>在CNN中的局部特征一般是通过不同大小的卷积核点乘得到的，而在PointNet++中，作者也采用了这类的思想，用来提取子区域。</p>
<p>其核心思想为：</p>
<ul>
<li>预设一个<strong>搜索半径</strong><code>radius</code>和<strong>子区域</strong>的点数量<code>k</code></li>
<li>在最远点采样中获取的簇中心<strong>构造球体</strong>，半径等于搜索半径</li>
<li>计算每个点离中心簇的距离，若该点<strong>落在球体内</strong>，则将其加入到簇中</li>
<li>若球体内的点小于子区域点数量<code>k</code>，则复制最近的点，直到满足条件，若大于，则选取前<code>k</code>个点。</li>
<li>现在每个中心都有<code>k</code>个点了，类似于CNN的<code>k*k</code>子区域</li>
</ul>
<p><strong>输入</strong>为：</p>
<ul>
<li>radius: 搜索半径</li>
<li>nsample: 采样点数量</li>
<li>xyz: 所有点的位置信息</li>
<li>new_xyz: 簇中心</li>
</ul>
<p><strong>输出</strong>为：</p>
<ul>
<li>一组簇点的索引，shape为 [B,S,nsample]</li>
</ul>
<p>如何去获取各点的距离呢？这里采用了如下算法：</p>
<p>对于输入<code>src</code>,shape为[B,N,3]；对于输入<code>dst</code>,shape为[B,S,3]</p>
<p>距离公式表示为：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>d</mi><mi>i</mi><mi>s</mi><mo>=</mo><mo stretchy="false">(</mo><msub><mi>x</mi><mi>n</mi></msub><mo>−</mo><msub><mi>x</mi><mi>m</mi></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>+</mo><mo stretchy="false">(</mo><msub><mi>y</mi><mi>n</mi></msub><mo>−</mo><msub><mi>y</mi><mi>m</mi></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>+</mo><mo stretchy="false">(</mo><msub><mi>z</mi><mi>n</mi></msub><mo>−</mo><msub><mi>z</mi><mi>m</mi></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mspace linebreak="newline"></mspace><mo>=</mo><msubsup><mi>x</mi><mi>n</mi><mn>2</mn></msubsup><mo>+</mo><msubsup><mi>x</mi><mi>m</mi><mn>2</mn></msubsup><mo>−</mo><mn>2</mn><msub><mi>x</mi><mi>n</mi></msub><msub><mi>x</mi><mi>m</mi></msub><mo>+</mo><msubsup><mi>y</mi><mi>n</mi><mn>2</mn></msubsup><mo>+</mo><msubsup><mi>y</mi><mi>m</mi><mn>2</mn></msubsup><mo>−</mo><mn>2</mn><msub><mi>y</mi><mi>n</mi></msub><msub><mi>y</mi><mi>m</mi></msub><mo>+</mo><mspace linebreak="newline"></mspace><msubsup><mi>z</mi><mi>n</mi><mn>2</mn></msubsup><mo>+</mo><msubsup><mi>z</mi><mi>m</mi><mn>2</mn></msubsup><mo>−</mo><mn>2</mn><msub><mi>z</mi><mi>n</mi></msub><msub><mi>z</mi><mi>m</mi></msub><mspace linebreak="newline"></mspace><mo>=</mo><mi>s</mi><mi>r</mi><msup><mi>c</mi><mn>2</mn></msup><mo>+</mo><mi>d</mi><mi>s</mi><msup><mi>t</mi><mn>2</mn></msup><mo>−</mo><mo stretchy="false">(</mo><mi>s</mi><mi>r</mi><msup><mi>c</mi><mi>T</mi></msup><mo>∗</mo><mi>d</mi><mi>s</mi><mi>t</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">dis=(x_n-x_m)^2+(y_n-y_m)^2+(z_n-z_m)^2
\\=x_n^2+x_m^2-2x_nx_m+y_n^2+y_m^2-2y_ny_m+\\
z_n^2+z_m^2-2z_nz_m
\\
=src^2+dst^2-(src^T*dst)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">d</span><span class="mord mathnormal">i</span><span class="mord mathnormal">s</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1141em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1141em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.044em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1141em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.044em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.3669em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1111em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1111em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7944em;vertical-align:-0.15em;"></span><span class="mord">2</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1111em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-2.453em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1111em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-2.453em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8389em;vertical-align:-0.1944em;"></span><span class="mord">2</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:1.1111em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-2.453em;margin-left:-0.044em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1111em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-2.453em;margin-left:-0.044em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7944em;vertical-align:-0.15em;"></span><span class="mord">2</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.044em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.044em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.3669em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.9474em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">sr</span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.9474em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">d</span><span class="mord mathnormal">s</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1413em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">sr</span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">d</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mclose">)</span></span></span></span></span></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">square_distance</span>(<span class="params">src,dst</span>):</span><br><span class="line">    <span class="comment"># 计算各点间的距离</span></span><br><span class="line">    B,N,_=src.shape</span><br><span class="line">    _,M,_=dst.shape</span><br><span class="line">    <span class="comment"># shape: [B,N,M]</span></span><br><span class="line">    dist=-<span class="number">2</span>*torch.matmul(src,dst.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>))</span><br><span class="line">    <span class="comment"># shape: [B,N,M]+[B,N,1]</span></span><br><span class="line">    dist+=torch.<span class="built_in">sum</span>(src**<span class="number">2</span>,-<span class="number">1</span>).view(B,N,<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># shape: [B,N,M]+[B,1,M]</span></span><br><span class="line">    dist+=torch.<span class="built_in">sum</span>(dst**<span class="number">2</span>,-<span class="number">1</span>).view(B,<span class="number">1</span>,M)</span><br><span class="line">    <span class="keyword">return</span> dist</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>在计算中，需要先构建一个索引组。根据计算得到的距离张量，将超过搜索半径的距离点索引设置为<strong>最大值</strong>。这样，我们就得到了<strong>实际</strong>落在圆内的点。</p>
<p>接着再做升序排序，选取我们需要的<code>nsample</code>个点。当然，会出现点数不足的情况，所以我们复制最近的点，取最大值的位置做掩膜<code>mask=group_idx==N</code>，将掩膜位置修正为第一个点。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">query_ball_point</span>(<span class="params">radius,nsample,xyz,new_xyz</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Input:</span></span><br><span class="line"><span class="string">        radius: local region radius</span></span><br><span class="line"><span class="string">        nsample: max sample number in local region</span></span><br><span class="line"><span class="string">        xyz: all points, [B, N, 3]</span></span><br><span class="line"><span class="string">        new_xyz: query points, [B, S, 3]</span></span><br><span class="line"><span class="string">    Return:</span></span><br><span class="line"><span class="string">        group_idx: grouped points index, [B, S, nsample]</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    device=xyz.device</span><br><span class="line">    B,N,C=xyz.shape</span><br><span class="line">    _,S,_=new_xyz.shape</span><br><span class="line">    group_idx=torch.<span class="built_in">range</span>(N,dtype=torch.long).to(device).view(<span class="number">1</span>,<span class="number">1</span>,N).repeat([B,S,<span class="number">1</span>])</span><br><span class="line">    <span class="comment"># 得到一组[ B , S , N ] 的数据，即new_xyz与xyz中每个点的距离</span></span><br><span class="line">    sqrdists=square_distance(new_xyz,xyz)</span><br><span class="line">    <span class="comment"># (x1-x2)**2+(y1-y2)**2+(z1-z2)**2&gt;r**2</span></span><br><span class="line">    <span class="comment"># 这部分点已经超过了搜索半径了，所以令其索引等于最大值N(之前有效的最大值是N-1)</span></span><br><span class="line">    group_idx[sqrdists&gt;radius**<span class="number">2</span>]=N</span><br><span class="line">    <span class="comment"># tensor.sort会返回一个value和一个index</span></span><br><span class="line">    <span class="comment"># 做了个升序排序，nsample就是我们需要的簇间点</span></span><br><span class="line">    group_idx=group_idx.sort(dim=-<span class="number">1</span>)[<span class="number">0</span>][...,:nsample]</span><br><span class="line">    <span class="comment"># 针对半径点不足的情况，使用第一个点进行替代</span></span><br><span class="line">    <span class="comment"># shape: [B,S,nsample]</span></span><br><span class="line">    group_first=group_idx[...,<span class="number">0</span>].view(B,S,<span class="number">1</span>).repeat([<span class="number">1</span>,<span class="number">1</span>,nsample])</span><br><span class="line">    mask=group_idx==N</span><br><span class="line">    group_idx=group_first[mask]</span><br><span class="line">    <span class="comment"># [B,S,nsample]</span></span><br><span class="line">    <span class="keyword">return</span> group_idx</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="四、采样打组">四、采样打组</h2>
<p>在原文中，二和三被定义为Sampling layer和Grouping layer，张量维度的变换如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># input</span></span><br><span class="line">shape: [B,N,d+C]</span><br><span class="line">-----&gt;</span><br><span class="line"><span class="comment"># sampling layer</span></span><br><span class="line">shape: [B,S,d+C]</span><br><span class="line">-----&gt;</span><br><span class="line"><span class="comment"># grouping layer</span></span><br><span class="line">shape: [B,S,K,d+C]</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">B: batch</span></span><br><span class="line"><span class="string">N: 点云总数</span></span><br><span class="line"><span class="string">S: 采样簇数量</span></span><br><span class="line"><span class="string">K: 簇中点云数量</span></span><br><span class="line"><span class="string">d: 位置信息xyz</span></span><br><span class="line"><span class="string">C: 特征</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>在此之前，需要定义一个函数，用于从索引中获取点。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">index_points</span>(<span class="params">points,idx</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Input:</span></span><br><span class="line"><span class="string">        points: input points data, [B, N, C]</span></span><br><span class="line"><span class="string">        idx: sample index data, [B, S]</span></span><br><span class="line"><span class="string">    Return:</span></span><br><span class="line"><span class="string">        new_points:, indexed points data, [B, S, C]</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    device = points.device</span><br><span class="line">    B = points.shape[<span class="number">0</span>]</span><br><span class="line">    view_shape = <span class="built_in">list</span>(idx.shape)</span><br><span class="line">    <span class="comment"># [ B , 1 ]</span></span><br><span class="line">    view_shape[<span class="number">1</span>:] = [<span class="number">1</span>] * (<span class="built_in">len</span>(view_shape) - <span class="number">1</span>)</span><br><span class="line">    repeat_shape = <span class="built_in">list</span>(idx.shape)</span><br><span class="line">    <span class="comment"># [ 1 , S ]</span></span><br><span class="line">    repeat_shape[<span class="number">0</span>] = <span class="number">1</span></span><br><span class="line">    <span class="comment"># [ B , S ]</span></span><br><span class="line">    batch_indices = torch.arange(B, dtype=torch.long).to(device).view(view_shape).repeat(repeat_shape)</span><br><span class="line">    <span class="comment"># row: batch_indices</span></span><br><span class="line">    <span class="comment"># col: idx</span></span><br><span class="line">    new_points = points[batch_indices, idx, :]</span><br><span class="line">    <span class="keyword">return</span> new_points</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>其中有一点需要注意的是，关于tensor索引为一个矩阵的情况。</p>
<p>例如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># row</span></span><br><span class="line">b=[[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]]</span><br><span class="line"><span class="comment"># col</span></span><br><span class="line">i=[[<span class="number">4</span>,<span class="number">3</span>],[<span class="number">2</span>,<span class="number">1</span>]]</span><br><span class="line"></span><br><span class="line"><span class="comment"># poi</span></span><br><span class="line">points=torch.arange(<span class="number">25</span>).view(<span class="number">5</span>,<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">points:</span></span><br><span class="line"><span class="string">tensor([[ 0,  1,  2,  3,  4],</span></span><br><span class="line"><span class="string">        [ 5,  6,  7,  8,  9],</span></span><br><span class="line"><span class="string">        [10, 11, 12, 13, 14],</span></span><br><span class="line"><span class="string">        [15, 16, 17, 18, 19],</span></span><br><span class="line"><span class="string">        [20, 21, 22, 23, 24]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">points[b,i]</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[ 9, 13],</span></span><br><span class="line"><span class="string">        [17, 21]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>这种情况下，是对b和i做组合，也就是说，实际取得的点对为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[[points[<span class="number">1</span>,<span class="number">4</span>], <span class="comment"># 9</span></span><br><span class="line">points[<span class="number">2</span>,<span class="number">3</span>]] <span class="comment"># 13</span></span><br><span class="line">[points[<span class="number">3</span>,<span class="number">2</span>], <span class="comment"># 17</span></span><br><span class="line">points[<span class="number">4</span>,<span class="number">1</span>]]] <span class="comment"># 21</span></span><br></pre></td></tr></table></figure>
<p>实现的算法为：</p>
<p><strong>输入</strong>:</p>
<ul>
<li>npoint: 簇中心数量</li>
<li>radius: 搜索半径</li>
<li>nsample: 簇内点数量</li>
<li>xyz: 位置信息</li>
<li>points: 全局点，主要是有其他维度时使用</li>
<li>returnfps: 是否返回最近点信息</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">sample_and_group</span>(<span class="params">npoint, radius, nsample, xyz, points, returnfps=<span class="literal">False</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Input:</span></span><br><span class="line"><span class="string">        npoint: the number of points</span></span><br><span class="line"><span class="string">        radius: search radius</span></span><br><span class="line"><span class="string">        nsample: the number of points which in cluster</span></span><br><span class="line"><span class="string">        xyz: input points position data, [B, N, 3]</span></span><br><span class="line"><span class="string">        points: input points data, [B, N, D]</span></span><br><span class="line"><span class="string">    Return:</span></span><br><span class="line"><span class="string">        new_xyz: sampled points position data, [B, npoint, nsample, 3]</span></span><br><span class="line"><span class="string">        new_points: sampled points data, [B, npoint, nsample, 3+D]</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    B,N,C=xyz.shape</span><br><span class="line">    S=npoint</span><br><span class="line">   </span><br><span class="line">    <span class="comment"># sampling layer</span></span><br><span class="line">    <span class="comment"># 数据的形状为: [ B , npoint , C ]</span></span><br><span class="line">    fps_idx=farthest_point_sample(xyz,npoint)</span><br><span class="line">    torch.cuda.empty_cache() <span class="comment"># 清空显存</span></span><br><span class="line">    <span class="comment"># 获取当前点对</span></span><br><span class="line">    new_xyz=index_points(xyz,fps_idx)</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># groupling layer</span></span><br><span class="line">    <span class="comment"># [ B , npoint , nsample ]</span></span><br><span class="line">    idx=query_ball_point(radius,nsample,xyz,new_xyz)</span><br><span class="line">    torch.cuda.empty_cache() <span class="comment"># 清空显存</span></span><br><span class="line">    <span class="comment"># [ B , npoint , nsample , C]</span></span><br><span class="line">    grouped_xyz=index_points(xyz,idx)</span><br><span class="line">    torch.cuda.empty_cache() <span class="comment"># 清空显存</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 中心化</span></span><br><span class="line">    <span class="comment"># 主要是减去中心点的坐标</span></span><br><span class="line">    grouped_xyz_norm=grouped_xyz-new_xyz.view(B,S,<span class="number">1</span>,C)</span><br><span class="line">    torch.cuda.empty_cache() <span class="comment"># 清空显存</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 其他维度特征融合</span></span><br><span class="line">    <span class="keyword">if</span> points <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        grouped_points=index_points(points,idx)</span><br><span class="line">        new_points=torch.cat([grouped_xyz_norm,grouped_points],dim=-<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        new_points=grouped_xyz_norm</span><br><span class="line">    <span class="keyword">if</span> returnfps:</span><br><span class="line">        <span class="keyword">return</span> new_xyz,new_points,grouped_xyz,fps_idx</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> new_xyz,new_points</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="五、局部特征提取">五、局部特征提取</h2>
<p>PointNet++的局部特征提取与PointNet相同，都是通过一个<code>max pool</code>来实现的。与CNN不同，CNN是在做卷积加权求和，而PointNet++则是通过最大池化来完成。在网络中，作者使用了<code>sampling layer</code>+<code>grouping layer</code>+<code>pointnet</code>来完成整个流程。并将该过程称作<code>set abstraction</code>。SA采样能得到一个融合了局部特征的全局特征。</p>
<img src="/2022/08/01/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91PointNet-%E7%BD%91%E7%BB%9C/image-20220401132016315.png" alt="image-20220401132016315" style="zoom:50%;">
<p><strong>输入</strong>：</p>
<ul>
<li>xyz: <code>N</code>个点的位置
<ul>
<li>类似于CNN的卷积，多次SA操作后输入的<code>N</code>会变成<code>npoint</code></li>
</ul>
</li>
<li>points: 全部的数据</li>
</ul>
<p><strong>输出</strong>：</p>
<ul>
<li>new_xyz: 对原始数据进行采样后，融合了局部特征的新的xyz。shape: [B , C , npoint]</li>
<li>new_points: shape: [B , C+N , npoint]</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PointNetSetAbstraction</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,npoint,radius,nsample,in_channel,mlp,group_all</span>):</span><br><span class="line">        <span class="built_in">super</span>(PointNetSetAbstraction, self).__init__()</span><br><span class="line">        self.npoint=npoint</span><br><span class="line">        self.radius=radius</span><br><span class="line">        self.nsample=nsample</span><br><span class="line">        self.mlp_convs=nn.ModuleList()</span><br><span class="line">        self.mlp_bns=nn.ModuleList()</span><br><span class="line">        last_channel=in_channel</span><br><span class="line">        <span class="keyword">for</span> out_channel <span class="keyword">in</span> mlp:</span><br><span class="line"></span><br><span class="line">            self.mlp_convs.append(nn.Conv2d(last_channel,out_channel,<span class="number">1</span>))</span><br><span class="line">            self.mlp_bns.append(nn.BatchNorm2d(out_channel))</span><br><span class="line">            last_channel=out_channel</span><br><span class="line">        self.group_all=group_all</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,xyz,points</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">              Input:</span></span><br><span class="line"><span class="string">                  xyz: input points position data, [B, C, N]</span></span><br><span class="line"><span class="string">                  points: input points data, [B, D, N]</span></span><br><span class="line"><span class="string">              Return:</span></span><br><span class="line"><span class="string">                  new_xyz: sampled points position data, [B, C, S]</span></span><br><span class="line"><span class="string">                  new_points_concat: sample points feature data, [B, D&#x27;, S]</span></span><br><span class="line"><span class="string">              &quot;&quot;&quot;</span></span><br><span class="line">        xyz = xyz.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> points <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            points = points.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">            </span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.group_all:</span><br><span class="line">            new_xyz,new_points=sample_and_group_all(xyz,points)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">		 new_xyz,new_points=sample_and_group(self.npoint,self.radius,self.nsample,xyz,points)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># new_xyz: 带有位置的采样点数据，形状为： [ B , npoint ,C ]</span></span><br><span class="line">        <span class="comment"># new_points: 采样点数据(聚类后的) [ B , npoint, nsample ,C+D ]</span></span><br><span class="line">        new_points=new_points.permute(<span class="number">0</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">1</span>) <span class="comment"># [ B , C+D , nsample , npoint ]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 这步是一个PointNet</span></span><br><span class="line">        <span class="keyword">for</span> i,conv <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.mlp_convs):</span><br><span class="line">            bn=self.mlp_bns[i]</span><br><span class="line">            new_points=F.relu(bn(conv(new_points)))</span><br><span class="line">        </span><br><span class="line">        new_points=torch.<span class="built_in">max</span>(new_points,<span class="number">2</span>)[<span class="number">0</span>] <span class="comment"># [ B , C+D , npoint]</span></span><br><span class="line">       </span><br><span class="line">        new_xyz=new_xyz.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> new_xyz,new_points</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="六、点云不均匀区域融合">六、点云不均匀区域融合</h2>
<p>作者在原文中提到：</p>
<p><strong>Features learned in dense data</strong> <strong>may not generalize to sparsely sampled regions</strong>.</p>
<p>密集区特征与稀疏区特征可能会出现不适配，这是因为采样时在稀疏区域采用了最近点补全的方法，且受于尺度的影像，在稀疏区的点往往分布的很开，密集区则相对集中，这也会对结果造成较大的影像。</p>
<p>作者提出了两种特征融合的方法，分别是<code>Multi-scale grouping</code>(MSG 多尺度组合)，<code>Multiresolution grouping</code>(MRG 多分辨率组合)。</p>
<img src="/2022/08/01/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91PointNet-%E7%BD%91%E7%BB%9C/image-20220401131928359.png" alt="image-20220401131928359" style="zoom:50%;">
<p>关于尺度和分辨率，尺度就是观测事物的一种度量，例如看到一辆车，观察车窗和观察车身就是不同的尺度。在图像上的表现为感受野的不同，或者说不同尺寸的卷积核卷积后的尺度不同。而分辨率则是观察汽车，戴眼镜看和不戴眼镜看，都是汽车，但是有模糊和清楚之分。在图像上类似于同一层做池化。</p>
<p>对于多尺度组合MSG而言，就是选取不同半径的子区域(在图像上就是选择不同大小的卷积核)进行特征提取后堆叠。</p>
<p>其代码如下：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PointNetSetAbstractionMsg</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,npoint,radius_list,nasmple_list,in_channel,mlp_list</span>):</span><br><span class="line">        <span class="built_in">super</span>(PointNetSetAbstractionMsg, self).__init__()</span><br><span class="line">        self.npoint=npoint</span><br><span class="line">        self.radius_list=radius_list</span><br><span class="line">        self.nsample_list=nasmple_list</span><br><span class="line">        self.conv_block=nn.ModuleList()</span><br><span class="line">        self.bn_block=nn.ModuleList()</span><br><span class="line">        <span class="keyword">for</span> idx,mlp <span class="keyword">in</span> mlp_list:</span><br><span class="line">            convs=nn.ModuleList()</span><br><span class="line">            bns=nn.ModuleList()</span><br><span class="line">            last_channel=in_channel+<span class="number">3</span></span><br><span class="line">            <span class="keyword">for</span> output <span class="keyword">in</span> mlp:</span><br><span class="line">                convs.append(nn.Conv2d(last_channel,output,<span class="number">1</span>))</span><br><span class="line">                bns.append(nn.BatchNorm2d(output))</span><br><span class="line">                last_channel=output</span><br><span class="line">            self.conv_block.append(convs)</span><br><span class="line">            self.bn_block.append(bns)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,xyz,points</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        Input:</span></span><br><span class="line"><span class="string">            xyz: input points position data, [B, C, N]</span></span><br><span class="line"><span class="string">            points: input points data, [B, D, N]</span></span><br><span class="line"><span class="string">        Return:</span></span><br><span class="line"><span class="string">            new_xyz: sampled points position data, [B, C, S]</span></span><br><span class="line"><span class="string">            new_points_concat: sample points feature data, [B, D&#x27;, S]</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># xyz是坐标点位置特征</span></span><br><span class="line">        xyz=xyz.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>) <span class="comment"># [B,N,C]</span></span><br><span class="line">        <span class="keyword">if</span> points <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># 提取到的额外特征</span></span><br><span class="line">            points=points.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>) <span class="comment"># [B,N,D]</span></span><br><span class="line"></span><br><span class="line">        B,N,C=xyz.shape</span><br><span class="line">        S=self.npoint</span><br><span class="line">        <span class="comment"># 采样后的坐标点</span></span><br><span class="line">        new_xyz=index_points(xyz,farthest_point_sample(xyz,S))</span><br><span class="line"></span><br><span class="line">        new_points_list=[]</span><br><span class="line">        <span class="comment"># 多尺度特征提取</span></span><br><span class="line">        <span class="keyword">for</span> i,radius <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.radius_list):</span><br><span class="line">            k=self.nsample_list[i]</span><br><span class="line">            group_idx=query_ball_point(radius,k,xyz,new_xyz)</span><br><span class="line">            group_xyz=index_points(xyz,group_idx)</span><br><span class="line">            <span class="comment"># 中心化</span></span><br><span class="line">            group_xyz-=new_xyz.view(B,S,<span class="number">1</span>,C)</span><br><span class="line">            <span class="keyword">if</span> points <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                group_points=index_points(points,group_idx)</span><br><span class="line">                group_points=torch.cat([group_points,group_xyz],dim=-<span class="number">1</span>)</span><br><span class="line">                </span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                group_points=group_xyz</span><br><span class="line"></span><br><span class="line">            group_points=group_points.permute(<span class="number">0</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">1</span>) <span class="comment"># [B,D,K,S]</span></span><br><span class="line">           </span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(self.conv_block[i])):</span><br><span class="line">                conv=self.conv_block[i][j]</span><br><span class="line">                bn=self.bn_block[i][j]</span><br><span class="line">                group_points=F.relu(bn(conv(group_points)))</span><br><span class="line">           </span><br><span class="line">            <span class="comment"># [B,D&#x27;,S]</span></span><br><span class="line">            new_points=torch.<span class="built_in">max</span>(group_points,<span class="number">2</span>)[<span class="number">0</span>]</span><br><span class="line">            </span><br><span class="line">            new_points_list.append(new_points)</span><br><span class="line"></span><br><span class="line">        new_xyz=new_xyz.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 多尺度特征融合</span></span><br><span class="line">        new_points_concat=torch.cat(new_points_list,dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> new_xyz,new_points_concat</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="七、点云上采样">七、点云上采样</h2>
<p>在连续的SA层中，不断对原始点进行下采样而获得数量更少的特征点，但若是做分割任务，则需要把点云中的所有点都带上语义标签。若是用之前分类的思想，也就是对所有点做圆进行局部特征提取，实在是太耗费时间了。于是作者提出了基于上采样的方式，将已提取特征的点传递给其他点、</p>
<p>在本部分，作者提出一种基于反距离权重差值的特征传播算法。</p>
<p>其核心思想在于：</p>
<ul>
<li>
<p><strong>反距离插值</strong>，对每个点的<code>k</code>个临近点按照IDW进行差值。公式如下：</p>
<ul>
<li>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msup><mi>f</mi><mrow><mo stretchy="false">(</mo><mi>j</mi><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><msub><mi>w</mi><mi>i</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><msubsup><mi>f</mi><mi>i</mi><mrow><mo stretchy="false">(</mo><mi>j</mi><mo stretchy="false">)</mo></mrow></msubsup></mrow><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><msub><mi>w</mi><mi>i</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">f^{(j)}(x)=\frac{\sum_{i=1}^k w_i(x)f_i^{(j)}}{\sum_{i=1}^kw_i(x)}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.188em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.9132em;vertical-align:-1.1787em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.7345em;"><span style="top:-2.1658em;"><span class="pstrut" style="height:3.0448em;"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.989em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span><span style="top:-3.2748em;"><span class="pstrut" style="height:3.0448em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.7345em;"><span class="pstrut" style="height:3.0448em;"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.989em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em;"><span style="top:-2.4231em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.2198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2769em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.1787em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<ul>
<li>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>w</mi><mi>i</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mi>d</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><msub><mi>x</mi><mi>i</mi></msub><msup><mo stretchy="false">)</mo><mi>p</mi></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">w_i(x)=\frac {1}{d(x,x_i)^p}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.2574em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.5904em;"><span style="top:-2.989em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>将插值得到的特征与SA阶段得到的特征通过skip-link连接后进行特征堆叠。</p>
</li>
<li>
<p>特征堆叠后输入到<code>unit pointnet</code>中进一步提取</p>
</li>
</ul>
<p><strong>输入</strong>：</p>
<ul>
<li>xyz1: 所有点对坐标</li>
<li>xyz2: 降采样后的点坐标</li>
<li>points1: SA层的点</li>
<li>points2: 降采样后的点</li>
</ul>
<p><strong>输出</strong>：</p>
<ul>
<li>skip-link后的特征点</li>
</ul>
<img src="/2022/08/01/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91PointNet-%E7%BD%91%E7%BB%9C/image-20220401132057972.png" alt="image-20220401132057972" style="zoom:50%;">
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PointNetFeaturePropagation</span>(nn.Module):</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channel, mlp</span>):</span><br><span class="line">        <span class="built_in">super</span>(PointNetFeaturePropagation, self).__init__()</span><br><span class="line">        self.mlp_convs = nn.ModuleList()</span><br><span class="line">        self.mlp_bns = nn.ModuleList()</span><br><span class="line">        last_channel = in_channel</span><br><span class="line">        <span class="keyword">for</span> out_channel <span class="keyword">in</span> mlp:</span><br><span class="line">            self.mlp_convs.append(nn.Conv1d(last_channel, out_channel, <span class="number">1</span>))</span><br><span class="line">            self.mlp_bns.append(nn.BatchNorm1d(out_channel))</span><br><span class="line">            last_channel = out_channel</span><br><span class="line">            </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,xyz1,xyz2,points1,points2</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Input:</span></span><br><span class="line"><span class="string">            xyz1: input points position data, [B, C, N]</span></span><br><span class="line"><span class="string">            xyz2: sampled input points position data, [B, C, S]</span></span><br><span class="line"><span class="string">            points1: input points data, [B, D, N]</span></span><br><span class="line"><span class="string">            points2: input points data, [B, D, S]</span></span><br><span class="line"><span class="string">        Return:</span></span><br><span class="line"><span class="string">            new_points: upsampled points data, [B, D&#x27;, N]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        xyz1,xyz2=xyz1.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>),xyz2.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">        points2=points2.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        B,N,C=xyz1.shape</span><br><span class="line">        _,S,_=xyz2.shape</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> S==<span class="number">1</span>:</span><br><span class="line">            <span class="comment"># 此时仅有一个采样点</span></span><br><span class="line">            interpolated_points=points2.repeat(<span class="number">1</span>,N,<span class="number">1</span>)</span><br><span class="line">            <span class="comment"># 上采样，把当前点的特征copy N 次</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            dists=square_distance(xyz1,xyz2)</span><br><span class="line">            <span class="comment"># 距离张量</span></span><br><span class="line">            <span class="built_in">print</span>(dists.shape)</span><br><span class="line">            dists,idx=dists.sort(dim=-<span class="number">1</span>)</span><br><span class="line">            dists,idx=dists[...,:<span class="number">3</span>],idx[...,:<span class="number">3</span>]</span><br><span class="line">            <span class="comment"># 反距离权重法</span></span><br><span class="line">            dist_recip=<span class="number">1.0</span>/(dists+<span class="number">1e-8</span>)</span><br><span class="line">            <span class="comment"># 为了让权重归一</span></span><br><span class="line">            norm=torch.<span class="built_in">sum</span>(dist_recip,dim=<span class="number">2</span>,keepdim=<span class="literal">True</span>)</span><br><span class="line">            weight=dist_recip/norm</span><br><span class="line">            interpolated_points=torch.<span class="built_in">sum</span>(index_points(points2,idx)* weight.view(B, N, <span class="number">3</span>, <span class="number">1</span>), dim=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> points1 <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            points1=points1.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">            <span class="comment"># 跟原先位置的点做skip-link</span></span><br><span class="line">            new_points=torch.cat([points1,interpolated_points],dim=-<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            new_points=interpolated_points</span><br><span class="line">        new_points=new_points.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># unit pointnet 部分</span></span><br><span class="line">        <span class="keyword">for</span> i,conv <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.mlp_convs):</span><br><span class="line">            bn=self.mlp_bns[i]</span><br><span class="line">            new_points=F.relu(bn(conv(new_points)))</span><br><span class="line">        <span class="keyword">return</span> new_points</span><br></pre></td></tr></table></figure>
<p>整个分类任务如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">get_model</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,num_class,normal_channel=<span class="literal">True</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(get_model, self).__init__()</span><br><span class="line">        in_channel=<span class="number">3</span> <span class="keyword">if</span> normal_channel <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">        self.normal_channel=normal_channel</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># SA层</span></span><br><span class="line">        self.sa1 = PointNetSetAbstractionMsg(<span class="number">512</span>, [<span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.4</span>], [<span class="number">16</span>, <span class="number">32</span>, <span class="number">128</span>], in_channel,[[<span class="number">32</span>, <span class="number">32</span>, <span class="number">64</span>], [<span class="number">64</span>, <span class="number">64</span>, <span class="number">128</span>], [<span class="number">64</span>, <span class="number">96</span>, <span class="number">128</span>]])</span><br><span class="line">        self.sa2 = PointNetSetAbstractionMsg(<span class="number">128</span>, [<span class="number">0.2</span>, <span class="number">0.4</span>, <span class="number">0.8</span>], [<span class="number">32</span>, <span class="number">64</span>, <span class="number">128</span>], <span class="number">320</span>,[[<span class="number">64</span>, <span class="number">64</span>, <span class="number">128</span>], [<span class="number">128</span>, <span class="number">128</span>, <span class="number">256</span>], [<span class="number">128</span>, <span class="number">128</span>, <span class="number">256</span>]])</span><br><span class="line">        self.sa3 = PointNetSetAbstraction(<span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="number">640</span> + <span class="number">3</span>, [<span class="number">256</span>, <span class="number">512</span>, <span class="number">1024</span>], <span class="literal">True</span>)</span><br><span class="line">		<span class="comment"># SA返回来的是全局特征</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 最后的判别层</span></span><br><span class="line">        self.fc1=nn.Linear(<span class="number">1024</span>,<span class="number">512</span>)</span><br><span class="line">        self.bn1=nn.BatchNorm1d(<span class="number">512</span>)</span><br><span class="line">        self.drop1=nn.Dropout(<span class="number">0.4</span>)</span><br><span class="line">        self.fc2=nn.Linear(<span class="number">512</span>,<span class="number">256</span>)</span><br><span class="line">        self.bn2=nn.BatchNorm1d(<span class="number">256</span>)</span><br><span class="line">        self.drop2=nn.Dropout(<span class="number">0.5</span>)</span><br><span class="line">        self.fc3=nn.Linear(<span class="number">256</span>,num_class)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,xyz</span>):</span><br><span class="line">        B,_,_=xyz.shape</span><br><span class="line">        <span class="keyword">if</span> self.normal_channel:</span><br><span class="line">            norm=xyz[:,<span class="number">3</span>:,:] <span class="comment"># 这个是特征</span></span><br><span class="line">            xyz=xyz[:,:<span class="number">3</span>,:] <span class="comment"># 这个是位置</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            norm=<span class="literal">None</span></span><br><span class="line"></span><br><span class="line">        l1_xyz,l1_points=self.sa1(xyz,norm) <span class="comment"># return [B,C+D,npoint]</span></span><br><span class="line">        l2_xyz, l2_points = self.sa2(l1_xyz, l1_points)</span><br><span class="line">        l3_xyz, l3_points = self.sa3(l2_xyz, l2_points)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 线性展平</span></span><br><span class="line">        x=l3_points.view(B,<span class="number">1024</span>)</span><br><span class="line">        <span class="comment"># 预测类别</span></span><br><span class="line">        x = self.drop1(F.relu(self.bn1(self.fc1(x))))</span><br><span class="line">        x = self.drop2(F.relu(self.bn2(self.fc2(x))))</span><br><span class="line">        x = self.fc3(x)</span><br><span class="line">        x=F.log_softmax(x,-<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> x,l3_points</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">get_loss</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(get_loss, self).__init__()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,pred,target,trans_feat=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="keyword">if</span> trans_feat:</span><br><span class="line">            total_loss=trans_feat(pred,target)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            total_loss=F.nll_loss(pred,target)</span><br><span class="line">        <span class="keyword">return</span> total_loss</span><br></pre></td></tr></table></figure>
<p>而分割任务则是使用了特征传递层的特征融合，代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">get_model</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_classes, normal_channel=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(get_model, self).__init__()</span><br><span class="line">        <span class="keyword">if</span> normal_channel:</span><br><span class="line">            additional_channel = <span class="number">3</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            additional_channel = <span class="number">0</span></span><br><span class="line">        self.normal_channel = normal_channel</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># SA层</span></span><br><span class="line">        self.sa1 = PointNetSetAbstractionMsg(<span class="number">512</span>, [<span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.4</span>], [<span class="number">32</span>, <span class="number">64</span>, <span class="number">128</span>], <span class="number">3</span>+additional_channel, [[<span class="number">32</span>, <span class="number">32</span>, <span class="number">64</span>], [<span class="number">64</span>, <span class="number">64</span>, <span class="number">128</span>], [<span class="number">64</span>, <span class="number">96</span>, <span class="number">128</span>]])</span><br><span class="line">        self.sa2 = PointNetSetAbstractionMsg(<span class="number">128</span>, [<span class="number">0.4</span>,<span class="number">0.8</span>], [<span class="number">64</span>, <span class="number">128</span>], <span class="number">128</span>+<span class="number">128</span>+<span class="number">64</span>, [[<span class="number">128</span>, <span class="number">128</span>, <span class="number">256</span>], [<span class="number">128</span>, <span class="number">196</span>, <span class="number">256</span>]])</span><br><span class="line">        self.sa3 = PointNetSetAbstraction(npoint=<span class="literal">None</span>, radius=<span class="literal">None</span>, nsample=<span class="literal">None</span>, in_channel=<span class="number">512</span> + <span class="number">3</span>, mlp=[<span class="number">256</span>, <span class="number">512</span>, <span class="number">1024</span>], group_all=<span class="literal">True</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># FP层</span></span><br><span class="line">        self.fp3 = PointNetFeaturePropagation(in_channel=<span class="number">1536</span>, mlp=[<span class="number">256</span>, <span class="number">256</span>])</span><br><span class="line">        self.fp2 = PointNetFeaturePropagation(in_channel=<span class="number">576</span>, mlp=[<span class="number">256</span>, <span class="number">128</span>])</span><br><span class="line">        self.fp1 = PointNetFeaturePropagation(in_channel=<span class="number">150</span>+additional_channel, mlp=[<span class="number">128</span>, <span class="number">128</span>])</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># MLP层</span></span><br><span class="line">        self.conv1 = nn.Conv1d(<span class="number">128</span>, <span class="number">128</span>, <span class="number">1</span>)</span><br><span class="line">        self.bn1 = nn.BatchNorm1d(<span class="number">128</span>)</span><br><span class="line">        self.drop1 = nn.Dropout(<span class="number">0.5</span>)</span><br><span class="line">        self.conv2 = nn.Conv1d(<span class="number">128</span>, num_classes, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, xyz, cls_label</span>):</span><br><span class="line">        <span class="comment"># Set Abstraction layers</span></span><br><span class="line">        B,C,N = xyz.shape</span><br><span class="line">        <span class="keyword">if</span> self.normal_channel:</span><br><span class="line">            l0_points = xyz</span><br><span class="line">            l0_xyz = xyz[:,:<span class="number">3</span>,:]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            l0_points = xyz</span><br><span class="line">            l0_xyz = xyz</span><br><span class="line">        l1_xyz, l1_points = self.sa1(l0_xyz, l0_points)</span><br><span class="line">        l2_xyz, l2_points = self.sa2(l1_xyz, l1_points)</span><br><span class="line">        l3_xyz, l3_points = self.sa3(l2_xyz, l2_points)</span><br><span class="line">        <span class="comment"># Feature Propagation layers</span></span><br><span class="line">        l2_points = self.fp3(l2_xyz, l3_xyz, l2_points, l3_points)</span><br><span class="line">        l1_points = self.fp2(l1_xyz, l2_xyz, l1_points, l2_points)</span><br><span class="line">        <span class="comment"># 获取类别的one-hot编码</span></span><br><span class="line">        cls_label_one_hot = cls_label.view(B,<span class="number">16</span>,<span class="number">1</span>).repeat(<span class="number">1</span>,<span class="number">1</span>,N)</span><br><span class="line">        l0_points = self.fp1(l0_xyz, l1_xyz, torch.cat([cls_label_one_hot,l0_xyz,l0_points],<span class="number">1</span>), l1_points)</span><br><span class="line">        <span class="comment"># FC layers</span></span><br><span class="line">        feat = F.relu(self.bn1(self.conv1(l0_points)))</span><br><span class="line">        x = self.drop1(feat)</span><br><span class="line">        x = self.conv2(x)</span><br><span class="line">        x = F.log_softmax(x, dim=<span class="number">1</span>)</span><br><span class="line">        x = x.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> x, l3_points</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 不想学辣 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 神经网络 </tag>
            
            <tag> 点云 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Open3D点云处理]]></title>
      <url>/2022/08/01/%E3%80%90%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E3%80%91open3d%E7%82%B9%E4%BA%91%E5%A4%84%E7%90%86/</url>
      <content type="html"><![CDATA[<h1>Open3D点云处理</h1>
<hr>
<h2 id="一、Open3D">一、Open3D</h2>
<p><em>Open3D is an open-source library that supports rapid development of software that deals with 3D data. The Open3D frontend exposes a set of carefully selected data structures and algorithms in both C++ and Python. The backend is highly optimized and is set up for parallelization.</em></p>
<p>Open3D是一个支持3D数据处理软件快速开发的开源库，在前端提供了一组精挑细选的C++和Python数据结构与算法。并且在后端高度优化且支持并行化。</p>
<p>其<strong>核心要素</strong>包括：</p>
<ul>
<li>3D数据结构</li>
<li>3D数据处理算法</li>
<li>场景重建</li>
<li>3D可视化</li>
<li>3D机器学习等</li>
</ul>
<p><strong>Python版快速安装</strong></p>
<p>需要的环境为：</p>
<ul>
<li>OS：Ubuntu 18.04+、macOS 10.15+、Windows 10(64-bit)</li>
<li>Python: 3.6-3.9</li>
<li>Pre-packages: <code>pip</code> and <code>conda</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Install</span></span><br><span class="line">pip install open3d</span><br><span class="line"></span><br><span class="line"><span class="comment"># Verify installation</span></span><br><span class="line">python -c <span class="string">&quot;import open3d as o3d; print(o3d.__version__)&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Python API</span></span><br><span class="line">python -c <span class="string">&quot;import open3d as o3d; \</span></span><br><span class="line"><span class="string">           mesh = o3d.geometry.TriangleMesh.create_sphere(); \</span></span><br><span class="line"><span class="string">           mesh.compute_vertex_normals(); \</span></span><br><span class="line"><span class="string">           o3d.visualization.draw(mesh, raw_mode=True)&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Open3D CLI</span></span><br><span class="line">open3d example visualization/draw</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="二、Open3D点云加载与显示">二、Open3D点云加载与显示</h2>
<h3 id="2-1-点云读取">2.1 点云读取</h3>
<p>Open3D提供了直接从文件中读取点云数据的API：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">open3d.io.read_point_cloud(filename, <span class="built_in">format</span>=<span class="string">&#x27;auto&#x27;</span>, remove_nan_points=<span class="literal">False</span>, remove_infinite_points=<span class="literal">False</span>, print_progress=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<p><strong>Parameters</strong></p>
<ul>
<li><strong>filename</strong> (<em>str</em>) – 文件路径</li>
<li><strong>format</strong> (<em>str</em>,<em>optional</em>,<em>default=‘auto’</em>) – 文件的格式，默认是<code>auto</code>，将影响如何读取文件</li>
<li><strong>remove_nan_points</strong> (<em>bool</em>*,* <em>optional</em>*,* <em>default=False</em>) – 是否移除值为<code>nan</code>的点</li>
<li><strong>remove_infinite_points</strong> (<em>bool</em>*,* <em>optional</em>*,* <em>default=False</em>) – 是否移除值为<code>inf</code>的点</li>
<li><strong>print_progress</strong> (<em>bool</em>*,* <em>optional</em>*,* <em>default=False</em>) – 当该值为True时，将会在可视化时出现一个过程条</li>
</ul>
<p><strong>Return</strong></p>
<ul>
<li>open3d.geometry.PointCloud对象</li>
</ul>
<p>其中，<code>format</code>参数的可选参数为：</p>
<table>
<thead>
<tr>
<th style="text-align:center">格式</th>
<th style="text-align:center">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">xyz</td>
<td style="text-align:center">每一行包含[x,y,z]</td>
</tr>
<tr>
<td style="text-align:center">xyzn</td>
<td style="text-align:center">每一行包含[x,y,z,nx,ny,nz]</td>
</tr>
<tr>
<td style="text-align:center">xyzrgb</td>
<td style="text-align:center">每一行包括[x,y,z,r,g,b] rgb为[0,1]之间的float类型</td>
</tr>
<tr>
<td style="text-align:center">pts</td>
<td style="text-align:center">第一行表示点数，之后每行包括[x,y,z,i,r,g,b] rgb为unit8类型</td>
</tr>
<tr>
<td style="text-align:center">ply</td>
<td style="text-align:center">ply文件</td>
</tr>
<tr>
<td style="text-align:center">pcd</td>
<td style="text-align:center">pcd文件</td>
</tr>
</tbody>
</table>
<p>我们来尝试读取一下数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> open3d <span class="keyword">as</span> o3d</span><br><span class="line"></span><br><span class="line">pcd=o3d.io.read_point_cloud(<span class="string">r&quot;Cloud.pcd&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(pcd)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">PointCloud with 2001009 points.</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 此时点云数据已经被读入了</span></span><br></pre></td></tr></table></figure>
<p>当然，对于某些格式稀奇古怪的，我们也可以通过转成<code>ndarray</code>然后再进行读取：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> open3d <span class="keyword">as</span> o3d</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取到ndarray</span></span><br><span class="line">data=np.genfromtxt(<span class="string">r&#x27;modelnet40_normal_resampled\airplane\airplane_0001.txt&#x27;</span>,delimiter=<span class="string">&quot;,&quot;</span>)</span><br><span class="line"><span class="comment"># 创建PointCloud类</span></span><br><span class="line">pcd=o3d.geometry.PointCloud()</span><br><span class="line">pcd.points=o3d.utility.Vector3dVector(data[:,:<span class="number">3</span>])</span><br><span class="line"><span class="built_in">print</span>(pcd)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">PointCloud with 10000 points.</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>关于PointCloud的属性，主要有以下四类：</p>
<ul>
<li>colors: 颜色信息，在可视化时能为几何体赋予视觉信息</li>
<li>covariances: 协方差</li>
<li>normal: 法向量</li>
<li>points: 位置信息</li>
</ul>
<h3 id="2-2-点云可视化">2.2  点云可视化</h3>
<p>在Open3D中，点云可视化其中之一的API为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">draw_geometries(geometry_list, window_name=’Open3D’, width=<span class="number">1920</span>, height=<span class="number">1080</span>, left=<span class="number">50</span>, top=<span class="number">50</span>, point_show_normal=<span class="literal">False</span>, mesh_show_wireframe=<span class="literal">False</span>, mesh_show_back_face=<span class="literal">False</span>, lookat, up, front, zoom)</span><br></pre></td></tr></table></figure>
<p><strong>Parameters</strong></p>
<ul>
<li><strong>geometry_list</strong> (List[open3d.geometry.Geometry]) – 需要可视化的几何体列表.</li>
<li><strong>window_name</strong> (<em>str</em>, <em>optional</em>, <em>default=‘Open3D’</em>) – 窗口名称</li>
<li><strong>width</strong> (<em>int</em>, <em>optional</em>, <em>default=1920</em>) – 窗口宽度</li>
<li><strong>height</strong> (<em>int</em>, <em>optional</em>, <em>default=1080</em>) – 窗口高度</li>
<li><strong>left</strong> (<em>int</em>, <em>optional</em>, <em>default=50</em>) – 窗口左边界</li>
<li><strong>top</strong> (<em>int</em>, <em>optional</em>, <em>default=50</em>) – 窗口顶部边界</li>
<li><strong>point_show_normal</strong> (<em>bool</em>, <em>optional</em>, <em>default=False</em>) – 是否展示法向量</li>
<li><strong>mesh_show_wireframe</strong> (<em>bool</em>, <em>optional</em>, <em>default=False</em>) – 是否可视化网格线框</li>
<li><strong>mesh_show_back_face</strong> (<em>bool</em>, <em>optional,</em> <em>default=False</em>) – 同时可视化格网三角形背部</li>
<li>**lookat ** (<em>numpy.ndarray[float64[3,1]]</em>) – 相机注视向量</li>
<li><strong>up</strong>  (<em>numpy.ndarray[float64[3,1]]</em>) – 相机的上方向向量</li>
<li><strong>front</strong>  (<em>numpy.ndarray[float64[3,1]]</em>) – 相机的前矢量</li>
<li><strong>zoom</strong>  (<em>float</em>) – 相机缩放倍数</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>None</li>
</ul>
<p>我们来尝试一下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">o3d.visualization.draw_geometries([pcd])</span><br></pre></td></tr></table></figure>
<img src="/2022/08/01/%E3%80%90%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E3%80%91open3d%E7%82%B9%E4%BA%91%E5%A4%84%E7%90%86/image-20220418232334893.png" alt="image-20220418232334893" style="zoom:50%;">
<p>显示法向量：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pcd.normals=o3d.utility.Vector3dVector(data[:,<span class="number">3</span>:])</span><br><span class="line">o3d.visualization.draw_geometries([pcd],window_name=<span class="string">&quot;o3d&quot;</span>,width=<span class="number">1920</span>,height=<span class="number">1080</span>,</span><br><span class="line">                                  left=<span class="number">50</span>,top=<span class="number">50</span>,point_show_normal=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<img src="/2022/08/01/%E3%80%90%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E3%80%91open3d%E7%82%B9%E4%BA%91%E5%A4%84%E7%90%86/image-20220418232509254.png" alt="image-20220418232509254" style="zoom:50%;">
<p>看起来跟毛毛虫一样…</p>
<p>提供了一组用户交互指令：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">-- Mouse view control --</span><br><span class="line">  Left button + drag         : Rotate.</span><br><span class="line">  Ctrl + left button + drag  : Translate.</span><br><span class="line">  Wheel button + drag        : Translate.</span><br><span class="line">  Shift + left button + drag : Roll.</span><br><span class="line">  Wheel                      : Zoom <span class="keyword">in</span>/out.</span><br><span class="line"></span><br><span class="line">-- Keyboard view control --</span><br><span class="line">  [/]          : Increase/decrease field of view.</span><br><span class="line">  R            : Reset view point.</span><br><span class="line">  Ctrl/Cmd + C : Copy current view status into the clipboard.</span><br><span class="line">  Ctrl/Cmd + V : Paste view status <span class="keyword">from</span> clipboard.</span><br><span class="line"></span><br><span class="line">-- General control --</span><br><span class="line">  Q, Esc       : Exit window.</span><br><span class="line">  H            : Print <span class="built_in">help</span> message.</span><br><span class="line">  P, PrtScn    : Take a screen capture.</span><br><span class="line">  D            : Take a depth capture.</span><br><span class="line">  O            : Take a capture of current rendering settings.</span><br></pre></td></tr></table></figure>
<img src="/2022/08/01/%E3%80%90%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E3%80%91open3d%E7%82%B9%E4%BA%91%E5%A4%84%E7%90%86/image-20220418232806941.png" alt="image-20220418232806941" style="zoom: 33%;">
<img src="/2022/08/01/%E3%80%90%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E3%80%91open3d%E7%82%B9%E4%BA%91%E5%A4%84%E7%90%86/image-20220418232817005.png" alt="image-20220418232817005" style="zoom: 33%;">
<p>也可以指定点云的颜色：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pcd.colors=o3d.utility.Vector3dVector(data[:,<span class="number">3</span>:])</span><br></pre></td></tr></table></figure>
<img src="/2022/08/01/%E3%80%90%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E3%80%91open3d%E7%82%B9%E4%BA%91%E5%A4%84%E7%90%86/image-20220418232939457.png" alt="image-20220418232939457" style="zoom:50%;">
<p>参数<code>geometry_list</code>支持多个空间集合对象：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">read_txt</span>(<span class="params">path</span>):</span><br><span class="line">    data=np.genfromtxt(path,delimiter=<span class="string">&quot;,&quot;</span>)</span><br><span class="line">    pcd=o3d.geometry.PointCloud()</span><br><span class="line">    pcd.points = o3d.utility.Vector3dVector(data[:, :<span class="number">3</span>])</span><br><span class="line">    pcd.normals = o3d.utility.Vector3dVector(data[:, <span class="number">3</span>:])</span><br><span class="line">    pcd.colors = o3d.utility.Vector3dVector(data[:, <span class="number">3</span>:])</span><br><span class="line">    <span class="keyword">return</span> pcd</span><br><span class="line"></span><br><span class="line">path=<span class="string">r&#x27;\airplane&#x27;</span></span><br><span class="line">pcd1=read_txt(path+<span class="string">r&quot;\airplane_0001.txt&quot;</span>)</span><br><span class="line">pcd2=read_txt(path+<span class="string">r&quot;\airplane_0012.txt&quot;</span>)</span><br><span class="line">o3d.visualization.draw_geometries([pcd1,pcd2],window_name=<span class="string">&quot;o3d&quot;</span>,width=<span class="number">1920</span>,height=<span class="number">1080</span>,</span><br><span class="line">                                  left=<span class="number">50</span>,top=<span class="number">50</span>,mesh_show_back_face=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<img src="/2022/08/01/%E3%80%90%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E3%80%91open3d%E7%82%B9%E4%BA%91%E5%A4%84%E7%90%86/image-20220418233416184.png" alt="image-20220418233416184" style="zoom:33%;">
<p>o3d提供了自动计算法向量的API：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">radius=<span class="number">0.01</span> <span class="comment"># 搜索半径</span></span><br><span class="line">max_nn=<span class="number">30</span> <span class="comment"># 邻域内用于估算法线的最大点数</span></span><br><span class="line"><span class="comment"># 执行KD树搜索</span></span><br><span class="line">pcd1.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius,max_nn))</span><br><span class="line">o3d.visualization.draw_geometries([pcd1],window_name=<span class="string">&quot;o3d&quot;</span>,width=<span class="number">1920</span>,height=<span class="number">1080</span>,</span><br><span class="line">                                  left=<span class="number">50</span>,top=<span class="number">50</span>,point_show_normal=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 同样能用KD树构建协方差表</span></span><br></pre></td></tr></table></figure>
<h3 id="2-3-点云保存">2.3  点云保存</h3>
<p>API如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">open3d.io.write_point_cloud(filename, pointcloud, write_ascii=<span class="literal">False</span>, compressed=<span class="literal">False</span>, print_progress=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<p><strong>Parameters</strong></p>
<ul>
<li><strong>filename</strong> (<em>str</em>) – 文件路径</li>
<li><strong>pointcloud</strong> (<a href="http://www.open3d.org/docs/release/python_api/open3d.geometry.PointCloud.html#open3d.geometry.PointCloud"><em>open3d.geometry.PointCloud</em></a>) – 点云对象</li>
<li><strong>write_ascii</strong> (<em>bool</em>，<em>optional</em>,<em>default=False</em>) – 该参数为True时，将会写入ASCII码，否则一般写入二进制文件</li>
<li><strong>compressed</strong> (<em>bool</em>,<em>optional</em>,<em>default=False</em>) – 是否以压缩格式进行输出</li>
<li><strong>print_progress</strong> (<em>bool</em>,<em>optional</em>,<em>default=False</em>) –是否在控制台打印一个进度条</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>bool</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">o3d.io.write_point_cloud(<span class="string">&quot;02.pcd&quot;</span>,pcd2,write_ascii=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>此时可以看到已经将读取的点云写入到文件中了。</p>
<img src="/2022/08/01/%E3%80%90%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E3%80%91open3d%E7%82%B9%E4%BA%91%E5%A4%84%E7%90%86/image-20220418234823724.png" alt="image-20220418234823724" style="zoom:50%;">
<hr>
<h2 id="三、Open3D点云常见操作">三、Open3D点云常见操作</h2>
<h3 id="3-1-体素下采样">3.1  体素下采样</h3>
<p>体素下采样(Voxel downsampling)采用规则体素格网从输入点云中创建分布均匀的下采样点云，是许多点云处理任务的预处理步骤。该算法主要分为两步：</p>
<ul>
<li>创建指定大小(分辨率)的体素网络</li>
<li>当点云中至少有一个点落在某个体素内，则认为该体素被占用，体素的颜色(属性)是该体素内所有点的平均值</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Downsample the point cloud with a voxel of 0.05&quot;</span>)</span><br><span class="line">downpcd = pcd1.voxel_down_sample(voxel_size=<span class="number">0.05</span>)</span><br><span class="line">o3d.visualization.draw_geometries([downpcd])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;The number of PC is : &quot;</span>,pcd1)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;The number of downPC is : &quot;</span>,downpcd)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">Downsample the point cloud with a voxel of 0.05</span></span><br><span class="line"><span class="string">The number of PC is :  PointCloud with 10000 points.</span></span><br><span class="line"><span class="string">The number of downPC is :  PointCloud with 1389 points.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Downsample the point cloud with a voxel of 0.005</span></span><br><span class="line"><span class="string">The number of PC is :  PointCloud with 10000 points.</span></span><br><span class="line"><span class="string">The number of downPC is :  PointCloud with 9825 points.</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<img src="/2022/08/01/%E3%80%90%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E3%80%91open3d%E7%82%B9%E4%BA%91%E5%A4%84%E7%90%86/image-20220419170509887.png" alt="image-20220419170509887" style="zoom:33%;">
<img src="/2022/08/01/%E3%80%90%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E3%80%91open3d%E7%82%B9%E4%BA%91%E5%A4%84%E7%90%86/image-20220419170527120.png" alt="image-20220419170527120" style="zoom:33%;">
<h3 id="3-2-点云正态估计">3.2  点云正态估计</h3>
<p>在交互页面，可以通过<code>N</code>查看点法线，<code>+</code>,<code>-</code>控制法线长度。</p>
<p>作为点云的基本操作之一，点云正态估计通过指定算法参数估测每个点可能的法向量，<code>estimate_normals</code>查找指定搜索半径内的临近点，通过这些临近点的协方差计算其主轴，从而估计法向量。正常情况下会产生两个方向相反的法向量，在不知道几何体的全局结构下，两者都可以是正确的。Open3D会尝试调整法线的方向，使其与原始法线对齐。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Recompute the normal of the downsampled point cloud&quot;</span>)</span><br><span class="line">downpcd.estimate_normals(</span><br><span class="line">    search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=<span class="number">0.1</span>, max_nn=<span class="number">30</span>))</span><br><span class="line">o3d.visualization.draw_geometries([downpcd],</span><br><span class="line">                                  zoom=<span class="number">0.3412</span>,</span><br><span class="line">                                  front=[<span class="number">0.4257</span>, -<span class="number">0.2125</span>, -<span class="number">0.8795</span>],</span><br><span class="line">                                  lookat=[<span class="number">2.6172</span>, <span class="number">2.0475</span>, <span class="number">1.532</span>],</span><br><span class="line">                                  up=[-<span class="number">0.0694</span>, -<span class="number">0.9768</span>, <span class="number">0.2024</span>],</span><br><span class="line">                                  point_show_normal=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<img src="/2022/08/01/%E3%80%90%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E3%80%91open3d%E7%82%B9%E4%BA%91%E5%A4%84%E7%90%86/image-20220419171325646.png" alt="image-20220419171325646" style="zoom:33%;">
<p>如果想要访问顶点法线的话，可以直接通过索引获取：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Print a normal vector of the 0th point&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(downpcd.normals[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">Print a normal vector of the 0th point</span></span><br><span class="line"><span class="string">[ 0.99552379 -0.03798043  0.08654404]</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>也可以将其转为<code>numpy</code>数组:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Print the normal vectors of the first 10 points&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(np.asarray(downpcd.normals)[:<span class="number">10</span>, :])</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">Print the normal vectors of the first 10 points</span></span><br><span class="line"><span class="string">[[ 0.99552379 -0.03798043  0.08654404]</span></span><br><span class="line"><span class="string"> [-0.00180642 -0.97317626  0.23005372]</span></span><br><span class="line"><span class="string"> [-0.03311035  0.95990356 -0.27836821]</span></span><br><span class="line"><span class="string"> [-0.18007638 -0.98233851 -0.05082867]</span></span><br><span class="line"><span class="string"> [ 0.03201738 -0.92865206  0.36956763]</span></span><br><span class="line"><span class="string"> [-0.09411325  0.9584897  -0.26914715]</span></span><br><span class="line"><span class="string"> [-0.00804695  0.97716482 -0.21233029]</span></span><br><span class="line"><span class="string"> [-0.95046739 -0.20590633  0.2328397 ]</span></span><br><span class="line"><span class="string"> [ 0.58566868  0.7923609   0.17075245]</span></span><br><span class="line"><span class="string"> [-0.19273423 -0.87191173  0.45013714]]</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<h3 id="3-3-点云裁剪">3.3  点云裁剪</h3>
<p>Open3D的点云裁剪需要通过<code>read_selection_polygon_volume</code>读取多边形选择区域的json文件，接着通过<code>.crop_point_cloud()</code>方法过滤出点。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Load a polygon volume and use it to crop the original point cloud&quot;</span>)</span><br><span class="line">demo_crop_data = o3d.data.DemoCropPointCloud()</span><br><span class="line">pcd = o3d.io.read_point_cloud(demo_crop_data.point_cloud_path)</span><br><span class="line">vol = o3d.visualization.read_selection_polygon_volume(demo_crop_data.cropped_json_path)</span><br><span class="line">chair = vol.crop_point_cloud(pcd)</span><br><span class="line">o3d.visualization.draw_geometries([chair],</span><br><span class="line">                                  zoom=<span class="number">0.7</span>,</span><br><span class="line">                                  front=[<span class="number">0.5439</span>, -<span class="number">0.2333</span>, -<span class="number">0.8060</span>],</span><br><span class="line">                                  lookat=[<span class="number">2.4615</span>, <span class="number">2.1331</span>, <span class="number">1.338</span>],</span><br><span class="line">                                  up=[-<span class="number">0.1781</span>, -<span class="number">0.9708</span>, <span class="number">0.1608</span>])</span><br></pre></td></tr></table></figure>
<img src="/2022/08/01/%E3%80%90%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E3%80%91open3d%E7%82%B9%E4%BA%91%E5%A4%84%E7%90%86/image-20220419173314661.png" alt="image-20220419173314661" style="zoom:33%;">
<img src="/2022/08/01/%E3%80%90%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E3%80%91open3d%E7%82%B9%E4%BA%91%E5%A4%84%E7%90%86/image-20220419173114201.png" alt="image-20220419173114201" style="zoom:33%;">
<h3 id="3-4-绘制点云">3.4  绘制点云</h3>
<p><code>paint_uniform_color</code>可以将点云颜色绘制成同一的色彩。注意颜色是在[0,1]之间的<code>float</code>类型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Paint chair&quot;</span>)</span><br><span class="line">chair.paint_uniform_color([<span class="number">1</span>, <span class="number">0.706</span>, <span class="number">0</span>])</span><br><span class="line">o3d.visualization.draw_geometries([chair],</span><br><span class="line">                                  zoom=<span class="number">0.7</span>,</span><br><span class="line">                                  front=[<span class="number">0.5439</span>, -<span class="number">0.2333</span>, -<span class="number">0.8060</span>],</span><br><span class="line">                                  lookat=[<span class="number">2.4615</span>, <span class="number">2.1331</span>, <span class="number">1.338</span>],</span><br><span class="line">                                  up=[-<span class="number">0.1781</span>, -<span class="number">0.9708</span>, <span class="number">0.1608</span>])</span><br></pre></td></tr></table></figure>
<img src="/2022/08/01/%E3%80%90%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E3%80%91open3d%E7%82%B9%E4%BA%91%E5%A4%84%E7%90%86/image-20220419173716954.png" alt="image-20220419173716954" style="zoom:33%;">
<h3 id="3-5-选择点云">3.5  选择点云</h3>
<p>在Open3D中，可以通过点云索引来进行筛选。<code>select_by_index</code>也可以通过修改<code>invert</code>方法进行反向选取。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">inner=pcd1.select_by_index([i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(pcd1.points)) <span class="keyword">if</span> i%<span class="number">2</span>==<span class="number">0</span>])</span><br><span class="line">outer=pcd1.select_by_index([i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)],invert=<span class="literal">True</span>)</span><br><span class="line">o3d.visualization.draw_geometries([pcd1])</span><br><span class="line">o3d.visualization.draw_geometries([inner])</span><br><span class="line">o3d.visualization.draw_geometries([outer])</span><br></pre></td></tr></table></figure>
<img src="/2022/08/01/%E3%80%90%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E3%80%91open3d%E7%82%B9%E4%BA%91%E5%A4%84%E7%90%86/image-20220419194816196.png" alt="image-20220419194816196" style="zoom:33%;">
<img src="/2022/08/01/%E3%80%90%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E3%80%91open3d%E7%82%B9%E4%BA%91%E5%A4%84%E7%90%86/image-20220419194824728.png" alt="image-20220419194824728" style="zoom:33%;">
<img src="/2022/08/01/%E3%80%90%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E3%80%91open3d%E7%82%B9%E4%BA%91%E5%A4%84%E7%90%86/image-20220419194833429.png" alt="image-20220419194833429" style="zoom:33%;">
<hr>
<h2 id="四、点云数据计算">四、点云数据计算</h2>
<h3 id="4-1-点云距离">4.1  点云距离</h3>
<p>Open3D提供了<code>compute_point_cloud_distance</code>方法，能够计算源点云到目标点云的<strong>最近距离</strong>，该方法也能用于计算两点云之间的切角距离。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">demo_crop_data = o3d.data.DemoCropPointCloud()</span><br><span class="line">pcd = o3d.io.read_point_cloud(demo_crop_data.point_cloud_path)</span><br><span class="line">vol = o3d.visualization.read_selection_polygon_volume(demo_crop_data.cropped_json_path)</span><br><span class="line">chair = vol.crop_point_cloud(pcd)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 从原始图像到裁剪图像中最近点的距离</span></span><br><span class="line">dists=pcd.compute_point_cloud_distance(chair)</span><br><span class="line">dists=np.asarray(dists)</span><br><span class="line">ind=np.where(dists&gt;<span class="number">0.1</span>)[<span class="number">0</span>]</span><br><span class="line">pcd_without_chair = pcd.select_by_index(ind)</span><br><span class="line">o3d.visualization.draw_geometries([pcd_without_chair],</span><br><span class="line">                                  zoom=<span class="number">0.3412</span>,</span><br><span class="line">                                  front=[<span class="number">0.4257</span>, -<span class="number">0.2125</span>, -<span class="number">0.8795</span>],</span><br><span class="line">                                  lookat=[<span class="number">2.6172</span>, <span class="number">2.0475</span>, <span class="number">1.532</span>],</span><br><span class="line">                                  up=[-<span class="number">0.0694</span>, -<span class="number">0.9768</span>, <span class="number">0.2024</span>])</span><br></pre></td></tr></table></figure>
<img src="/2022/08/01/%E3%80%90%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E3%80%91open3d%E7%82%B9%E4%BA%91%E5%A4%84%E7%90%86/image-20220419174501565.png" alt="image-20220419174501565" style="zoom: 33%;">
<h3 id="4-2-边界体积">4.2  边界体积</h3>
<p>与其几何类型相似，<code>PointCloud</code>也具有边界体积。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">aabb = chair.get_axis_aligned_bounding_box()</span><br><span class="line">aabb.color = (<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">obb = chair.get_oriented_bounding_box()</span><br><span class="line">obb.color = (<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">o3d.visualization.draw_geometries([chair, aabb, obb],</span><br><span class="line">                                  zoom=<span class="number">0.7</span>,</span><br><span class="line">                                  front=[<span class="number">0.5439</span>, -<span class="number">0.2333</span>, -<span class="number">0.8060</span>],</span><br><span class="line">                                  lookat=[<span class="number">2.4615</span>, <span class="number">2.1331</span>, <span class="number">1.338</span>],</span><br><span class="line">                                  up=[-<span class="number">0.1781</span>, -<span class="number">0.9708</span>, <span class="number">0.1608</span>])</span><br></pre></td></tr></table></figure>
<img src="/2022/08/01/%E3%80%90%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E3%80%91open3d%E7%82%B9%E4%BA%91%E5%A4%84%E7%90%86/image-20220419174746069.png" alt="image-20220419174746069" style="zoom: 33%;">
<h3 id="4-3-凸包计算">4.3  凸包计算</h3>
<p>点云凸包是包含所有点的最小凸集，在Open3D中，可采用<code>compute_convex_hull</code>计算。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">bunny = o3d.data.BunnyMesh()</span><br><span class="line">mesh = o3d.io.read_triangle_mesh(bunny.path)</span><br><span class="line">mesh.compute_vertex_normals()</span><br><span class="line"></span><br><span class="line">pcl = mesh.sample_points_poisson_disk(number_of_points=<span class="number">2000</span>)</span><br><span class="line">hull, _ = pcl.compute_convex_hull()</span><br><span class="line">hull_ls = o3d.geometry.LineSet.create_from_triangle_mesh(hull)</span><br><span class="line">hull_ls.paint_uniform_color((<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>))</span><br><span class="line">o3d.visualization.draw_geometries([pcl, hull_ls])</span><br></pre></td></tr></table></figure>
<img src="/2022/08/01/%E3%80%90%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E3%80%91open3d%E7%82%B9%E4%BA%91%E5%A4%84%E7%90%86/image-20220419175508582.png" alt="image-20220419175508582" style="zoom: 33%;">
<h3 id="4-4-DBSCAN聚类">4.4  DBSCAN聚类</h3>
<p>DBSCAN是Ester在1996年提出的一种聚类算法，Open3D中也提供了该算法的API<code>pc.cluster_dbscan(eps,min_points,print_progress)</code>，<code>eps</code>定义了簇的半径距离，而<code>min_points</code>定义形成簇的最小点数量。返回是一个标签对象，若值为<code>-1</code>则表示噪声。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">ply_point_cloud = o3d.data.PLYPointCloud()</span><br><span class="line">pcd = o3d.io.read_point_cloud(ply_point_cloud.path)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> o3d.utility.VerbosityContextManager(</span><br><span class="line">        o3d.utility.VerbosityLevel.Debug) <span class="keyword">as</span> cm:</span><br><span class="line">    labels = np.array(</span><br><span class="line">        pcd.cluster_dbscan(eps=<span class="number">0.02</span>, min_points=<span class="number">10</span>, print_progress=<span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line">max_label = labels.<span class="built_in">max</span>()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;point cloud has <span class="subst">&#123;max_label + <span class="number">1</span>&#125;</span> clusters&quot;</span>)</span><br><span class="line">colors = plt.get_cmap(<span class="string">&quot;tab20&quot;</span>)(labels / (max_label <span class="keyword">if</span> max_label &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="number">1</span>))</span><br><span class="line">colors[labels &lt; <span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">pcd.colors = o3d.utility.Vector3dVector(colors[:, :<span class="number">3</span>])</span><br><span class="line">o3d.visualization.draw_geometries([pcd],</span><br><span class="line">                                  zoom=<span class="number">0.455</span>,</span><br><span class="line">                                  front=[-<span class="number">0.4999</span>, -<span class="number">0.1659</span>, -<span class="number">0.8499</span>],</span><br><span class="line">                                  lookat=[<span class="number">2.1813</span>, <span class="number">2.0619</span>, <span class="number">2.0999</span>],</span><br><span class="line">                                  up=[<span class="number">0.1204</span>, -<span class="number">0.9852</span>, <span class="number">0.1</span></span><br></pre></td></tr></table></figure>
<img src="/2022/08/01/%E3%80%90%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E3%80%91open3d%E7%82%B9%E4%BA%91%E5%A4%84%E7%90%86/image-20220419192728206.png" alt="image-20220419192728206" style="zoom: 33%;">
<h3 id="4-5-平面分割">4.5  平面分割</h3>
<p>Open3D支持使用<code>RANSAC</code>方法从点云中分割几何基元(geometric primitives)。通过<code>segment_plane</code>方法，可以找到点云中的最大支持平面(the plane with the largest support)。该方法提供了三个参数：</p>
<ul>
<li><code>distance_threshold</code>：定义了一个点可被视为内嵌点的估计平面的最大距离</li>
<li><code>ransac_n</code>：定义用来估计平面的随机抽样点数量</li>
<li><code>num_iterations</code>：定义了随机平面抽样和验证的频率</li>
</ul>
<img src="/2022/08/01/%E3%80%90%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E3%80%91open3d%E7%82%B9%E4%BA%91%E5%A4%84%E7%90%86/image-20220419194854087.png" alt="image-20220419194854087" style="zoom:33%;">
<h3 id="4-6-消隐点">4.6  消隐点</h3>
<p>当我们从给定视角渲染点云时，由于前方没有遮挡，可能会有背面的点渗入到前景中。Katz提出了一种消隐算法(Hidden point removal),可以从给定的视图中近似地获得点云的可见性，而无需表面重建或正常的估计。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Convert mesh to a point cloud and estimate dimensions&quot;</span>)</span><br><span class="line">armadillo = o3d.data.ArmadilloMesh()</span><br><span class="line">mesh = o3d.io.read_triangle_mesh(armadillo.path)</span><br><span class="line">mesh.compute_vertex_normals()</span><br><span class="line"></span><br><span class="line">pcd = mesh.sample_points_poisson_disk(<span class="number">5000</span>)</span><br><span class="line">diameter = np.linalg.norm(</span><br><span class="line">    np.asarray(pcd.get_max_bound()) - np.asarray(pcd.get_min_bound()))</span><br><span class="line">o3d.visualization.draw_geometries([pcd])</span><br></pre></td></tr></table></figure>
<img src="/2022/08/01/%E3%80%90%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E3%80%91open3d%E7%82%B9%E4%BA%91%E5%A4%84%E7%90%86/image-20220419195442181.png" alt="image-20220419195442181" style="zoom:33%;">
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Define parameters used for hidden_point_removal&quot;</span>)</span><br><span class="line">camera = [<span class="number">0</span>, <span class="number">0</span>, diameter]</span><br><span class="line">radius = diameter * <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Get all points that are visible from given view point&quot;</span>)</span><br><span class="line">_, pt_map = pcd.hidden_point_removal(camera, radius)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Visualize result&quot;</span>)</span><br><span class="line">pcd = pcd.select_by_index(pt_map)</span><br><span class="line">o3d.visualization.draw_geometries([pcd])</span><br></pre></td></tr></table></figure>
<img src="/2022/08/01/%E3%80%90%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E3%80%91open3d%E7%82%B9%E4%BA%91%E5%A4%84%E7%90%86/image-20220419195457783.png" alt="image-20220419195457783" style="zoom:33%;">
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 不想学辣 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 点云 </tag>
            
            <tag> Open3D </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[点云数据简介]]></title>
      <url>/2022/08/01/%E3%80%90%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E3%80%91%E7%82%B9%E4%BA%91%E6%95%B0%E6%8D%AE%E7%AE%80%E4%BB%8B/</url>
      <content type="html"><![CDATA[<h1>点云数据概述</h1>
<hr>
<h2 id="一、什么是点云">一、什么是点云</h2>
<p>点云(Point Cloud)是指目标表面特性的海量点集合<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mrow><mo stretchy="false">[</mo><mn>1</mn><mo stretchy="false">]</mo></mrow></msup></mrow><annotation encoding="application/x-tex">^{[1]}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.888em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.888em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">[</span><span class="mord mtight">1</span><span class="mclose mtight">]</span></span></span></span></span></span></span></span></span></span></span></span>，一般是通过激光测量或摄影测量获得的。能够以较高的精度反应地表的真实情况，如地面状态、地物反射特征等等。</p>
<p><strong>激光点云与摄影点云</strong></p>
<p>对于激光测量得到的点云，包括三维坐标(XYZ)和激光反射强度。这类点云通常可以通过回波特性和反射强度判别物体的状态，例如植被会有多次回波，反射强度也要弱于建筑。</p>
<p>对于摄影测量得到的点云，通常包括三维坐标(XYZ)和颜色信息。颜色信息在识别物体上有着重要的语义。</p>
<p><strong>稀疏点云与密集点云</strong></p>
<p>三维坐标测量机获得的点数量较少，点与点的间距也较大，称为稀疏点云(如全站仪获取的点云)。</p>
<p>而三维激光扫描仪或照相式扫描仪得到的点云，数量较多且较密集，称为密集点云。</p>
<p><strong>点云的格式</strong></p>
<p>事实上点云的存储就是一张属性表，常见的格式有pts,asc,dat,stl,imw,xyz,txt,csv等。</p>
<p>下图是用CloudCompare软件打开的点云数据：</p>
<img src="/2022/08/01/%E3%80%90%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E3%80%91%E7%82%B9%E4%BA%91%E6%95%B0%E6%8D%AE%E7%AE%80%E4%BB%8B/image-20220327184915038.png" alt="image-20220327184915038" style="zoom: 33%;">
<img src="/2022/08/01/%E3%80%90%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E3%80%91%E7%82%B9%E4%BA%91%E6%95%B0%E6%8D%AE%E7%AE%80%E4%BB%8B/image-20220327185328465.png" alt="image-20220327185328465" style="zoom:33%;">
<hr>
<h2 id="二、点云能做什么">二、点云能做什么</h2>
<p>基于点云数据的特性，生产活动中常常将其运用于三维实体重建、自动驾驶、地物分割、地图绘制、机器视觉、安全隐患排除等领域。</p>
<h2 id="三、点云研究领域">三、点云研究领域</h2>
<p><strong>点云分割</strong></p>
<p>一般是逐体素对点云数据进行判别，类似全卷积中的逐像素分割。点云分割又可以分为<strong>部件</strong>分割和<strong>整体</strong>分割。</p>
<img src="/2022/08/01/%E3%80%90%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E3%80%91%E7%82%B9%E4%BA%91%E6%95%B0%E6%8D%AE%E7%AE%80%E4%BB%8B/image-20220327212317160.png" alt="image-20220327212317160" style="zoom: 33%;">
<p><strong>点云补全</strong></p>
<p>点云补全类似于GAN，就是编码器和解码器的对抗过程。能够将缺失的点云部件补全。</p>
<img src="/2022/08/01/%E3%80%90%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E3%80%91%E7%82%B9%E4%BA%91%E6%95%B0%E6%8D%AE%E7%AE%80%E4%BB%8B/image-20220327213827668.png" alt="image-20220327213827668" style="zoom: 33%;">
<img src="/2022/08/01/%E3%80%90%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E3%80%91%E7%82%B9%E4%BA%91%E6%95%B0%E6%8D%AE%E7%AE%80%E4%BB%8B/image-20220327213846262.png" alt="image-20220327213846262" style="zoom: 33%;">
<p><strong>点云配准</strong></p>
<p>点云配准一般用于医学和地图学领域，将两个不同拍摄角度的点云数据进行拼接、融合。</p>
<img src="/2022/08/01/%E3%80%90%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E3%80%91%E7%82%B9%E4%BA%91%E6%95%B0%E6%8D%AE%E7%AE%80%E4%BB%8B/image-20220327214904741.png" alt="image-20220327214904741" style="zoom: 33%;">
<p><strong>点云检测</strong></p>
<p>类似于图像识别，点云检测对点云中的地物进行识别、跟踪。</p>
<img src="/2022/08/01/%E3%80%90%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E3%80%91%E7%82%B9%E4%BA%91%E6%95%B0%E6%8D%AE%E7%AE%80%E4%BB%8B/image-20220327220625693.png" alt="image-20220327220625693" style="zoom: 33%;">
<h2 id="参考文献">参考文献</h2>
<p>[1] <a href="https://baike.baidu.com/item/%E7%82%B9%E4%BA%91/10823598?fr=aladdin">https://baike.baidu.com/item/点云/10823598?fr=aladdin</a></p>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 不想学辣 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 点云 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[英语常见前缀]]></title>
      <url>/2022/08/01/%E3%80%90%E8%8B%B1%E8%AF%AD%E3%80%91%E8%8B%B1%E8%AF%AD%E5%B8%B8%E8%A7%81%E5%89%8D%E7%BC%80/</url>
      <content type="html"><![CDATA[<h2 id="常见前缀">常见前缀</h2>
<h3 id="一、外-出">一、外/出</h3>
<ul>
<li>e</li>
<li>ex</li>
<li>ef</li>
</ul>
<p><code>export 出口</code></p>
<p><strong>助记</strong></p>
<p><code>e</code>，是杨颜<code>xf</code>诶，他出去找斯卡蒂了</p>
<h3 id="二、内-进">二、内/进</h3>
<ul>
<li>in</li>
<li>im</li>
</ul>
<p><code>inject 注射</code></p>
<p><strong>助记</strong></p>
<p><code>i</code>小智，今天看到<code>nm</code>走进大木博士家了。</p>
<hr>
<h3 id="三、前">三、前</h3>
<p><strong>动态向前</strong></p>
<ul>
<li>pro</li>
</ul>
<p><code>progress 进步 promote 升值 propel 促进</code></p>
<p><strong>静态在前</strong></p>
<ul>
<li>pre</li>
</ul>
<p><code>prepare 准备 predict预测</code></p>
<p><strong>助记</strong></p>
<p>在<code>p</code>水节时，人们常常拿出<code>ro</code>泼向前方，即使前方有<code>re</code></p>
<h3 id="四、回-重新">四、回/重新</h3>
<ul>
<li>re</li>
</ul>
<p><code>return 返回 recede 衰退</code></p>
<p><strong>助记</strong></p>
<p><code>re</code>还需要记？</p>
<hr>
<h3 id="五、聚集-一起-共同">五、聚集/一起/共同</h3>
<ul>
<li>co</li>
<li>con</li>
<li>com</li>
<li>col</li>
</ul>
<p><code>collaborate 合作 cooperate 合作 combine 结合</code></p>
<p><strong>助记</strong></p>
<p><code>c</code>，<code>o</code>发现了，为啥<code>nmsl</code>唯独少了<code>s</code>，这还算个共同体吗？</p>
<h3 id="六、分散-分开">六、分散/分开</h3>
<ul>
<li>di</li>
<li>dis</li>
<li>dif</li>
</ul>
<p><code>divorce 离婚 divide 分成 distribute 分配</code></p>
<p><strong>助记</strong></p>
<p>即使你<code>di</code>一直在<code>dis</code>他，但在没<code>f</code>气之前，他们是不会分开的</p>
<hr>
<h3 id="七、上-超过">七、上/超过</h3>
<ul>
<li>super</li>
<li>over</li>
<li>sur</li>
</ul>
<p><code>surrealism 超现实主义 surpass 超过</code></p>
<p><strong>助记</strong></p>
<p><code>superman</code>飞上了天！要放激光眼了！</p>
<p><code>over</code>，收到！马上准备熟人sur~</p>
<h3 id="八、下-不足">八、下/不足</h3>
<ul>
<li>under</li>
<li>de</li>
<li>sub</li>
<li>sup</li>
</ul>
<p><code>decrease 向下</code></p>
<p><strong>助记</strong></p>
<p>额，<code>under</code>不需要，上是<code>r</code>，上面做好了后自然要做下面<code>de</code>的<code>bp</code>，</p>
<hr>
<h3 id="九、转移-转变">九、转移/转变</h3>
<ul>
<li>trans</li>
</ul>
<p><code>transfer 转变</code></p>
<h3 id="十、相互之间">十、相互之间</h3>
<ul>
<li>inter</li>
</ul>
<p><code>internet 互联网</code></p>
<hr>
<h3 id="十一、a-双写辅音字母-强调-无意义">十一、a+双写辅音字母 = 强调/无意义</h3>
<p><code>accompany 陪同 affirm 申明</code></p>
<h3 id="十二、否定前缀">十二、否定前缀</h3>
<ul>
<li>un</li>
<li>mis</li>
<li>in</li>
<li>im</li>
<li>dis</li>
<li>ab</li>
<li>il</li>
</ul>
<p><strong>助记</strong></p>
<p>物(<code>un</code>)<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mtext>理</mtext><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">理^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord cjk_fallback">理</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span>(<code>il</code>)老师总是想着进入(<code>inm</code>)AngleBaby(<code>ab</code>)的家，即使这样做会被人<code>dis</code>，但他实在是太想念了<code>mis</code></p>
<p><strong>词根助记</strong></p>
<p>有扇门可以<strong>进出</strong>，小智往<strong>前</strong>走出了门，但发现精灵球没拿，又<strong>回</strong>去了。随后小明跟着小霞小刚<strong>一起</strong>去旅行，但最终<strong>分开</strong>。小明往<strong>上</strong>走，<strong>超过</strong>了火箭队，但发现钱<strong>不够</strong>了，又往<strong>下</strong>走迫使火箭队将他们的钱<strong>转交</strong>给小智，几人<strong>相互</strong>之间笑的可开心了。虽然<strong>毫无意义</strong>，但别<strong>否定</strong>小智的努力哦。</p>
<hr>
<h2 id="后缀">后缀</h2>
<h3 id="动词后缀">动词后缀</h3>
<ul>
<li>ate(大部分)</li>
<li>ize</li>
<li>ify</li>
<li>ish</li>
</ul>
<p><strong>助记</strong></p>
<p>这只大尺寸<code>size</code>的鱼<code>fish</code>，其实并没有带上动词词根的命运<code>fate</code>，我们可以证明<code>exemplify</code></p>
<h3 id="形容词后缀">形容词后缀</h3>
<ul>
<li>ent</li>
<li>ful</li>
<li>ous</li>
<li>al</li>
<li>ive</li>
<li>ible</li>
<li>able</li>
<li>ant</li>
</ul>
<p><strong>助记</strong></p>
<p>nt家族有两大少爷，一个叫<code>e</code>一个叫<code>a</code>，他们有两把武器，分贝是<code>ible</code>和<code>able</code>。<code>a</code>少爷学的是<code>al</code>专业，绩点全是<code>ful</code>满分。<code>e</code>少爷则是作为偶像出道<code>ive</code>，跟大家的关系<code>ous</code>都不错。</p>
<p><strong>名词后缀</strong></p>
<ul>
<li>ion</li>
<li>tion</li>
<li>ation</li>
<li>ness</li>
<li>ity</li>
<li>ality</li>
<li>ment</li>
<li>ence</li>
<li>ance</li>
<li>ism</li>
</ul>
<p><strong>助记</strong></p>
<p><code>ion</code>家族、<code>nce</code>家族、<code>ity</code>家族，<code>ism</code>和<code>ment</code>，<code>ness</code>独一档</p>
<hr>
<h2 id="词根">词根</h2>
<h3 id="Day1">Day1</h3>
<p><strong>radi</strong></p>
<p>植物的<strong>根</strong>在rua地~</p>
<ul>
<li>radical adj. 根本的，彻底的</li>
<li>eradicate v. 根除</li>
<li>radiate v. 辐射/发散</li>
<li>radiant adj. 辐射的，容光焕发的</li>
<li>radio n. 收音机</li>
<li>radioactive adj. 放射性的</li>
<li>radium n. 镭</li>
</ul>
<p><strong>pose</strong></p>
<p><strong>摆放</strong>一个pose~</p>
<ul>
<li>
<p>expose v. 暴露，揭露</p>
</li>
<li>
<p>compose v. 组成，创作，创造</p>
</li>
<li>
<p>compositon n. 作文/品/曲</p>
</li>
<li>
<p>composite adj. 复合的，合成的</p>
</li>
<li>
<p>propose v. 求婚/提名/提议</p>
</li>
<li>
<p>dispose v. 处理/扔掉/安排</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Man propose, God dispose</span><br><span class="line"><span class="comment"># 尽人事，听天命</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p>oppose v. 反对</p>
</li>
<li>
<p>opponent n. 敌人/对手</p>
</li>
<li>
<p>depose v. 废除/罢免</p>
</li>
<li>
<p>deposit n. 沉淀物/定金</p>
</li>
</ul>
<p><strong>vers(t)</strong></p>
<p>嗡嗡嗡<strong>转</strong>起来喽！</p>
<ul>
<li>
<p>reverse v. 扭转，颠倒</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reverse the trend. <span class="comment"># 扭转趋势</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p>avert v. 转移，避免</p>
</li>
<li>
<p>convert v. 转变/换算/改变信仰</p>
</li>
<li>
<p>divert v. 转移/改道</p>
</li>
<li>
<p>diverse adj. 多样性的</p>
</li>
<li>
<p>introvert n. 内向的人</p>
</li>
<li>
<p>extrovert n. 外向的人</p>
</li>
<li>
<p>anniversary n. 周年纪念</p>
</li>
<li>
<p>controversy n. 争论/争吵</p>
</li>
</ul>
<p><strong>press</strong></p>
<p><strong>压</strong></p>
<ul>
<li>compress v. 压缩 condense 浓缩</li>
<li>depress v. 使压抑/萧条/低迷 depression 压抑</li>
<li>suppress v. 镇压/抑制/控制</li>
<li>impress v. 使印象深刻</li>
<li>express v. 表达 adj. 特快的 n. 快递</li>
<li>repress v. 抑制/忍住(感情)</li>
</ul>
<p><strong>duce</strong></p>
<p>赌博<code>du</code>会把警车<code>ce</code><strong>引</strong>来的哦</p>
<ul>
<li>produce v. 生产/产生、引起</li>
<li>induce v. 优化/引诱 = tempt</li>
<li>seduce v. 诱惑/色诱/勾引</li>
<li>deduce v. 推理/推断 = conclude = learn from = infer</li>
<li>educe v. 使显现 educate v. 教育</li>
<li>traduce v. 中伤/诽谤</li>
<li>introduce v. 介绍/引入/提出</li>
<li>reduce v. 减少/缩小/降低</li>
</ul>
<p><strong>gress</strong></p>
<p><strong>走</strong>在草地(grass)上</p>
<ul>
<li>congress n. 国会/代表大会</li>
<li>regress v. 倒退/退化 ----&gt; recede v. 退潮/衰退</li>
<li>aggressive adj. 激进的</li>
<li>progress n. 进步/进展 --&gt;advance v. 进步/前进</li>
<li>transgress v. 越轨/违反/违背</li>
</ul>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 不想学辣 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 英语 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[古诗]]></title>
      <url>/2022/08/01/%E3%80%90%E8%AF%97%E8%AF%8D%E5%90%8D%E5%8F%A5%E3%80%91%E5%8F%A4%E8%AF%97/</url>
      <content type="html"><![CDATA[<hr>
<h2 id="浣溪沙·谁念西风独自凉">浣溪沙·谁念西风独自凉</h2>
<p>(清)纳兰性德</p>
<p>谁念西风独自凉，萧萧黄叶闭疏窗，沉思往事立残阳。</p>
<p>被酒莫惊春睡醒，赌书消得泼茶香，当时只道是寻常。</p>
<hr>
<h2 id="赠刘侍御二首·其一">赠刘侍御二首·其一</h2>
<p>(明)王守仁</p>
<p>道自升沉宁有定，心存气节不无偏。</p>
<p>知君已得虚舟意，随处风波只晏然。</p>
<hr>
<h2 id="客中行">客中行</h2>
<p>李白</p>
<p>兰陵美酒郁金香，玉碗盛来琥珀光。</p>
<p>但使主人能醉客，不知何处是他乡。0</p>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 梦时风月 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 诗文 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[古诗]]></title>
      <url>/2022/08/01/%E3%80%90%E5%90%8D%E4%BA%BA%E9%9B%85%E5%8F%A5%E3%80%91%E5%90%8D%E4%BA%BA%E9%9B%85%E5%8F%A5/</url>
      <content type="html"><![CDATA[<h2 id="名人雅句">名人雅句</h2>
<h3 id="陶哲轩-Terence-Tao">陶哲轩 Terence Tao</h3>
<p>🌟 It’s okay  to fail! Failing is how you learn to approach problem differently, and find creative soulution.</p>
<p>数学并不是单纯的解决问题，而是在于发掘两件事物之间前所未有的，令人惊叹的<strong>联系</strong>。</p>
<p>🌟 The deeper you dive into anything in your life. the more you will discover and learn.</p>
<h3 id="笛卡尔-Descartes">笛卡尔 Descartes</h3>
<p>🌟 I doubt, therefore I think; I think, therefore I am.</p>
<h3 id="Abeba-Birhane">Abeba Birhane</h3>
<p>🌟 A person is a person through other persons</p>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 梦时风月 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 诗文 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Argparse模块常见用法]]></title>
      <url>/2022/07/29/%E3%80%90Python%E3%80%91Argparse/</url>
      <content type="html"><![CDATA[<h1>Argparse模块常见用法</h1>
<hr>
<p><code>argparse</code>模块是Python中用来读取命令行参数的模块，程序定义它需要的参数，然后<code>argparse</code>会自动从<code>sys.argv</code>中解析出这些参数。</p>
<h2 id="一、创建一个解释器">一、创建一个解释器</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span>  argparse</span><br><span class="line"></span><br><span class="line">parser=argparse.ArgumentParser(description=<span class="string">&quot;Test&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>接着我们试试执行该程序，使用<code>-h</code>参数打印帮助文档：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">python main.py -h</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">usage: main.py [-h]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Test</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">optional arguments:</span></span><br><span class="line"><span class="string">  -h, --help  show this help message and exit</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p><code>description</code>是在帮助文档解释参数前提供的文本信息。</p>
<p>在官方文档中，给出了ArgumentParse对象的参数解释：</p>
<ul>
<li><a href="https://docs.python.org/zh-cn/3/library/argparse.html#prog">prog</a> - 项目名称 (default: <code>os.path.basename(sys.argv[0])</code>)</li>
<li><a href="https://docs.python.org/zh-cn/3/library/argparse.html#usage">usage</a> - 描述程序用途的字符串（默认值：从添加到解析器的参数生成）</li>
<li><a href="https://docs.python.org/zh-cn/3/library/argparse.html#description">description</a> - 在参数帮助文档之前显示的文本（默认值：无）</li>
<li><a href="https://docs.python.org/zh-cn/3/library/argparse.html#epilog">epilog</a> - 在参数帮助文档之后显示的文本（默认值：无）</li>
<li><a href="https://docs.python.org/zh-cn/3/library/argparse.html#parents">parents</a> - 一个 <a href="https://docs.python.org/zh-cn/3/library/argparse.html#argparse.ArgumentParser"><code>ArgumentParser</code></a> 对象的列表，它们的参数也应包含在内</li>
<li><a href="https://docs.python.org/zh-cn/3/library/argparse.html#formatter-class">formatter_class</a> - 用于自定义帮助文档输出格式的类</li>
<li><a href="https://docs.python.org/zh-cn/3/library/argparse.html#prefix-chars">prefix_chars</a> - 可选参数的前缀字符集合（默认值： ‘-’）</li>
<li><a href="https://docs.python.org/zh-cn/3/library/argparse.html#fromfile-prefix-chars">fromfile_prefix_chars</a> - 当需要从文件中读取其他参数时，用于标识文件名的前缀字符集合（默认值： <code>None</code>）</li>
<li><a href="https://docs.python.org/zh-cn/3/library/argparse.html#argument-default">argument_default</a> - 参数的全局默认值（默认值： <code>None</code>）</li>
<li><a href="https://docs.python.org/zh-cn/3/library/argparse.html#conflict-handler">conflict_handler</a> - 解决冲突选项的策略（通常是不必要的）</li>
<li><a href="https://docs.python.org/zh-cn/3/library/argparse.html#add-help">add_help</a> - 为解析器添加一个 <code>-h/--help</code> 选项（默认值： <code>True</code>）</li>
<li><a href="https://docs.python.org/zh-cn/3/library/argparse.html#allow-abbrev">allow_abbrev</a> - 如果缩写是无歧义的，则允许缩写长选项 （默认值：<code>True</code>）</li>
<li><a href="https://docs.python.org/zh-cn/3/library/argparse.html#exit-on-error">exit_on_error</a> - 决定当错误发生时是否让 ArgumentParser 附带错误信息退出。 (默认值: <code>True</code>)</li>
</ul>
<hr>
<h2 id="二、为解释器添加参数">二、为解释器添加参数</h2>
<p>此时需要使用parser的<code>add_argument</code>方法，以下是常见用法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">parser.add_argument(<span class="string">&#x27;-n&#x27;</span>,<span class="string">&#x27;--name&#x27;</span>,default=<span class="string">&quot;Torture&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;-u&#x27;</span>,<span class="string">&#x27;--university&#x27;</span>,default=<span class="string">&quot;UCAS&quot;</span>,<span class="built_in">help</span>=<span class="string">&quot;发生什么事了&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(parser.parse_args())</span><br></pre></td></tr></table></figure>
<p>可以通过打印<code>parser.parse_args()</code>来查看当前的解释器参数状态：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">Namespace(name=&#x27;Torture&#x27;, university=&#x27;UCAS&#x27;)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>执行命令<code>python main.py -h</code>查看帮助文档：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">usage: main.py [-h] [-n NAME] [-u UNIVERSITY]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Test</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">optional arguments:</span></span><br><span class="line"><span class="string">  -h, --help            show this help message and exit</span></span><br><span class="line"><span class="string">  -n NAME, --name NAME</span></span><br><span class="line"><span class="string">  -u UNIVERSITY, --university UNIVERSITY</span></span><br><span class="line"><span class="string">                        发生什么事了</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>我们发现，现在的参数有三个了。可以通过<code>-h</code>,<code>-n</code>,<code>-u</code>来调用这些参数。关于<code>add_argument</code>方法，第一个参数是用于存放名称或选项字符串的。前面一个参数<code>-u</code>是简化的输入，只有<code>-</code>前缀会被以<strong>选项</strong>进行识别，剩下的参数都会被假定为<strong>位置参数</strong>。所以，<code>--university</code>则是该参数的名称。当然通过<code>-u</code>或是<code>--university</code>都能往该参数中输入。</p>
<p><code>default</code>是默认值参数，用于设定默认值的，而<code>help</code>则是在帮助文档中用来描述该参数。</p>
<h4 id="指定参数动作">指定参数动作</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">parser.add_argument(<span class="string">&#x27;-f&#x27;</span>,<span class="string">&#x27;--foo&#x27;</span>,action=<span class="string">&#x27;store&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><code>action</code>用来指定动作，&quot;store&quot;是默认值，用于存储参数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">python main.py -f <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">Namespace(foo=&#x27;10&#x27;)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>也可以指定存储布尔型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">parser.add_argument(<span class="string">&#x27;-f&#x27;</span>,<span class="string">&#x27;--foo&#x27;</span>,action=<span class="string">&#x27;store_true&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Namespace(foo=False)</span></span><br></pre></td></tr></table></figure>
<p><code>append</code>是存储一个列表，并将每个参数的值追加：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">parser.add_argument(<span class="string">&#x27;-f&#x27;</span>,<span class="string">&#x27;--foo&#x27;</span>,action=<span class="string">&#x27;append&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(parser.parse_args(<span class="string">&#x27;-f 1 -f 2 -f 3&#x27;</span>.split()))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Namespace(foo=[&#x27;1&#x27;, &#x27;2&#x27;, &#x27;3&#x27;])</span></span><br></pre></td></tr></table></figure>
<h4 id="指定版本信息">指定版本信息</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">parser=argparse.ArgumentParser(description=<span class="string">&quot;Test&quot;</span>,prog=<span class="string">&quot;ARGPARSE&quot;</span>)</span><br><span class="line"></span><br><span class="line">parser.add_argument(<span class="string">&#x27;-v&#x27;</span>,<span class="string">&#x27;--version&#x27;</span>,action=<span class="string">&#x27;version&#x27;</span>,version=<span class="string">&#x27;%(prog)s 2.0&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>通过指定<code>version</code>动作和<code>version</code>参数进行输出：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">python main.py -v</span><br><span class="line"></span><br><span class="line"><span class="comment">#  ARGPARSE 2.0</span></span><br></pre></td></tr></table></figure>
<h4 id="指定参数类型">指定参数类型</h4>
<p><code>type</code>参数可以指定类型，一般读进来的参数是字符串，此时可以通过<code>type</code>参数转换到需要的格式</p>
<p>例如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">parser=argparse.ArgumentParser(description=<span class="string">&quot;Test&quot;</span>,prog=<span class="string">&quot;ARGPARSE&quot;</span>)</span><br><span class="line"></span><br><span class="line">parser.add_argument(<span class="string">&quot;-d&quot;</span>,<span class="string">&#x27;--data&#x27;</span>,<span class="built_in">type</span>=<span class="built_in">int</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;-f&#x27;</span>,<span class="string">&#x27;--float&#x27;</span>,<span class="built_in">type</span>=<span class="built_in">float</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;-p&#x27;</span>,<span class="string">&#x27;--path&#x27;</span>,<span class="built_in">type</span>=<span class="built_in">open</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;-c&#x27;</span>,<span class="string">&#x27;--code&#x27;</span>,<span class="built_in">type</span>=<span class="built_in">ord</span>)</span><br></pre></td></tr></table></figure>
<p>输入参数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python main.py -d <span class="number">10</span> -f <span class="number">10.658</span> -p <span class="number">1.</span>txt -c <span class="string">&#x27;t&#x27;</span></span><br></pre></td></tr></table></figure>
<p>得到的结果为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Namespace(data=<span class="number">10</span>, <span class="built_in">float</span>=<span class="number">10.658</span>, path=&lt;_io.TextIOWrapper name=<span class="string">&#x27;1.txt&#x27;</span> mode=<span class="string">&#x27;r&#x27;</span> encoding=<span class="string">&#x27;cp936&#x27;</span>&gt;, code=<span class="number">116</span>)</span><br></pre></td></tr></table></figure>
<h4 id="指定参数数量">指定参数数量</h4>
<p>通过<code>nargs</code>参数可以关联不同数目的命令行参数到单一的动作，支持的值有：</p>
<p><strong>N</strong></p>
<ul>
<li>
<p>整数，命令行中的<strong>N</strong>个参数会被聚集到一个列表中。</p>
</li>
<li>
<p>例如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">parser.add_argument(<span class="string">&quot;-d&quot;</span>,<span class="string">&#x27;--data&#x27;</span>,nargs=<span class="number">2</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;-f&#x27;</span>,<span class="string">&#x27;--float&#x27;</span>,nargs=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(parser.parse_args(<span class="string">&quot;-d 1 2 -f 1.0&quot;</span>.split()))</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>结果如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Namespace(data=[<span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;2&#x27;</span>], <span class="built_in">float</span>=[<span class="string">&#x27;1.0&#x27;</span>])</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>+</strong></p>
<ul>
<li>至少有一个值被加入参数</li>
<li>没有的话会报错</li>
</ul>
<p><strong>?</strong></p>
<ul>
<li>至少有零个值被加入参数</li>
<li>没有的话会调用default值</li>
</ul>
<hr>
<h2 id="三、获取参数">三、获取参数</h2>
<p>我们可以定义一个载入的函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">arg_parse</span>():</span><br><span class="line">    parser=argparse.ArgumentParser(description=<span class="string">&quot;Test&quot;</span>,prog=<span class="string">&quot;ARGPARSE&quot;</span>)</span><br><span class="line"></span><br><span class="line">    parser.add_argument(<span class="string">&quot;-d&quot;</span>,<span class="string">&#x27;--data&#x27;</span>,nargs=<span class="number">2</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;-f&#x27;</span>,<span class="string">&#x27;--float&#x27;</span>,nargs=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> parser.parse_args()</span><br></pre></td></tr></table></figure>
<p>注意将<code>parser</code>返回回来</p>
<p>然后可以通过该函数获取参数信息了</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">arg=arg_parse()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;data :&quot;</span>,arg.data)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">python main.py -d 1 2 -f 3.2</span></span><br><span class="line"><span class="string">data : [&#x27;1&#x27;, &#x27;2&#x27;]</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<hr>
<p>更多内容详见官方文档：<a href="https://docs.python.org/zh-cn/3/library/argparse.html#the-add-argument-method">https://docs.python.org/zh-cn/3/library/argparse.html#the-add-argument-method</a>.</p>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 不想学辣 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 插件工具 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Unit3 形容词和副词]]></title>
      <url>/2022/07/29/%E3%80%90%E8%8B%B1%E8%AF%AD%E3%80%91Unit3%20%E5%BD%A2%E5%AE%B9%E8%AF%8D%E5%92%8C%E5%89%AF%E8%AF%8D/</url>
      <content type="html"><![CDATA[<h1>Unit3 形容词和副词</h1>
<hr>
<p>形容词是用来修饰名词，说明事物或人的性质、状态或特征的词，一般在句中主要充当定语或表语，还能做补语和状语。</p>
<p>副词主要用来修饰动词、形容词、副词或其他结构的词。一般做状语。</p>
<hr>
<h2 id="一、形容词">一、形容词</h2>
<blockquote>
<p>表语：说明主语的身份、性质、品性、特征和状态，例如：He is [a student].</p>
<p>定语：修饰、限定、说明名词或代词的性质、品质、特征，例如：It’s a [bad] manner.</p>
</blockquote>
<h3 id="1-1-作定语时的基本用法">1.1  作定语时的基本用法</h3>
<p>单个形容词作定语，一般放在所修饰的名词之前。形容词短语做定语时，需放在所修饰的名词之后。</p>
<p>而在修饰复合不定代词时(如<code>somebody, someone, something</code>等)则必须放在不定代词后面。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">He read an interesting storybook this morning.</span><br><span class="line">I know an actor suitable <span class="keyword">for</span> hte part <span class="keyword">in</span> the play.</span><br><span class="line">I would like something cheaper.</span><br></pre></td></tr></table></figure>
<h3 id="1-2-多个形容词修饰名词的顺序">1.2  多个形容词修饰名词的顺序</h3>
<ol>
<li>冠词、代词</li>
<li>序数词、基数词</li>
<li>一般描绘性形容词</li>
<li>大小、长短、形状</li>
<li>年龄、新旧</li>
<li>颜色</li>
<li>国籍、出处</li>
<li>材料</li>
<li>用途、类别</li>
</ol>
<p><strong>冠代</strong>山下，有一位<strong>数</strong>理<strong>基</strong>地班的学生在画画，宣纸上他将山的外在<strong>轮廓</strong>绘制了下来。此时，一位白发翩然的<strong>老</strong>者出现在他的身后，<strong>新与旧</strong>的时代似乎与此交汇。老人看学生的画精妙绝伦，可惜没有<strong>色彩</strong>，便上前询问学生的<strong>国籍</strong>和<strong>出处</strong>。没想到，这位学生竟然是个间谍，身上所有的<strong>材料</strong>都是妙妙工具！这些喵喵工具按照<strong>类别</strong>，各有其<strong>用途</strong>。</p>
<h3 id="1-3-同一形容词做前置定语和后置定语的区别">1.3  同一形容词做前置定语和后置定语的区别</h3>
<p>部分形容词做前置和做后置完全不同</p>
<table>
<thead>
<tr>
<th style="text-align:center">形容词</th>
<th style="text-align:center">前置含义</th>
<th style="text-align:center">后置含义</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">absent</td>
<td style="text-align:center">茫然的，恍惚的</td>
<td style="text-align:center">缺席的</td>
</tr>
<tr>
<td style="text-align:center">present</td>
<td style="text-align:center">现在的</td>
<td style="text-align:center">出席的</td>
</tr>
<tr>
<td style="text-align:center">concerned</td>
<td style="text-align:center">忧心忡忡的</td>
<td style="text-align:center">有关的</td>
</tr>
<tr>
<td style="text-align:center">responsible</td>
<td style="text-align:center">可靠的</td>
<td style="text-align:center">应负责的</td>
</tr>
<tr>
<td style="text-align:center">involved</td>
<td style="text-align:center">复杂难懂的</td>
<td style="text-align:center">相关的，有关的</td>
</tr>
</tbody>
</table>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">I am an accountant. It&#x27;s a responsible position, I suppose, but not very exciting.</span><br><span class="line"># 我是个会计，虽然是责任重大的职位，但并不有趣</span><br><span class="line">The man responsible for finding the volunteers is Dr.Charles Weber.</span><br><span class="line"># 负责寻找志愿者的人是查尔斯韦伯</span><br></pre></td></tr></table></figure>
<h3 id="1-4-以-a-开头的形容词">1.4  以**a-**开头的形容词</h3>
<p>这些词只能做表语，不做前置定语，可以做后置定语，相当于一个定语从句</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">afraid</span><br><span class="line">asleep</span><br><span class="line">alike</span><br><span class="line">alive</span><br><span class="line">awake</span><br><span class="line">alone</span><br><span class="line">ashamed</span><br><span class="line"></span><br><span class="line">Time alone will show who was right.</span><br><span class="line"><span class="comment"># 唯独时间能证明谁是对的</span></span><br><span class="line">alone相当于 which/that <span class="keyword">is</span> alone</span><br></pre></td></tr></table></figure>
<h3 id="1-5-形容词或形容词短语作状语">1.5  形容词或形容词短语作状语</h3>
<p>这种情况一般用于意义上的增补，位置十分灵活。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Crusoe stared at the footprint, full of fear.</span><br><span class="line">Tom, very ill, sent <span class="keyword">for</span> a doctor.</span><br><span class="line">Old <span class="keyword">or</span> young, they <span class="built_in">all</span> like these cartoon pictures.</span><br></pre></td></tr></table></figure>
<h3 id="1-6-以-ing、-ed结尾的形容词">1.6  以-ing、-ed结尾的形容词</h3>
<p>此类形容词由动词变化而来，<strong>-ing</strong>一般修饰物，表示&quot;令人…的&quot;，常做定语；<strong>-ed</strong>一般修饰人，表示&quot;(人)…的&quot;，常做表语。<strong>-ed</strong>分词表示被动含义，而**-ing**表示主动含义。</p>
<h2 id="二、副词">二、副词</h2>
<h3 id="2-1-形容词转化为副词">2.1  形容词转化为副词</h3>
<p><strong>口诀</strong>：“元e”去“e”加，“辅y”改i加，“le”结尾改e为y</p>
<ol>
<li>一般情况下直接加<strong>ly</strong>7</li>
<li>元音+<strong>e</strong>结尾一般去掉<strong>e</strong>再加<strong>ly</strong>，辅音+<strong>e</strong>直接加<strong>ly</strong></li>
<li>辅音+<strong>y</strong>结尾需要改成<strong>i</strong>(同化规则)，要求<strong>y</strong>读音为/i/，而当<strong>y</strong>读音为/ai/时不需要改</li>
<li>辅音+<strong>le</strong>去<strong>e</strong>加<strong>y</strong></li>
<li>以<strong>ic</strong>结尾的加<strong>ally</strong></li>
<li>以<strong>ll</strong>结尾只需加<strong>y</strong></li>
</ol>
<p>有些形容词有两种副词，一种形副同形，一种加<strong>ly</strong>，加<strong>ly</strong>往往有另外的意思：</p>
<table>
<thead>
<tr>
<th style="text-align:center">Type 1</th>
<th style="text-align:center">Type 2</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">hard 刻苦地，猛烈地，困难地</td>
<td style="text-align:center">hardly 几乎不</td>
</tr>
<tr>
<td style="text-align:center">free 免费地</td>
<td style="text-align:center">freely 自由地</td>
</tr>
<tr>
<td style="text-align:center">late 晚，迟</td>
<td style="text-align:center">lately 最近</td>
</tr>
<tr>
<td style="text-align:center">high 高高地</td>
<td style="text-align:center">highly 高度地</td>
</tr>
<tr>
<td style="text-align:center">close 接近地</td>
<td style="text-align:center">closely 仔细地</td>
</tr>
<tr>
<td style="text-align:center">direct 径直地、直接地</td>
<td style="text-align:center">directly (抽象)立刻马上</td>
</tr>
<tr>
<td style="text-align:center">deep 深度(只能修饰动词，多表示空间)</td>
<td style="text-align:center">deeply (抽象，可修饰多种，多表示情感0s)</td>
</tr>
<tr>
<td style="text-align:center">wide 充分地，完全地</td>
<td style="text-align:center">widely 广泛地</td>
</tr>
</tbody>
</table>
<p>wide awake 完全清醒</p>
<p>当然，有些词是以<strong>ly</strong>结尾的，但本质上是形容词</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">likely <span class="comment"># 可能的</span></span><br><span class="line">costly <span class="comment"># 花费大的</span></span><br><span class="line">orderly <span class="comment"># 整齐的</span></span><br><span class="line">deadly <span class="comment"># 致命的</span></span><br><span class="line">ugly <span class="comment"># 丑的</span></span><br><span class="line">lively <span class="comment"># 活泼的</span></span><br><span class="line">lonely <span class="comment"># 孤独的，寂寞的</span></span><br><span class="line">friendly <span class="comment"># 友好的</span></span><br><span class="line">daily <span class="comment"># 每天的</span></span><br><span class="line">weekly <span class="comment"># 每周的</span></span><br><span class="line">monthly <span class="comment"># 每月的</span></span><br><span class="line">yearly <span class="comment"># 每年的</span></span><br></pre></td></tr></table></figure>
<h3 id="2-2-连接副词">2.2  连接副词</h3>
<p>常见的连接副词有：</p>
<ul>
<li>therefore</li>
<li>besides</li>
<li>otherwise</li>
<li>however</li>
<li>moreover</li>
<li>still</li>
<li>thus</li>
<li>meanwhile</li>
<li>nevertheless</li>
</ul>
<h3 id="2-3-评注性副词">2.3  评注性副词</h3>
<p>用来修饰整个句子，通常表示说话人的态度和看问题的角度。</p>
<ul>
<li>表示说话人观点的副词
<ul>
<li>clearly</li>
<li>certainly</li>
<li>surely</li>
<li>fortunately</li>
<li>hopefully</li>
<li>naturally</li>
<li>obviously</li>
<li>possibly</li>
<li>strangely</li>
<li>surprisingly</li>
<li>undoubtedly</li>
</ul>
</li>
<li>表示人说话的角度
<ul>
<li>briefly</li>
<li>exactly</li>
<li>frankly</li>
<li>generally</li>
<li>honestly</li>
<li>roughly</li>
<li>seriously</li>
</ul>
</li>
<li>表示看问题的角度
<ul>
<li>economically</li>
<li>historically</li>
<li>physically</li>
<li>scientifically</li>
</ul>
</li>
</ul>
<hr>
<h2 id="三、-比较级">三、 比较级</h2>
<h3 id="3-1-比较级和最高级变化规则">3.1  比较级和最高级变化规则</h3>
<h4 id="3-1-1-直接加-er-est">3.1.1  直接加-er, -est</h4>
<p>一般单音节词和少数以-er, -ow 结尾的双音节词，比较级加-er， 最高级加-est</p>
<h4 id="3-1-2-加-r-st">3.1.2  加-r, -st</h4>
<p>以不发音<code>e</code>结尾的单音节词，比较级直接加<code>r</code>，最高级加<code>st</code></p>
<h4 id="3-1-3-双写末尾辅音加-er，-est">3.1.3  双写末尾辅音加<code>-er</code>，<code>-est</code></h4>
<p>重读闭音节(辅音+元音+辅音)中，先双写末尾的辅音字母，比较级加<code>-er</code>，最高级加<code>-est</code></p>
<h4 id="3-1-4-把y边i后再加er-est">3.1.4  把y边i后再加er,est</h4>
<p>辅音字母+y结尾的双音节，需要把y改成i</p>
<h4 id="3-1-5-双音节或多音节">3.1.5  双音节或多音节</h4>
<p>需要在前面加上most或more</p>
<h4 id="3-1-6-不规则情况">3.1.6  不规则情况</h4>
<table>
<thead>
<tr>
<th style="text-align:center">原形</th>
<th style="text-align:center">比较级</th>
<th style="text-align:center">最高级</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">good/well</td>
<td style="text-align:center">better</td>
<td style="text-align:center">best</td>
</tr>
<tr>
<td style="text-align:center">many/much</td>
<td style="text-align:center">more</td>
<td style="text-align:center">most</td>
</tr>
<tr>
<td style="text-align:center">old</td>
<td style="text-align:center">older/elder</td>
<td style="text-align:center">oldest/eldest</td>
</tr>
<tr>
<td style="text-align:center">little</td>
<td style="text-align:center">less</td>
<td style="text-align:center">least</td>
</tr>
<tr>
<td style="text-align:center">bad/ill/badly</td>
<td style="text-align:center">worse</td>
<td style="text-align:center">worst</td>
</tr>
<tr>
<td style="text-align:center">far</td>
<td style="text-align:center">further/father</td>
<td style="text-align:center">furthest/farthest</td>
</tr>
</tbody>
</table>
<h2 id="3-2-形容词、副词比较级和最高级的用法">3.2  形容词、副词比较级和最高级的用法</h2>
<h4 id="3-2-1-一般用法">3.2.1  一般用法</h4>
<ul>
<li>
<p>A+谓语动词+形容词/副词比较级+than+B</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">This tree is taller than that one.</span><br><span class="line">Gary runs faster than Jack.</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>最高级还能表示三个或是以上</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Tome <span class="keyword">is</span> the smartest of the three boys.</span><br></pre></td></tr></table></figure>
<p>当然了，在含有连词<strong>than</strong>的比较级中，前后的比较对象必须是一个范畴的，且在比较级前面可以使用<code>a bit, a little, rather than, much, far, by far, many, a lot, lots, a great deal, any, still, even</code>。而且<code>very</code>和<code>quite</code>一般只能修饰原级。</p>
</li>
</ul>
<h4 id="3-2-2-比较级-and-比较级或more-and-more-原级">3.2.2  比较级+and+比较级或more and more+原级</h4>
<p>&quot;比较级+and+比较级&quot;或者&quot;more and more + 原级&quot;表示越来越</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">It becomes warmer <span class="keyword">and</span> warmer when spring comes.</span><br><span class="line">Our school <span class="keyword">is</span> becoming more <span class="keyword">and</span> more beautiful.</span><br></pre></td></tr></table></figure>
<h4 id="3-2-3-“the-比较级…-the-比较级”">3.2.3  “the+比较级…,the+比较级”</h4>
<p>表示越来越</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">The harder you work, the greater progress you will make.</span><br></pre></td></tr></table></figure>
<h4 id="3-2-4-表示倍数的比较级用法">3.2.4  表示倍数的比较级用法</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">A <span class="keyword">is</span> ... times the size/height/length/width of B. <span class="comment">#  X times the 名词</span></span><br><span class="line">A <span class="keyword">is</span> ... times <span class="keyword">as</span> big/high/long/wide/large <span class="keyword">as</span> B. <span class="comment"># X times as 形容词 as </span></span><br><span class="line">A <span class="keyword">is</span> ... times larger/higher/lnger/wider than B. <span class="comment"># X times 比较级 than</span></span><br></pre></td></tr></table></figure>
<p>当然，as…, as…作为习惯用语，也有特定的含义：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">as</span> long <span class="keyword">as</span> <span class="comment"># 只要</span></span><br><span class="line"><span class="keyword">as</span> soon <span class="keyword">as</span> <span class="comment"># 一...就...</span></span><br><span class="line"><span class="keyword">as</span> far <span class="keyword">as</span> <span class="comment"># 远到...,据...</span></span><br><span class="line"><span class="keyword">as</span> well <span class="keyword">as</span> <span class="comment"># 和，也</span></span><br><span class="line"><span class="keyword">as</span> good <span class="keyword">as</span> <span class="comment"># 几乎，实际上</span></span><br></pre></td></tr></table></figure>
<hr>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 不想学辣 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 英语 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[图卷积神经网络(GCN)综述与实现]]></title>
      <url>/2022/07/29/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E5%9B%BE%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
      <content type="html"><![CDATA[<h1>图卷积神经网络(GCN)综述与实现（PyTorch版)</h1>
<hr>
<p>本文的实验环境为<code>PyTorch = 1.11.0 + cu113，PyG = 2.0.4</code>，相关依赖库和数据集的下载请见<a href="https://blog.csdn.net/qq_45957458/article/details/125260352?spm=1001.2014.3001.5502">链接</a>。</p>
<hr>
<h2 id="一、图卷积神经网络介绍">一、图卷积神经网络介绍</h2>
<h3 id="1-1-传统图像卷积">1.1  传统图像卷积</h3>
<p>卷积神经网络中的<strong>卷积(Convolution)<strong>指的是在图像上进行的输入和卷积核之间</strong>离散内积运算</strong>，其本质上就是利用<strong>共享参数</strong>的滤波器，通过计算中心值以及相邻节点的值进行<strong>加权</strong>获得带有<strong>局部空间特征</strong>的特征提取器。</p>
<p>其具有三个重要的特征，分别为：</p>
<ul>
<li><strong>稀疏连接</strong>
<ul>
<li>相较于全连接层，卷积层输入和输出间的连接是稀疏的，能够大大减少参数的数量，加快网络的训练速度。</li>
</ul>
</li>
<li><strong>参数共享</strong>
<ul>
<li>卷积核的权重参数可以被多个函数或操作共享，这样只需要训练一个参数集，而不需要对每个位置都训练一个参数集。此外，由于卷积核的大小一般是小于输入大小，也能起到减少参数数量的作用</li>
</ul>
</li>
<li><strong>等变表示</strong>
<ul>
<li>事实上，每个卷积层可以通过多个卷积核来进行特征提取，并且在卷积运算后，卷积神经网络对输入的图像具有平移不变性(有严格的数学论证)</li>
</ul>
</li>
</ul>
<img src="/2022/07/29/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E5%9B%BE%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20220729002859162.png" alt="image-20220729002859162" style="zoom:50%;">
<p>一般在卷积层后，会通过一个<strong>池化层</strong>进行降维，进一步降低网络的复杂度和非线性程度。在那之后，可以将通过卷积池化层后的特征输入全连接层或反卷积层进行进一步的分类、分割、重建工作。当然，传统的卷积操作一般适用于结构化数据。</p>
<h3 id="1-2-图结构">1.2  图结构</h3>
<p>图作为一种典型的非结构化非线性数据(非欧几里得数据)，其可以表示一对一、一对多、多对多的关系，因而常被用于描述复杂的数据对象，譬如社交网络、知识图谱、城市路网、3D点云等。与结构化数据不同，图的局部输入维度可变，即每个节点的邻居节点数量不同；图具有无序性，即节点间并不存在先后关系，仅存在连接关系(点云是置换不变性，在无序性的基础上，交换两点或多点不会影响整体结果)。由于图结构的特殊性，传统CNN和RNN对其的表征能力并不理想。</p>
<img src="/2022/07/29/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E5%9B%BE%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20220613221407489.png" alt="image-20220613221407489" style="zoom:50%;">
<p>对于图结构，我们可以将其抽象表示为：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>G</mi><mo>=</mo><mo stretchy="false">(</mo><mi>V</mi><mo separator="true">,</mo><mi>E</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">G=(V,E)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">G</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mclose">)</span></span></span></span></span></p>
<p>在这里<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span>表示图中节点的集合，而<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi></mrow><annotation encoding="application/x-tex">E</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span></span></span></span>为边的集合。对于图特征，我们一般有三个重要矩阵进行表示。</p>
<ul>
<li>邻接矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span>：<code>adjacency matrix</code>用来表示节点间的连接关系。</li>
</ul>
<img src="/2022/07/29/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E5%9B%BE%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20220729003011071.png" alt="image-20220729003011071" style="zoom:50%;">
$$
\begin{vmatrix}
&0 & 1 & 0 & 0&\\
&0 & 0 & 1 & 0&\\
&1 & 1 & 0 & 0&\\
&0 & 1 & 1 & 0&\\
\end{vmatrix}
$$
​		对于带权的图，邻接矩阵将把1替换为对应的权重
<ul>
<li>
<p>度矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span></span></span></span>：<code>degree matrix</code>用来表示节点的连接数，可以表征某个节点在图中的重要程度，是一个对角矩阵，例如针对上图的入度矩阵：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mo fence="true">∣</mo><mtable rowspacing="0.16em" columnalign="center center center center center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>3</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd></mtr></mtable><mo fence="true">∣</mo></mrow><annotation encoding="application/x-tex">\begin{vmatrix}
&amp;1 &amp; 0 &amp; 0 &amp; 0&amp;\\
&amp;0 &amp; 3 &amp; 0 &amp; 0&amp;\\
&amp;0 &amp; 0 &amp; 2 &amp; 0&amp;\\
&amp;0 &amp; 0 &amp; 0 &amp; 0&amp;\\
\end{vmatrix}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:4.8121em;vertical-align:-2.15em;"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.662em;"><span style="top:-3.466em;"><span class="pstrut" style="height:5.6161em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-4.064em;"><span class="pstrut" style="height:5.6161em;"></span><span style="height:3.6161em;width:0.3333em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.3333em" height="3.6161em" style="width:0.3333em" viewbox="0 0 333.33000000000004 3616" preserveaspectratio="xMinYMin"><path d="M145 0 H188 V3616 H145z M145 0 H188 V3616 H145z"/></svg></span></span><span style="top:-7.6721em;"><span class="pstrut" style="height:5.6161em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.65em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span><span style="top:-3.45em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span><span style="top:-2.25em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span><span style="top:-1.05em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-1.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">3</span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-1.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-1.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-1.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.65em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span><span style="top:-3.45em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span><span style="top:-2.25em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span><span style="top:-1.05em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.662em;"><span style="top:-3.466em;"><span class="pstrut" style="height:5.6161em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-4.064em;"><span class="pstrut" style="height:5.6161em;"></span><span style="height:3.6161em;width:0.3333em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.3333em" height="3.6161em" style="width:0.3333em" viewbox="0 0 333.33000000000004 3616" preserveaspectratio="xMinYMin"><path d="M145 0 H188 V3616 H145z M145 0 H188 V3616 H145z"/></svg></span></span><span style="top:-7.6721em;"><span class="pstrut" style="height:5.6161em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span></span></span></span></span></span></span></p>
</li>
<li>
<p>特征矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span>：<code>feature matrix</code>用来表示节点的特征</p>
</li>
</ul>
<h3 id="1-3-图卷积神经网络">1.3  图卷积神经网络</h3>
<p>目前主流的图卷积基本上可以分为两类，一种是基于谱的图卷积，一种是基于空域的图卷积。</p>
<p>基于谱的图卷积通过傅里叶变换(FFT干的一件事情就是连接空域和频域)将节点映射到频域空间，通过频域空间上的卷积来实现时域上的卷积，最后将特征映射回空域。而基于空域的图卷积则是直接基于节点与邻居进行卷积提取特征，没有做域上的变换。</p>
<p>图卷积算子可表示为：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msubsup><mi>h</mi><mi>i</mi><mrow><mi>l</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><munder><mo>∑</mo><mrow><mi>j</mi><mo>∈</mo><msub><mi>N</mi><mi>i</mi></msub></mrow></munder><mfrac><mn>1</mn><msub><mi>C</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mfrac><msubsup><mi>h</mi><mi>j</mi><mi>l</mi></msubsup><msubsup><mi>w</mi><msub><mi>R</mi><mi>j</mi></msub><mi>l</mi></msubsup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">h_i^{l+1}=\sigma(\sum_{j\in N_i}\frac{1}{C_{ij}}h_j^lw_{R_j}^l)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1661em;vertical-align:-0.267em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8991em;"><span style="top:-2.433em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.267em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.7519em;vertical-align:-1.4304em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.8557em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">∈</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.4304em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9721em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8991em;"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3831em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8991em;"><span style="top:-2.453em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.0077em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2819em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4443em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
<p>其中，设中心结点为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span>；<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>h</mi><mi>i</mi><mi>l</mi></msubsup></mrow><annotation encoding="application/x-tex">h_i^l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1078em;vertical-align:-0.2587em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-2.4413em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2587em;"><span></span></span></span></span></span></span></span></span></span>为结点<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span>在<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi></mrow><annotation encoding="application/x-tex">l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span></span></span></span>层的特征表达；<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>σ</mi></mrow><annotation encoding="application/x-tex">\sigma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span></span></span></span>是非线性激活函数；<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>C</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">C_{ij}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span>则是归一化因子，譬如结点度的倒数、反距离权重、高斯衰减权重等；<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>N</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">N_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是结点<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span>的邻接节点(包括自身)；<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>R</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">R_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>表示节点<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span>的类型；<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><msub><mi>R</mi><mi>j</mi></msub></msub></mrow><annotation encoding="application/x-tex">W_{R_j}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0307em;vertical-align:-0.3473em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.0077em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2819em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3473em;"><span></span></span></span></span></span></span></span></span></span>表示<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>R</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">R_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span>类型的节点变换权重参数。</p>
<hr>
<p>下面围绕<a href="https://arxiv.org/pdf/1609.02907.pdf">Semi-supervised Classification with Graph Convolutional Networks</a>一文中提出的GCN结构进行分析。</p>
<p>该篇文章由阿姆斯特丹(the University of Amsterdam)大学机器学习专业的Thomas Kipf 博士于2016年提出，并于2017年被深度学习的顶会ICLR(International Conference on Learning Representations)接收！这位大佬的研究方向是学习结构化数据和结构化表示/计算，包括推理、(多智能体)强化学习和结构化深度生成模型。</p>
<p><strong>核心思想</strong></p>
<p>该篇文章提出了一种新的网络结构，用于处理非结构化的图数据，并解决了在一个图中，只有少部分节点的标签是已知情况下的节点分类问题(半监督学习)。</p>
<p>对于带有特征的图结构，例如下图中的<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>×</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">n\times3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">3</span></span></span></span>网络结构，有部分是带有标识的，而有部分则是无标识的。</p>
<img src="/2022/07/29/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E5%9B%BE%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20220614012201305.png" alt="image-20220614012201305" style="zoom:50%;">
<p>GCN通过考虑节点本身以及邻居节点的特征信息来提取潜在的关系。比如我们在中心节点拼接了邻居的特征后，使用平均池化的方式对这些特征进行聚合，再通过浅层网络进行学习训练得到新的数据。</p>
<img src="/2022/07/29/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E5%9B%BE%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20220614012428581.png" alt="image-20220614012428581" style="zoom:50%;">
<p>每个GCN层做的事情：</p>
<ul>
<li>获取当前节点和邻接节点特征</li>
<li>通过聚合函数获取局部特征(带有拓扑关系)</li>
<li>浅层学习训练，获取高维特征</li>
</ul>
<img src="/2022/07/29/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E5%9B%BE%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20220614012503541.png" alt="image-20220614012503541" style="zoom:50%;">
<p><strong>数学推导</strong></p>
<img src="/2022/07/29/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E5%9B%BE%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20220614014620294.png" alt="image-20220614014620294" style="zoom:50%;">
<p>对于一个如上图所示的无向图，我们要怎么样才能获取到某个节点以及其邻居节点的特征呢？一种非常直观的想法💡是，在当前节点的特征之后，根据权重<strong>拼接</strong>与之<strong>相邻节点</strong>的特征。此时，空域上的距离往往成为了权重的影响因素。</p>
<p>那么，邻接表就成了我们考虑节点间拓扑关系最重要的结构。我们写成<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>×</mo><mi>X</mi><mo>×</mo><mi>W</mi></mrow><annotation encoding="application/x-tex">A\times X\times W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span></span></span></span>，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span>是邻接矩阵，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span>是特征矩阵，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi></mrow><annotation encoding="application/x-tex">W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span></span></span></span>是权重。右乘相当于控制行，左乘相当于控制列，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span>左乘<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span>，相当于在对应节点处，使用哪些节点特征构建新的特征：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mrow><mo fence="true">∣</mo><mtable rowspacing="0.16em" columnalign="center center center center center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd></mtr></mtable><mo fence="true">∣</mo></mrow><mo>×</mo><mrow><mo fence="true">∣</mo><mtable rowspacing="0.16em" columnalign="center center center center center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>3</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>3</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>3</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>3</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>40</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>40</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>40</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>40</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd></mtr></mtable><mo fence="true">∣</mo></mrow><mo>=</mo><mrow><mo fence="true">∣</mo><mtable rowspacing="0.16em" columnalign="center center center center center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>43</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>43</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>43</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>43</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>42</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>42</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>42</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>42</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>3</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>3</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>3</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>3</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd></mtr></mtable><mo fence="true">∣</mo></mrow></mrow><annotation encoding="application/x-tex">\begin{vmatrix}
&amp;0 &amp; 1 &amp; 0&amp;0&amp;\\
&amp;0 &amp; 0 &amp; 1&amp;1&amp;\\
&amp;0 &amp; 1 &amp; 0&amp;1&amp;\\
&amp;1 &amp; 1 &amp; 0&amp;0&amp;\\
\end{vmatrix}\times
\begin{vmatrix}
&amp;1 &amp; 1 &amp; 1&amp;1&amp;\\
&amp;2 &amp; 2 &amp; 2&amp;2&amp;\\
&amp;3 &amp; 3 &amp; 3&amp;3&amp;\\
&amp;40 &amp; 40 &amp; 40&amp;40&amp;\\
\end{vmatrix}=
\begin{vmatrix}
&amp;2 &amp; 2 &amp; 2&amp;2&amp;\\
&amp;43 &amp; 43 &amp; 43&amp;43&amp;\\
&amp;42 &amp; 42 &amp; 42&amp;42&amp;\\
&amp;3 &amp; 3 &amp; 3&amp;3&amp;\\
\end{vmatrix}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:4.8121em;vertical-align:-2.15em;"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.662em;"><span style="top:-3.466em;"><span class="pstrut" style="height:5.6161em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-4.064em;"><span class="pstrut" style="height:5.6161em;"></span><span style="height:3.6161em;width:0.3333em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.3333em" height="3.6161em" style="width:0.3333em" viewbox="0 0 333.33000000000004 3616" preserveaspectratio="xMinYMin"><path d="M145 0 H188 V3616 H145z M145 0 H188 V3616 H145z"/></svg></span></span><span style="top:-7.6721em;"><span class="pstrut" style="height:5.6161em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.65em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span><span style="top:-3.45em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span><span style="top:-2.25em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span><span style="top:-1.05em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-1.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span><span style="top:-1.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-1.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span><span style="top:-1.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.65em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span><span style="top:-3.45em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span><span style="top:-2.25em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span><span style="top:-1.05em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.662em;"><span style="top:-3.466em;"><span class="pstrut" style="height:5.6161em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-4.064em;"><span class="pstrut" style="height:5.6161em;"></span><span style="height:3.6161em;width:0.3333em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.3333em" height="3.6161em" style="width:0.3333em" viewbox="0 0 333.33000000000004 3616" preserveaspectratio="xMinYMin"><path d="M145 0 H188 V3616 H145z M145 0 H188 V3616 H145z"/></svg></span></span><span style="top:-7.6721em;"><span class="pstrut" style="height:5.6161em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:4.8121em;vertical-align:-2.15em;"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.662em;"><span style="top:-3.466em;"><span class="pstrut" style="height:5.6161em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-4.064em;"><span class="pstrut" style="height:5.6161em;"></span><span style="height:3.6161em;width:0.3333em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.3333em" height="3.6161em" style="width:0.3333em" viewbox="0 0 333.33000000000004 3616" preserveaspectratio="xMinYMin"><path d="M145 0 H188 V3616 H145z M145 0 H188 V3616 H145z"/></svg></span></span><span style="top:-7.6721em;"><span class="pstrut" style="height:5.6161em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.65em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span><span style="top:-3.45em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span><span style="top:-2.25em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span><span style="top:-1.05em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">3</span></span></span><span style="top:-1.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">40</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">3</span></span></span><span style="top:-1.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">40</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">3</span></span></span><span style="top:-1.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">40</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">3</span></span></span><span style="top:-1.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">40</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.65em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span><span style="top:-3.45em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span><span style="top:-2.25em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span><span style="top:-1.05em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.662em;"><span style="top:-3.466em;"><span class="pstrut" style="height:5.6161em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-4.064em;"><span class="pstrut" style="height:5.6161em;"></span><span style="height:3.6161em;width:0.3333em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.3333em" height="3.6161em" style="width:0.3333em" viewbox="0 0 333.33000000000004 3616" preserveaspectratio="xMinYMin"><path d="M145 0 H188 V3616 H145z M145 0 H188 V3616 H145z"/></svg></span></span><span style="top:-7.6721em;"><span class="pstrut" style="height:5.6161em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:4.8121em;vertical-align:-2.15em;"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.662em;"><span style="top:-3.466em;"><span class="pstrut" style="height:5.6161em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-4.064em;"><span class="pstrut" style="height:5.6161em;"></span><span style="height:3.6161em;width:0.3333em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.3333em" height="3.6161em" style="width:0.3333em" viewbox="0 0 333.33000000000004 3616" preserveaspectratio="xMinYMin"><path d="M145 0 H188 V3616 H145z M145 0 H188 V3616 H145z"/></svg></span></span><span style="top:-7.6721em;"><span class="pstrut" style="height:5.6161em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.65em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span><span style="top:-3.45em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span><span style="top:-2.25em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span><span style="top:-1.05em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">43</span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">42</span></span></span><span style="top:-1.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">43</span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">42</span></span></span><span style="top:-1.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">43</span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">42</span></span></span><span style="top:-1.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">43</span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">42</span></span></span><span style="top:-1.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.65em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span><span style="top:-3.45em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span><span style="top:-2.25em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span><span style="top:-1.05em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.662em;"><span style="top:-3.466em;"><span class="pstrut" style="height:5.6161em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-4.064em;"><span class="pstrut" style="height:5.6161em;"></span><span style="height:3.6161em;width:0.3333em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.3333em" height="3.6161em" style="width:0.3333em" viewbox="0 0 333.33000000000004 3616" preserveaspectratio="xMinYMin"><path d="M145 0 H188 V3616 H145z M145 0 H188 V3616 H145z"/></svg></span></span><span style="top:-7.6721em;"><span class="pstrut" style="height:5.6161em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>诶，糟糕，这矩阵数数数着数着咋把自己给忘了呀！而且似乎…有些小朋友发育的过于良好，这样会导致梯度消化不良的！(梯度爆炸或消失问题)</p>
<p>为了处理这种情况，我们引入了新的邻接矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>A</mi><mo>~</mo></mover></mrow><annotation encoding="application/x-tex">\tilde A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9202em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9202em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">A</span></span><span style="top:-3.6023em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1111em;"><span class="mord">~</span></span></span></span></span></span></span></span></span></span>用于承载当前节点信息~</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mover accent="true"><mi>A</mi><mo>~</mo></mover><mo>=</mo><mi>A</mi><mo>+</mo><mi>λ</mi><msub><mi>I</mi><mi>N</mi></msub></mrow><annotation encoding="application/x-tex">\tilde A =A+\lambda I_N
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9202em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9202em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">A</span></span><span style="top:-3.6023em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1111em;"><span class="mord">~</span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord mathnormal">λ</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p>
<p>当权重因子<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">λ</span></span></span></span>取<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span>时，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>A</mi><mo>~</mo></mover><mo>=</mo><mi>A</mi><mo>+</mo><msub><mi>I</mi><mi>N</mi></msub></mrow><annotation encoding="application/x-tex">\tilde A =A+I_N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9202em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9202em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">A</span></span><span style="top:-3.6023em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1111em;"><span class="mord">~</span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，此时意味着节点中心和邻居一样重要啦。🎉</p>
<p>值得注意的是，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">λ</span></span></span></span>本身也是一个可以由训练得到的参数。</p>
<p>针对梯度问题呢，我们可以利用对角矩阵实现标准化，譬如利用度矩阵的逆<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover accent="true"><mi>D</mi><mo>~</mo></mover><mrow><mo>−</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">\tilde D^{-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9202em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9202em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span></span><span style="top:-3.6023em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">~</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span>进行平均化的操作：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mrow><mo fence="true">∣</mo><mtable rowspacing="0.16em" columnalign="center center center center center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>3</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>4</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd></mtr></mtable><mo fence="true">∣</mo></mrow><mover><mo stretchy="true" minsize="3.0em">→</mo><mpadded width="+0.6em" lspace="0.3em"><mrow><mi>i</mi><mi>n</mi><mi>v</mi><mi>e</mi><mi>r</mi><mi>s</mi><mi>e</mi></mrow></mpadded></mover><mrow><mo fence="true">∣</mo><mtable rowspacing="0.16em" columnalign="center center center center center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mn>1</mn><mi mathvariant="normal">/</mi><mn>2</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mn>1</mn><mi mathvariant="normal">/</mi><mn>3</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mn>1</mn><mi mathvariant="normal">/</mi><mn>4</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd></mtr></mtable><mo fence="true">∣</mo></mrow></mrow><annotation encoding="application/x-tex">\begin{vmatrix}
&amp;2 &amp; 0 &amp; 0&amp;0&amp;\\
&amp;0 &amp; 3 &amp; 0&amp;0&amp;\\
&amp;0 &amp; 0 &amp; 4&amp;0&amp;\\
&amp;0 &amp;0 &amp; 0&amp;1&amp;\\
\end{vmatrix}\xrightarrow{inverse}
\begin{vmatrix}
&amp;1/2 &amp; 0 &amp; 0&amp;0&amp;\\
&amp;0 &amp; 1/3 &amp; 0&amp;0&amp;\\
&amp;0 &amp; 0 &amp; 1/4&amp;0&amp;\\
&amp;0 &amp;0 &amp;0&amp;1&amp;\\
\end{vmatrix}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:4.8121em;vertical-align:-2.15em;"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.662em;"><span style="top:-3.466em;"><span class="pstrut" style="height:5.6161em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-4.064em;"><span class="pstrut" style="height:5.6161em;"></span><span style="height:3.6161em;width:0.3333em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.3333em" height="3.6161em" style="width:0.3333em" viewbox="0 0 333.33000000000004 3616" preserveaspectratio="xMinYMin"><path d="M145 0 H188 V3616 H145z M145 0 H188 V3616 H145z"/></svg></span></span><span style="top:-7.6721em;"><span class="pstrut" style="height:5.6161em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.65em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span><span style="top:-3.45em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span><span style="top:-2.25em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span><span style="top:-1.05em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-1.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">3</span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-1.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">4</span></span></span><span style="top:-1.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-1.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.65em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span><span style="top:-3.45em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span><span style="top:-2.25em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span><span style="top:-1.05em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.662em;"><span style="top:-3.466em;"><span class="pstrut" style="height:5.6161em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-4.064em;"><span class="pstrut" style="height:5.6161em;"></span><span style="height:3.6161em;width:0.3333em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.3333em" height="3.6161em" style="width:0.3333em" viewbox="0 0 333.33000000000004 3616" preserveaspectratio="xMinYMin"><path d="M145 0 H188 V3616 H145z M145 0 H188 V3616 H145z"/></svg></span></span><span style="top:-7.6721em;"><span class="pstrut" style="height:5.6161em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel x-arrow"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0837em;"><span style="top:-3.322em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight x-arrow-pad"><span class="mord mtight"><span class="mord mathnormal mtight">in</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span><span class="mord mathnormal mtight">erse</span></span></span></span><span class="svg-align" style="top:-2.689em;"><span class="pstrut" style="height:2.7em;"></span><span class="hide-tail" style="height:0.522em;min-width:1.469em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="0.522em" viewbox="0 0 400000 522" preserveaspectratio="xMaxYMin slice"><path d="M0 241v40h399891c-47.3 35.3-84 78-110 128
-16.7 32-27.7 63.7-33 95 0 1.3-.2 2.7-.5 4-.3 1.3-.5 2.3-.5 3 0 7.3 6.7 11 20
 11 8 0 13.2-.8 15.5-2.5 2.3-1.7 4.2-5.5 5.5-11.5 2-13.3 5.7-27 11-41 14.7-44.7
 39-84.5 73-119.5s73.7-60.2 119-75.5c6-2 9-5.7 9-11s-3-9-9-11c-45.3-15.3-85
-40.5-119-75.5s-58.3-74.8-73-119.5c-4.7-14-8.3-27.3-11-40-1.3-6.7-3.2-10.8-5.5
-12.5-2.3-1.7-7.5-2.5-15.5-2.5-14 0-21 3.7-21 11 0 2 2 10.3 6 25 20.7 83.3 67
 151.7 139 205zm0 0v40h399900v-40z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.011em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:4.8121em;vertical-align:-2.15em;"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.662em;"><span style="top:-3.466em;"><span class="pstrut" style="height:5.6161em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-4.064em;"><span class="pstrut" style="height:5.6161em;"></span><span style="height:3.6161em;width:0.3333em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.3333em" height="3.6161em" style="width:0.3333em" viewbox="0 0 333.33000000000004 3616" preserveaspectratio="xMinYMin"><path d="M145 0 H188 V3616 H145z M145 0 H188 V3616 H145z"/></svg></span></span><span style="top:-7.6721em;"><span class="pstrut" style="height:5.6161em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.65em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span><span style="top:-3.45em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span><span style="top:-2.25em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span><span style="top:-1.05em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1/2</span></span></span><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-1.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1/3</span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-1.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1/4</span></span></span><span style="top:-1.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-1.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.65em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span><span style="top:-3.45em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span><span style="top:-2.25em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span><span style="top:-1.05em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.662em;"><span style="top:-3.466em;"><span class="pstrut" style="height:5.6161em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-4.064em;"><span class="pstrut" style="height:5.6161em;"></span><span style="height:3.6161em;width:0.3333em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.3333em" height="3.6161em" style="width:0.3333em" viewbox="0 0 333.33000000000004 3616" preserveaspectratio="xMinYMin"><path d="M145 0 H188 V3616 H145z M145 0 H188 V3616 H145z"/></svg></span></span><span style="top:-7.6721em;"><span class="pstrut" style="height:5.6161em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>于是乎，新的公式诞生啦：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msup><mover accent="true"><mi>D</mi><mo>~</mo></mover><mrow><mo>−</mo><mn>1</mn></mrow></msup><mo stretchy="false">(</mo><mover accent="true"><mi>A</mi><mo>~</mo></mover><mi>X</mi><mo stretchy="false">)</mo><mi>W</mi></mrow><annotation encoding="application/x-tex">\tilde D^{-1}(\tilde AX)W
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1702em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9202em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span></span><span style="top:-3.6023em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">~</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9202em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">A</span></span><span style="top:-3.6023em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1111em;"><span class="mord">~</span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span></span></span></span></span></p>
<p>但我们在这里仅仅对行进行了标准化，在列方向上并没有被标准化，所以，修正后的公式为：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mo stretchy="false">(</mo><msup><mover accent="true"><mi>D</mi><mo>~</mo></mover><mrow><mo>−</mo><mn>1</mn></mrow></msup><mover accent="true"><mi>A</mi><mo>~</mo></mover><msup><mover accent="true"><mi>D</mi><mo>~</mo></mover><mrow><mo>−</mo><mn>1</mn></mrow></msup><mo stretchy="false">)</mo><mi>X</mi><mi>W</mi><mspace linebreak="newline"></mspace><mi>L</mi><mi>e</mi><mi>t</mi><mtext>‘</mtext><mi>s</mi><mspace width="1em"><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi><mspace width="1em"><mover accent="true"><mi>A</mi><mo stretchy="true">^</mo></mover><mo>=</mo><mo stretchy="false">(</mo><msup><mover accent="true"><mi>D</mi><mo>~</mo></mover><mrow><mo>−</mo><mn>1</mn></mrow></msup><mover accent="true"><mi>A</mi><mo>~</mo></mover><msup><mover accent="true"><mi>D</mi><mo>~</mo></mover><mrow><mo>−</mo><mn>1</mn></mrow></msup><mo stretchy="false">)</mo></mspace></mspace></mrow><annotation encoding="application/x-tex">(\tilde D^{-1}\tilde A\tilde D^{-1})XW
\\
Let‘s\quad call\quad \widehat{A}=(\tilde D^{-1}\tilde A\tilde D^{-1})
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1702em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9202em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span></span><span style="top:-3.6023em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">~</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9202em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">A</span></span><span style="top:-3.6023em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1111em;"><span class="mord">~</span></span></span></span></span></span></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9202em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span></span><span style="top:-3.6023em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">~</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.9233em;"></span><span class="mord mathnormal">L</span><span class="mord mathnormal">e</span><span class="mord mathnormal">t</span><span class="mord">‘</span><span class="mord mathnormal">s</span><span class="mspace" style="margin-right:1em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.01968em;">ll</span><span class="mspace" style="margin-right:1em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9233em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">A</span></span><span class="svg-align" style="width:calc(100% - 0.2778em);margin-left:0.2778em;top:-3.6833em;"><span class="pstrut" style="height:3em;"></span><span style="height:0.24em;"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="0.24em" viewbox="0 0 1062 239" preserveaspectratio="none"><path d="M529 0h5l519 115c5 1 9 5 9 10 0 1-1 2-1 3l-4 22
c-1 5-5 9-11 9h-2L532 67 19 159h-2c-5 0-9-4-11-9l-5-22c-1-6 2-12 8-13z"/></svg></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1702em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9202em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span></span><span style="top:-3.6023em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">~</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9202em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">A</span></span><span style="top:-3.6023em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1111em;"><span class="mord">~</span></span></span></span></span></span></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9202em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span></span><span style="top:-3.6023em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">~</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
<p>当然了，行做了一次标准化，列做了一次标准化，那么对于元素<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>X</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">X_{ij}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span>来说，那就是做了两次标准化诶！我们再开个方吧:happy:</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mo stretchy="false">(</mo><msup><mover accent="true"><mi>D</mi><mo>~</mo></mover><mrow><mo>−</mo><mn>1</mn><mi mathvariant="normal">/</mi><mn>2</mn></mrow></msup><mover accent="true"><mi>A</mi><mo>~</mo></mover><msup><mover accent="true"><mi>D</mi><mo>~</mo></mover><mrow><mo>−</mo><mn>1</mn><mi mathvariant="normal">/</mi><mn>2</mn></mrow></msup><mo stretchy="false">)</mo><mi>X</mi><mi>W</mi><mspace linebreak="newline"></mspace><mi>L</mi><mi>e</mi><mi>t</mi><mtext>‘</mtext><mi>s</mi><mspace width="1em"><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi><mspace width="1em"><mover accent="true"><mi>A</mi><mo stretchy="true">^</mo></mover><mo>=</mo><mo stretchy="false">(</mo><msup><mover accent="true"><mi>D</mi><mo>~</mo></mover><mrow><mo>−</mo><mn>1</mn><mi mathvariant="normal">/</mi><mn>2</mn></mrow></msup><mover accent="true"><mi>A</mi><mo>~</mo></mover><msup><mover accent="true"><mi>D</mi><mo>~</mo></mover><mrow><mo>−</mo><mn>1</mn><mi mathvariant="normal">/</mi><mn>2</mn></mrow></msup><mo stretchy="false">)</mo></mspace></mspace></mrow><annotation encoding="application/x-tex">(\tilde D^{-1/2}\tilde A\tilde D^{-1/2})XW\\
Let‘s\quad call\quad \widehat{A}=(\tilde D^{-1/2}\tilde A\tilde D^{-1/2})
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.188em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9202em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span></span><span style="top:-3.6023em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">~</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1/2</span></span></span></span></span></span></span></span></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9202em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">A</span></span><span style="top:-3.6023em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1111em;"><span class="mord">~</span></span></span></span></span></span></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9202em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span></span><span style="top:-3.6023em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">~</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1/2</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.9233em;"></span><span class="mord mathnormal">L</span><span class="mord mathnormal">e</span><span class="mord mathnormal">t</span><span class="mord">‘</span><span class="mord mathnormal">s</span><span class="mspace" style="margin-right:1em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.01968em;">ll</span><span class="mspace" style="margin-right:1em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9233em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">A</span></span><span class="svg-align" style="width:calc(100% - 0.2778em);margin-left:0.2778em;top:-3.6833em;"><span class="pstrut" style="height:3em;"></span><span style="height:0.24em;"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="0.24em" viewbox="0 0 1062 239" preserveaspectratio="none"><path d="M529 0h5l519 115c5 1 9 5 9 10 0 1-1 2-1 3l-4 22
c-1 5-5 9-11 9h-2L532 67 19 159h-2c-5 0-9-4-11-9l-5-22c-1-6 2-12 8-13z"/></svg></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.188em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9202em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span></span><span style="top:-3.6023em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">~</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1/2</span></span></span></span></span></span></span></span></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9202em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">A</span></span><span style="top:-3.6023em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1111em;"><span class="mord">~</span></span></span></span></span></span></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9202em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span></span><span style="top:-3.6023em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">~</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1/2</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
<p>于是乎，最终可以得到以下的标准格式：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>Z</mi><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><mi>X</mi><mo separator="true">,</mo><mi>A</mi><mo stretchy="false">)</mo><mo>=</mo><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><mover accent="true"><mi>A</mi><mo stretchy="true">^</mo></mover><mi>R</mi><mi>e</mi><mi>L</mi><mi>U</mi><mo stretchy="false">(</mo><mover accent="true"><mi>A</mi><mo stretchy="true">^</mo></mover><mi>X</mi><msup><mi>W</mi><mrow><mo stretchy="false">(</mo><mn>0</mn><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">)</mo><msup><mi>W</mi><mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Z=f(X,A)=softmax(\widehat A ReLU(\widehat AXW^{(0)})W^{(1)})
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">A</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.188em;vertical-align:-0.25em;"></span><span class="mord mathnormal">so</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">t</span><span class="mord mathnormal">ma</span><span class="mord mathnormal">x</span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9233em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">A</span></span><span class="svg-align" style="width:calc(100% - 0.2778em);margin-left:0.2778em;top:-3.6833em;"><span class="pstrut" style="height:3em;"></span><span style="height:0.24em;"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="0.24em" viewbox="0 0 1062 239" preserveaspectratio="none"><path d="M529 0h5l519 115c5 1 9 5 9 10 0 1-1 2-1 3l-4 22
c-1 5-5 9-11 9h-2L532 67 19 159h-2c-5 0-9-4-11-9l-5-22c-1-6 2-12 8-13z"/></svg></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.10903em;">LU</span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9233em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">A</span></span><span class="svg-align" style="width:calc(100% - 0.2778em);margin-left:0.2778em;top:-3.6833em;"><span class="pstrut" style="height:3em;"></span><span style="height:0.24em;"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="0.24em" viewbox="0 0 1062 239" preserveaspectratio="none"><path d="M529 0h5l519 115c5 1 9 5 9 10 0 1-1 2-1 3l-4 22
c-1 5-5 9-11 9h-2L532 67 19 159h-2c-5 0-9-4-11-9l-5-22c-1-6 2-12 8-13z"/></svg></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">0</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi></mrow><annotation encoding="application/x-tex">W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span></span></span></span>是可训练的权重，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>A</mi><mo stretchy="true">^</mo></mover></mrow><annotation encoding="application/x-tex">\widehat A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9233em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9233em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">A</span></span><span class="svg-align" style="width:calc(100% - 0.2778em);margin-left:0.2778em;top:-3.6833em;"><span class="pstrut" style="height:3em;"></span><span style="height:0.24em;"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="0.24em" viewbox="0 0 1062 239" preserveaspectratio="none"><path d="M529 0h5l519 115c5 1 9 5 9 10 0 1-1 2-1 3l-4 22
c-1 5-5 9-11 9h-2L532 67 19 159h-2c-5 0-9-4-11-9l-5-22c-1-6 2-12 8-13z"/></svg></span></span></span></span></span></span></span></span></span>是标准化后的邻接矩阵。</p>
<p>此时我们在回过头来看这个图卷积算子，是不是有些恍然大悟了呢🤔</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msubsup><mi>h</mi><mi>i</mi><mrow><mi>l</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><munder><mo>∑</mo><mrow><mi>j</mi><mo>∈</mo><msub><mi>N</mi><mi>i</mi></msub></mrow></munder><mfrac><mn>1</mn><msub><mi>C</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mfrac><msubsup><mi>h</mi><mi>j</mi><mi>l</mi></msubsup><msubsup><mi>w</mi><msub><mi>R</mi><mi>j</mi></msub><mi>l</mi></msubsup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">h_i^{l+1}=\sigma(\sum_{j\in N_i}\frac{1}{C_{ij}}h_j^lw_{R_j}^l)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1661em;vertical-align:-0.267em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8991em;"><span style="top:-2.433em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.267em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.7519em;vertical-align:-1.4304em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.8557em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">∈</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.4304em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9721em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8991em;"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3831em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8991em;"><span style="top:-2.453em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.0077em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2819em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4443em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
<p>Thomas经过实验比对，浅层的GCN(一般为2层)取得的效果往往要比没有加入残差块的深层GCN来的好。GCN的网络层数代表着节点特征所能到达的最远距离，或者说节点信息的传播距离。深层的网络可能会令节点信息传播到整个网络，反而效果不那么好。</p>
<p>举个简单的栗子~🐈</p>
<p>假设有邻接矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span>：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>A</mi><mo>=</mo><mrow><mo fence="true">∣</mo><mtable rowspacing="0.16em" columnalign="center center center center center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd></mtr></mtable><mo fence="true">∣</mo></mrow></mrow><annotation encoding="application/x-tex">A=\begin{vmatrix}
&amp;0&amp;1&amp;0&amp;0&amp;\\
&amp;1&amp;0&amp;1&amp;1&amp;\\
&amp;0&amp;1&amp;0&amp;1&amp;\\
&amp;0&amp;1&amp;1&amp;1&amp;\\
\end{vmatrix}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:4.8121em;vertical-align:-2.15em;"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.662em;"><span style="top:-3.466em;"><span class="pstrut" style="height:5.6161em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-4.064em;"><span class="pstrut" style="height:5.6161em;"></span><span style="height:3.6161em;width:0.3333em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.3333em" height="3.6161em" style="width:0.3333em" viewbox="0 0 333.33000000000004 3616" preserveaspectratio="xMinYMin"><path d="M145 0 H188 V3616 H145z M145 0 H188 V3616 H145z"/></svg></span></span><span style="top:-7.6721em;"><span class="pstrut" style="height:5.6161em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.65em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span><span style="top:-3.45em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span><span style="top:-2.25em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span><span style="top:-1.05em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-1.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span><span style="top:-1.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-1.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span><span style="top:-1.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65em;"><span style="top:-4.65em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span><span style="top:-3.45em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span><span style="top:-2.25em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span><span style="top:-1.05em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.662em;"><span style="top:-3.466em;"><span class="pstrut" style="height:5.6161em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-4.064em;"><span class="pstrut" style="height:5.6161em;"></span><span style="height:3.6161em;width:0.3333em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.3333em" height="3.6161em" style="width:0.3333em" viewbox="0 0 333.33000000000004 3616" preserveaspectratio="xMinYMin"><path d="M145 0 H188 V3616 H145z M145 0 H188 V3616 H145z"/></svg></span></span><span style="top:-7.6721em;"><span class="pstrut" style="height:5.6161em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15em;"><span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>对于节点<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">A_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>来说，跟他接轨的只有节点<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">A_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，那么在第一层计算后，节点<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">A_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>聚合了来自节点<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">A_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的特征。而对于节点<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">A_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，与之接轨的则有节点<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>A</mi><mn>3</mn></msub><mo separator="true">,</mo><msub><mi>A</mi><mn>4</mn></msub></mrow><annotation encoding="application/x-tex">A_1,A_3,A_4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，经过第一层后，该节点聚合了所有节点的信息。那么在第二层，由于图结构不是动态更新的，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">A_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>又会聚合<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">A_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的特征信息，但此时的<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">A_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>已经聚合了<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mn>3</mn></msub><mo separator="true">,</mo><msub><mi>A</mi><mn>4</mn></msub></mrow><annotation encoding="application/x-tex">A_3,A_4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的特征信息！换言之，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">A_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>感受到了来自远方的召唤！(<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mn>3</mn></msub><mo separator="true">,</mo><msub><mi>A</mi><mn>4</mn></msub></mrow><annotation encoding="application/x-tex">A_3,A_4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的信息经过两层网络后传递到了<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">A_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>处，传递过程类似于并查集啦)</p>
<p>最后对于这些分类任务，采用交叉熵函数作为损失函数，计算获取最可能的情况即可。</p>
<hr>
<h2 id="二、基于PyG的图卷积神经网络半监督分类">二、基于PyG的图卷积神经网络半监督分类</h2>
<h3 id="2-1-模型准备">2.1  模型准备</h3>
<p>模块导入阶段，在本实验中，<code>networkx</code>主要用于图结构可视化，<code>argparse</code>用于参数的读写</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> GCNConv</span><br><span class="line"><span class="keyword">from</span> torch_geometric.datasets <span class="keyword">import</span> Planetoid</span><br><span class="line"><span class="keyword">from</span> torch_geometric.utils <span class="keyword">import</span> to_networkx</span><br><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="keyword">from</span> sklearn.manifold <span class="keyword">import</span> TSNE</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"><span class="keyword">from</span> sklearn.semi_supervised <span class="keyword">import</span> _label_propagation</span><br><span class="line"><span class="keyword">import</span> argparse</span><br></pre></td></tr></table></figure>
<h3 id="2-2-数据探查">2.2  数据探查</h3>
<p>我们导入Cora数据集。</p>
<p>Cora数据集由2078篇机器学习领域的论文构成，每个样本点都是一篇论文，这些论文主要分为了7个类别，分别为基于案例、遗传算法、神经网络、概率方法、强化学习、规则学习与理论。在该数据集中，每篇论文都至少引用了该数据集中的另一篇论文，对每个节点所代表的论文，都由一个1433维的词向量表示，即该图上每个节点都具有1433个特征，词向量的每个元素都对应一个词，且该元素仅有0或1两个取值，取0表示该元素对应的词不在论文中，取1表示在。</p>
<h3 id="Cora参数-v2">Cora参数</h3>
<ul>
<li><strong>ind.cora.x</strong> : 训练集节点特征向量，保存对象为：scipy.sparse.csr.csr_matrix，实际展开后大小为： (140, 1433)</li>
<li><strong>ind.cora.tx</strong> : 测试集节点特征向量，保存对象为：scipy.sparse.csr.csr_matrix，实际展开后大小为： (1000, 1433)</li>
<li><strong>ind.cora.allx</strong> : 包含有标签和无标签的训练节点特征向量，保存对象为：scipy.sparse.csr.csr_matrix，实际展开后大小为：(1708, 1433)，可以理解为除测试集以外的其他节点特征集合，训练集是它的子集</li>
<li><strong>ind.cora.y</strong> : one-hot表示的训练节点的标签，保存对象为：numpy.ndarray</li>
<li><strong>ind.cora.ty</strong> : one-hot表示的测试节点的标签，保存对象为：numpy.ndarray</li>
<li><strong>ind.cora.ally</strong> : one-hot表示的ind.cora.allx对应的标签，保存对象为：numpy.ndarray</li>
<li><strong>ind.cora.graph</strong> : 保存节点之间边的信息，保存格式为：{ index : [ index_of_neighbor_nodes ] }</li>
<li><strong>ind.cora.test.index</strong> : 保存测试集节点的索引，保存对象为：List，用于后面的归纳学习设置。</li>
</ul>
<p>通过以下语句下载或读取，若当前路径下没有找到文件，则会自动下载。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入Cora数据集</span></span><br><span class="line">dataset=Planetoid(root=<span class="string">r&quot;./Cora&quot;</span>,name=<span class="string">&quot;Cora&quot;</span>) <span class="comment"># root: 指定路径 name: 数据集名称</span></span><br><span class="line"><span class="comment"># 查看数据的基本情况</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;网络数据包含的类数量:&quot;</span>,dataset.num_classes)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;网络数据边的特征数量:&quot;</span>,dataset.num_edge_features)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;网络数据边的数量:&quot;</span>,dataset.data.edge_index.shape[<span class="number">1</span>]/<span class="number">2</span>) <span class="comment"># 除以2是OOC的组织形式</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;网络数据节点的特征数量:&quot;</span>,dataset.num_node_features)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;网络数据节点的数量:&quot;</span>,dataset.data.x.shape[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<p>输出的结果为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">网络数据包含的类数量: <span class="number">7</span></span><br><span class="line">网络数据边的特征数量: <span class="number">0</span></span><br><span class="line">网络数据边的数量: <span class="number">5278.0</span></span><br><span class="line">网络数据节点的特征数量: <span class="number">1433</span></span><br><span class="line">网络数据节点的数量: <span class="number">2708</span></span><br><span class="line">网络的边的数量:  <span class="number">5278</span></span><br><span class="line">网络的节点的数量:  <span class="number">2708</span></span><br></pre></td></tr></table></figure>
<p>我们可以看到，Cora数据集囊括了七个类共2708个节点，每个节点都带有1433个特征，一共有5278条边，边没有包含特征。</p>
<p>重点来看<code>dataset.data</code>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Data(x=[<span class="number">2708</span>, <span class="number">1433</span>], edge_index=[<span class="number">2</span>, <span class="number">10556</span>], y=[<span class="number">2708</span>], train_mask=[<span class="number">2708</span>], val_mask=[<span class="number">2708</span>], test_mask=[<span class="number">2708</span>])</span><br></pre></td></tr></table></figure>
<p>该数据中的x是节点和对应的特征矩阵，y是标签值，edge_index则是COO的网络连接格式(第一行表示节点顺序，第二行表示连接对象，因而每条边会出现两次)，mask对象则是一个逻辑向量(与节点数量相同)，表示该节点的用途。</p>
<h3 id="2-3-结构可视化">2.3  结构可视化</h3>
<p>为了更直观地分析数据，我们可以考虑将图结构可视化，但使用张量格式的数据十分不方便，PyG提供了<code>to_networkx()</code>函数，可用于将<code>torch_geometric.data.Data</code>对象转化为<code>networkx</code>库中的有向图数据，方便进一步的分析和可视化。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过networkx库进行可视化</span></span><br><span class="line">CoraNet=to_networkx(dataset.data) <span class="comment"># type : networkx.classes.graph.Graph</span></span><br><span class="line">CoraNet=CoraNet.to_undirected() <span class="comment"># 转化为无向图</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看网络情况</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;网络的边的数量: &quot;</span>,CoraNet.number_of_edges())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;网络的节点的数量: &quot;</span>,CoraNet.number_of_nodes())</span><br><span class="line">Node_class=dataset.data.y.data.numpy()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;节点分类:&quot;</span>,Node_class)</span><br></pre></td></tr></table></figure>
<p>结果为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">网络的边的数量:  <span class="number">5278</span></span><br><span class="line">网络的节点的数量:  <span class="number">2708</span></span><br><span class="line">节点分类: [<span class="number">3</span> <span class="number">4</span> <span class="number">4</span> ... <span class="number">3</span> <span class="number">3</span> <span class="number">3</span>]</span><br></pre></td></tr></table></figure>
<p>此时数据已经由<code>Tensor</code>格式转化为<code>Graph</code>格式啦，并且我们将标签<code>y</code>单独提取出来，方便接下来的操作。</p>
<p>在<code>Graph</code>类中，我们可以使用<code>Graph.degree</code>方法计算度，度越大的节点，说明跟其他节点的连通性越好，在整个网络中具有更大的贡献度，即越重要。下面我们对前三十的节点进行可视化：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 计算节点的度</span></span><br><span class="line">Node_degree=pd.DataFrame(data=CoraNet.degree,columns=[<span class="string">&quot;Node&quot;</span>,<span class="string">&quot;Degree&quot;</span>])</span><br><span class="line">Node_degree=Node_degree.sort_values(by=[<span class="string">&quot;Degree&quot;</span>],ascending=<span class="literal">False</span>)</span><br><span class="line">Node_degree=Node_degree.reset_index(drop=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用直方图可视化度较多的前三十个节点</span></span><br><span class="line">Node_degree.iloc[<span class="number">0</span>:<span class="number">30</span>,:].plot(x=<span class="string">&quot;Node&quot;</span>,y=<span class="string">&quot;Degree&quot;</span>,kind=<span class="string">&quot;bar&quot;</span>,figsize=(<span class="number">10</span>,<span class="number">7</span>))</span><br><span class="line">plt.xlabel(<span class="string">&quot;Node&quot;</span>,size=<span class="number">12</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Degree&quot;</span>,size=<span class="number">12</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<img src="/2022/07/29/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E5%9B%BE%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20220614200700531.png" alt="image-20220614200700531" style="zoom:50%;">
<p>接着借助<code>networkx</code>库对网络结构进行可视化，<code>nx.spring_layout(Graph)</code>会自动计算网络节点中的布局方式，我们需要做的事情有：</p>
<ul>
<li>为不同类的节点指定不同的颜色
<ul>
<li><code>draw_networkx_nodes(Graph,pos,nodelist,nodesize,node_color,alpha)</code>可用于以特定颜色绘制一张图里面的指定索引的节点</li>
</ul>
</li>
<li>为网络添加边
<ul>
<li><code>draw_networkx_edges(Graph,pos,width,edge_color)</code>用于绘制图结构的边</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># nx图结构可视化</span></span><br><span class="line">pos=nx.spring_layout(CoraNet) <span class="comment"># 网络图中节点的布局方式</span></span><br><span class="line">nodecolor=[<span class="string">&quot;red&quot;</span>,<span class="string">&quot;blue&quot;</span>,<span class="string">&quot;green&quot;</span>,<span class="string">&quot;yellow&quot;</span>,<span class="string">&quot;peru&quot;</span>,<span class="string">&quot;violet&quot;</span>,<span class="string">&quot;cyan&quot;</span>]</span><br><span class="line">nodelabel=np.array(<span class="built_in">list</span>(CoraNet.nodes))</span><br><span class="line">plt.figure(figsize=(<span class="number">16</span>,<span class="number">12</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 不同的类使用不同的颜色</span></span><br><span class="line"><span class="keyword">for</span> ii <span class="keyword">in</span> np.arange(<span class="built_in">len</span>(np.unique(Node_class))):</span><br><span class="line">    nodelist=nodelabel[Node_class==ii]</span><br><span class="line">    <span class="comment"># 绘制节点</span></span><br><span class="line">    nx.draw_networkx_nodes(CoraNet,pos,nodelist=<span class="built_in">list</span>(nodelist),node_size=<span class="number">20</span>,</span><br><span class="line">                           node_color=nodecolor[ii],alpha=<span class="number">0.8</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 为网络添加边</span></span><br><span class="line">nx.draw_networkx_edges(CoraNet,pos,width=<span class="number">1</span>,edge_color=<span class="string">&quot;gray&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>结果如下图所示：</p>
<img src="/2022/07/29/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E5%9B%BE%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20220614200734449.png" alt="image-20220614200734449" style="zoom: 25%;">
<p>我们可以再对训练集单独绘制一下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 可视化训练集的节点分布</span></span><br><span class="line">nodelabel=np.arange(<span class="number">0</span>,<span class="number">140</span>) <span class="comment"># 训练集节点位置</span></span><br><span class="line">Node_class=dataset.data.y.data.numpy()[<span class="number">0</span>:<span class="number">140</span>]</span><br><span class="line"><span class="comment"># nx可视化</span></span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>,<span class="number">6</span>))</span><br><span class="line"><span class="keyword">for</span> ii <span class="keyword">in</span> np.arange(<span class="built_in">len</span>(np.unique(Node_class))):</span><br><span class="line">    nodelist=nodelabel[Node_class==ii]</span><br><span class="line">    <span class="comment"># 绘制节点</span></span><br><span class="line">    nx.draw_networkx_nodes(CoraNet,pos,nodelist=<span class="built_in">list</span>(nodelist),node_size=<span class="number">20</span>,</span><br><span class="line">                           node_color=nodecolor[ii],alpha=<span class="number">0.8</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>简单来说，训练集的分布大致体现了原始数据的分布</p>
<img src="/2022/07/29/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E5%9B%BE%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20220614200756459.png" alt="image-20220614200756459" style="zoom: 50%;">
<h3 id="2-4-网络搭建">2.4  网络搭建</h3>
<p>我们这边直接使用PyG的GCNConv进行搭建：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">GCNNet</span>(torch.nn.Module):</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,input_feature,num_classes</span>):</span><br><span class="line">            <span class="built_in">super</span>(GCNNet, self).__init__()</span><br><span class="line">            self.input_feature=input_feature</span><br><span class="line">            self.num_classes=num_classes</span><br><span class="line">            <span class="comment"># 这里我们用了两个图卷积层</span></span><br><span class="line">            <span class="comment"># 1433-&gt;32</span></span><br><span class="line">            self.conv1=GCNConv(input_feature,<span class="number">32</span>)</span><br><span class="line">            <span class="comment"># 32-&gt;num_classes</span></span><br><span class="line">            self.conv2=GCNConv(<span class="number">32</span>,num_classes)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,data</span>):</span><br><span class="line">            x,edge_index=data.x,data.edge_index</span><br><span class="line">            <span class="comment"># 需要输入的是节点的数据(index,feature)</span></span><br><span class="line">            <span class="comment"># 以及边索引COO，用于构建邻接矩阵和入度矩阵</span></span><br><span class="line">            x=F.relu(self.conv1(x,edge_index))</span><br><span class="line">            x=F.relu(self.conv2(x,edge_index))</span><br><span class="line">            <span class="keyword">return</span> F.softmax(x,dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h3 id="2-5-网络训练">2.5  网络训练</h3>
<p>在进行训练前，需要先设定好全局变量，这里我们使用<code>argparse</code>库进行操作。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">parse_args</span>():</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;PARAMETERS&#x27;&#x27;&#x27;</span></span><br><span class="line">    parser=argparse.ArgumentParser(<span class="string">&quot;GCN&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;-e&#x27;</span>,<span class="string">&#x27;--epochs&#x27;</span>,<span class="built_in">type</span>=<span class="built_in">int</span>,default=<span class="number">500</span>,<span class="built_in">help</span>=<span class="string">&#x27;number of epoch in training [default: 200]&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;-lr&#x27;</span>,<span class="string">&#x27;--learning_rate&#x27;</span>,<span class="built_in">type</span>=<span class="built_in">float</span>,default=<span class="number">0.01</span>, <span class="built_in">help</span>=<span class="string">&#x27;learning rate in training [default: 0.01]&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;-op&#x27;</span>,<span class="string">&#x27;--optimizer&#x27;</span>,<span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;Adam&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;optimizer for training [default: Adam]&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;-g&#x27;</span>,<span class="string">&#x27;--gpu&#x27;</span>,<span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;0&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;specify gpu device [default: 0]&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;-p&#x27;</span>,<span class="string">&#x27;--path&#x27;</span>,<span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;./save&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;the path of file saving [default: ./save]&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;-dr&#x27;</span>,<span class="string">&#x27;--decay_rate&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">5e-4</span>, <span class="built_in">help</span>=<span class="string">&#x27;decay rate [default: 5e-4]&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> parser.parse_args()</span><br></pre></td></tr></table></figure>
<p>我们可以定义一个保存路径，用于存放最优的模型参数和最优的优化器参数，譬如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 环境</span></span><br><span class="line">    args = args</span><br><span class="line">    savepath = args.path</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(savepath):</span><br><span class="line">        os.makedirs(savepath)</span><br><span class="line">        </span><br><span class="line"><span class="comment"># 保存</span></span><br><span class="line">    <span class="keyword">if</span> 当前精度&gt;最优精度:</span><br><span class="line">            sp=savepath+<span class="string">&quot;/best_model.pth&quot;</span></span><br><span class="line">            state=&#123;</span><br><span class="line">                <span class="string">&quot;epoch&quot;</span>:epoch,</span><br><span class="line">                <span class="string">&quot;accuracy&quot;</span>:acc,</span><br><span class="line">                <span class="string">&quot;model_state_dict&quot;</span>:model.state_dict(),</span><br><span class="line">                <span class="string">&quot;optimizer_state_dict&quot;</span>:optimizer.state_dict()</span><br><span class="line">            &#125;</span><br><span class="line">            torch.save(state,sp)</span><br><span class="line">            best_acc = acc</span><br><span class="line"><span class="comment"># 读取</span></span><br><span class="line"> <span class="comment"># 读取模型</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        checkpoint=torch.load(savepath+<span class="string">&quot;/best_model.pth&quot;</span>)</span><br><span class="line">        mygcn.load_state_dict(checkpoint[<span class="string">&#x27;model_state_dict&#x27;</span>])</span><br><span class="line">        start_epoch = checkpoint[<span class="string">&#x27;epoch&#x27;</span>]</span><br><span class="line">        optimizer.load_state_dict(checkpoint[<span class="string">&#x27;optimizer_state_dict&#x27;</span>])</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        mygcn=GCNNet(input_feature,num_classes)</span><br><span class="line">        start_epoch=<span class="number">0</span></span><br></pre></td></tr></table></figure>
<p>那首先进行网络的初始化</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 初始化网络</span></span><br><span class="line">   args = args</span><br><span class="line">   savepath = args.path</span><br><span class="line"></span><br><span class="line">   <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(savepath):</span><br><span class="line">       os.makedirs(savepath)</span><br><span class="line"></span><br><span class="line">   input_feature = dataset.num_node_features</span><br><span class="line">   num_classes = dataset.num_classes</span><br><span class="line">   mygcn = GCNNet(input_feature, num_classes)</span><br><span class="line">   model=mygcn</span><br><span class="line">   data = dataset[<span class="number">0</span>]</span><br><span class="line">   os.environ[<span class="string">&quot;CUDA_VISIBLE_DEVICES&quot;</span>] = args.gpu</span><br></pre></td></tr></table></figure>
<p>接着咱定义优化器</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 优化器</span></span><br><span class="line">    <span class="keyword">if</span> args.optimizer == <span class="string">&#x27;Adam&#x27;</span>:</span><br><span class="line">        optimizer = torch.optim.Adam(</span><br><span class="line">            model.parameters(),</span><br><span class="line">            lr=args.learning_rate,</span><br><span class="line">            <span class="comment"># betas=(0.9, 0.999),</span></span><br><span class="line">            <span class="comment"># eps=1e-08,</span></span><br><span class="line">            weight_decay=args.decay_rate</span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        optimizer = torch.optim.SGD(model.parameters(), lr=<span class="number">0.01</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>再来读取模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 读取模型</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        checkpoint=torch.load(savepath+<span class="string">&quot;/best_model.pth&quot;</span>)</span><br><span class="line">        mygcn.load_state_dict(checkpoint[<span class="string">&#x27;model_state_dict&#x27;</span>])</span><br><span class="line">        start_epoch = checkpoint[<span class="string">&#x27;epoch&#x27;</span>]</span><br><span class="line">        optimizer.load_state_dict(checkpoint[<span class="string">&#x27;optimizer_state_dict&#x27;</span>])</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        mygcn=GCNNet(input_feature,num_classes)</span><br><span class="line">        start_epoch=<span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(mygcn)</span><br></pre></td></tr></table></figure>
<p>此时的输出为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">GCNNet(</span></span><br><span class="line"><span class="string">  (conv1): GCNConv(1433, 32)</span></span><br><span class="line"><span class="string">  (conv2): GCNConv(32, 7)</span></span><br><span class="line"><span class="string">)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>接下来，我们再进行网络的训练：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 网络训练</span></span><br><span class="line">   train_loss_all=[]</span><br><span class="line">   val_loss_all=[]</span><br><span class="line">   best_acc=<span class="number">0</span></span><br><span class="line">   train_acc_all=[]</span><br><span class="line">   model.train()</span><br><span class="line"></span><br><span class="line">   <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(start_epoch,args.epochs):</span><br><span class="line">       optimizer.zero_grad()</span><br><span class="line">       out=model(data)</span><br><span class="line">       loss=F.cross_entropy(out[data.train_mask],data.y[data.train_mask])</span><br><span class="line">       loss.backward()</span><br><span class="line">       optimizer.step()</span><br><span class="line"></span><br><span class="line">       train_loss_all.append(loss.data.cpu().numpy())</span><br><span class="line"></span><br><span class="line">       <span class="comment"># 计算在验证集上的损失</span></span><br><span class="line">       loss=F.cross_entropy(out[data.val_mask],data.y[data.val_mask])</span><br><span class="line">       val_loss_all.append(loss.data.cpu().numpy())</span><br><span class="line">       _,pred=out.<span class="built_in">max</span>(dim=<span class="number">1</span>)</span><br><span class="line">       acc=<span class="built_in">float</span>(pred[data.train_mask].eq(data.y[data.train_mask]).<span class="built_in">sum</span>().item())/data.train_mask.<span class="built_in">sum</span>().item()</span><br><span class="line">       train_acc_all.append(acc)</span><br><span class="line"></span><br><span class="line">       <span class="keyword">if</span> acc&gt;best_acc:</span><br><span class="line">           sp=savepath+<span class="string">&quot;/best_model.pth&quot;</span></span><br><span class="line">           state=&#123;</span><br><span class="line">               <span class="string">&quot;epoch&quot;</span>:epoch,</span><br><span class="line">               <span class="string">&quot;accuracy&quot;</span>:acc,</span><br><span class="line">               <span class="string">&quot;model_state_dict&quot;</span>:model.state_dict(),</span><br><span class="line">               <span class="string">&quot;optimizer_state_dict&quot;</span>:optimizer.state_dict()</span><br><span class="line">           &#125;</span><br><span class="line">           torch.save(state,sp)</span><br><span class="line">           best_acc = acc</span><br><span class="line"></span><br><span class="line">       <span class="keyword">if</span> epoch%<span class="number">20</span>==<span class="number">0</span>:</span><br><span class="line">           <span class="built_in">print</span>(<span class="string">&quot;Epoch:&quot;</span>,epoch,<span class="string">&quot;;Train Loss:&quot;</span>,train_loss_all[-<span class="number">1</span>],<span class="string">&quot;;Val Loss:&quot;</span>,val_loss_all[-<span class="number">1</span>],<span class="string">&quot;Train acc:&quot;</span>,train_acc_all[-<span class="number">1</span>])</span><br></pre></td></tr></table></figure>
<p>最后自然是结果的可视化啦：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 可视化损失函数变化</span></span><br><span class="line">   plt.figure(figsize=(<span class="number">10</span>,<span class="number">6</span>))</span><br><span class="line">   plt.plot(train_loss_all,<span class="string">&quot;ro-&quot;</span>,label=<span class="string">&quot;Train Loss&quot;</span>)</span><br><span class="line">   plt.plot(val_loss_all,<span class="string">&quot;bs-&quot;</span>,label=<span class="string">&quot;Val Loss&quot;</span>)</span><br><span class="line">   plt.legend()</span><br><span class="line">   plt.grid()</span><br><span class="line">   plt.xlabel(<span class="string">&quot;epoch&quot;</span>,size=<span class="number">13</span>)</span><br><span class="line">   plt.ylabel(<span class="string">&quot;loss&quot;</span>,size=<span class="number">13</span>)</span><br><span class="line">   plt.title(<span class="string">&quot;Graph Convolutional Networks&quot;</span>,size=<span class="number">14</span>)</span><br><span class="line">   plt.show()</span><br><span class="line"></span><br><span class="line">   <span class="comment"># 计算预测精度</span></span><br><span class="line">   model.<span class="built_in">eval</span>()</span><br><span class="line">   _,pred=model(data).<span class="built_in">max</span>(dim=<span class="number">1</span>)</span><br><span class="line">   correct=<span class="built_in">float</span>(pred[data.test_mask].eq(data.y[data.test_mask]).<span class="built_in">sum</span>().item())</span><br><span class="line">   acc=correct/data.test_mask.<span class="built_in">sum</span>().item()</span><br><span class="line">   <span class="built_in">print</span>(<span class="string">&quot;Accuracy: &#123;:.4f&#125;&quot;</span>.<span class="built_in">format</span>(acc))</span><br></pre></td></tr></table></figure>
<img src="/2022/07/29/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E5%9B%BE%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20220614211702630.png" alt="image-20220614211702630" style="zoom:50%;">
<p>可以发现，到200个epoch后，模型已经收敛。当然有很大程度上是因为我们并没有随机取出数据集(用的是固定顺序)，最终的精度结果为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Accuracy: <span class="number">0.8060</span></span><br></pre></td></tr></table></figure>
<p>为了直观体现网络的特征提取能力，我们对隐藏层获得的32维特征在空间中的分布情况进行可视化,与原始数据1433维进行比较，统一使用TSNE算法降到二维。首先我们先定义一个用于TSNE绘制的函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对原始数据分布进行展示</span></span><br><span class="line">   <span class="keyword">def</span> <span class="title function_">draw</span>(<span class="params">x_tsne,text</span>):</span><br><span class="line">       plt.figure(figsize=(<span class="number">12</span>, <span class="number">8</span>))</span><br><span class="line">       axl = plt.subplot(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">       X = x_tsne[:, <span class="number">0</span>]</span><br><span class="line">       Y = x_tsne[:, <span class="number">1</span>]</span><br><span class="line">       axl.set_xlim([<span class="built_in">min</span>(X), <span class="built_in">max</span>(X)])</span><br><span class="line">       axl.set_ylim([<span class="built_in">min</span>(Y), <span class="built_in">max</span>(Y)])</span><br><span class="line"></span><br><span class="line">       <span class="keyword">for</span> ii <span class="keyword">in</span> <span class="built_in">range</span>(x_tsne.shape[<span class="number">0</span>]):</span><br><span class="line">           text = data.y.data.numpy()[ii]</span><br><span class="line">           axl.text(X[ii], Y[ii], <span class="built_in">str</span>(text), fontsize=<span class="number">5</span>,</span><br><span class="line">                    bbox=<span class="built_in">dict</span>(boxstyle=<span class="string">&quot;round&quot;</span>, facecolor=plt.cm.Set1(text), alpha=<span class="number">0.7</span>))</span><br><span class="line"></span><br><span class="line">       axl.set_xlabel(<span class="string">&quot;TSNE Feature 1&quot;</span>, size=<span class="number">13</span>)</span><br><span class="line">       axl.set_xlabel(<span class="string">&quot;TSNE Feature 2&quot;</span>, size=<span class="number">13</span>)</span><br><span class="line">       axl.set_title(t, size=<span class="number">15</span>)</span><br><span class="line">       plt.show()</span><br></pre></td></tr></table></figure>
<p>我们来绘制原始数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x_tsne=TSNE(n_components=<span class="number">2</span>).fit_transform(dataset.data.x.data.numpy())</span><br><span class="line">    draw(x_tsne,<span class="string">&quot;Original feature TSNE&quot;</span>)</span><br></pre></td></tr></table></figure>
<img src="/2022/07/29/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E5%9B%BE%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20220614212707458.png" alt="image-20220614212707458" style="zoom: 33%;">
<p>接着呢，利用<code>hook</code>函数获取中间层的输入，板子如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对中间层32维数据进行可视化</span></span><br><span class="line">   activation=&#123;&#125; <span class="comment"># 保存不同层的输出</span></span><br><span class="line">   <span class="keyword">def</span> <span class="title function_">get_activation</span>(<span class="params">name</span>):</span><br><span class="line">       <span class="keyword">def</span> <span class="title function_">hook</span>(<span class="params">model,<span class="built_in">input</span>,output</span>):</span><br><span class="line">           activation[name]=output.detach()</span><br><span class="line">       <span class="keyword">return</span> hook</span><br><span class="line">   </span><br><span class="line">   model.conv1.register_forward_hook(get_activation(<span class="string">&quot;conv1&quot;</span>))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 绘制32维特征</span></span><br><span class="line">    _=model(data)</span><br><span class="line">    conv1=activation[<span class="string">&quot;conv1&quot;</span>].data.cpu().numpy()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;conv1.shape: &quot;</span>,conv1.shape)</span><br><span class="line"></span><br><span class="line">    x_tsne=TSNE(n_components=<span class="number">2</span>).fit_transform(conv1)</span><br><span class="line">    draw(x_tsne,<span class="string">&quot;GCNConv Feature TSNE&quot;</span>)</span><br></pre></td></tr></table></figure>
<img src="/2022/07/29/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E5%9B%BE%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20220614212727353.png" alt="image-20220614212727353" style="zoom:33%;">
<p>可以发现，在高维特征中挖掘出了每个类的潜在关系。</p>
<h3 id="2-6-模型比较">2.6  模型比较</h3>
<p>我们再用GCN对比下传统的SVM和LP(Label Propagation)算法:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用SVM进行计算</span></span><br><span class="line">   X=dataset.data.x.data.numpy()</span><br><span class="line">   Y=dataset.data.y.data.numpy()</span><br><span class="line"></span><br><span class="line">   train_mask=dataset.data.train_mask.data.numpy()</span><br><span class="line">   test_mask=dataset.data.test_mask.data.numpy()</span><br><span class="line"></span><br><span class="line">   train_x=X[:<span class="number">140</span>,:]</span><br><span class="line">   train_y=Y[train_mask]</span><br><span class="line">   test_x=X[<span class="number">1708</span>:<span class="number">2709</span>,:]</span><br><span class="line">   test_y=Y[test_mask]</span><br><span class="line"></span><br><span class="line">   svmmodel=SVC()</span><br><span class="line">   svmmodel.fit(train_x,train_y)</span><br><span class="line">   prelab=svmmodel.predict(test_x)</span><br><span class="line">   <span class="built_in">print</span>(<span class="string">&quot;SVM的预测精度：&quot;</span>,accuracy_score(test_y,prelab))</span><br></pre></td></tr></table></figure>
<p>最终的结果为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SVM的预测精度： <span class="number">0.56</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用LabelPropagation模型进行计算</span></span><br><span class="line"><span class="comment"># 对于不是有监督的训练数据的样本标签使用-1表示</span></span><br><span class="line">   train_y=Y.copy()</span><br><span class="line">   train_y[test_mask==<span class="literal">True</span>]=-<span class="number">1</span> <span class="comment"># 使用非测试数据作为由表亲啊的训练集</span></span><br><span class="line">   <span class="comment"># 预测数据</span></span><br><span class="line">   test_y=Y[test_mask]</span><br><span class="line">   lp_model=_label_propagation.LabelPropagation(kernel=<span class="string">&quot;knn&quot;</span>,n_neighbors=<span class="number">3</span>)</span><br><span class="line">   lp_model.fit(X,train_y)</span><br><span class="line">   prelab=lp_model.transduction_</span><br><span class="line">   <span class="built_in">print</span>(<span class="string">&quot;LP模型的预测精度：&quot;</span>,accuracy_score(Y[test_mask],prelab[test_mask]))</span><br></pre></td></tr></table></figure>
<p>结果为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LP模型的预测精度： <span class="number">0.45</span></span><br></pre></td></tr></table></figure>
<p>GCN在精度上远高于上面两个模型，具体原因在前面已经介绍过了。</p>
<h3 id="2-7-完整代码">2.7  完整代码</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 完整代码</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> GCNConv</span><br><span class="line"><span class="keyword">from</span> torch_geometric.datasets <span class="keyword">import</span> Planetoid</span><br><span class="line"><span class="keyword">from</span> torch_geometric.utils <span class="keyword">import</span> to_networkx</span><br><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="keyword">from</span> sklearn.manifold <span class="keyword">import</span> TSNE</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"><span class="keyword">from</span> sklearn.semi_supervised <span class="keyword">import</span> _label_propagation</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">dataset=Planetoid(root=<span class="string">r&quot;./Cora&quot;</span>,name=<span class="string">&quot;Cora&quot;</span>) <span class="comment"># root: 指定路径 name: 数据集名称</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">parse_args</span>():</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;PARAMETERS&#x27;&#x27;&#x27;</span></span><br><span class="line">    parser=argparse.ArgumentParser(<span class="string">&quot;GCN&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;-e&#x27;</span>,<span class="string">&#x27;--epochs&#x27;</span>,<span class="built_in">type</span>=<span class="built_in">int</span>,default=<span class="number">500</span>,<span class="built_in">help</span>=<span class="string">&#x27;number of epoch in training [default: 200]&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;-lr&#x27;</span>,<span class="string">&#x27;--learning_rate&#x27;</span>,<span class="built_in">type</span>=<span class="built_in">float</span>,default=<span class="number">0.01</span>, <span class="built_in">help</span>=<span class="string">&#x27;learning rate in training [default: 0.01]&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;-op&#x27;</span>,<span class="string">&#x27;--optimizer&#x27;</span>,<span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;Adam&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;optimizer for training [default: Adam]&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;-g&#x27;</span>,<span class="string">&#x27;--gpu&#x27;</span>,<span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;0&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;specify gpu device [default: 0]&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;-p&#x27;</span>,<span class="string">&#x27;--path&#x27;</span>,<span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;./save&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;the path of file saving [default: ./save]&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;-dr&#x27;</span>,<span class="string">&#x27;--decay_rate&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">5e-4</span>, <span class="built_in">help</span>=<span class="string">&#x27;decay rate [default: 5e-4]&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> parser.parse_args()</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GCNNet</span>(torch.nn.Module):</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,input_feature,num_classes</span>):</span><br><span class="line">            <span class="built_in">super</span>(GCNNet, self).__init__()</span><br><span class="line">            self.input_feature=input_feature</span><br><span class="line">            self.num_classes=num_classes</span><br><span class="line">            <span class="comment"># 这里我们用了两个图卷积层</span></span><br><span class="line">            <span class="comment"># 1433-&gt;32</span></span><br><span class="line">            self.conv1=GCNConv(input_feature,<span class="number">32</span>)</span><br><span class="line">            <span class="comment"># 32-&gt;num_classes</span></span><br><span class="line">            self.conv2=GCNConv(<span class="number">32</span>,num_classes)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,data</span>):</span><br><span class="line">            x,edge_index=data.x,data.edge_index</span><br><span class="line">            <span class="comment"># 需要输入的是节点的数据(index,feature)</span></span><br><span class="line">            <span class="comment"># 以及边索引COO，用于构建邻接矩阵和入度矩阵</span></span><br><span class="line">            x=F.relu(self.conv1(x,edge_index))</span><br><span class="line">            x=F.relu(self.conv2(x,edge_index))</span><br><span class="line">            <span class="keyword">return</span> F.softmax(x,dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">dataset,args</span>):</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化网络</span></span><br><span class="line">    args = args</span><br><span class="line">    savepath = args.path</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(savepath):</span><br><span class="line">        os.makedirs(savepath)</span><br><span class="line"></span><br><span class="line">    input_feature = dataset.num_node_features</span><br><span class="line">    num_classes = dataset.num_classes</span><br><span class="line">    data = dataset[<span class="number">0</span>]</span><br><span class="line">    os.environ[<span class="string">&quot;CUDA_VISIBLE_DEVICES&quot;</span>] = args.gpu</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 优化器</span></span><br><span class="line">    <span class="keyword">if</span> args.optimizer == <span class="string">&#x27;Adam&#x27;</span>:</span><br><span class="line">        optimizer = torch.optim.Adam(</span><br><span class="line">            model.parameters(),</span><br><span class="line">            lr=args.learning_rate,</span><br><span class="line">            <span class="comment"># betas=(0.9, 0.999),</span></span><br><span class="line">            <span class="comment"># eps=1e-08,</span></span><br><span class="line">            weight_decay=args.decay_rate</span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        optimizer = torch.optim.SGD(model.parameters(), lr=<span class="number">0.01</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 读取模型</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        checkpoint=torch.load(savepath+<span class="string">&quot;/best_model.pth&quot;</span>)</span><br><span class="line">        mygcn.load_state_dict(checkpoint[<span class="string">&#x27;model_state_dict&#x27;</span>])</span><br><span class="line">        start_epoch = checkpoint[<span class="string">&#x27;epoch&#x27;</span>]</span><br><span class="line">        optimizer.load_state_dict(checkpoint[<span class="string">&#x27;optimizer_state_dict&#x27;</span>])</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        mygcn=GCNNet(input_feature,num_classes)</span><br><span class="line">        start_epoch=<span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(mygcn)</span><br><span class="line">	model=mygcn</span><br><span class="line">    <span class="comment"># 网络训练</span></span><br><span class="line">    train_loss_all=[]</span><br><span class="line">    val_loss_all=[]</span><br><span class="line">    best_acc=<span class="number">0</span></span><br><span class="line">    train_acc_all=[]</span><br><span class="line">    model.train()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(start_epoch,args.epochs):</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        out=model(data)</span><br><span class="line">        loss=F.cross_entropy(out[data.train_mask],data.y[data.train_mask])</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        train_loss_all.append(loss.data.cpu().numpy())</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算在验证集上的损失</span></span><br><span class="line">        loss=F.cross_entropy(out[data.val_mask],data.y[data.val_mask])</span><br><span class="line">        val_loss_all.append(loss.data.cpu().numpy())</span><br><span class="line">        _,pred=out.<span class="built_in">max</span>(dim=<span class="number">1</span>)</span><br><span class="line">        acc=<span class="built_in">float</span>(pred[data.train_mask].eq(data.y[data.train_mask]).<span class="built_in">sum</span>().item())/data.train_mask.<span class="built_in">sum</span>().item()</span><br><span class="line">        train_acc_all.append(acc)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> acc&gt;best_acc:</span><br><span class="line">            sp=savepath+<span class="string">&quot;/best_model.pth&quot;</span></span><br><span class="line">            state=&#123;</span><br><span class="line">                <span class="string">&quot;epoch&quot;</span>:epoch,</span><br><span class="line">                <span class="string">&quot;accuracy&quot;</span>:acc,</span><br><span class="line">                <span class="string">&quot;model_state_dict&quot;</span>:model.state_dict(),</span><br><span class="line">                <span class="string">&quot;optimizer_state_dict&quot;</span>:optimizer.state_dict()</span><br><span class="line">            &#125;</span><br><span class="line">            torch.save(state,sp)</span><br><span class="line">            best_acc = acc</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> epoch%<span class="number">20</span>==<span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Epoch:&quot;</span>,epoch,<span class="string">&quot;;Train Loss:&quot;</span>,train_loss_all[-<span class="number">1</span>],<span class="string">&quot;;Val Loss:&quot;</span>,val_loss_all[-<span class="number">1</span>],<span class="string">&quot;Train acc:&quot;</span>,train_acc_all[-<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 可视化损失函数变化</span></span><br><span class="line">    plt.figure(figsize=(<span class="number">10</span>,<span class="number">6</span>))</span><br><span class="line">    plt.plot(train_loss_all,<span class="string">&quot;ro-&quot;</span>,label=<span class="string">&quot;Train Loss&quot;</span>)</span><br><span class="line">    plt.plot(val_loss_all,<span class="string">&quot;bs-&quot;</span>,label=<span class="string">&quot;Val Loss&quot;</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.grid()</span><br><span class="line">    plt.xlabel(<span class="string">&quot;epoch&quot;</span>,size=<span class="number">13</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&quot;loss&quot;</span>,size=<span class="number">13</span>)</span><br><span class="line">    plt.title(<span class="string">&quot;Graph Convolutional Networks&quot;</span>,size=<span class="number">14</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算预测精度</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    _,pred=model(data).<span class="built_in">max</span>(dim=<span class="number">1</span>)</span><br><span class="line">    correct=<span class="built_in">float</span>(pred[data.test_mask].eq(data.y[data.test_mask]).<span class="built_in">sum</span>().item())</span><br><span class="line">    acc=correct/data.test_mask.<span class="built_in">sum</span>().item()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Accuracy: &#123;:.4f&#125;&quot;</span>.<span class="built_in">format</span>(acc))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 为了直观体现网络的特征提取能力，我们对隐藏层获得的32维特征在空间中的分布情况进行可视化,</span></span><br><span class="line">    <span class="comment"># 与原始数据1433维进行比较，统一使用TSNE算法降维</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 对原始数据分布进行展示</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">draw</span>(<span class="params">x_tsne,t</span>):</span><br><span class="line">        plt.figure(figsize=(<span class="number">12</span>, <span class="number">8</span>))</span><br><span class="line">        axl = plt.subplot(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        X = x_tsne[:, <span class="number">0</span>]</span><br><span class="line">        Y = x_tsne[:, <span class="number">1</span>]</span><br><span class="line">        axl.set_xlim([<span class="built_in">min</span>(X), <span class="built_in">max</span>(X)])</span><br><span class="line">        axl.set_ylim([<span class="built_in">min</span>(Y), <span class="built_in">max</span>(Y)])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> ii <span class="keyword">in</span> <span class="built_in">range</span>(x_tsne.shape[<span class="number">0</span>]):</span><br><span class="line">            text = data.y.data.numpy()[ii]</span><br><span class="line">            axl.text(X[ii], Y[ii], <span class="built_in">str</span>(text), fontsize=<span class="number">5</span>,</span><br><span class="line">                     bbox=<span class="built_in">dict</span>(boxstyle=<span class="string">&quot;round&quot;</span>, facecolor=plt.cm.Set1(text), alpha=<span class="number">0.7</span>))</span><br><span class="line"></span><br><span class="line">        axl.set_xlabel(<span class="string">&quot;TSNE Feature 1&quot;</span>, size=<span class="number">13</span>)</span><br><span class="line">        axl.set_xlabel(<span class="string">&quot;TSNE Feature 2&quot;</span>, size=<span class="number">13</span>)</span><br><span class="line">        axl.set_title(t, size=<span class="number">15</span>)</span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line">    x_tsne=TSNE(n_components=<span class="number">2</span>).fit_transform(dataset.data.x.data.numpy())</span><br><span class="line">    draw(x_tsne,<span class="string">&quot;Original feature TSNE&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 对中间层32维数据进行可视化</span></span><br><span class="line">    activation=&#123;&#125; <span class="comment"># 保存不同层的输出</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_activation</span>(<span class="params">name</span>):</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">hook</span>(<span class="params">model,<span class="built_in">input</span>,output</span>):</span><br><span class="line">            activation[name]=output.detach()</span><br><span class="line">        <span class="keyword">return</span> hook</span><br><span class="line"></span><br><span class="line">    model.conv1.register_forward_hook(get_activation(<span class="string">&quot;conv1&quot;</span>))</span><br><span class="line">    _=model(data)</span><br><span class="line">    conv1=activation[<span class="string">&quot;conv1&quot;</span>].data.cpu().numpy()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;conv1.shape: &quot;</span>,conv1.shape)</span><br><span class="line"></span><br><span class="line">    x_tsne=TSNE(n_components=<span class="number">2</span>).fit_transform(conv1)</span><br><span class="line">    draw(x_tsne,<span class="string">&quot;GCNConv Feature TSNE&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 使用SVM进行计算</span></span><br><span class="line">    X=dataset.data.x.data.numpy()</span><br><span class="line">    Y=dataset.data.y.data.numpy()</span><br><span class="line"></span><br><span class="line">    train_mask=dataset.data.train_mask.data.numpy()</span><br><span class="line">    test_mask=dataset.data.test_mask.data.numpy()</span><br><span class="line"></span><br><span class="line">    train_x=X[:<span class="number">140</span>,:]</span><br><span class="line">    train_y=Y[train_mask]</span><br><span class="line">    test_x=X[<span class="number">1708</span>:<span class="number">2709</span>,:]</span><br><span class="line">    test_y=Y[test_mask]</span><br><span class="line"></span><br><span class="line">    svmmodel=SVC()</span><br><span class="line">    svmmodel.fit(train_x,train_y)</span><br><span class="line">    prelab=svmmodel.predict(test_x)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;SVM的预测精度：&quot;</span>,accuracy_score(test_y,prelab))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 使用LabelPropagation模型进行计算</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 对于不是有监督的训练数据的样本标签使用-1表示</span></span><br><span class="line">    train_y=Y.copy()</span><br><span class="line">    train_y[test_mask==<span class="literal">True</span>]=-<span class="number">1</span> <span class="comment"># 使用非测试数据作为由表亲啊的训练集</span></span><br><span class="line">    <span class="comment"># 预测数据</span></span><br><span class="line">    test_y=Y[test_mask]</span><br><span class="line">    lp_model=_label_propagation.LabelPropagation(kernel=<span class="string">&quot;knn&quot;</span>,n_neighbors=<span class="number">3</span>)</span><br><span class="line">    lp_model.fit(X,train_y)</span><br><span class="line">    prelab=lp_model.transduction_</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;LP模型的预测精度：&quot;</span>,accuracy_score(Y[test_mask],prelab[test_mask]))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    args=parse_args()</span><br><span class="line">    main(dataset,args)</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="三、图卷积层底层原理">三、图卷积层底层原理</h2>
<h3 id="3-1-基于Python的Graph-Convolution结构">3.1  基于Python的Graph Convolution结构</h3>
<p>我们对PyG的Graph Convolution结构进行分析：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">glorot</span>(<span class="params">tensor</span>):</span><br><span class="line">    <span class="comment"># 参数标准化(方差)</span></span><br><span class="line">    <span class="keyword">if</span> tensor <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        stdv = math.sqrt(<span class="number">6.0</span> / (tensor.size(-<span class="number">2</span>) + tensor.size(-<span class="number">1</span>)))</span><br><span class="line">        tensor.data.uniform_(-stdv, stdv)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">zeros</span>(<span class="params">tensor</span>):</span><br><span class="line">    <span class="comment"># 归零</span></span><br><span class="line">    <span class="keyword">if</span> tensor <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        tensor.data.fill_(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">GCNConv</span>(<span class="title class_ inherited__">MessagePassing</span>):</span><br><span class="line">   </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels, improved=<span class="literal">False</span>, cached=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">                 bias=<span class="literal">True</span>, normalize=<span class="literal">True</span>, **kwargs</span>):</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">super</span>(GCNConv, self).__init__(aggr=<span class="string">&#x27;add&#x27;</span>, **kwargs)</span><br><span class="line">        </span><br><span class="line">        self.in_channels = in_channels <span class="comment"># 输入维度</span></span><br><span class="line">        self.out_channels = out_channels <span class="comment"># 输出维度</span></span><br><span class="line">        self.improved = improved <span class="comment"># 影响自环权重，也就是hat A = A+\lambda I 中的\lambda</span></span><br><span class="line">        self.cached = cached <span class="comment"># 缓存计算值</span></span><br><span class="line">        self.normalize = normalize <span class="comment"># 是否添加自环并对称标准化</span></span><br><span class="line"></span><br><span class="line">        self.weight = Parameter(torch.Tensor(in_channels, out_channels)) <span class="comment"># 权重参数，size为(in,out)</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> bias:</span><br><span class="line">            self.bias = Parameter(torch.Tensor(out_channels)) <span class="comment"># 偏置参数,size为(out)</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.register_parameter(<span class="string">&#x27;bias&#x27;</span>, <span class="literal">None</span>)</span><br><span class="line">            </span><br><span class="line">        <span class="comment"># 我们刚刚又定义了两个参数，现在需要再次初始化</span></span><br><span class="line">        self.reset_parameters()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reset_parameters</span>(<span class="params">self</span>):</span><br><span class="line">        </span><br><span class="line">        glorot(self.weight) <span class="comment"># 参数标准化</span></span><br><span class="line">        zeros(self.bias) <span class="comment"># 偏置归零</span></span><br><span class="line">        self.cached_result = <span class="literal">None</span></span><br><span class="line">        self.cached_num_edges = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">norm</span>(<span class="params">edge_index, num_nodes, edge_weight=<span class="literal">None</span>, improved=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">             dtype=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="comment"># 边索引</span></span><br><span class="line">        <span class="comment"># 节点数量</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> edge_weight <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># 构建边权重，默认是等权无向图</span></span><br><span class="line">            edge_weight = torch.ones((edge_index.size(<span class="number">1</span>), ), dtype=dtype,</span><br><span class="line">                                     device=edge_index.device)</span><br><span class="line">		<span class="comment"># 这玩意就是lambda , 影响自环权重</span></span><br><span class="line">        fill_value = <span class="number">1</span> <span class="keyword">if</span> <span class="keyword">not</span> improved <span class="keyword">else</span> <span class="number">2</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 加入自环，做的就是：A&#x27; = A + \lambda I</span></span><br><span class="line">        edge_index, edge_weight = add_remaining_self_loops(</span><br><span class="line">            edge_index, edge_weight, fill_value, num_nodes)</span><br><span class="line"></span><br><span class="line">        row, col = edge_index</span><br><span class="line">        <span class="comment"># 构建对角矩阵(degree) D</span></span><br><span class="line">        deg = scatter_add(edge_weight, row, dim=<span class="number">0</span>, dim_size=num_nodes)</span><br><span class="line">        <span class="comment"># D=(D^-0.5)</span></span><br><span class="line">        deg_inv_sqrt = deg.<span class="built_in">pow</span>(-<span class="number">0.5</span>)</span><br><span class="line">        <span class="comment"># 把某些离谱的家伙修正为0</span></span><br><span class="line">        <span class="comment"># 会出现inf也是因为浮点的计算可能出现问题</span></span><br><span class="line">        deg_inv_sqrt[deg_inv_sqrt == <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)] = <span class="number">0</span></span><br><span class="line">		<span class="comment"># return : COO边,(D^-0.5) W (D^-0.5)</span></span><br><span class="line">        <span class="keyword">return</span> edge_index, deg_inv_sqrt[row] * edge_weight * deg_inv_sqrt[col]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, edge_index, edge_weight=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;&quot;&quot;&quot;</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 公式： (D^-0.5) A&#x27; (D^-0.5) X W</span></span><br><span class="line">        <span class="comment"># A&#x27; = A +\lambda I</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 这里做的就是 X W</span></span><br><span class="line">        x = torch.matmul(x, self.weight)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.cached <span class="keyword">and</span> self.cached_result <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">if</span> edge_index.size(<span class="number">1</span>) != self.cached_num_edges:</span><br><span class="line">                <span class="keyword">raise</span> RuntimeError(</span><br><span class="line">                    <span class="string">&#x27;Cached &#123;&#125; number of edges, but found &#123;&#125;. Please &#x27;</span></span><br><span class="line">                    <span class="string">&#x27;disable the caching behavior of this layer by removing &#x27;</span></span><br><span class="line">                    <span class="string">&#x27;the `cached=True` argument in its constructor.&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">                        self.cached_num_edges, edge_index.size(<span class="number">1</span>)))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.cached <span class="keyword">or</span> self.cached_result <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># 边数量</span></span><br><span class="line">            self.cached_num_edges = edge_index.size(<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">if</span> self.normalize:</span><br><span class="line">                <span class="comment"># 是否进行标准化(利用D矩阵，相当于权重)</span></span><br><span class="line">                edge_index, norm = self.norm(edge_index, x.size(self.node_dim),</span><br><span class="line">                                             edge_weight, self.improved,</span><br><span class="line">                                             x.dtype)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                norm = edge_weight</span><br><span class="line">            <span class="comment"># 边索引，边权重</span></span><br><span class="line">            self.cached_result = edge_index, norm</span><br><span class="line">		</span><br><span class="line">        edge_index, norm = self.cached_result</span><br><span class="line">		</span><br><span class="line">        <span class="comment"># Message.propagate 主要是利用邻接矩阵完成一些信息的堆叠</span></span><br><span class="line">        <span class="keyword">return</span> self.propagate(edge_index, x=x, norm=norm)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">message</span>(<span class="params">self, x_j, norm</span>):</span><br><span class="line">        <span class="keyword">return</span> norm.view(-<span class="number">1</span>, <span class="number">1</span>) * x_j <span class="keyword">if</span> norm <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">else</span> x_j</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self, aggr_out</span>):</span><br><span class="line">        <span class="keyword">if</span> self.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            aggr_out = aggr_out + self.bias</span><br><span class="line">        <span class="keyword">return</span> aggr_out</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__repr__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 输出时的实例信息</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;&#123;&#125;(&#123;&#125;, &#123;&#125;)&#x27;</span>.<span class="built_in">format</span>(self.__class__.__name__, self.in_channels,</span><br><span class="line">                                   self.out_channels)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">propagate</span>(<span class="params">self, edge_index: Adj, size: Size = <span class="literal">None</span>, **kwargs</span>):</span><br><span class="line"></span><br><span class="line">    decomposed_layers = <span class="number">1</span> <span class="keyword">if</span> self._explain <span class="keyword">else</span> self.decomposed_layers</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> hook <span class="keyword">in</span> self._propagate_forward_pre_hooks.values():</span><br><span class="line">        res = hook(self, (edge_index, size, kwargs))</span><br><span class="line">        <span class="keyword">if</span> res <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            edge_index, size, kwargs = res</span><br><span class="line"></span><br><span class="line">    size = self.__check_input__(edge_index, size)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Run &quot;fused&quot; message and aggregation (if applicable).</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">isinstance</span>(edge_index, SparseTensor) <span class="keyword">and</span> self.fuse</span><br><span class="line">            <span class="keyword">and</span> <span class="keyword">not</span> self._explain):</span><br><span class="line">        coll_dict = self.__collect__(self.__fused_user_args__, edge_index,</span><br><span class="line">                                     size, kwargs)</span><br><span class="line"></span><br><span class="line">        msg_aggr_kwargs = self.inspector.distribute(</span><br><span class="line">            <span class="string">&#x27;message_and_aggregate&#x27;</span>, coll_dict)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> hook <span class="keyword">in</span> self._message_and_aggregate_forward_pre_hooks.values():</span><br><span class="line">            res = hook(self, (edge_index, msg_aggr_kwargs))</span><br><span class="line">            <span class="keyword">if</span> res <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                edge_index, msg_aggr_kwargs = res</span><br><span class="line">                </span><br><span class="line">        out = self.message_and_aggregate(edge_index, **msg_aggr_kwargs)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> hook <span class="keyword">in</span> self._message_and_aggregate_forward_hooks.values():</span><br><span class="line">            res = hook(self, (edge_index, msg_aggr_kwargs), out)</span><br><span class="line">            <span class="keyword">if</span> res <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                out = res</span><br><span class="line"></span><br><span class="line">        update_kwargs = self.inspector.distribute(<span class="string">&#x27;update&#x27;</span>, coll_dict)</span><br><span class="line">        out = self.update(out, **update_kwargs)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Otherwise, run both functions in separation.</span></span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">isinstance</span>(edge_index, Tensor) <span class="keyword">or</span> <span class="keyword">not</span> self.fuse:</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> decomposed_layers &gt; <span class="number">1</span>:</span><br><span class="line">            user_args = self.__user_args__</span><br><span class="line">            decomp_args = &#123;a[:-<span class="number">2</span>] <span class="keyword">for</span> a <span class="keyword">in</span> user_args <span class="keyword">if</span> a[-<span class="number">2</span>:] == <span class="string">&#x27;_j&#x27;</span>&#125;</span><br><span class="line">            decomp_kwargs = &#123;</span><br><span class="line">                a: kwargs[a].chunk(decomposed_layers, -<span class="number">1</span>)</span><br><span class="line">                <span class="keyword">for</span> a <span class="keyword">in</span> decomp_args</span><br><span class="line">            &#125;</span><br><span class="line">            decomp_out = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(decomposed_layers):</span><br><span class="line">            <span class="keyword">if</span> decomposed_layers &gt; <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">for</span> arg <span class="keyword">in</span> decomp_args:</span><br><span class="line">                    kwargs[arg] = decomp_kwargs[arg][i]</span><br><span class="line"></span><br><span class="line">            coll_dict = self.__collect__(self.__user_args__, edge_index,</span><br><span class="line">                                         size, kwargs)</span><br><span class="line"></span><br><span class="line">            msg_kwargs = self.inspector.distribute(<span class="string">&#x27;message&#x27;</span>, coll_dict)</span><br><span class="line">            <span class="keyword">for</span> hook <span class="keyword">in</span> self._message_forward_pre_hooks.values():</span><br><span class="line">                res = hook(self, (msg_kwargs, ))</span><br><span class="line">                <span class="keyword">if</span> res <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    msg_kwargs = res[<span class="number">0</span>] <span class="keyword">if</span> <span class="built_in">isinstance</span>(res, <span class="built_in">tuple</span>) <span class="keyword">else</span> res</span><br><span class="line">            out = self.message(**msg_kwargs)</span><br><span class="line">            <span class="keyword">for</span> hook <span class="keyword">in</span> self._message_forward_hooks.values():</span><br><span class="line">                res = hook(self, (msg_kwargs, ), out)</span><br><span class="line">                <span class="keyword">if</span> res <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    out = res</span><br><span class="line"></span><br><span class="line">            <span class="comment"># For `GNNExplainer`, we require a separate message and</span></span><br><span class="line">            <span class="comment"># aggregate procedure since this allows us to inject the</span></span><br><span class="line">            <span class="comment"># `edge_mask` into the message passing computation scheme.</span></span><br><span class="line">            <span class="keyword">if</span> self._explain:</span><br><span class="line">                edge_mask = self._edge_mask</span><br><span class="line">                <span class="keyword">if</span> self._apply_sigmoid:</span><br><span class="line">                    edge_mask = edge_mask.sigmoid()</span><br><span class="line">                <span class="comment"># Some ops add self-loops to `edge_index`. We need to do</span></span><br><span class="line">                <span class="comment"># the same for `edge_mask` (but do not train those).</span></span><br><span class="line">                <span class="keyword">if</span> out.size(self.node_dim) != edge_mask.size(<span class="number">0</span>):</span><br><span class="line">                    edge_mask = edge_mask[self._loop_mask]</span><br><span class="line">                    loop = edge_mask.new_ones(size[<span class="number">0</span>])</span><br><span class="line">                    edge_mask = torch.cat([edge_mask, loop], dim=<span class="number">0</span>)</span><br><span class="line">                <span class="keyword">assert</span> out.size(self.node_dim) == edge_mask.size(<span class="number">0</span>)</span><br><span class="line">                out = out * edge_mask.view([-<span class="number">1</span>] + [<span class="number">1</span>] * (out.dim() - <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">            aggr_kwargs = self.inspector.distribute(<span class="string">&#x27;aggregate&#x27;</span>, coll_dict)</span><br><span class="line">            <span class="keyword">for</span> hook <span class="keyword">in</span> self._aggregate_forward_pre_hooks.values():</span><br><span class="line">                res = hook(self, (aggr_kwargs, ))</span><br><span class="line">                <span class="keyword">if</span> res <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    aggr_kwargs = res[<span class="number">0</span>] <span class="keyword">if</span> <span class="built_in">isinstance</span>(res, <span class="built_in">tuple</span>) <span class="keyword">else</span> res</span><br><span class="line">            out = self.aggregate(out, **aggr_kwargs)</span><br><span class="line">            <span class="keyword">for</span> hook <span class="keyword">in</span> self._aggregate_forward_hooks.values():</span><br><span class="line">                res = hook(self, (aggr_kwargs, ), out)</span><br><span class="line">                <span class="keyword">if</span> res <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    out = res</span><br><span class="line"></span><br><span class="line">            update_kwargs = self.inspector.distribute(<span class="string">&#x27;update&#x27;</span>, coll_dict)</span><br><span class="line">            out = self.update(out, **update_kwargs)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> decomposed_layers &gt; <span class="number">1</span>:</span><br><span class="line">                decomp_out.append(out)</span><br><span class="line">			</span><br><span class="line">        <span class="keyword">if</span> decomposed_layers &gt; <span class="number">1</span>:</span><br><span class="line">            <span class="comment"># 这里做了数据的堆叠</span></span><br><span class="line">            out = torch.cat(decomp_out, dim=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> hook <span class="keyword">in</span> self._propagate_forward_hooks.values():</span><br><span class="line">        res = hook(self, (edge_index, size, kwargs), out)</span><br><span class="line">        <span class="keyword">if</span> res <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            out = res</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>
<hr>
<p>好复杂呀！我们只需要其中的精华就行啦，那么有一种比较简单的实现方式：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GCNConv</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_dim, output_dim, use_bias=<span class="literal">True</span></span>):</span><br><span class="line"></span><br><span class="line">        <span class="built_in">super</span>(GCNConv, self).__init__()</span><br><span class="line">        self.input_dim = input_dim <span class="comment"># 输入维度</span></span><br><span class="line">        self.output_dim = output_dim <span class="comment"># 输出维度</span></span><br><span class="line">        self.use_bias = use_bias <span class="comment"># 偏置</span></span><br><span class="line">        self.weight = nn.Parameter(torch.Tensor(input_dim, output_dim)) <span class="comment"># 初始权重</span></span><br><span class="line">        <span class="keyword">if</span> self.use_bias:</span><br><span class="line">            self.bias = nn.Parameter(torch.Tensor(output_dim)) <span class="comment"># 偏置</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.register_parameter(<span class="string">&#x27;bias&#x27;</span>, <span class="literal">None</span>)</span><br><span class="line">        self.reset_parameters()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reset_parameters</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 重新设置参数</span></span><br><span class="line">        <span class="comment"># 进行凯明初始化</span></span><br><span class="line">        nn.init.kaiming_uniform_(self.weight)</span><br><span class="line">        <span class="keyword">if</span> self.use_bias:</span><br><span class="line">            <span class="comment"># 偏置先全给0</span></span><br><span class="line">            nn.init.zeros_(self.bias)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, adjacency, input_feature,l=<span class="number">1</span></span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param adjacency: 邻接矩阵</span></span><br><span class="line"><span class="string">        :param input_feature: 输入特征</span></span><br><span class="line"><span class="string">        :param l: lambda 影响自环权重值</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># 公式: (D^-0.5) A&#x27; (D^-0.5) X W</span></span><br><span class="line">        size = adjacency.shape[<span class="number">0</span>]</span><br><span class="line">        <span class="comment"># X W</span></span><br><span class="line">        support = torch.mm(input_feature, self.weight)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># A&#x27; = A + \lambda I</span></span><br><span class="line">        A=adjacency+l*torch.eye(size)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># D: degree</span></span><br><span class="line">        SUM=A.<span class="built_in">sum</span>(dim=<span class="number">1</span>)</span><br><span class="line">        D=torch.diag_embed(SUM)</span><br><span class="line">        <span class="comment"># D&#x27;=D^(-0.5)</span></span><br><span class="line">        D=D.__pow__(-<span class="number">0.5</span>)</span><br><span class="line">        <span class="comment"># 让inf值变成0</span></span><br><span class="line">        D[D==<span class="built_in">float</span>(<span class="string">&quot;inf&quot;</span>)]=<span class="number">0</span></span><br><span class="line">        <span class="comment"># (D^-0.5) A&#x27; (D^-0.5)</span></span><br><span class="line">        adjacency=torch.sparse.mm(D,adjacency)</span><br><span class="line">        adjacency=torch.sparse.mm(adjacency,D)</span><br><span class="line">        <span class="comment"># (D^-0.5) A&#x27; (D^-0.5) X W</span></span><br><span class="line">        output = torch.sparse.mm(adjacency, support)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> self.use_bias:</span><br><span class="line">            <span class="comment"># 使用偏置</span></span><br><span class="line">            output += self.bias</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__repr__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 打印的时候内存信息属性</span></span><br><span class="line">        <span class="keyword">return</span> self.__class__.__name__ + <span class="string">&#x27; (&#x27;</span> + <span class="built_in">str</span>(self.input_dim) + <span class="string">&#x27; -&gt; &#x27;</span> + <span class="built_in">str</span>(self.output_dim) + <span class="string">&#x27;)&#x27;</span></span><br></pre></td></tr></table></figure>
<hr>
<h2 id="四、参考">四、参考</h2>
<p>本文中的部分图片参考自博客：<a href="https://blog.csdn.net/qq_43787862/article/details/113830925%EF%BC%8C%E9%9D%9E%E5%B8%B8%E6%84%9F%E8%B0%A2%E5%A4%A7%E4%BD%AC%E7%9A%84%E7%BF%BB%E8%AF%91%EF%BC%81">https://blog.csdn.net/qq_43787862/article/details/113830925，非常感谢大佬的翻译！</a></p>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 不想学辣 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 神经网络 </tag>
            
            <tag> 卷积神经网络 </tag>
            
            <tag> 图卷积 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[PyG(PyTorch Geometric)安装教程(附Cora数据集)]]></title>
      <url>/2022/07/29/%E3%80%90Python%E3%80%91%E5%9B%BE%E5%8D%B7%E7%A7%AF%E5%BA%93PyG/</url>
      <content type="html"><![CDATA[<h2 id="PyG-PyTorch-Geometric-安装教程-附Cora数据集">PyG(PyTorch Geometric)安装教程(附Cora数据集)</h2>
<hr>
<p>PyG是多特蒙德工业大学（Technische University Dortmund）的Matthias Fey博士基于PyTorch框架提出的图卷积(Graph Convolution Net)神经网络框架，用于方便地编写和训练图神经网络(GNNs)。该框架由各种对图和其他不规则结构进行深度学习的方法组成，且提供了大量的公共基准数据集，可以进行任意图形、3D格网甚至是点云数据的学习和处理。官方网址：<a href="https://github.com/pyg-team/pytorch_geometric/releases">https://github.com/pyg-team/pytorch_geometric/releases</a></p>
<hr>
<p>我们来介绍PyG在Windows环境下的安装。</p>
<p>首先，我们需要下载好对应版本的<code>pytorch</code>，这里不做过多赘述。</p>
<p>在对应环境中，我们可以直接使用以下conda命令进行安装：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conda install pyg -c pyg</span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line">pip install torch_geometric</span><br></pre></td></tr></table></figure>
<p>除此之外，我们需要安装PyG的依赖库：<code>torch-spares</code>、<code>torch-scatter</code>，根据PyTorch版本不同，安装的方式有所不同。注意查询Torch的版本。</p>
<hr>
<h3 id="PyTorch-1-11-版本✅">PyTorch 1.11 版本✅</h3>
<p><code>pip</code>命令如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-<span class="number">1.11</span><span class="number">.0</span>+$&#123;CUDA&#125;.html</span><br></pre></td></tr></table></figure>
<p>注意将<code>$&#123;CUDA&#125;</code>换成自己的版本，否则会爆错。</p>
<p>例如，我的PyTorch版本是:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过pip list查看</span></span><br><span class="line"><span class="comment"># 或者python import torch print(torch.__version__)</span></span><br><span class="line">torch                 <span class="number">1.11</span><span class="number">.0</span>+cu113</span><br></pre></td></tr></table></figure>
<p>那么，只需要做如下替换：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-<span class="number">1.11</span><span class="number">.0</span>+cu113.html</span><br></pre></td></tr></table></figure>
<p>值得注意的是，<code>cuxxx</code>并不支持macOS。</p>
<hr>
<h3 id="PyTorch-1-10版本✅">PyTorch 1.10版本✅</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-<span class="number">1.10</span><span class="number">.0</span>+$&#123;CUDA&#125;.html</span><br></pre></td></tr></table></figure>
<p>其他版本的需要根据PyTorch版本指定依赖库的版本！</p>
<p>其他版本请参考https://data.pyg.org/whl</p>
<hr>
<h2 id="Cora数据集介绍">Cora数据集介绍</h2>
<p>Cora数据集由2078篇机器学习领域的论文构成，每个样本点都是一篇论文，这些论文主要分为了7个类别，分别为基于案例、遗传算法、神经网络、概率方法、强化学习、规则学习与理论。在该数据集中，每篇论文都至少引用了该数据集中的另一篇论文，对每个节点所代表的论文，都由一个1433维的词向量表示，即该图上每个节点都具有1433个特征，词向量的每个元素都对应一个词，且该元素仅有0或1两个取值，取0表示该元素对应的词不在论文中，取1表示在。</p>
<h3 id="Cora参数">Cora参数</h3>
<ul>
<li><strong>ind.cora.x</strong> : 训练集节点特征向量，保存对象为：scipy.sparse.csr.csr_matrix，实际展开后大小为： (140, 1433)</li>
<li><strong>ind.cora.tx</strong> : 测试集节点特征向量，保存对象为：scipy.sparse.csr.csr_matrix，实际展开后大小为： (1000, 1433)</li>
<li><strong>ind.cora.allx</strong> : 包含有标签和无标签的训练节点特征向量，保存对象为：scipy.sparse.csr.csr_matrix，实际展开后大小为：(1708, 1433)，可以理解为除测试集以外的其他节点特征集合，训练集是它的子集</li>
<li><strong>ind.cora.y</strong> : one-hot表示的训练节点的标签，保存对象为：numpy.ndarray</li>
<li><strong>ind.cora.ty</strong> : one-hot表示的测试节点的标签，保存对象为：numpy.ndarray</li>
<li><strong>ind.cora.ally</strong> : one-hot表示的ind.cora.allx对应的标签，保存对象为：numpy.ndarray</li>
<li><strong>ind.cora.graph</strong> : 保存节点之间边的信息，保存格式为：{ index : [ index_of_neighbor_nodes ] }</li>
<li><strong>ind.cora.test.index</strong> : 保存测试集节点的索引，保存对象为：List，用于后面的归纳学习设置。</li>
</ul>
<h3 id="Cora下载">Cora下载</h3>
<p>可以通过以下语句进行下载，当然，由于服务器和主机之间的物理距离，很可能会出现下载失败。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch_geometric.datasets <span class="keyword">import</span> Planetoid</span><br><span class="line">dataset=Planetoid(root=<span class="string">r&quot;./Cora&quot;</span>,name=<span class="string">&quot;Cora&quot;</span>) <span class="comment"># root: 指定路径 name: 数据集名称</span></span><br></pre></td></tr></table></figure>
<p>我将数据集放在百度网盘上了哦，有需要的可以自行下载：</p>
<p>链接：<a href="https://pan.baidu.com/s/18Qlhu_dyIUAOoDEeRDvtHw?pwd=UCAS">https://pan.baidu.com/s/18Qlhu_dyIUAOoDEeRDvtHw?pwd=UCAS</a><br>
提取码：UCAS</p>
<p>检查其是否成功：</p>
<p>将文件解压放在给定的<code>root</code>下即可。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;网络数据包含的类数量:&quot;</span>,dataset.num_classes)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;网络数据边的特征数量:&quot;</span>,dataset.num_edge_features)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;网络数据边的数量:&quot;</span>,dataset.data.edge_index.shape[<span class="number">1</span>]/<span class="number">2</span>) <span class="comment"># 除以2是因为有向图哦</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;网络数据节点的特征数量:&quot;</span>,dataset.num_node_features)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;网络数据节点的数量:&quot;</span>,dataset.data.x.shape[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">网络数据包含的类数量: 7</span></span><br><span class="line"><span class="string">网络数据边的特征数量: 0</span></span><br><span class="line"><span class="string">网络数据边的数量: 5278.0</span></span><br><span class="line"><span class="string">网络数据节点的特征数量: 1433</span></span><br><span class="line"><span class="string">网络数据节点的数量: 2708</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 不想学辣 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 插件工具 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[FCN语义分割网络]]></title>
      <url>/2022/07/29/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91FCN%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%BD%91%E7%BB%9C/</url>
      <content type="html"><![CDATA[<h1>语义分割网络</h1>
<hr>
<p>语义分割是对图像在像素级别上进行分类的方法，在一张图像中，属于同一类的像素点都要被预测为相同的类。因此语义分割是从像素级别来理解图像。</p>
<p>注意，语义分割仅仅是把某一类划分出来，而针对每个个体没办法进行分割(实例分割)。</p>
<p>常见的语义分割网络有很多，如FCN、U-Net、SegNet、DeepLab等。</p>
<h2 id="FCN">FCN</h2>
<p>FCN(Fully Convolutional Networks)属于利用深度网络进行图片语义分割的开山之作，其主要思想为：</p>
<ul>
<li>对于一般的CNN网络分类图像，如VGG和ResNet，在网络的最后是通过全连接层，通过softmax进行分类，但这只能表示整个图片的类别。FCN把最后几个全连接层都换成了卷积操作，得到和输入图像尺寸相当的特征映射，最后通过softmax获取每个像素点的分类信息，实现像素点的图像分割。</li>
<li>端到端像素级语义分割任务，需要输出分类结果尺寸和输入图像尺寸一致，面对池化造成的图面尺寸缩小，FCN采用反卷积(deconvolution)进行上采样，从而保证图像大小的一致。</li>
<li>为了更有效的利用特征映射的信息，FCN提出一种跨层连接结构，将低层和高层的目标位置信息的特征映射进行融合，即将低层位置强语义弱的信息跟高层位置弱语义强的信息进行融合，提升网络对图像分割的性能。</li>
</ul>
<h2 id="U-Net">U-Net</h2>
<p>U-Net基于FCN网络提出，能够适应较小的训练集。其采用大量弹性形变的方法对数据进行增强，让模型更好的学习形变不变形。在不同特征融合方式上，U-Net采用通道维度上的拼接融合代替FCN的逐点相加。</p>
<h2 id="SegNet">SegNet</h2>
<p>SegNet的网络结构借鉴了自编码网络的思想，具有编码器网络和解码器网络。最后通过softmax分类器对每个像素点进行分类。网络在编码器处会执行卷积和最大池化，在解码器部分则会执行上采样和卷积。</p>
<hr>
<h2 id="基于PyTorch预训练好的语义分割网络实现VOC数据集分类">基于PyTorch预训练好的语义分割网络实现VOC数据集分类</h2>
<h3 id="数据集">数据集</h3>
<p>本次使用VOC2012数据集，来源于：<a href="http://host.robots.ox.ac.uk/pascal/VOC/voc2012/index.html%E3%80%82">http://host.robots.ox.ac.uk/pascal/VOC/voc2012/index.html。</a></p>
<p>数据集中存在20个类别的1个背景类：</p>
<p>Person: person</p>
<p>Animal: bird, cat, cow, dog, horse, sheep</p>
<p>Vehicle: aeroplane, bicycle, boat, bus, car, motorbike, train</p>
<p>Indoor: bottle, chair, dining table, potted plant, sofa, tv/monitor</p>
<p>在Annotations文件夹中，存放有对应图片的标记文件，以XML格式存储。</p>
<h3 id="网络">网络</h3>
<p>在Pytorch中，提供训练好的fcn和deeplabv3网络，可以用作图像分割。</p>
<h3 id="实现">实现</h3>
<h4 id="1-1-导入模块">1.1 导入模块</h4>
<p>需要用到的模块主要是<code>torchvision</code>，直接<code>pip install torchvision</code>即可。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> PIL.Image <span class="keyword">as</span> Image</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> torchvisio</span><br></pre></td></tr></table></figure>
<h4 id="1-2-数据处理">1.2 数据处理</h4>
<p>我们加载torch中训练好的全卷积残差网络<code>fcn_resnet101</code>，设置预训练。如果是第一次加载需要在网络上下载参数。</p>
<p>由于该网络已经训练好了，所以我们不再进行训练，使用其评估模式<code>eval</code>。该该模式下，不启用 Batch Normalization 和 Dropout。即在测试过程中保证BN层均值方差不变，在Dropout层不随机舍弃神经元。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入训练好的模块</span></span><br><span class="line">model=torchvision.models.segmentation.fcn_resnet101(pretrained=<span class="literal">True</span>)</span><br><span class="line">model.<span class="built_in">eval</span>()</span><br></pre></td></tr></table></figure>
<p>然后就需要把我们的图像读取进来啦，这里随机选用一张VOC2012数据。</p>
<p>对图片需要进行预处理：</p>
<ul>
<li>数据格式转化为张量</li>
<li>RGB通道标准化</li>
<li>添加batch维度</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 读取图片</span></span><br><span class="line">image=Image.<span class="built_in">open</span>(<span class="string">r&quot;F:\VOCdevkit\VOC2012\JPEGImages\2007_002488.jpg&quot;</span>)</span><br><span class="line"><span class="comment"># 图片预处理</span></span><br><span class="line">image_transf=transforms.Compose([</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize(mean=[<span class="number">0.485</span>,<span class="number">0.456</span>,<span class="number">0.406</span>],</span><br><span class="line">                         std=[<span class="number">0.229</span>,<span class="number">0.224</span>,<span class="number">0.225</span>])</span><br><span class="line">])</span><br><span class="line">image_tensor=image_transf(image).unsqueeze(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<h4 id="1-3-网络预测">1.3  网络预测</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">output=model(image_tensor)[<span class="string">&quot;out&quot;</span>]</span><br></pre></td></tr></table></figure>
<h4 id="1-4-结果可视化">1.4  结果可视化</h4>
<p>输出的Tensor是结果分类的，为了方便可视化，需要做以下处理：</p>
<ul>
<li>将Tensor重新转为图像</li>
<li>定义每一类对应的色彩，并将图像编码</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将输出转化为二维图像</span></span><br><span class="line">outputarg=torch.argmax(output.squeeze(),dim=<span class="number">0</span>).numpy()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取指定颜色编码</span></span><br><span class="line">label_colors=np.array([(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>),(<span class="number">128</span>,<span class="number">0</span>,<span class="number">0</span>),(<span class="number">0</span>,<span class="number">128</span>,<span class="number">0</span>),(<span class="number">128</span>,<span class="number">128</span>,<span class="number">0</span>),(<span class="number">0</span>,<span class="number">0</span>,<span class="number">128</span>),(<span class="number">128</span>,<span class="number">0</span>,<span class="number">128</span>),</span><br><span class="line">                       (<span class="number">0</span>,<span class="number">128</span>,<span class="number">128</span>),(<span class="number">128</span>,<span class="number">128</span>,<span class="number">128</span>),(<span class="number">64</span>,<span class="number">0</span>,<span class="number">0</span>),(<span class="number">192</span>,<span class="number">0</span>,<span class="number">0</span>),(<span class="number">64</span>,<span class="number">128</span>,<span class="number">0</span>),(<span class="number">192</span>,<span class="number">128</span>,<span class="number">0</span>),</span><br><span class="line">                       (<span class="number">64</span>,<span class="number">0</span>,<span class="number">128</span>),(<span class="number">192</span>,<span class="number">0</span>,<span class="number">128</span>),(<span class="number">64</span>,<span class="number">128</span>,<span class="number">128</span>),(<span class="number">192</span>,<span class="number">128</span>,<span class="number">128</span>),(<span class="number">0</span>,<span class="number">64</span>,<span class="number">0</span>),(<span class="number">128</span>,<span class="number">64</span>,<span class="number">0</span>),</span><br><span class="line">                       (<span class="number">0</span>,<span class="number">192</span>,<span class="number">0</span>),(<span class="number">128</span>,<span class="number">192</span>,<span class="number">0</span>),(<span class="number">0</span>,<span class="number">64</span>,<span class="number">128</span>)])</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>图像编码的话，先生成三个维度的初始数据，接着获取输出类别的位置，并在该位置上为三个维度附上颜色值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 我们对该图像进行编码，以便可视化</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">decode_segmaps</span>(<span class="params">image,label_colors,nc=<span class="number">21</span></span>):</span><br><span class="line">    <span class="comment"># 先生成三个通道等大小的影像</span></span><br><span class="line">    r=np.zeros_like(image).astype(np.uint8)</span><br><span class="line">    g=np.zeros_like(image).astype(np.uint8)</span><br><span class="line">    b=np.zeros_like(image).astype(np.uint8)</span><br><span class="line">    <span class="keyword">for</span> cla <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,nc):</span><br><span class="line">        idx=(image==cla) <span class="comment"># 某一类的位置索引</span></span><br><span class="line">        r[idx]=label_colors[cla,<span class="number">0</span>]</span><br><span class="line">        g[idx]=label_colors[cla,<span class="number">1</span>]</span><br><span class="line">        b[idx]=label_colors[cla,<span class="number">2</span>]</span><br><span class="line">    <span class="comment"># 三通道转为图像</span></span><br><span class="line">    rgbimage=np.stack([r,g,b],axis=<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> rgbimage</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>最后输出即可</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 进行可视化</span></span><br><span class="line">outputrgb=decode_segmaps(outputarg,label_colors)</span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>,<span class="number">8</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">plt.imshow(image)</span><br><span class="line">plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">plt.imshow(outputrgb)</span><br><span class="line">plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">plt.subplots_adjust(wspace=<span class="number">0.05</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h3 id="结果">结果</h3>
<img src="/2022/07/29/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91FCN%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%BD%91%E7%BB%9C/image-20220324203124769.png" alt="image-20220324203124769" style="zoom: 25%;">
<img src="/2022/07/29/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91FCN%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%BD%91%E7%BB%9C/image-20220324203248135.png" alt="image-20220324203248135" style="zoom: 25%;">
<hr>
<h2 id="训练语义分割网络">训练语义分割网络</h2>
<p>基于VGG19搭建全卷积语义分割网络。</p>
<p>首先数据有一个标记集：</p>
<img src="/2022/07/29/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91FCN%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%BD%91%E7%BB%9C/image-20220324204811702.png" alt="image-20220324204811702" style="zoom:50%;">
<p>也有一个原始集：</p>
<img src="/2022/07/29/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91FCN%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%BD%91%E7%BB%9C/image-20220324204830403.png" alt="image-20220324204830403" style="zoom:50%;">
<p>针对一个图像，在训练阶段我们需要做的事情是：</p>
<ul>
<li>将标记图像和原始图像对应的图片<strong>路径一一对应</strong></li>
<li>将图像统一分为<strong>固定的尺寸</strong>时，需要保持原始图像和其对应的标记图像从相同位置进行分割。</li>
<li>对原始图像进行<strong>标准化</strong></li>
<li>对标记好的图像，其中的RGB值对应着一个类，需要将其转化为一个二维数据，其中每个位置的取值对应着图像在该像素点的类。</li>
</ul>
<h3 id="实现-v2">实现</h3>
<h4 id="1-1-导入模块-v2">1.1  导入模块</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> PIL.Image <span class="keyword">as</span> Image</span><br><span class="line"><span class="keyword">import</span> torch.utils.data <span class="keyword">as</span> Data</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torchsummary <span class="keyword">import</span> summary</span><br></pre></td></tr></table></figure>
<h4 id="1-2-数据处理-v2">1.2  数据处理</h4>
<p>全局信息，包括是否使用GPU，以及图像色带。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 指定设备</span></span><br><span class="line">device=torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"><span class="comment"># 标识类</span></span><br><span class="line">colormap=[(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>),(<span class="number">128</span>,<span class="number">0</span>,<span class="number">0</span>),(<span class="number">0</span>,<span class="number">128</span>,<span class="number">0</span>),(<span class="number">128</span>,<span class="number">128</span>,<span class="number">0</span>),(<span class="number">0</span>,<span class="number">0</span>,<span class="number">128</span>),(<span class="number">128</span>,<span class="number">0</span>,<span class="number">128</span>),</span><br><span class="line">                       (<span class="number">0</span>,<span class="number">128</span>,<span class="number">128</span>),(<span class="number">128</span>,<span class="number">128</span>,<span class="number">128</span>),(<span class="number">64</span>,<span class="number">0</span>,<span class="number">0</span>),(<span class="number">192</span>,<span class="number">0</span>,<span class="number">0</span>),(<span class="number">64</span>,<span class="number">128</span>,<span class="number">0</span>),(<span class="number">192</span>,<span class="number">128</span>,<span class="number">0</span>),</span><br><span class="line">                       (<span class="number">64</span>,<span class="number">0</span>,<span class="number">128</span>),(<span class="number">192</span>,<span class="number">0</span>,<span class="number">128</span>),(<span class="number">64</span>,<span class="number">128</span>,<span class="number">128</span>),(<span class="number">192</span>,<span class="number">128</span>,<span class="number">128</span>),(<span class="number">0</span>,<span class="number">64</span>,<span class="number">0</span>),(<span class="number">128</span>,<span class="number">64</span>,<span class="number">0</span>),</span><br><span class="line">                       (<span class="number">0</span>,<span class="number">192</span>,<span class="number">0</span>),(<span class="number">128</span>,<span class="number">192</span>,<span class="number">0</span>),(<span class="number">0</span>,<span class="number">64</span>,<span class="number">128</span>)]</span><br></pre></td></tr></table></figure>
<p>对于图像数据，我们主要进行以下几个工作：</p>
<ul>
<li>将RGB类型的标签图片转化成单类图像</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将RGB图像处理为一个类</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">img2lab</span>(<span class="params">img,colormap</span>):</span><br><span class="line">    cm2lbl=np.zeros(<span class="number">256</span>**<span class="number">3</span>)</span><br><span class="line">    <span class="comment"># 将每个像素转化为一类数据</span></span><br><span class="line">    <span class="keyword">for</span> i,cm <span class="keyword">in</span> <span class="built_in">enumerate</span>(colormap):</span><br><span class="line">        <span class="comment"># 这步能够将每个rgb类型的颜色转为单独一类</span></span><br><span class="line">        cm2lbl[((cm[<span class="number">0</span>]*<span class="number">256</span>+cm[<span class="number">1</span>])*<span class="number">256</span>+cm[<span class="number">2</span>])]=i</span><br><span class="line">        <span class="comment"># 对一张图像进行转化</span></span><br><span class="line">    image=np.array(img,dtype=<span class="string">&quot;int64&quot;</span>)</span><br><span class="line">    ix=((image[:,:,<span class="number">0</span>]*<span class="number">256</span>+image[:,:,<span class="number">1</span>])*<span class="number">256</span>+image[:,:,<span class="number">2</span>]) <span class="comment"># 这里会将每个像素点都做映射</span></span><br><span class="line">    <span class="comment"># 做完映射后，留下的ix只剩下了两个维度</span></span><br><span class="line">    image2=cm2lbl[ix] <span class="comment"># 将对应像素的类映射过去，ix的shape跟img展平后相同</span></span><br><span class="line">    <span class="comment"># ix; high,width</span></span><br><span class="line">    <span class="comment"># 所以image2是单维度的数据</span></span><br><span class="line">    <span class="keyword">return</span> image2</span><br></pre></td></tr></table></figure>
<ul>
<li>图像增强，通过随机裁剪实现</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 随机裁剪图像数据</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">rand_crop</span>(<span class="params">data,label,high,width</span>):</span><br><span class="line">    im_width,im_high=data.size</span><br><span class="line">    <span class="comment"># 生成图像随机点</span></span><br><span class="line">    left=np.random.randint(<span class="number">0</span>,im_width-width)</span><br><span class="line">    top=np.random.randint(<span class="number">0</span>,im_high-high)</span><br><span class="line">    right=left+width</span><br><span class="line">    bottom=top+high</span><br><span class="line">    data=data.crop((left,top,right,bottom))</span><br><span class="line">    label=label.crop((left,top,right,bottom))</span><br><span class="line">    <span class="keyword">return</span> data,label</span><br></pre></td></tr></table></figure>
<ul>
<li>图像转换，将图像转为Tensor格式并进行标准化</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 图像转换操作</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">img_transforms</span>(<span class="params">data,label,high,width,colormap</span>):</span><br><span class="line">    data,label=rand_crop(data,label,high,width)</span><br><span class="line">    data_tfs=transforms.Compose([</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize([<span class="number">0.485</span>,<span class="number">0.456</span>,<span class="number">0.406</span>],[<span class="number">0.229</span>,<span class="number">0.224</span>,<span class="number">0.225</span>])</span><br><span class="line"></span><br><span class="line">    ])</span><br><span class="line">    data=data_tfs(data)</span><br><span class="line">    label=torch.from_numpy(img2lab(label,colormap))</span><br><span class="line">    <span class="keyword">return</span> data,label</span><br></pre></td></tr></table></figure>
<h4 id="1-3-读取文件">1.3  读取文件</h4>
<p>VOC2012的数据集路径保存在<code>train.txt</code>中，我们需要获取该文件，通过<code>np.loadtxt</code>保存路径信息。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 读取路径函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">read_image_path</span>(<span class="params">root=<span class="string">r&quot;F:\VOCdevkit\VOC2012\ImageSets\Segmentation\train.txt&quot;</span></span>):</span><br><span class="line">    image=np.loadtxt(root,dtype=<span class="built_in">str</span>)</span><br><span class="line">    n=<span class="built_in">len</span>(image)</span><br><span class="line">    data,label=[<span class="literal">None</span>]*n,[<span class="literal">None</span>]*n</span><br><span class="line">    <span class="keyword">for</span> i,fname <span class="keyword">in</span> <span class="built_in">enumerate</span>(image):</span><br><span class="line">        data[i]=<span class="string">r&quot;F:\VOCdevkit\VOC2012\JPEGImages\%s.jpg&quot;</span>%(fname)</span><br><span class="line">        label[i]=<span class="string">r&quot;F:\VOCdevkit\VOC2012\SegmentationClass\%s.png&quot;</span>%(fname)</span><br><span class="line">    <span class="keyword">return</span> data,label</span><br></pre></td></tr></table></figure>
<p>接着我们需要定义一个<code>Dataset</code>类，继承自<code>torch.utils.data.Dataset</code>，作为<code>DataLoade</code>中的数据源。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义一个MyDataset继承于torch.utils.data.Dataset</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyDataset</span>(Data.Dataset):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,data_root,high,width,imtransform,colormap</span>):</span><br><span class="line">        self.data_root=data_root</span><br><span class="line">        self.high=high</span><br><span class="line">        self.width=width</span><br><span class="line">        self.imtransform=imtransform</span><br><span class="line">        self.cm=colormap</span><br><span class="line">        data_list,label_list=read_image_path(data_root)</span><br><span class="line">        self.data_list=self._<span class="built_in">filter</span>(data_list)</span><br><span class="line">        self.label_list=self._<span class="built_in">filter</span>(label_list)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_filter</span>(<span class="params">self,images</span>):</span><br><span class="line">    	<span class="comment"># 处理掉不符合尺寸的数据</span></span><br><span class="line">    	<span class="comment"># 这步需要打开图片，耗时会有点久</span></span><br><span class="line">        imlist=[]</span><br><span class="line">        <span class="keyword">for</span> im <span class="keyword">in</span> images:</span><br><span class="line">            img=Image.<span class="built_in">open</span>(im)</span><br><span class="line">            <span class="keyword">if</span> img.size[<span class="number">1</span>]&gt;self.high <span class="keyword">and</span> img.size[<span class="number">0</span>]&gt;self.width:</span><br><span class="line">                <span class="comment"># 注意此时还是路径</span></span><br><span class="line">                imlist.append(im)</span><br><span class="line">        <span class="keyword">return</span> imlist</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self,idx</span>):</span><br><span class="line">        <span class="comment"># 这步是核心</span></span><br><span class="line">        img=self.data_list[idx]</span><br><span class="line">        lab=self.label_list[idx]</span><br><span class="line">        img=Image.<span class="built_in">open</span>(img)</span><br><span class="line">        lab=Image.<span class="built_in">open</span>(lab).convert(<span class="string">&quot;RGB&quot;</span>)</span><br><span class="line">        img,lab=self.imtransform(img,lab,self.high,self.width,self.cm)</span><br><span class="line">        <span class="keyword">return</span> img,lab</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.data_list)</span><br></pre></td></tr></table></figure>
<p>查看数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 读取数据</span></span><br><span class="line">high,width=<span class="number">320</span>,<span class="number">480</span></span><br><span class="line">voc_train=MyDataset(<span class="string">r&quot;F:\VOCdevkit\VOC2012\ImageSets\Segmentation\train.txt&quot;</span>,high,width,img_transforms,colormap)</span><br><span class="line">voc_val=MyDataset(<span class="string">r&quot;F:\VOCdevkit\VOC2012\ImageSets\Segmentation\val.txt&quot;</span>,high,width,img_transforms,colormap)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建数据加载器每个batch使用4个图像</span></span><br><span class="line">train_loader=Data.DataLoader(voc_train,batch_size=<span class="number">4</span>,shuffle=<span class="literal">True</span>,pin_memory=<span class="literal">True</span>)</span><br><span class="line">val_loader=Data.DataLoader(voc_val,batch_size=<span class="number">4</span>,shuffle=<span class="literal">True</span>,pin_memory=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查训练数据集的一个batch的样本维度是否正确</span></span><br><span class="line"><span class="keyword">for</span> step,(bx,by) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">    <span class="keyword">if</span> step&gt;<span class="number">0</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;bx.shape&quot;</span>,bx.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;by.shape&quot;</span>,by.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;bx&quot;</span>,bx)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;by&quot;</span>,by)</span><br></pre></td></tr></table></figure>
<h4 id="1-4-可视化函数">1.4  可视化函数</h4>
<p>本部分需要做的事情是将Tensor数据转化为图像数据，包括<code>label</code>和<code>image</code>的转化。</p>
<p>需要反标准化回去，并且将溢出的浮点抹去</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">inv_normalize_img</span>(<span class="params">data</span>):</span><br><span class="line">    rgb_mean=np.array([<span class="number">0.485</span>,<span class="number">0.456</span>,<span class="number">0.406</span>])</span><br><span class="line">    rgb_std=np.array([<span class="number">0.229</span>,<span class="number">0.224</span>,<span class="number">0.225</span>])</span><br><span class="line">    data=data.astype(<span class="string">&quot;float32&quot;</span>)*rgb_std+rgb_mean</span><br><span class="line">    <span class="keyword">return</span> data.clip(<span class="number">0</span>,<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>将标签转化为RGB图像</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">label2img</span>(<span class="params">prelab,colormap</span>):</span><br><span class="line">    <span class="comment">#从预测到的标签转化为图像，针对一个标签图</span></span><br><span class="line">    h,w=prelab.shape</span><br><span class="line">    prelab=prelab.reshape(h*w,-<span class="number">1</span>)</span><br><span class="line">    img=np.zeros((h*w,<span class="number">3</span>),dtype=<span class="string">&quot;int32&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> ii <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(colormap)):</span><br><span class="line">        index=np.where(prelab==ii)</span><br><span class="line">        img[index,:]=colormap[ii]</span><br><span class="line">    <span class="keyword">return</span> img.reshape(h,w,<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<p>可视化图像</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 可视化一个batch图像</span></span><br><span class="line">bx_numpy=bx.data.numpy()</span><br><span class="line">bx_numpy=bx_numpy.transpose(<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>)</span><br><span class="line">by_numpy=by.data.numpy()</span><br><span class="line">plt.figure(figsize=(<span class="number">16</span>,<span class="number">6</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">    plt.subplot(<span class="number">2</span>,<span class="number">4</span>,i+<span class="number">1</span>)</span><br><span class="line">    plt.imshow(inv_normalize_img(bx_numpy[i]))</span><br><span class="line">    plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">    plt.subplot(<span class="number">2</span>,<span class="number">4</span>,i+<span class="number">5</span>)</span><br><span class="line">    plt.imshow(label2img(by_numpy[i],colormap))</span><br><span class="line">    plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">plt.subplots_adjust(wspace=<span class="number">0.1</span>,hspace=<span class="number">0.1</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<img src="/2022/07/29/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91FCN%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%BD%91%E7%BB%9C/image-20220327144450083.png" alt="image-20220327144450083" style="zoom:50%;">
<h4 id="1-5-网络构建">1.5  网络构建</h4>
<p>使用训练好的VGG19网络作为backbone，定义语义分割网络FCN8S。其核心在于：</p>
<ul>
<li>将卷积后的结果反卷积</li>
<li>在不同层进行特征融合，提高辨识度</li>
<li>最终得到与原图大小相同的图片，利用softmax判别类别</li>
</ul>
<p>FCN8S会在第五个最大池化层进行反卷积，得到大小为<code>w/16</code>的特征，融合将其加上第四个最大池化后的数据后进行处理，再次反卷积得到<code>w/8</code>的特征。最后通过分类器，将特征维度转换为类别数量，判断每个像素点在每个特征维度上的概率，即可实现图像分割。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义语义分割网络FCN-8S</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FCN8S</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,num_class</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param num_class: 训练数据的类别</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="built_in">super</span>(FCN8S, self).__init__()</span><br><span class="line">        self.num_class=num_class</span><br><span class="line">        model_vgg19=torchvision.models.vgg19(pretrained=<span class="literal">True</span>)</span><br><span class="line">        self.backbone=model_vgg19.features</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 需要做的事情是反卷积、特征融合</span></span><br><span class="line">        <span class="comment"># 传到这里的数据已经成了[batch,512,10,15]</span></span><br><span class="line">        self.relu=nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        self.deconv1=nn.ConvTranspose2d(<span class="number">512</span>,<span class="number">512</span>,kernel_size=<span class="number">3</span>,stride=<span class="number">2</span>,padding=<span class="number">1</span>,dilation=<span class="number">1</span>,output_padding=<span class="number">1</span>)</span><br><span class="line">        self.bn1=nn.BatchNorm2d(<span class="number">512</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 512-&gt;256</span></span><br><span class="line">        self.deconv2=nn.ConvTranspose2d(<span class="number">512</span>,<span class="number">256</span>,kernel_size=<span class="number">3</span>,stride=<span class="number">2</span>,padding=<span class="number">1</span>,dilation=<span class="number">1</span>,output_padding=<span class="number">1</span>)</span><br><span class="line">        self.bn2=nn.BatchNorm2d(<span class="number">256</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#256-&gt;128</span></span><br><span class="line">        self.deconv3=nn.ConvTranspose2d(<span class="number">256</span>,<span class="number">128</span>,kernel_size=<span class="number">3</span>,stride=<span class="number">2</span>,padding=<span class="number">1</span>,dilation=<span class="number">1</span>,output_padding=<span class="number">1</span>)</span><br><span class="line">        self.bn3=nn.BatchNorm2d(<span class="number">128</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 128-&gt;64</span></span><br><span class="line">        self.deconv4 = nn.ConvTranspose2d(<span class="number">128</span>, <span class="number">64</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>, dilation=<span class="number">1</span>, output_padding=<span class="number">1</span>)</span><br><span class="line">        self.bn4 = nn.BatchNorm2d(<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 64-&gt;32</span></span><br><span class="line">        self.deconv5 = nn.ConvTranspose2d(<span class="number">64</span>, <span class="number">32</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>, dilation=<span class="number">1</span>, output_padding=<span class="number">1</span>)</span><br><span class="line">        self.bn5 = nn.BatchNorm2d(<span class="number">32</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 提取32维特征FCN32S</span></span><br><span class="line">        self.classifier=nn.Conv2d(<span class="number">32</span>,num_class,kernel_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># VGG19中maxpool2所在的层</span></span><br><span class="line">        self.layers=&#123;<span class="string">&quot;4&quot;</span>:<span class="string">&quot;maxpool_1&quot;</span>,</span><br><span class="line">                     <span class="string">&quot;9&quot;</span>:<span class="string">&quot;maxpool_2&quot;</span>,</span><br><span class="line">                     <span class="string">&quot;18&quot;</span>:<span class="string">&quot;maxpool_3&quot;</span>,</span><br><span class="line">                     <span class="string">&quot;27&quot;</span>:<span class="string">&quot;maxpool_4&quot;</span>,</span><br><span class="line">                     <span class="string">&quot;36&quot;</span>:<span class="string">&quot;maxpool_5&quot;</span>&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        output=&#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> name,layer <span class="keyword">in</span> self.backbone._modules.items():</span><br><span class="line">            x=layer(x)</span><br><span class="line">            <span class="keyword">if</span> name <span class="keyword">in</span> self.layers:</span><br><span class="line">                <span class="comment"># 留下这层信息</span></span><br><span class="line">                output[self.layers[name]]=x</span><br><span class="line">        <span class="comment"># 获取各层的信息</span></span><br><span class="line">        x5=output[<span class="string">&quot;maxpool_5&quot;</span>] <span class="comment"># (b,512,x.H/32,x.W/32)</span></span><br><span class="line">        x4=output[<span class="string">&quot;maxpool_4&quot;</span>] <span class="comment"># (b,512,x.H/16,x.W/16)</span></span><br><span class="line">        x3=output[<span class="string">&quot;maxpool_3&quot;</span>] <span class="comment"># (b,256,x.H/8,x.W/8)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 转置卷积</span></span><br><span class="line">        score=self.relu(self.deconv1(x5)) <span class="comment"># 512 16 16</span></span><br><span class="line">        <span class="comment"># 加上16s的信息</span></span><br><span class="line">        score=self.bn1(score+x4)</span><br><span class="line">        <span class="comment"># 再反卷积</span></span><br><span class="line">        score=self.relu(self.deconv2(score)) <span class="comment"># 256 8 8</span></span><br><span class="line">        <span class="comment"># 加上8s的信息</span></span><br><span class="line">        score=self.bn2(score+x3)</span><br><span class="line">        <span class="comment"># 一步一步慢慢回去</span></span><br><span class="line">        score=self.bn3(self.relu(self.deconv3(score))) <span class="comment"># 128 4 4</span></span><br><span class="line">        score=self.bn4(self.relu(self.deconv4(score))) <span class="comment"># 64 2 2</span></span><br><span class="line">        score=self.bn5(self.relu(self.deconv5(score))) <span class="comment"># 32 1 1</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 最后将这32维转成输入维度(rgb:3,gray:1)</span></span><br><span class="line">        score=self.classifier(score)</span><br><span class="line">        <span class="keyword">return</span> score <span class="comment"># b,n_class,1,1</span></span><br></pre></td></tr></table></figure>
<h4 id="1-6-网络训练">1.6  网络训练</h4>
<p>正常去训练就好，注意这里没有使用残差网络，所以可以保留最好的参数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 网络训练</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_model</span>(<span class="params">model,criterion,optimizer,traindataloader,valdataloader,num_epoch=<span class="number">25</span></span>):</span><br><span class="line">    since=time()</span><br><span class="line">    best_model_wts=copy.deepcopy(model.state_dict())</span><br><span class="line">    best_loss=<span class="number">1e10</span></span><br><span class="line">    train_loss_all=[]</span><br><span class="line">    train_acc_all=[]</span><br><span class="line">    val_loss_all=[]</span><br><span class="line">    val_acc_all=[]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 训练num_epoch次</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epoch):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Epoch &#123;&#125;/&#123;&#125;&quot;</span>.<span class="built_in">format</span>(epoch,num_epoch-<span class="number">1</span>))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;-&quot;</span>*<span class="number">10</span>)</span><br><span class="line">        train_loss=<span class="number">0.0</span></span><br><span class="line">        train_num=<span class="number">0</span></span><br><span class="line">        val_loss=<span class="number">0.0</span></span><br><span class="line">        val_num=<span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 训练阶段</span></span><br><span class="line">        model.train()</span><br><span class="line">        <span class="keyword">for</span> step,(bx,by) <span class="keyword">in</span> <span class="built_in">enumerate</span>(traindataloader):</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            bx=bx.<span class="built_in">float</span>().to(device)</span><br><span class="line">            by=by.long().to(device)</span><br><span class="line"></span><br><span class="line">            out=model(bx)</span><br><span class="line">            </span><br><span class="line"></span><br><span class="line">            <span class="comment"># 柔和21个类做一个softmax后再做log</span></span><br><span class="line">            out=F.log_softmax(out,dim=<span class="number">1</span>)</span><br><span class="line">            pre_lab=torch.argmax(out,<span class="number">1</span>)</span><br><span class="line">            loss=criterion(out,by)</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line">            train_loss+=loss.item()*<span class="built_in">len</span>(by)</span><br><span class="line">            train_num+=<span class="built_in">len</span>(by)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算训练集上的精度</span></span><br><span class="line">        train_loss_all.append(train_loss/train_num)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;&#123;&#125; Train Loss: &#123;:.4f&#125;&quot;</span>.<span class="built_in">format</span>(epoch,train_loss_all[-<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 进入评估阶段</span></span><br><span class="line">        model.<span class="built_in">eval</span>()</span><br><span class="line">        <span class="keyword">for</span> step,(bx,by) <span class="keyword">in</span> <span class="built_in">enumerate</span>(valdataloader):</span><br><span class="line">            bx,by=bx.<span class="built_in">float</span>().to(device),by.long().to(device)</span><br><span class="line">            out=model(bx)</span><br><span class="line">            out=F.log_softmax(out,dim=<span class="number">1</span>)</span><br><span class="line">            pre_lab=torch.argmax(out,<span class="number">1</span>)</span><br><span class="line">            loss=criterion(out,by)</span><br><span class="line">            val_loss+=loss.item()*<span class="built_in">len</span>(by)</span><br><span class="line">            val_num+=<span class="built_in">len</span>(by)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算损失和精度</span></span><br><span class="line">        val_loss_all.append(val_loss/val_num)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;&#123;&#125; Val Loss: &#123;:.4f&#125;&quot;</span>.<span class="built_in">format</span>(epoch,val_loss_all[-<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 保留最好的参数</span></span><br><span class="line">        <span class="keyword">if</span> val_loss_all[-<span class="number">1</span>]&lt;best_loss:</span><br><span class="line">            best_loss=val_loss_all[-<span class="number">1</span>]</span><br><span class="line">            best_model_wts=copy.deepcopy(model.state_dict())</span><br><span class="line">        time_use=time()-since</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Train and val complete in &#123;:.0f&#125;m &#123;:.0f&#125;s&quot;</span>.<span class="built_in">format</span>(time_use//<span class="number">60</span>,time_use%<span class="number">60</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 输出训练信息</span></span><br><span class="line">    train_process=pd.DataFrame(</span><br><span class="line">        data=&#123;<span class="string">&quot;epoch&quot;</span>:<span class="built_in">range</span>(num_epoch),</span><br><span class="line">              <span class="string">&quot;train_loss_all&quot;</span>:train_loss_all,</span><br><span class="line">              <span class="string">&quot;val_loss_all&quot;</span>:val_loss_all&#125;</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 加载最好的模型</span></span><br><span class="line">    model.load_state_dict(best_model_wts)</span><br><span class="line">    <span class="keyword">return</span> model,train_process</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义损失函数和优化器</span></span><br><span class="line">lr=<span class="number">0.0003</span></span><br><span class="line">criterion=nn.NLLLoss()</span><br><span class="line">optimizer=optim.Adam(fcn8s.parameters(),lr=lr,weight_decay=<span class="number">1e-4</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 迭代训练</span></span><br><span class="line">fcn8s,train_process=train_model(fcn8s,criterion,optimizer,train_loader,val_loader,num_epoch=<span class="number">5</span>)</span><br><span class="line">torch.save(fcn8s,<span class="string">&quot;fcn8s.pkl&quot;</span>)</span><br></pre></td></tr></table></figure>
<h4 id="1-7-结果可视化">1.7  结果可视化</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 可视化训练过程</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">6</span>))</span><br><span class="line">plt.plot(train_process.epoch,train_process.train_loss_all,<span class="string">&quot;ro-&quot;</span>,label=<span class="string">&quot;Train Loss&quot;</span>)</span><br><span class="line">plt.plot(train_process.epoch,train_process.val_loss_all,<span class="string">&quot;bs-&quot;</span>,label=<span class="string">&quot;Val Loss&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.xlabel(<span class="string">&quot;epoch&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Loss&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<img src="/2022/07/29/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91FCN%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%BD%91%E7%BB%9C/image-20220326235720662.png" alt="image-20220326235720662" style="zoom:50%;">
<p>​                                                                                                                                                                                                                                                                                                                                                                                                                                                          查看在验证集上的效果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从验证集中获取一个batch的数据</span></span><br><span class="line"><span class="keyword">for</span> step,(bx,by) <span class="keyword">in</span> <span class="built_in">enumerate</span>(val_loader):</span><br><span class="line">    <span class="keyword">if</span> step&gt;<span class="number">0</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">fcn8s.<span class="built_in">eval</span>()</span><br><span class="line">bx=bx.<span class="built_in">float</span>().to(device)</span><br><span class="line">by=by.long().to(device)</span><br><span class="line">out=fcn8s(bx)</span><br><span class="line"><span class="comment"># 拿出来结果后需要在维度上做一个log_softmax</span></span><br><span class="line">out=F.log_softmax(out,dim=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 判别最可能的概率</span></span><br><span class="line">pre_lab=torch.argmax(out,<span class="number">1</span>)</span><br><span class="line">bx_numpy=bx.cpu().data.numpy()</span><br><span class="line">bx_numpy=bx_numpy.transpose(<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>)</span><br><span class="line">by_numpy=by.cpu().data.numpy()</span><br><span class="line">pre_lab_numpy=pre_lab.cpu().numpy()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">    plt.subplot(<span class="number">3</span>,<span class="number">4</span>,i+<span class="number">1</span>)</span><br><span class="line">    plt.imshow(inv_normalize_img(bx_numpy[i]))</span><br><span class="line">    plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">    plt.subplot(<span class="number">3</span>,<span class="number">4</span>,i+<span class="number">5</span>)</span><br><span class="line">    plt.imshow(label2img(by_numpy[i],colormap))</span><br><span class="line">    plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">    plt.imshow(label2img(pre_lab_numpy[i],colormap))</span><br><span class="line">    plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">plt.subplots_adjust(wspace=<span class="number">0.05</span>,hspace=<span class="number">0.05</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<img src="/2022/07/29/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91FCN%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%BD%91%E7%BB%9C/image-20220326235824843.png" alt="image-20220326235824843" style="zoom: 80%;"><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 不想学辣 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 神经网络 </tag>
            
            <tag> 图像处理 </tag>
            
            <tag> 卷积神经网络 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[第一章  深度学习与PyTorch]]></title>
      <url>/2022/07/28/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E7%AC%AC%E4%B8%80%E7%AB%A0%20%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%8EPyTorch/</url>
      <content type="html"><![CDATA[<h1>第一章    深度学习与PyTorch</h1>
<hr>
<h2 id="1-1-机器学习">1.1 机器学习</h2>
<p>在人工智能领域，机器学习是实现人工智能的一个分支，也是其中发展最快的一个分支。</p>
<p>简单来说，机器学习是计算机程序如何随着经验的积累而提高性能，使系统自我完善的过程。</p>
<p>根据应用场景和学习方式的不同，可以简单分为三类：</p>
<ul>
<li>
<p><strong>无监督学习 unsupervised learning</strong></p>
<p>无监督学习不需要提前知道数据集的类别标签，通常运用场景为聚类和降维。</p>
</li>
<li>
<p><strong>半监督学习 semi-supervised learning</strong></p>
<p>半监督学习介于二者之间，利用极少的有标签数据和大量无标签数据进行学习，同过学习得到的经验对无标签的数据进行预测。</p>
</li>
<li>
<p><strong>有监督学习 supervised learning</strong></p>
<p>主要特征是数据集具备标签数据。</p>
</li>
</ul>
<hr>
<h2 id="1-2-深度学习">1.2 深度学习</h2>
<p>深度学习是一种机器学习方法，与传统的机器学习方法相同，可以根据输入的数据进行分类或回归。但随着数据量的增加，传统机器学习方法表现不尽如人意，而此时利用更深的网络挖掘数据信息的方法----深度学习表现出了优异的性能，2010年后，更是迎来了爆发式增长。</p>
<p>在20世纪60~70年代，神经生理学家发现猫的视觉皮层中有两种细胞，一种是简单细胞，他们对图像中的细节信息更加敏感，如边缘、角点。另一种是复杂细胞，能够分析处理图像的空间不变性，如旋转、放缩、远近等图像。学者们根据这点提出了卷积神经网络，在图像处理方面取得了较大的成果。</p>
<p>事实上，在当时未能解决梯度消失问题前，基于深度卷积神经网络的算法并没有引起人们的重视，在分层训练过程中，本应用于修正模型参数的误差随着层数的增加指数递减，这就导致了模型训练效果低下。</p>
<p>尽管深度算法在2000年前就被使用，并且受到了SVM的压制，但其发展并未停止，1992年多层网络提出，通过无监督学习训练深度网络中的每一层，再通过反向传播算法调优。在这一模型中，神经网络的每一层都代表观测变量的一种压缩表示，而这一表示又被传入到下一层网络。</p>
<p>进入21世纪后，随着数据量的积累和计算机性能的提升，神经网络终于迎来了新一轮的春天。深度学习算法和传统的机器学习算法相比，其最大的特点是端到端的学习，在进行学习之前无需进行特征提取等操作，可以通过深层的网络结构自动从原始图像中提取有用的特征。而传统的机器学习过程则需要更多的人工干预，其稳定性较弱。</p>
<hr>
<h2 id="Pytorch">Pytorch</h2>
<hr>
<h3 id="一-Pytorch是什么？">一.Pytorch是什么？</h3>
<p>Pytorch是torch的python版本，是由<strong>Facebook</strong>开源的神经网络框架，专门针对 <strong>GPU</strong> 加速的深度神经网络（DNN）编程。Torch 是一个经典的对多维矩阵数据进行操作的张量（tensor ）库，在机器学习和其他数学密集型应用有广泛应用。与Tensorflow的静态计算图不同，pytorch的计算图是<strong>动态</strong>的，可以根据计算需要<strong>实时改变计算图</strong>。但由于Torch语言采用 Lua，导致在国内一直很小众，并逐渐被支持 Python 的 Tensorflow 抢走用户。作为经典机器学习库 Torch 的端口，PyTorch 为 Python 语言使用者提供了舒适的写代码选择。</p>
<hr>
<h3 id="二、Pytorch优势">二、Pytorch优势</h3>
<ul>
<li>
<p>自动求导</p>
<ul>
<li>
<p>例如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x=torch.tensor(<span class="number">1.</span>,)</span><br><span class="line">a=torch.tensor(<span class="number">1.</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line">b=torch.tensor(<span class="number">2.</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line">c=torch.tensor(<span class="number">3.</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line">y=a**<span class="number">2</span>*x+b*x+c</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;before&#x27;</span>,a.grad,b.grad,c.grad)</span><br><span class="line"><span class="comment"># 自动求导，对表达式a中的参数[b,c,d]进行求偏导</span></span><br><span class="line">grads=torch.autograd.grad(y,[a,b,c])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;after&#x27;</span>,grads[<span class="number">0</span>],grads[<span class="number">1</span>],grads[<span class="number">2</span>])</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li>
<p>GPU加速计算(可用于numpy的加速)</p>
</li>
<li>
<p>常用API</p>
</li>
<li>
<p>简洁</p>
<ul>
<li>不同于TF，PyTorch的设计遵照<code>tensor</code>-&gt;<code>variable(autograd)</code>-&gt;<code>nn.Module</code>三个由低到高的抽象层次，分别代表高维数组(张量)、自动求导(变量)和神经网络(层/模块)。PT的源码只有TF的十分钟之一左右，更少的抽象、更直观的设计使得PT十分容易阅读。</li>
</ul>
</li>
<li>
<p>速度</p>
<ul>
<li>PT的速度胜过TF和Keras等框架</li>
</ul>
</li>
<li>
<p>易用</p>
</li>
</ul>
<hr>
<h3 id="线性回归">线性回归</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">error_rate</span>(<span class="params">a,b,points</span>):</span><br><span class="line">    <span class="comment"># 计算均方差</span></span><br><span class="line">    total=<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="built_in">len</span>(points)):</span><br><span class="line">        x=points[i][<span class="number">0</span>]</span><br><span class="line">        y=points[i][<span class="number">1</span>]</span><br><span class="line">        total+=(x*a+b-y)**<span class="number">2</span></span><br><span class="line">    <span class="keyword">return</span> total/<span class="built_in">float</span>(<span class="built_in">len</span>(points))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">step_gradient</span>(<span class="params">a_cur,b_cur,points,lr</span>):</span><br><span class="line">    <span class="comment"># 当前梯度方向</span></span><br><span class="line">    b_gradient=<span class="number">0</span></span><br><span class="line">    a_gradient=<span class="number">0</span></span><br><span class="line">    size=<span class="built_in">float</span>(<span class="built_in">len</span>(points))</span><br><span class="line">    total=<span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="built_in">len</span>(points)):</span><br><span class="line">        x=points[i][<span class="number">0</span>]</span><br><span class="line">        y=points[i][<span class="number">1</span>]</span><br><span class="line">        <span class="comment"># 修正梯度</span></span><br><span class="line">        <span class="comment"># (ax+b-y)**2对a求偏导: 2*(ax+b-y)*x</span></span><br><span class="line">        <span class="comment"># 对b求偏导: 2*(ax+b-y)</span></span><br><span class="line">        a_gradient+=-<span class="number">2</span>*(y-(a_cur*x+b_cur))*x/size</span><br><span class="line">        b_gradient+=-<span class="number">2</span>*(y-(a_cur*x+b_cur))/size</span><br><span class="line">        total += (y-(a_cur*x+b_cur)) ** <span class="number">2</span></span><br><span class="line">    <span class="comment"># 平均梯度方向</span></span><br><span class="line">    <span class="comment"># 修正</span></span><br><span class="line">    <span class="comment"># x=x-/delta x * LearningRate</span></span><br><span class="line">    <span class="keyword">return</span> [a_cur-a_gradient*lr,b_cur-b_gradient*lr,total/size]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">linear_regressing</span>(<span class="params">points,start_a,start_b,learningrate,iterations</span>):</span><br><span class="line"></span><br><span class="line">    a=start_a</span><br><span class="line">    b=start_b</span><br><span class="line">    time=<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(iterations):</span><br><span class="line">        a,b,tem=step_gradient(a,b,points,learningrate)</span><br><span class="line">        time+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> time%<span class="number">10</span>==<span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(tem)</span><br><span class="line">    <span class="keyword">return</span> [a,b]</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">point=[]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">50</span>):</span><br><span class="line">    t = random.randint(<span class="number">0</span>, <span class="number">100</span>)</span><br><span class="line">    point.append([t,t*<span class="number">2</span>+<span class="number">6</span>+random.randrange(<span class="number">0</span>,<span class="number">10</span>)])</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=[<span class="number">20</span>,<span class="number">8</span>],dpi=<span class="number">300</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> point:</span><br><span class="line">    plt.plot(i[<span class="number">0</span>],i[<span class="number">1</span>],<span class="string">&#x27;o&#x27;</span>)</span><br><span class="line">a,b=linear_regressing(point,<span class="number">2</span>,<span class="number">6</span>,<span class="number">0.0002</span>,<span class="number">10000</span>)</span><br><span class="line"><span class="comment"># 学习率必须设置得很小，不然会冲出去</span></span><br><span class="line">new_x=[i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="number">101</span>) <span class="keyword">if</span> i%<span class="number">10</span>==<span class="number">0</span>]</span><br><span class="line">new_y=[i*a+b <span class="keyword">for</span> i <span class="keyword">in</span> new_x]</span><br><span class="line">plt.plot(new_x,new_y)</span><br><span class="line"><span class="built_in">print</span>(a,b)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<hr>
<h2 id="Torch基本操作">Torch基本操作</h2>
<h3 id="1-Torch数据类型">1.Torch数据类型</h3>
<blockquote>
<p>dim: 维度，如2</p>
<p>shape: 长度/形状，如[2,2]</p>
</blockquote>
<h4 id="1-1标量Scalar">1.1<strong>标量Scalar</strong></h4>
<p>常见于<code>loss</code>评估</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 直接创建</span></span><br><span class="line">torch.tensor(<span class="number">1.</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获得形状</span></span><br><span class="line">a=torch.tensor(<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">a.shape <span class="comment"># or a.size()</span></span><br><span class="line"><span class="built_in">len</span>(a.shape) <span class="comment"># --&gt;0</span></span><br><span class="line"><span class="comment"># 形状交互</span></span><br><span class="line"><span class="built_in">list</span>(a.shape)</span><br><span class="line"><span class="comment"># 获取该标量</span></span><br><span class="line">a.item()</span><br></pre></td></tr></table></figure>
<hr>
<h4 id="1-2向量Vector">1.2<strong>向量Vector</strong></h4>
<p>常见于<code>bias</code>和<code>linear_input</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">torch.tensor([<span class="number">1.1</span>,<span class="number">2.2</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定类型</span></span><br><span class="line">torch.FloatTensro(n) <span class="comment"># 随机初始化向量长度</span></span><br><span class="line"><span class="comment"># 会生成n个符合类型的向量元素</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 从np中获取</span></span><br><span class="line">data=np.ones(<span class="number">2</span>)</span><br><span class="line">torch.from_numpy(data)</span><br></pre></td></tr></table></figure>
<hr>
<h4 id="1-3张量Tensor">1.3<strong>张量Tensor</strong></h4>
<p>实际上在torch0.4之后都叫张量了</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">a=torch.randn(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 常见的数据交互</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># number of element 获得元素数量</span></span><br><span class="line">a.numel() </span><br><span class="line"><span class="comment"># 实际上就是1*2*3</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获得维度</span></span><br><span class="line">a.dim()</span><br></pre></td></tr></table></figure>
<p>Tensor的数据类型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># CPU</span></span><br><span class="line">a=torch.randn(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">a.<span class="built_in">type</span>()</span><br><span class="line"><span class="comment"># &quot;torch.FloatTensor&quot;</span></span><br><span class="line"><span class="built_in">type</span>(a)</span><br><span class="line"><span class="comment"># torch.Tensor</span></span><br><span class="line"><span class="built_in">isinstance</span>(a,torch.FloatTensor)</span><br><span class="line"><span class="comment"># True</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># GPU</span></span><br><span class="line"><span class="built_in">isinstance</span>(data,torch.cuda.DoubleTensor)</span><br><span class="line"><span class="comment"># 转换</span></span><br><span class="line">data=data.cuda</span><br><span class="line">data=data.<span class="built_in">float</span>()</span><br><span class="line">data=data.<span class="built_in">int</span>()</span><br></pre></td></tr></table></figure>
<p>类型表</p>
<p><code>注意，Torch没有string类型，可以通过one-hot处理，或是语义关系采用embedded中的word2vec。</code></p>
<hr>
<h4 id="1-4创建Tensor">1.4<strong>创建Tensor</strong></h4>
<p>我们可以从<code>numpy</code>中获取</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a=np.ndarray([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line">a=torch.from_numpy(a)</span><br></pre></td></tr></table></figure>
<p>可以从<code>list</code>中获取</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">torch.tensor([<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">torch.FloatTensor([<span class="number">2.</span>,<span class="number">3.</span>])</span><br></pre></td></tr></table></figure>
<p>注意<code>torch.tensor</code>是接收现有数据，而<code>torch.Tensor</code>是接收数据维度(当然也可以接收现实数据)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">torch.FloatTensor(<span class="number">2</span>,<span class="number">3</span>) <span class="comment"># 接收维度随机创建</span></span><br><span class="line">torch.FloatTensro([<span class="number">2</span>,<span class="number">3</span>])</span><br></pre></td></tr></table></figure>
<p>生成<strong>未初始化</strong>的数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Torch.empty([<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>设置<strong>默认数据类型</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Torch.Tensor默认的是FloatTensor</span></span><br><span class="line">torch.set_default_tensor_type(torch.DoubleTensor)</span><br></pre></td></tr></table></figure>
<p>生成<strong>分布</strong>数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 0-1区间</span></span><br><span class="line">a=torch.rand(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line"><span class="comment"># like方法是先读取shape，然后送过去生成数据</span></span><br><span class="line">torch.rand_like(a)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 自定义区间</span></span><br><span class="line">torch.randint(<span class="number">1</span>,<span class="number">10</span>,[<span class="number">3</span>,<span class="number">3</span>])</span><br><span class="line"><span class="comment"># 最小值，最大值-1，形状</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 正态分布N(0,1)</span></span><br><span class="line">torch.randn(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line"><span class="comment"># 自定义正态</span></span><br><span class="line">torch.normal(mean=torch.full([<span class="number">10</span>],<span class="number">0</span>),std=torch.arange(<span class="number">1</span>,<span class="number">0</span>,-<span class="number">0.1</span>))</span><br><span class="line"><span class="comment"># 得到一个长度为10，维度为1的数据</span></span><br><span class="line"><span class="comment"># 一般再做个view</span></span><br></pre></td></tr></table></figure>
<p><strong>全部赋值</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">torch.full([<span class="number">2</span>,<span class="number">3</span>],<span class="number">7</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成标量</span></span><br><span class="line">torch.full([],<span class="number">7</span>)</span><br></pre></td></tr></table></figure>
<p><strong>等差数列</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">torch.arange(<span class="number">0</span>,<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">torch.arange(<span class="number">0</span>,<span class="number">10</span>,<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p><strong>等分生成</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 线性等分</span></span><br><span class="line"><span class="comment"># 注意，包含了最大值</span></span><br><span class="line">torch.linspace(<span class="number">0</span>,<span class="number">10</span>,steps=<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对数等分</span></span><br><span class="line">torch.logspace(<span class="number">0</span>,-<span class="number">1</span>,steps=<span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<p><strong>规则矩阵</strong>生成</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对角</span></span><br><span class="line"><span class="comment"># 但是只能到二维</span></span><br><span class="line">torch.eye(<span class="number">3</span>) <span class="comment"># 3x3</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 全零</span></span><br><span class="line">torch.zeros(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 利用like生成</span></span><br><span class="line">torch.ones_like(a)</span><br></pre></td></tr></table></figure>
<p>随机<strong>打散</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">torch.randperm(<span class="number">10</span>)</span><br><span class="line"><span class="comment"># 生成一个随机打乱的tensor</span></span><br><span class="line"><span class="comment"># 如tensor([1,5,7,9,8,6,3,4,0])</span></span><br><span class="line"><span class="comment"># 一般用于随机化索引</span></span><br><span class="line"><span class="comment"># 如</span></span><br><span class="line">a=torch.rand(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">b=torch.rand(<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">idx=torch.randperm(<span class="number">2</span>)</span><br><span class="line">a[idx] <span class="comment"># 可以交换行</span></span><br><span class="line">b[idx]</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="2-Tensor索引与切片">2.Tensor索引与切片</h3>
<p>tensor的切片索引非常大胆</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对一个四位数据进行操作</span></span><br><span class="line">a=torch.rand(<span class="number">4</span>,<span class="number">3</span>,<span class="number">28</span>,<span class="number">28</span>)</span><br><span class="line">a[<span class="number">0</span>].shape <span class="comment"># torch.Size([3,28,28])</span></span><br><span class="line">a[<span class="number">0</span>,<span class="number">0</span>].shape <span class="comment"># torch.Size([28,28])</span></span><br><span class="line">a[<span class="number">0</span>,<span class="number">0</span>,<span class="number">2</span>,<span class="number">4</span>] <span class="comment"># tensor(0.8082)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 可以与切片一起使用</span></span><br><span class="line">a[:<span class="number">2</span>].shape <span class="comment"># torch.Size([2,3,28,28])</span></span><br><span class="line">a[:<span class="number">2</span>,<span class="number">1</span>:,:,:].shape</span><br><span class="line">a[:<span class="number">2</span>,-<span class="number">1</span>,:,:].shape</span><br><span class="line"></span><br><span class="line"><span class="comment"># 隔点采样</span></span><br><span class="line">a[:,:,<span class="number">0</span>:<span class="number">28</span>:<span class="number">2</span>,<span class="number">0</span>:<span class="number">15</span>:<span class="number">3</span>].shape</span><br><span class="line">a[:,:,::<span class="number">2</span>,::<span class="number">2</span>].shape</span><br><span class="line"></span><br><span class="line"><span class="comment"># 具体索引方式</span></span><br><span class="line">torch.index_select(dim,[])</span><br><span class="line">torch.index_select(<span class="number">0</span>,[<span class="number">1</span>,<span class="number">2</span>]) <span class="comment"># 从第一个维度上选择1,2个数据</span></span><br><span class="line">a.index_select(<span class="number">2</span>,torch.arange(<span class="number">8</span>)).shape</span><br><span class="line"><span class="comment"># torch.Size([4,3,8,28])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 任意多的维度</span></span><br><span class="line"><span class="comment"># ...</span></span><br><span class="line">a[...].shape</span><br><span class="line">a[<span class="number">0</span>,...].shape <span class="comment"># ==a[0]</span></span><br><span class="line">a[<span class="number">0</span>:,...,::<span class="number">2</span>] <span class="comment"># 对第一个维度和最后一个维度做限定</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过掩码选取</span></span><br><span class="line">x=torch.randn(<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">mask=x.ge(<span class="number">0.5</span>) <span class="comment"># 一个零一矩阵，大于0.5时为1</span></span><br><span class="line">torch.masked_select(x,mask) <span class="comment"># 直接获取一个vectory，是mask为1的数据</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 打平选取</span></span><br><span class="line"><span class="comment"># 先将数据排成一排</span></span><br><span class="line"><span class="comment"># 然后再选取</span></span><br><span class="line">scr=torch.tensor([[<span class="number">4</span>,<span class="number">3</span>,<span class="number">5</span>],</span><br><span class="line">                  [<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>]])</span><br><span class="line">torch.take(scr,torch.tensor[[<span class="number">0</span>,<span class="number">2</span>,-<span class="number">1</span>]])</span><br><span class="line"><span class="comment"># tensor([4,5,8])</span></span><br></pre></td></tr></table></figure>
<hr>
<h3 id="3-维度变化">3.维度变化</h3>
<h4 id="3-1-view与reshape">3.1 <strong>view与reshape</strong></h4>
<p><code>view</code>与<code>reshape</code>效果完全一致</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a=torch.randn(<span class="number">4</span>,<span class="number">1</span>,<span class="number">28</span>,<span class="number">28</span>)</span><br><span class="line"></span><br><span class="line">a.view(<span class="number">4</span>,<span class="number">28</span>*<span class="number">28</span>)</span><br></pre></td></tr></table></figure>
<h4 id="3-2-squeeze与unsqueeze">3.2 <strong>squeeze与unsqueeze</strong></h4>
<p>压缩与维度增加</p>
<p><code>unsqueeze</code>可以在指定位置上插入新的维度</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">a.shape</span><br><span class="line"><span class="comment"># torch.Size([4,1,28,28])</span></span><br><span class="line"></span><br><span class="line">a.unsqueeze(<span class="number">0</span>).shape</span><br><span class="line"><span class="comment"># torch.Size([1,4,1,28,28])</span></span><br><span class="line"></span><br><span class="line">a.unsqueeze(<span class="number">4</span>).shape</span><br><span class="line"><span class="comment"># torch.Size([4,1,28,28,1])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Demo</span></span><br><span class="line"><span class="comment"># 例如有一张 4,32,14,14的图像</span></span><br><span class="line"><span class="comment"># 我们现在还有一个标量核</span></span><br><span class="line">b=torch.rand(<span class="number">32</span>)</span><br><span class="line">f=torch.rand(<span class="number">4</span>,<span class="number">32</span>,<span class="number">14</span>,<span class="number">14</span>)</span><br><span class="line"><span class="comment"># 如何达成f+b</span></span><br><span class="line">b=b.unsqueeze(<span class="number">1</span>).unsqueeze(<span class="number">2</span>).unsqueeze(<span class="number">0</span>)</span><br><span class="line">b.shape</span><br><span class="line"><span class="comment"># torch.Size([1,32,1,1])</span></span><br></pre></td></tr></table></figure>
<p><code>squeeze</code>则是删减维度</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 不给定参数会把能删减的全删减了</span></span><br><span class="line">a.shape</span><br><span class="line"><span class="comment"># torch.Size([4,1,28,28])</span></span><br><span class="line"></span><br><span class="line">a.squeeze().shape</span><br><span class="line"><span class="comment"># torch.Size([32])</span></span><br><span class="line"></span><br><span class="line">a.squeeze(<span class="number">0</span>).shape</span><br><span class="line"><span class="comment"># torch.Size([32,1,1])</span></span><br></pre></td></tr></table></figure>
<h4 id="3-3-expand-与-repeat">3.3 <strong>expand 与 repeat</strong></h4>
<p><code>expand</code> 并没有主动复制数据，而<code>repeat</code>则会copy数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">a=torch.rand(<span class="number">4</span>,<span class="number">32</span>,<span class="number">14</span>,<span class="number">14</span>)</span><br><span class="line">b.shape</span><br><span class="line"><span class="comment"># torch.Size([1,32,1,1])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 现在为了让b与a做处理</span></span><br><span class="line"><span class="comment"># 需要对b进行扩展</span></span><br><span class="line">b.expand(<span class="number">4</span>,<span class="number">32</span>,<span class="number">14</span>,<span class="number">14</span>).shape</span><br><span class="line"><span class="comment"># torch.Size([4,32,14,14])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 而要保持某一维度不变，使用负一即可</span></span><br><span class="line">b.expande(-<span class="number">1</span>,<span class="number">32</span>,-<span class="number">1</span>,-<span class="number">1</span>).shape</span><br><span class="line"><span class="comment"># torch.Size([1,32,1,1])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># repeat 参数表示某一维度上需要拷贝多少次</span></span><br><span class="line">b.repeat(<span class="number">4</span>,<span class="number">32</span>,<span class="number">1</span>,<span class="number">1</span>).shape</span><br><span class="line"><span class="comment"># torch.Size([4,1024,1,1])</span></span><br></pre></td></tr></table></figure>
<h4 id="3-4-转置">3.4 <strong>转置</strong></h4>
<p><code>.t</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a=torch.randn(<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line"><span class="comment"># .t只能用于二维矩阵</span></span><br><span class="line">a.t()</span><br></pre></td></tr></table></figure>
<p><code>transpose</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># transpose能交换任意两个维度</span></span><br><span class="line"><span class="comment"># 但是维度打乱后的数据不再联系</span></span><br><span class="line"><span class="comment"># 需要使用contiguous进行处理</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 注意view会丢失维度信息！</span></span><br><span class="line"><span class="comment"># 需要跟踪维度信息</span></span><br><span class="line">al=a.transpose(<span class="number">1</span>,<span class="number">3</span>).contiguous().view(<span class="number">4</span>,<span class="number">3</span>*<span class="number">32</span>*<span class="number">32</span>).view(<span class="number">4</span>,<span class="number">32</span>,<span class="number">32</span>,<span class="number">3</span>).transpose(<span class="number">1</span>,<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<p><code>permute</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># permute可以多次交换</span></span><br><span class="line"><span class="comment"># 自动调用transpose</span></span><br><span class="line"></span><br><span class="line">b.permute(<span class="number">0</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="4-自动扩展">4. 自动扩展</h3>
<p><strong>核心思想</strong>：</p>
<ul>
<li>若前方无维度，则新增维度</li>
<li>将不足的维度扩展到需求维度</li>
</ul>
<blockquote>
<p>有则相加，无则补全</p>
</blockquote>
<p>注意，<code>expand</code>不能自动增加维度，所以需要先用<code>unqueeze</code>增加维度</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">b.unsqueeze[0].unsqueeze[-1].expand_as(A)</span><br></pre></td></tr></table></figure>
<p>能够自动扩展的情况：</p>
<ul>
<li>需要添加的数据符合最后一维数量</li>
<li>添加的数据维度与需要处理的数据维度相同</li>
</ul>
<hr>
<h3 id="5-拼接与分割">5.  拼接与分割</h3>
<h4 id="5-1-cat">5.1 <strong>cat</strong></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">a=torch.rand(<span class="number">4</span>,<span class="number">32</span>,<span class="number">8</span>)</span><br><span class="line">b=torch.rand(<span class="number">5</span>,<span class="number">32</span>,<span class="number">8</span>)</span><br><span class="line"></span><br><span class="line">torch.cat([a,b],dim=<span class="number">0</span>).shape</span><br><span class="line"></span><br><span class="line"><span class="comment"># 合并维度之外的维度必须相同</span></span><br></pre></td></tr></table></figure>
<h4 id="5-2-stack">5.2 <strong>stack</strong></h4>
<p><code>stack</code>会在需要合并的维度前新添加一个维度(等于上半部分是A，下半部分是B),且要求维度完全一致。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a=torch.randn([<span class="number">32</span>,<span class="number">32</span>,<span class="number">16</span>])</span><br><span class="line">b=torch.randn([<span class="number">32</span>,<span class="number">32</span>,<span class="number">16</span>])</span><br><span class="line"></span><br><span class="line">torch.stack([a,b],dim=<span class="number">0</span>).shape</span><br><span class="line"><span class="comment"># torch.Size([2,32,32,16])</span></span><br></pre></td></tr></table></figure>
<h4 id="5-3-split">5.3 <strong>split</strong></h4>
<p>split是按长度分割</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">a=torch.rand(<span class="number">4</span>,<span class="number">32</span>,<span class="number">8</span>)</span><br><span class="line"><span class="comment"># 将指定维度进行切割，每一份长度是第一个参数</span></span><br><span class="line"><span class="comment"># 不够的地方取余数</span></span><br><span class="line">t=a.split(<span class="number">7</span>,dim=<span class="number">1</span>)</span><br><span class="line">t[<span class="number">4</span>].shape</span><br><span class="line"><span class="comment"># torch.Size([4, 4, 8])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 也能指定长度</span></span><br><span class="line">a.split([<span class="number">15</span>,<span class="number">1</span>,<span class="number">16</span>],dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h4 id="5-4-Chunk">5.4 <strong>Chunk</strong></h4>
<p><code>chunk</code>是等距分割</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 分成两份</span></span><br><span class="line">a.chunk(<span class="number">2</span>,dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="6-Tensor运算">6.Tensor运算</h3>
<h4 id="加法">加法</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a=torch.rand(<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">b=torch.rand(<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">a+b <span class="comment"># 自动广播机制</span></span><br><span class="line">torch.add(a,b)</span><br></pre></td></tr></table></figure>
<h4 id="减法">减法</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a-b</span><br><span class="line">torch.sub(a,b)</span><br></pre></td></tr></table></figure>
<h4 id="乘法">乘法</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a*b</span><br><span class="line">torch.mul(a,b)</span><br></pre></td></tr></table></figure>
<h4 id="除法">除法</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a/b</span><br><span class="line">torch.div(a,b)</span><br></pre></td></tr></table></figure>
<h4 id="矩阵相乘">矩阵相乘</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">torch.mm(a,b) <span class="comment"># martix mul</span></span><br><span class="line">torch.matmul(a,b)</span><br><span class="line">a@b</span><br><span class="line"></span><br><span class="line"><span class="comment"># deom</span></span><br><span class="line">a=torch.rand(<span class="number">4</span>,<span class="number">784</span>)</span><br><span class="line">x=torch.rand(<span class="number">4</span>,<span class="number">784</span>)</span><br><span class="line">w=torch.rand(<span class="number">512</span>,<span class="number">784</span>)</span><br><span class="line">(x@w.t()).shape</span><br><span class="line"><span class="comment"># torch.Size([4,512])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 对于高维矩阵</span></span><br><span class="line"><span class="comment"># mm无法运算</span></span><br><span class="line"><span class="comment"># matmu则会运算后两维</span></span><br></pre></td></tr></table></figure>
<h4 id="幂运算">幂运算</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">a=torch.full([<span class="number">2</span>,<span class="number">2</span>],<span class="number">3</span>)</span><br><span class="line">a.<span class="built_in">pow</span>(<span class="number">2</span>)</span><br><span class="line">a**<span class="number">2</span></span><br><span class="line"><span class="comment"># 开方</span></span><br><span class="line">a.sqrt()</span><br><span class="line">a**<span class="number">0.5</span></span><br><span class="line"><span class="comment"># 指数</span></span><br><span class="line">a=torch.exp(torch.ones(<span class="number">2</span>,<span class="number">2</span>))</span><br><span class="line">torch.log(a)</span><br><span class="line"><span class="comment"># 近似值</span></span><br><span class="line">torch.ceil() <span class="comment"># 上</span></span><br><span class="line">torch.floor() <span class="comment"># 下</span></span><br><span class="line"><span class="comment"># 四舍五入</span></span><br><span class="line">torch.<span class="built_in">round</span>()</span><br><span class="line"><span class="comment"># 裁剪</span></span><br><span class="line">torch.trunc() <span class="comment"># 整数部分</span></span><br><span class="line">torch.frac() <span class="comment"># 小数部分</span></span><br></pre></td></tr></table></figure>
<h4 id="梯度裁剪">梯度裁剪</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">torch.clamp(<span class="number">10</span>) <span class="comment"># 将所有小于10的设置为10</span></span><br><span class="line">torch.clamp(<span class="built_in">min</span>,<span class="built_in">max</span>) <span class="comment"># 限制数据范围</span></span><br></pre></td></tr></table></figure>
<hr>
<h3 id="7-统计API">7.统计API</h3>
<h4 id="范数norm">范数norm</h4>
<p><strong>L0范数</strong>：向量中非零元素的数目</p>
<p><strong>L1范数</strong>：向量中各个元素的绝对值之和，也称稀疏规则算子</p>
<p><strong>L2范数</strong>：向量中各个元素的平方求和后开根号。其回归称为“<strong>岭回归</strong>”，也称<strong>权值衰减</strong></p>
<p>L2范数可以防止过拟合，提高模型泛化能力</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tensor.norm(<span class="number">1</span>)</span><br><span class="line">tensor.norm(<span class="number">2</span>)</span><br><span class="line">tensor.norm(<span class="number">1</span>,dim=<span class="number">1</span>) <span class="comment"># 指定维度上所有元素做范数</span></span><br></pre></td></tr></table></figure>
<h4 id="统计">统计</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">tensor.<span class="built_in">min</span>()</span><br><span class="line">tensor.<span class="built_in">max</span>()</span><br><span class="line">tensor.mean() <span class="comment"># 元素累加除以元素个数</span></span><br><span class="line">tensor.prod() <span class="comment"># 累乘 所有元素相乘</span></span><br><span class="line">tensor.<span class="built_in">sum</span>()</span><br><span class="line">tensor.argmax()</span><br><span class="line">tensor.argmin()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 返回dim=1上的最大三个元素及其下标</span></span><br><span class="line"><span class="comment"># largest=False则会返回最小</span></span><br><span class="line">tensor.topk(<span class="number">3</span>,dim=<span class="number">1</span>，largest=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 返回第 4 小的元素及其下标</span></span><br><span class="line">tensor.kthvalue(<span class="number">4</span>,dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># deom</span></span><br><span class="line">a.shape</span><br><span class="line"><span class="comment"># [4,10]</span></span><br><span class="line">a.<span class="built_in">max</span>(dim=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 会从四个维度里各取dim=1上的最大值，并返回下标</span></span><br><span class="line">a.<span class="built_in">max</span>(dim=<span class="number">1</span>,keepdim=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 这样会保持原有的形状</span></span><br><span class="line"><span class="comment"># 不会破坏返回值的结构</span></span><br></pre></td></tr></table></figure>
<h4 id="比较">比较</h4>
<p>返回的都是逻辑矩阵</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt; &gt;=</span><br><span class="line">&lt; &lt;=</span><br><span class="line">!=</span><br><span class="line">==</span><br><span class="line">torch.eq(a,b)</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="8-高级操作">8.高级操作</h3>
<h4 id="三元运算符"><strong>三元运算符</strong></h4>
<p><code>torch.where(condition,x,y)-&gt;Tensor</code></p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>o</mi><mi>u</mi><mi>t</mi><mo>:</mo><msub><mi>x</mi><mi>i</mi></msub><mspace width="1em"><mi>i</mi><mi>f</mi><mspace width="1em"><mi>c</mi><mi>o</mi><mi>n</mi><mi>d</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>o</mi><msub><mi>n</mi><mi>i</mi></msub><mspace width="1em"><mi>e</mi><mi>l</mi><mi>s</mi><mi>e</mi><mspace width="1em"><msub><mi>y</mi><mi>i</mi></msub></mspace></mspace></mspace></mspace></mrow><annotation encoding="application/x-tex">out: x_i\quad if \quad condition_i \quad else  \quad y_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6151em;"></span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:1em;"></span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mspace" style="margin-right:1em;"></span><span class="mord mathnormal">co</span><span class="mord mathnormal">n</span><span class="mord mathnormal">d</span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:1em;"></span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">se</span><span class="mspace" style="margin-right:1em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cond=torch.rand([<span class="number">2</span>,<span class="number">2</span>])</span><br><span class="line">a=torch.full([<span class="number">2</span>,<span class="number">2</span>],<span class="number">0</span>)</span><br><span class="line">b=torch.full([<span class="number">2</span>,<span class="number">2</span>],<span class="number">1</span>)</span><br><span class="line">torch.where(cond&gt;<span class="number">0.5</span>,a,b)</span><br></pre></td></tr></table></figure>
<h4 id="查表"><strong>查表</strong></h4>
<p><code>torch.gather(input,dim,index,out=None)</code><br>
在input中的dim维寻找符合index的值</p>
<hr>
<h2 id="随机梯度下降">随机梯度下降</h2>
<h3 id="1-梯度">1.梯度</h3>
<p>导数：某一方向上的变化率</p>
<p>偏微分：指定方向的变化率</p>
<p>梯度：偏微分向量[所有方向的变化率向量]</p>
<p>梯度具有<strong>方向</strong>和<strong>大小</strong></p>
<p>那么，所谓<strong>梯度下降</strong>，就是沿着<strong>梯度变化最大</strong>（也就是函数本身变化最快）的方向前进。这样在满足一定学习率的情况下，能够到达<strong>局部极小值点</strong>。</p>
<p><strong>鞍点</strong>：某一方向达到了局部最小，但另一方向处于局部最大</p>
<p>影响搜索结果的因素：</p>
<ul>
<li>初始状态</li>
<li>学习率</li>
<li>动量</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">torch.autograd.grad(equation,[parameter])</span><br><span class="line"><span class="comment"># 返回参数的梯度向量</span></span><br><span class="line"></span><br><span class="line">equation.backward()</span><br><span class="line"><span class="comment"># 不会返回值</span></span><br><span class="line">parameter.grad()</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="2-激活函数">2.激活函数</h3>
<h4 id="2-1Sigmoid">2.1Sigmoid</h4>
<p>科学家发现动物的神经元存在某一<strong>阈值</strong>，当输入刺激小于该阈值时，不会引起神经元变化。于是，学者们借鉴该思想，设置了激活函数。</p>
<p>激活函数是不连续的，不可以求导。为了解决单层神经元激活函数不可导的情况，科学家提出了<strong>平滑连续</strong>的激活函数曲线，即<strong>Sigmoid</strong>，也叫<strong>Logistic</strong>。</p>
<p>其导数性质能够直接通过本身求得，十分方便，能将数据范围压缩到[0,1]</p>
<p>sigmoid会出现梯度离散现象，即长时间的梯度不更新</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a=torch.linspace(-<span class="number">100</span>,<span class="number">100</span>,<span class="number">10</span>)</span><br><span class="line">torch.sigmoid(a)</span><br></pre></td></tr></table></figure>
<hr>
<h4 id="2-2Tanh">2.2Tanh</h4>
<p>常见于RNN网络</p>
<p>取值为[-1,1]</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.sigmoid(a)</span><br></pre></td></tr></table></figure>
<hr>
<h4 id="2-3Rectified-Linear-Unit">2.3Rectified Linear Unit</h4>
<p>减少梯度离散和梯度爆炸，保证梯度连续</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">torch.relu(a)</span><br><span class="line"><span class="keyword">import</span> torch.nn.function <span class="keyword">as</span> F</span><br><span class="line">F.relu(a)</span><br></pre></td></tr></table></figure>
<h4 id="2-4LeakyReLU">2.4LeakyReLU</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nn.LeakyReLU(inplace=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="3-LOSS">3.LOSS</h3>
<h4 id="MSE"><strong>MSE</strong></h4>
<ul>
<li>
<p>均方根误差</p>
</li>
<li>
<pre><code class="language-python">torch.norm(y-pred,2).pow(2)

F.mse_loss(x,y)
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">#### **Softmax**</span><br><span class="line"></span><br><span class="line">+ 常用于分类任务</span><br><span class="line"></span><br><span class="line">+ 输入是对于类别强度值，输出是概率</span><br><span class="line"></span><br><span class="line">+ 柔性最大传输网络能够保证概率之和为1</span><br><span class="line"></span><br><span class="line">+ 属于金字塔效应函数</span><br><span class="line"></span><br><span class="line">+ 每个节点对每个输入都有偏导</span><br><span class="line"></span><br><span class="line">+ ```python</span><br><span class="line">  a=torch.rand(3,requires_grad=True)</span><br><span class="line">  from torch.nn import functional as F</span><br><span class="line">  p=F.softmax(a,dim=0)</span><br><span class="line">  torch.autograd.grad(p[1],[a],retain_graph=True)</span><br><span class="line">  torch.autograd.grad(p[2],[a],retain_graph=True)</span><br></pre></td></tr></table></figure>

</code></pre>
</li>
</ul>
<p>注意torch是动态图，每次都需要更新，backward时得格外注意，若是想要不更新，可以使用<code>retain_graph</code>参数。求导只能对scalar类型进行求导。</p>
<h4 id="Cross-Entropy">Cross Entropy</h4>
<p>置信度的度量，更高的不确定性</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>E</mi><mi>n</mi><mi>t</mi><mi>r</mi><mi>o</mi><mi>p</mi><mi>y</mi><mo>=</mo><mo>−</mo><munder><mo>∑</mo><mi>i</mi></munder><mi>P</mi><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo><mi>l</mi><mi>o</mi><mi>g</mi><mi>P</mi><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Entropy=-\sum_iP(i)logP(i)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mord mathnormal">ro</span><span class="mord mathnormal">p</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.3277em;vertical-align:-1.2777em;"></span><span class="mord">−</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal">i</span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal">i</span><span class="mclose">)</span></span></span></span></span></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a=torch.full([<span class="number">4</span>],<span class="number">1</span>/<span class="number">4.</span>)</span><br><span class="line">-(a*torch.log2(a)).<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure>
<p>衡量两个分布的不稳定</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>H</mi><mo stretchy="false">(</mo><mi>p</mi><mo separator="true">,</mo><mi>q</mi><mo stretchy="false">)</mo><mo>=</mo><mo>−</mo><mo>∑</mo><mi>p</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mi>l</mi><mi>o</mi><mi>g</mi><mi>q</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mspace linebreak="newline"></mspace><mi>H</mi><mo stretchy="false">(</mo><mi>p</mi><mo separator="true">,</mo><mi>q</mi><mo stretchy="false">)</mo><mo>=</mo><mi>H</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo><mo>+</mo><msub><mi>D</mi><mrow><mi>K</mi><mi>L</mi></mrow></msub><mo stretchy="false">(</mo><mi>p</mi><mi mathvariant="normal">∣</mi><mi>q</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">H(p,q)=-\sum p(x)logq(x)
\\
H(p,q)=H(p)+D_{KL}(p|q)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.6em;vertical-align:-0.55em;"></span><span class="mord">−</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-symbol large-op" style="position:relative;top:0em;">∑</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mclose">)</span></span></span></span></span></p>
<p>KL即分布离散度</p>
<p>优化目标即让两个分布越来越接近，也就是KL最小</p>
<p>一个好的模型应该让<strong>不确定性降到最低</strong></p>
<p>于是，优化就是判断</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>m</mi><mi>i</mi><mi>n</mi><mi mathvariant="normal">.</mi><mspace width="1em"><mi>C</mi><mi>E</mi></mspace></mrow><annotation encoding="application/x-tex">min.\quad CE
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">min</span><span class="mord">.</span><span class="mspace" style="margin-right:1em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">CE</span></span></span></span></span></p>
<p>例如一个二分类案例</p>
<ul>
<li>第一步是将所有预测概率(即P(cat)、P(dog))与实际概率Q(cat)、Q(dog)求交叉熵</li>
<li>y表示预测概率，p表示实际概率</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">x=torch.randn(<span class="number">1</span>,<span class="number">784</span>)</span><br><span class="line">w=torch.randn(<span class="number">10</span>,<span class="number">784</span>)</span><br><span class="line">logits=x@w.t()</span><br><span class="line">F.cross_entrop(logits,torch.tensor([<span class="number">3</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 交叉熵的值是先经过softmax层，然后走一个log取对数，再通过nllloss进行计算</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># CE=softmax+log+nll_loss</span></span><br><span class="line">pre=F.softmax(logits,dim=<span class="number">1</span>)</span><br><span class="line">pred_log=torch.log(pre)</span><br><span class="line">F.nll_loss(pred_log,torch.tensor([<span class="number">3</span>]))</span><br></pre></td></tr></table></figure>
<h3 id="1-感知机">1.感知机</h3>
<p>感知机(perceptron)是二类分类的<strong>线性分类模型</strong>，其输入为实例的特征向量，输出为实例的类别。</p>
<h4 id="单层感知机">单层感知机</h4>
<p><strong>输入层</strong>：第0层，其元素表示<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>x</mi><mi>n</mi><mn>0</mn></msubsup></mrow><annotation encoding="application/x-tex">x_n^0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0611em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span>，0表示第1层，n表示所在节点次序</p>
<p><strong>隐含层</strong>：第1层，其元素表示为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>W</mi><mrow><mi>i</mi><mi>j</mi></mrow><mn>1</mn></msubsup></mrow><annotation encoding="application/x-tex">W_{ij}^1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2089em;vertical-align:-0.3948em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-2.4413em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3948em;"><span></span></span></span></span></span></span></span></span></span>，1表示第1层，i表示上一层节点，j表示当前层连接节点</p>
<p><strong>激活层</strong>：其元素表示为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>O</mi><mn>1</mn><mn>1</mn></msubsup></mrow><annotation encoding="application/x-tex">O_1^1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0622em;vertical-align:-0.2481em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-2.4519em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2481em;"><span></span></span></span></span></span></span></span></span></span>，为经过激活后的元素。</p>
<p><strong>损失层</strong>：E层，表示loss</p>
<p>发现其导数仅跟神经元节点输出和输入层有关。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 一个简单的单层感知机求导demo</span></span><br><span class="line"><span class="comment"># 输入数据</span></span><br><span class="line">x=torch.randn(<span class="number">1</span>,<span class="number">10</span>)</span><br><span class="line"><span class="comment"># 隐层权重</span></span><br><span class="line">w=torch.randn(<span class="number">1</span>,<span class="number">10</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 激活函数</span></span><br><span class="line">o=torch.sigmoid(x@w.t())</span><br><span class="line"><span class="comment"># 损失表达</span></span><br><span class="line">loss=F.mse_loss(torch.ones(<span class="number">1</span>,<span class="number">1</span>),o)</span><br><span class="line"><span class="comment"># 反向传播</span></span><br><span class="line">loss.backward()</span><br><span class="line">w.grad</span><br></pre></td></tr></table></figure>
<h4 id="多层感知机">多层感知机</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 一个简单的多层感知机求导demo</span></span><br><span class="line"><span class="comment"># 输入数据</span></span><br><span class="line">x=torch.randn(<span class="number">1</span>,<span class="number">10</span>)</span><br><span class="line"><span class="comment"># 隐层权重</span></span><br><span class="line">w=torch.randn(<span class="number">2</span>,<span class="number">10</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 激活函数</span></span><br><span class="line">o=torch.sigmoid(x@w.t())</span><br><span class="line"><span class="comment"># 损失表达</span></span><br><span class="line">loss=F.mse_loss(torch.ones(<span class="number">1</span>,<span class="number">2</span>),o)</span><br><span class="line"><span class="comment"># 反向传播</span></span><br><span class="line">loss.backward()</span><br><span class="line">w.grad</span><br></pre></td></tr></table></figure>
<h3 id="2-链式法则">2.链式法则</h3>
<hr>
<h3 id="3-MLP反向传播推导">3.MLP反向传播推导</h3>
<p>Multi-Layer Perceptron 多层感知机</p>
<hr>
<h3 id="4-函数优化实例">4.函数优化实例</h3>
<p><strong>target</strong></p>
<p>实现绘制该函数覆盖图</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">himmelblau</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> (x[<span class="number">0</span>]**<span class="number">2</span>+x[<span class="number">1</span>]-<span class="number">11</span>)**<span class="number">2</span>+(x[<span class="number">0</span>]+x[<span class="number">1</span>]**<span class="number">2</span>-<span class="number">7</span>)**<span class="number">2</span></span><br><span class="line">    </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">x=np.arange(-<span class="number">6</span>,<span class="number">6</span>,<span class="number">0.1</span>)</span><br><span class="line">y=np.arange(-<span class="number">6</span>,<span class="number">6</span>,<span class="number">0.1</span>)</span><br><span class="line">X,Y=np.meshgrid(x,y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;X,Y maps: &quot;</span>,X.shape,<span class="string">&quot;before :&quot;</span>,x.shape)</span><br><span class="line"></span><br><span class="line">Z=himmelblau([X,Y])</span><br><span class="line">fig=plt.figure(<span class="string">&quot;HIMMELBLAU&quot;</span>)</span><br><span class="line">ax=fig.gca(projection=<span class="string">&#x27;3d&#x27;</span>)</span><br><span class="line">ax.plot_surface(X,Y,Z)</span><br><span class="line">ax.view_init(<span class="number">60</span>,-<span class="number">30</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;y&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>利用随机梯度下降优化</p>
<p>注意优化目标不再是LOSS，而是函数本身，求导对象是x，即<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi>δ</mi><msub><mi>P</mi><mrow><mi>r</mi><mi>e</mi></mrow></msub></mrow><mrow><mi>δ</mi><mi>x</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\delta P_{re}}{\delta x}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2412em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8962em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03785em;">δ</span><span class="mord mathnormal mtight">x</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.4101em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03785em;">δ</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1645em;"><span style="top:-2.357em;margin-left:-0.1389em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">re</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">x=torch.tensor([<span class="number">0.</span>,<span class="number">0.</span>],requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 定义一个优化器</span></span><br><span class="line">optimizer=torch.optim.Adam([x],lr=<span class="number">1e-3</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">20000</span>):</span><br><span class="line">    <span class="comment"># 寻找本函数的最优区间</span></span><br><span class="line">    pred=himmelblau(x)</span><br><span class="line">    <span class="comment"># 需要将累计梯度清空</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    <span class="comment"># 寻找梯度方向</span></span><br><span class="line">    pred.backward()</span><br><span class="line">    <span class="comment"># 自动优化，也就是x-lr*x&#x27;</span></span><br><span class="line">    optimizer.step()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">2000</span> ==<span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;step &#123;&#125;： x=&#123;&#125;,f(x)=&#123;&#125;&quot;</span>.<span class="built_in">format</span>(i,x.tolist(),pred.item()))</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="神经网络">神经网络</h2>
<h3 id="1-逻辑回归">1.逻辑回归</h3>
<h3 id="分类问题"><strong>分类问题</strong></h3>
<ul>
<li>问题一：当权重改变时，梯度很可能不变！因为准确率不变！</li>
<li>问题二：梯度不连续！【从0.6直接变成0.8】</li>
</ul>
<p><strong>逻辑回归</strong></p>
<ul>
<li>本质上更像分类</li>
<li>使用了sigmoid函数，使用MSE评估回归，Cross Entropy评估分类</li>
<li>在判断输出值与阈值的距离，用以评估二分类，并通过MSE评估输出效果</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets,transforms</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line">batch_size=<span class="number">200</span></span><br><span class="line">lr=<span class="number">0.01</span></span><br><span class="line">epochs=<span class="number">10</span></span><br><span class="line"></span><br><span class="line">train_loader=DataLoader(</span><br><span class="line">    datasets.MNIST(<span class="string">&#x27;../data&#x27;</span>,train=<span class="literal">True</span>,download=<span class="literal">True</span>,transform=</span><br><span class="line">                   transforms.Compose([</span><br><span class="line">                       transforms.ToTensor(),</span><br><span class="line">                       transforms.Normalize((<span class="number">0.1307</span>),(<span class="number">0.3081</span>,))</span><br><span class="line">                   ])),</span><br><span class="line">    batch_size=batch_size,shuffle=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">test_loader=DataLoader(</span><br><span class="line">    datasets.MNIST(<span class="string">&#x27;../data&#x27;</span>,train=<span class="literal">False</span>,transform=</span><br><span class="line">                   transforms.Compose([</span><br><span class="line">                       transforms.ToTensor(),</span><br><span class="line">                       transforms.Normalize((<span class="number">0.1307</span>),(<span class="number">0.3081</span>,))</span><br><span class="line">                   ])),</span><br><span class="line">    batch_size=batch_size,shuffle=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">w1=torch.randn(<span class="number">200</span>,<span class="number">784</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line">b1=torch.zeros(<span class="number">200</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">w2=torch.randn(<span class="number">200</span>,<span class="number">200</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line">b2=torch.zeros(<span class="number">200</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">w3=torch.randn(<span class="number">10</span>,<span class="number">200</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line">b3=torch.zeros(<span class="number">10</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">x</span>):</span><br><span class="line">    x=x@w1.t()+b1</span><br><span class="line">    x=F.relu(x)</span><br><span class="line">    x=x@w2.t()+b2</span><br><span class="line">    x=F.relu(x)</span><br><span class="line">    x=x@w3.t()+b3</span><br><span class="line">    x=F.relu(x)</span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">optimizer=torch.optim.SGD([w1,b1,w2,b2,w3,b3],lr=<span class="number">1e-3</span>)</span><br><span class="line">criteon=torch.nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10000</span>):</span><br><span class="line">    <span class="keyword">for</span> batch_idx,(data,target) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">        data=data.view(-<span class="number">1</span>,<span class="number">28</span>*<span class="number">28</span>)</span><br><span class="line">        logits=forward(data)</span><br><span class="line">        loss=criteon(logits,target)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        <span class="keyword">if</span> batch_idx % <span class="number">100</span>==<span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Train Epoch: &#123;&#125; [&#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)]\tLoss:&#123;:.6f&#125;&quot;</span>.</span><br><span class="line">                  <span class="built_in">format</span>(epoch,batch_idx*<span class="built_in">len</span>(data),<span class="built_in">len</span>(train_loader.dataset),</span><br><span class="line">                         <span class="number">100.</span>*batch_idx/<span class="built_in">len</span>(train_loader),loss.item()))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># test_loss=0</span></span><br><span class="line">        <span class="comment"># correct=0</span></span><br><span class="line">        <span class="comment"># for data,target in test_loader:</span></span><br><span class="line">        <span class="comment">#     data=data.view(-1,28*28)</span></span><br><span class="line">        <span class="comment">#     logits=forward(data)</span></span><br><span class="line">        <span class="comment">#     test_loss+=criteon(logits,target).item()</span></span><br><span class="line">        <span class="comment">#     pred=logits.data.max(1)[1]</span></span><br><span class="line">        <span class="comment">#     correct+=pred.eq(target.data).sum()</span></span><br><span class="line">        <span class="comment"># test_loss/=len(test_loader.dataset)</span></span><br><span class="line">        <span class="comment"># print(&quot;\nTest set: Average loss: &#123;:.4f&#125;, Accuracy:&#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)\n&quot;.format(</span></span><br><span class="line">        <span class="comment">#     test_loss,correct,len(test_loader.dataset),100.*correct/len(test_loader.dataset)</span></span><br><span class="line">        <span class="comment"># ))</span></span><br></pre></td></tr></table></figure>
<p>发现陷入了局部最小值，本次并没有做初始化，如果做了初始化就能大大降低损失。</p>
<h3 id="2-全连接层">2.全连接层</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">x=torch.tensor([<span class="number">1</span>,<span class="number">784</span>])</span><br><span class="line">layer1=nn.Linear(<span class="number">784</span>:<span class="keyword">in</span>,<span class="number">200</span>:out)</span><br><span class="line">layer2=nn.Linear(<span class="number">200</span>,<span class="number">200</span>)</span><br><span class="line">layer3=nn.Linear(<span class="number">200</span>,<span class="number">10</span>)</span><br><span class="line">x=layer3(layer2(layer1(x)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加激活函数</span></span><br><span class="line">x=layer1(x)</span><br><span class="line">x=F.relu(x,inplace=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>如何创建一个层？</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MLP</span>(nn.Module):</span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">		<span class="built_in">super</span>(MLP,self).__init__()</span><br><span class="line">		self.model=nn.Sequential(</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># nn.Sequential就是一个容器</span></span><br><span class="line">            <span class="comment"># 可以添加任何继承自nn.Module的类</span></span><br><span class="line">            <span class="comment"># 并让输入依次经过容器内放置的神经元</span></span><br><span class="line">            </span><br><span class="line">            nn.Linear(<span class="number">784</span>,<span class="number">200</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">200</span>,<span class="number">200</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">200</span>,<span class="number">10</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">            <span class="comment"># 继承了nn.module.forward的方法</span></span><br><span class="line">            <span class="keyword">return</span> self.model(x)</span><br></pre></td></tr></table></figure>
<p>pyTorch有两种风格的API，一种是class风格的API，如<code>nn.ReLU</code>，一种是函数风格的API，如<code>F.relu()</code></p>
<p>类风格的API需要构造</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">net=MLP()</span><br><span class="line"></span><br><span class="line">optimizer=torch.optim.SGD(net.parameters(),lr=<span class="number">1e-3</span>)</span><br><span class="line">criteon=torch.nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10000</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> batch_idx,(data,target) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">        data=data.view(-<span class="number">1</span>,<span class="number">28</span>*<span class="number">28</span>)</span><br><span class="line">        </span><br><span class="line">        logits=net(data)</span><br><span class="line">        loss=criteon(logits,target)</span><br><span class="line">        </span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        </span><br><span class="line">        optimizer.step()</span><br><span class="line">        <span class="keyword">if</span> batch_idx % <span class="number">100</span>==<span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Train Epoch: &#123;&#125; [&#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)]\tLoss:&#123;:.6f&#125;&quot;</span>.</span><br><span class="line">                  <span class="built_in">format</span>(epoch,batch_idx*<span class="built_in">len</span>(data),<span class="built_in">len</span>(train_loader.dataset),</span><br><span class="line">                         <span class="number">100.</span>*batch_idx/<span class="built_in">len</span>(train_loader),loss.item()))</span><br></pre></td></tr></table></figure>
<h3 id="3-GPU加速">3.GPU加速</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如何使用GPU加速</span></span><br><span class="line"><span class="comment"># cuda n 第n显卡</span></span><br><span class="line"><span class="comment"># 需要用GPU时，直接用 .to 方法</span></span><br><span class="line"><span class="comment"># 注意对模块调用GPU方法时，返回的模块不会改变</span></span><br><span class="line"><span class="comment"># 而对数据调用GPU方法时，返回的数据跟原始数据不一样，会产生一个CPU数据和一个GPU数据</span></span><br><span class="line"></span><br><span class="line">device=torch.device(<span class="string">&quot;cuda:0&quot;</span>)</span><br><span class="line">net=MLP().to(device)</span><br><span class="line">optimizer=optim.SGD(net.paameters(),lr=lr)</span><br><span class="line">criteon=nn.CrossEntropyLoss().to(device)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> e <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">	<span class="keyword">for</span> batch_idx,(data,target) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">	data=data.view(-<span class="number">1</span>,<span class="number">28</span>*<span class="number">28</span>)</span><br><span class="line">	data,target=data.to(device),target.cuda()</span><br></pre></td></tr></table></figure>
<p>精度验证</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">logits=torch.rand(<span class="number">4</span>,<span class="number">10</span>)</span><br><span class="line">pred=F.softmax(logits,dim=<span class="number">1</span>)</span><br><span class="line">pred_label=pred.argmax(dim=<span class="number">1</span>)</span><br><span class="line">label=torch.tensor([<span class="number">9</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># eq返回的是一个逻辑矩阵，是就是1，不是就是0</span></span><br><span class="line">correct=torch.eq(pred_label,label)</span><br><span class="line"><span class="comment"># 该方法能求出多少被成功预测</span></span><br><span class="line">correct.<span class="built_in">sum</span>().<span class="built_in">float</span>().item()/<span class="number">4</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">test_loss=<span class="number">0</span></span><br><span class="line">correct=<span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> data,target <span class="keyword">in</span> test_loader:</span><br><span class="line">	data=data.view(-<span class="number">1</span>,<span class="number">28</span>*<span class="number">28</span>)</span><br><span class="line">	data,target=data.to(device),target.cuda()</span><br><span class="line">	</span><br><span class="line">	logits=net(data)</span><br><span class="line">	test_loss+=criteon(logits,target).item()</span><br><span class="line">	</span><br><span class="line">	pred=logits.argmax(dim=<span class="number">1</span>)</span><br><span class="line">	correct+=pred.eq(target).<span class="built_in">float</span>().<span class="built_in">sum</span>().item()</span><br><span class="line">    </span><br><span class="line">test_loss/=<span class="built_in">len</span>(test_loader.dataset)</span><br></pre></td></tr></table></figure>
<p>可视化交互</p>
<p><code>TensorboardX</code></p>
<p><code>visdom</code></p>
<p>相较于TBX读取的numpy，VD能直接跟Tensor进行交互(当然只能是img)，且不会大量存放监听文件。</p>
<p>本质上是一个外部的服务器，需要配合命令。</p>
<p><code>python -m visdom.server</code></p>
<p>于是就能在8097端口找到visdom。</p>
<p>如何使用？</p>
<p><strong>单线追踪</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> visdom <span class="keyword">import</span> Visdom</span><br><span class="line">viz=Visdom()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建直线</span></span><br><span class="line"><span class="comment"># Y,X win 是标志符，类似ID </span></span><br><span class="line"><span class="comment"># 每个窗格叫做env，即一个新的进程</span></span><br><span class="line"><span class="comment"># 默认env=‘main’</span></span><br><span class="line">viz.line([<span class="number">0.</span>],[<span class="number">0.</span>],win=<span class="string">&#x27;train_loss&#x27;</span>,opts=<span class="built_in">dict</span>(title=<span class="string">&quot;train loss&quot;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 能够逐渐添加数据</span></span><br><span class="line"><span class="comment"># y:loss x:全局迭代</span></span><br><span class="line"><span class="comment"># update: &quot;append&quot; 不会覆盖</span></span><br><span class="line">viz.line([loss.item()],[global_step],win=<span class="string">&quot;train_loss&quot;</span>,update=<span class="string">&quot;append&quot;</span>)</span><br></pre></td></tr></table></figure>
<p><strong>多线追踪</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> visdom <span class="keyword">import</span> Visdom</span><br><span class="line">viz=Visdom()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建直线</span></span><br><span class="line">viz.line([<span class="number">0.0</span>,<span class="number">0.0</span>],[<span class="number">0.</span>],win=<span class="string">&#x27;test&#x27;</span>,opts=<span class="built_in">dict</span>(title=<span class="string">&quot;train loss&amp;acc.&quot;</span>,legend=[<span class="string">&#x27;loss&#x27;</span>,<span class="string">&#x27;acc.&#x27;</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 能够逐渐添加数据</span></span><br><span class="line">viz.line([[test_loss,correct/<span class="built_in">len</span>(test_loader.dataset)]],[global_step],win=<span class="string">&quot;test&quot;</span>,update=<span class="string">&quot;append&quot;</span>)</span><br></pre></td></tr></table></figure>
<p><strong>可视化</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> visdom <span class="keyword">import</span> Visdom</span><br><span class="line">viz=Visdom()</span><br><span class="line">viz.images(data.view(-<span class="number">1</span>,<span class="number">1</span>,<span class="number">28</span>,<span class="number">28</span>),win=<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">viz.text(<span class="built_in">str</span>(pred.detach().cpu().numpy()),win=<span class="string">&#x27;pred&#x27;</span>,opts=<span class="built_in">dict</span>(title=<span class="string">&#x27;pred&#x27;</span>))</span><br></pre></td></tr></table></figure>
<h3 id="4-过拟合-v2">4.过拟合</h3>
<h3 id="5-交叉验证">5.交叉验证</h3>
<p>如何划分<strong>train-val-test</strong></p>
<p>对<strong>train</strong>人为切割：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">train_db,val_db=torch.utils.data.random_split(train_db,[<span class="number">50000</span>,<span class="number">10000</span>])</span><br><span class="line"></span><br><span class="line">train_loader=torch.utils.data.DataLoader(</span><br><span class="line"><span class="comment"># 获取数据位置</span></span><br><span class="line">	train_db,</span><br><span class="line"><span class="comment"># 每一批次的数据量</span></span><br><span class="line">	batch_size=batch_size,</span><br><span class="line"><span class="comment"># 是否打乱</span></span><br><span class="line">	shuffle=<span class="literal">True</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p><strong>关于批训练</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.utils.data <span class="keyword">as</span> Data <span class="comment">#将数据分批次需要用到它</span></span><br><span class="line"> </span><br><span class="line">torch.manual_seed(<span class="number">1</span>)    <span class="comment"># 种子，可复用</span></span><br><span class="line">BATCH_SIZE = <span class="number">8</span> <span class="comment">#设置批次大小</span></span><br><span class="line"> </span><br><span class="line">x = torch.linspace(<span class="number">1</span>, <span class="number">15</span>, <span class="number">15</span>)       <span class="comment"># 1到15共15个点</span></span><br><span class="line">y = torch.linspace(<span class="number">15</span>, <span class="number">1</span>, <span class="number">15</span>)       <span class="comment"># 15到1共15个点</span></span><br><span class="line"> </span><br><span class="line">torch_dataset = Data.TensorDataset(x, y) <span class="comment">#将x,y读取，转换成Tensor格式</span></span><br><span class="line">loader = Data.DataLoader(</span><br><span class="line">    dataset=torch_dataset,      <span class="comment"># torch TensorDataset format</span></span><br><span class="line">    batch_size=BATCH_SIZE,      <span class="comment"># 最新批数据</span></span><br><span class="line">    shuffle=<span class="literal">True</span>,               <span class="comment"># 是否随机打乱数据</span></span><br><span class="line">    num_workers=<span class="number">2</span>,              <span class="comment"># 用于加载数据的子进程</span></span><br><span class="line">)</span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">show_batch</span>():</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):   <span class="comment"># 对整个数据集进行3次培训</span></span><br><span class="line">        <span class="keyword">for</span> step, (batch_x, batch_y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(loader):  <span class="comment"># 每个训练步骤</span></span><br><span class="line">            <span class="comment"># 此处省略一些训练数据步骤...</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Epoch: &#x27;</span>, epoch, <span class="string">&#x27;| Step: &#x27;</span>, step, <span class="string">&#x27;| batch x: &#x27;</span>,</span><br><span class="line">                  batch_x.numpy(), <span class="string">&#x27;| batch y: &#x27;</span>, batch_y.numpy())</span><br><span class="line"> </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    show_batch()</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">(1)每次训练5个数据，打乱数据；每进行一次完整的训练需要进行3个训练步骤：</span></span><br><span class="line"><span class="string">Epoch:  0 | Step:  0 | batch x:  [10. 12.  9.  5.  1.] | batch y:  [ 6.  4.  7. 11. 15.]</span></span><br><span class="line"><span class="string">Epoch:  0 | Step:  1 | batch x:  [ 7. 15.  8. 13.  3.] | batch y:  [ 9.  1.  8.  3. 13.]</span></span><br><span class="line"><span class="string">Epoch:  0 | Step:  2 | batch x:  [ 2.  6. 14.  4. 11.] | batch y:  [14. 10.  2. 12.  5.]</span></span><br><span class="line"><span class="string">Epoch:  1 | Step:  0 | batch x:  [ 3. 10.  8. 13.  2.] | batch y:  [13.  6.  8.  3. 14.]</span></span><br><span class="line"><span class="string">Epoch:  1 | Step:  1 | batch x:  [ 5.  4. 12. 14.  1.] | batch y:  [11. 12.  4.  2. 15.]</span></span><br><span class="line"><span class="string">Epoch:  1 | Step:  2 | batch x:  [15.  9. 11.  6.  7.] | batch y:  [ 1.  7.  5. 10.  9.]</span></span><br><span class="line"><span class="string">Epoch:  2 | Step:  0 | batch x:  [ 8.  7.  3. 10. 12.] | batch y:  [ 8.  9. 13.  6.  4.]</span></span><br><span class="line"><span class="string">Epoch:  2 | Step:  1 | batch x:  [ 6. 13.  9.  4. 15.] | batch y:  [10.  3.  7. 12.  1.]</span></span><br><span class="line"><span class="string">Epoch:  2 | Step:  2 | batch x:  [14.  2.  5.  1. 11.] | batch y:  [ 2. 14. 11. 15.  5.]</span></span><br><span class="line"><span class="string">(2)每次训练8个数据，打乱数据；每进行一次完整的训练需要进行2个训练步骤,一次8个数据，一次7个数据：</span></span><br><span class="line"><span class="string">Epoch:  0 | Step:  0 | batch x:  [10. 12.  9.  5.  1.  7. 15.  8.] | batch y:  [ 6.  4.  7. 11. 15.  9.  1.  8.]</span></span><br><span class="line"><span class="string">Epoch:  0 | Step:  1 | batch x:  [13.  3.  2.  6. 14.  4. 11.] | batch y:  [ 3. 13. 14. 10.  2. 12.  5.]</span></span><br><span class="line"><span class="string">Epoch:  1 | Step:  0 | batch x:  [ 3. 10.  8. 13.  2.  5.  4. 12.] | batch y:  [13.  6.  8.  3. 14. 11. 12.  4.]</span></span><br><span class="line"><span class="string">Epoch:  1 | Step:  1 | batch x:  [14.  1. 15.  9. 11.  6.  7.] | batch y:  [ 2. 15.  1.  7.  5. 10.  9.]</span></span><br><span class="line"><span class="string">Epoch:  2 | Step:  0 | batch x:  [ 8.  7.  3. 10. 12.  6. 13.  9.] | batch y:  [ 8.  9. 13.  6.  4. 10.  3.  7.]</span></span><br><span class="line"><span class="string">Epoch:  2 | Step:  1 | batch x:  [ 4. 15. 14.  2.  5.  1. 11.] | batch y:  [12.  1.  2. 14. 11. 15.  5.]</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<h3 id="6-正则化">6.正则化</h3>
<p>当范数接近于0时，模型的复杂度会降低。可以有效处理过拟合。</p>
<p>是一个<code>weight_decay</code></p>
<p>在学习时，如果数据提供的特征有些影响模型的复杂度或这个特征数据异常特别多，那么应该尽量减少(甚至删除某个特征的影响)，这就是正则化</p>
<p>L2正则化:</p>
<ul>
<li>
<p>作用:可以使得其中的一些权重w都很小，削弱某个特征的影响</p>
</li>
<li>
<p>优点:越小的参数说明模型越简单，越简单的模型越不容易发生过拟合</p>
</li>
<li>
<p>Ridge回归</p>
</li>
<li>
<p>作用:可以将一些w直接设置为0，直接删除该特征的影响</p>
</li>
<li>
<p>LASSO回归</p>
<p>​</p>
</li>
</ul>
<p>如何添加一个L2正则化呢？</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">device=torch.device(<span class="string">&quot;cuda:0&quot;</span>)</span><br><span class="line">net=MLP().to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 我们只需要设置w参数即可，能够降低网络复杂度</span></span><br><span class="line">optimizer=optim.SGD(net.parameters(),lr=learning_rate,weight_decay=<span class="number">0.01</span>) <span class="comment"># 权值递减 </span></span><br><span class="line"></span><br><span class="line">criteon=nn.CrossEntropyLoss().to(device)</span><br></pre></td></tr></table></figure>
<p>对于L1正则化</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">regularization_loss=<span class="number">0</span></span><br><span class="line"><span class="comment"># 对每一个参数都加上去</span></span><br><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> model.parameters():</span><br><span class="line">	regularization_loss+=torch.<span class="built_in">sum</span>(torch.<span class="built_in">abs</span>(param))</span><br><span class="line">classify_loss=criteon(logits,target)</span><br><span class="line"><span class="comment"># 本质上是对网络参数做约束</span></span><br><span class="line">loss=classify_loss+<span class="number">0.01</span>*regularization_loss</span><br></pre></td></tr></table></figure>
<h3 id="7-动量">7.动量</h3>
<p><strong>momentum</strong></p>
<p>如何实现动量捏</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">optimizer=torch.optim.SGD(model.parameter(),args.lr,momentum=args.momentum,weight_decay=args.weight_decay)</span><br><span class="line"></span><br><span class="line">scheduler=ReduceLROnPlateau(optimizer,<span class="string">&#x27;min&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>部分优化器如<code>Adam</code>内置动量属性了，不能额外设置</p>
<p><strong>learning-rate decay</strong></p>
<p>学习率如何选择是一个比较困难的过程，那么我们为什么不考虑让他自动衰减呢？</p>
<p>如上图所示，发生斜率爆炸的情况是因为改变了学习率，可能之前的过程都是在双峰之间打转，而改变了学习率马上就能找到新的谷底。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Scheme 1.</span></span><br><span class="line"></span><br><span class="line">optimizer=torch.optim.SGD(model.parameter(),args.lr,momentum=args.momentum,weight_decay=args.weight_decay)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 监听loss，当patient的值(如连续十次调用)超过阈值时，降低学习率</span></span><br><span class="line">scheduler=ReduceLROnPlateau(optimizer,<span class="string">&#x27;min&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> xrange(args.start_epoch,args.epochs):</span><br><span class="line">	train(train_loader,model,criterion,optimizer,epoch)</span><br><span class="line">	result_avg,loss_val=validate(val_loader,model,criterion,epoch)</span><br><span class="line">	<span class="comment"># 每次监听loss_val是否达到平衡</span></span><br><span class="line">    scheduler.step(loss_val)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Scheme 2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 每30次进行衰减</span></span><br><span class="line">scheduler=StepLR(optimizer,step_size=<span class="number">30</span>,gamma=<span class="number">0.1</span>)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">	shceduler.step()</span><br><span class="line">	train(...)</span><br><span class="line">	validate(...)</span><br></pre></td></tr></table></figure>
<p><strong>Early Stopping</strong></p>
<p>有概率断掉某些层</p>
<p>如何添加dropout？</p>
<p>我们在任意一层添加即可</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">net_dropped=torch.nn.Sequential(</span><br><span class="line">	torch.nn.Linear(<span class="number">784</span>,<span class="number">200</span>),</span><br><span class="line">	torch.nn.Dropout(<span class="number">0.5</span>), <span class="comment"># drop 50% of the neutron</span></span><br><span class="line">	torch.nn.ReLU()</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>当然，在测试的时候，我们需要把断掉的层添加回去</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">	net_dropped.train()</span><br><span class="line">	<span class="keyword">for</span> batch_idx,(data,target) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">	...</span><br><span class="line">	<span class="comment"># 添加断层</span></span><br><span class="line">	net_dropped.<span class="built_in">eval</span>()</span><br><span class="line">	test_loss=<span class="number">0</span></span><br><span class="line">	correct=<span class="number">0</span></span><br><span class="line">	<span class="keyword">for</span> data,target <span class="keyword">in</span> test_loader:</span><br><span class="line">	...</span><br></pre></td></tr></table></figure>
<p><strong>stochastic</strong></p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>−</mo><mo>−</mo><mo>−</mo><mo>&gt;</mo><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mtext>  </mtext><mi>N</mi><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">x---&gt;f(x) ~~ N(0,x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord">−</span><span class="mord">−</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace nobreak"> </span><span class="mspace nobreak"> </span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span></p>
<p>也就是说并不是完全符合映射关系，而是符合某一分布</p>
<p>为了节省内存，并不对全部数据做梯度，而是对少量banch数据做梯度</p>
<hr>
<h2 id="卷积神经网络">卷积神经网络</h2>
<ul>
<li></li>
</ul>
<p><strong>多卷积核</strong></p>
<p>注意Kernel的多通道运算最后还需要求和</p>
<p>每一次卷积观察的特征都不同，但根据经验公式可以发现，基本上是由局部到全局的变化。</p>
<p><strong>使用Pytorch实现Convolution</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 参数分别为: channel数量 Kernel数量 Kernel大小 步长 padding大小</span></span><br><span class="line">layer=nn.Conv2d(<span class="number">1</span>,<span class="number">3</span>,kernel_size=<span class="number">3</span>,stride=<span class="number">1</span>,padding=<span class="number">0</span>)</span><br><span class="line">x=torch.rand(<span class="number">1</span>,<span class="number">1</span>,<span class="number">28</span>,<span class="number">28</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可以看到输出的数据大小发生了改变</span></span><br><span class="line"><span class="comment"># 3是三个卷积核所造成的</span></span><br><span class="line">out=layer.forward(x)</span><br><span class="line"><span class="comment"># torch.Size([1,3,26,26])</span></span><br><span class="line"></span><br><span class="line">layer=nn.Conv2d(<span class="number">1</span>,<span class="number">3</span>,kernel_size=<span class="number">3</span>,stride=<span class="number">1</span>,padding=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 此时数据维度匹配，不再发生改变</span></span><br><span class="line">out=layer.forward(x)</span><br><span class="line"><span class="comment"># torch.Size([1,3,28,28])</span></span><br><span class="line"></span><br><span class="line">layer=nn.Conv2d(<span class="number">1</span>,<span class="number">3</span>,kernel_size=<span class="number">3</span>,stride=<span class="number">2</span>,padding=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 步长改变后输出大小也会发生改变</span></span><br><span class="line">out=layer.forward(x)</span><br><span class="line"><span class="comment"># torch.Size([1,3,14,14])</span></span><br><span class="line"></span><br><span class="line">out=layer(x)</span><br><span class="line"><span class="comment"># 可以直接调用</span></span><br><span class="line"><span class="comment"># torch.Size([1,3,14,14])</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看权重和偏置值</span></span><br><span class="line">layer.weight</span><br><span class="line">layer.bias</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><strong>池化层</strong></p>
<p><strong>降采样Downsample</strong></p>
<p><strong>最大池化Max pooling</strong></p>
<p>通过一个移动窗口对图像进行处理，从而达到降采样的效果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">x=out</span><br><span class="line"><span class="comment"># torch.Size([1,16,14,14])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 采样核大小是2</span></span><br><span class="line">layer=nn.MaxPool2d(<span class="number">2</span>,stride=<span class="number">2</span>)</span><br><span class="line">out=layer(x)</span><br><span class="line"><span class="comment"># torch.Size([1,16,7,7])</span></span><br><span class="line"></span><br><span class="line">out=F.avg_pool3d(x,<span class="number">2</span>,stride=<span class="number">2</span>)</span><br><span class="line"><span class="comment"># torch.Size([1,16,7,7])</span></span><br></pre></td></tr></table></figure>
<p>上采样</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x=out</span><br><span class="line">out=F.interpolate(x,scale_factor=<span class="number">2</span>,mode=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line"><span class="comment"># linear bilinear bicubic</span></span><br></pre></td></tr></table></figure>
<p><strong>Batch Normal</strong></p>
<p>为什么要batch normal</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">normalize=transforms.Normalize(mean=[<span class="number">0.485</span>,<span class="number">0.456</span>,<span class="number">0.406</span>],</span><br><span class="line">								std=[<span class="number">0.229</span>,<span class="number">0.224</span>,<span class="number">0.225</span>])</span><br></pre></td></tr></table></figure>
<p>对于一个维度为[6,3,28,28]的均值，一般是[3]大小，统计的是六张图片每个通道的均值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">x=torch.rand(<span class="number">100</span>,<span class="number">16</span>,<span class="number">784</span>)</span><br><span class="line">layer=nn.BatchNorm1d(<span class="number">16</span>)</span><br><span class="line">out=layer(x)</span><br><span class="line"><span class="comment"># 获取</span></span><br><span class="line">layer.running_mean</span><br><span class="line">layer.running_var</span><br></pre></td></tr></table></figure>
<p>而对于2d数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">x.shape</span><br><span class="line"><span class="comment"># [1,16,7,7]</span></span><br><span class="line">layer=nn.BatchNorm2d(<span class="number">16</span>)</span><br><span class="line">out=layer(x)</span><br><span class="line">layer.weight</span><br><span class="line"><span class="comment"># [16]</span></span><br><span class="line">layer.bias</span><br><span class="line"><span class="comment"># [16]</span></span><br></pre></td></tr></table></figure>
<p>BatchNorm的优势：</p>
<ul>
<li>更快的收敛速度</li>
<li>更好的Robust</li>
<li>更好的执行</li>
</ul>
<p><strong>经典卷积神经网络</strong></p>
<hr>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 不想学辣 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[第五章  全连接神经网络]]></title>
      <url>/2022/07/28/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E7%AC%AC%E4%BA%94%E7%AB%A0%20%20%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
      <content type="html"><![CDATA[<h1>第五章    全连接神经网络</h1>
<hr>
<h2 id="1-1-全连接神经网络">1.1      全连接神经网络</h2>
<p>人工神经网络(Artificial Neural Network)可以对一组输入信号和一组输出信号之间的关系进行建模，是机器学习和认知科学中的一种模仿生物神经网络的结构和功能的数学模型。其灵感源于动物的神经中枢，由大量的人工神经元连接而成，能够根据外界环境改变内部结构，是一种自适应的系统。</p>
<img src="/2022/07/28/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E7%AC%AC%E4%BA%94%E7%AB%A0%20%20%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20220728200247211.png" alt="image-20220728200247211" style="zoom:50%;">
<p>全连接神经网络(Multi-Layer Perception)也称多层感知机，是一种连接方式较为简单的人共神经网络结构，属于前馈神经网络的一种。主要由输入层、隐藏层、输出层构成，并且在每个隐藏层中可以有多个神经元。</p>
<p>神经网络的学习能力主要来源于网络结构，根据层级数量的不同，每层神经元数量的多少，以及信息在层之间的传播方式，可以组合层多种神经网络模型。一般在隐层和输出层对信号进行加工处理，根据隐层的数量，MLP可分为单层或是多(隐)层。</p>
<p>针对单层MLP和多层MLP，每个隐层的神经元数量是可以变化的。通常没有一个很好的标准用于确定每层神经元的数量和隐层的个数。根据经验，更多的神经元会有更强的表示能力，同时也更容易造成网络的过拟合。</p>
<p>下面我们尝试用PyTorch搭建MLP回归与分类模型。</p>
<p>先导入需要的模块</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler,MinMaxScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score,confusion_matrix,classification_report</span><br><span class="line"><span class="keyword">from</span> sklearn.manifold <span class="keyword">import</span> TSNE</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> SGD,Adam</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> torch.utils.data <span class="keyword">as</span> Data</span><br><span class="line"><span class="keyword">import</span> hiddenlayer <span class="keyword">as</span> hl</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="1-2-MLP分类模型">1.2    MLP分类模型</h2>
<h3 id="数据准备与探查">数据准备与探查</h3>
<p>数据采用UCI机器学习库的垃圾邮件数据，下载网址为：<a href="https://archive.ics.uci.edu/ml/datasets.Spambase">https://archive.ics.uci.edu/ml/datasets.Spambase</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 读取数据集</span></span><br><span class="line">spam=pd.read_csv(<span class="string">r&quot;C:\Users\lenovo\Desktop\spambase.csv&quot;</span>)</span><br><span class="line"><span class="comment"># 前五十七列是属性</span></span><br><span class="line"><span class="comment"># 最后一列是分类</span></span><br><span class="line">x=spam.iloc[:,<span class="number">0</span>:<span class="number">57</span>].values</span><br><span class="line">y=spam.tar.values</span><br><span class="line"><span class="comment"># 然后需要将数据分割为训练集和测试集</span></span><br><span class="line">X_train,X_test,Y_train,Y_test=train_test_split(x,y,test_size=<span class="number">0.25</span>,random_state=<span class="number">123</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="数据预处理">数据预处理</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 为了消除量纲和减少离群点影响，需要对属性做标准化</span></span><br><span class="line"><span class="comment"># 可以用中心化或是归一化</span></span><br><span class="line"><span class="comment"># 对数据的前57列特征进行数据标准化处理</span></span><br><span class="line">scales=MinMaxScaler(feature_range=(<span class="number">0</span>,<span class="number">1</span>))</span><br><span class="line">X_train_s=scales.fit_transform(X_train)</span><br><span class="line">X_test_s=scales.transform(X_test)</span><br></pre></td></tr></table></figure>
<h3 id="数据可视化">数据可视化</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过箱线图对数据进行可视化</span></span><br><span class="line">colname=spam.columns.values[:-<span class="number">1</span>]</span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>,<span class="number">14</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(colname)):</span><br><span class="line">    plt.subplot(<span class="number">7</span>,<span class="number">9</span>,i+<span class="number">1</span>)</span><br><span class="line">    sns.boxplot(x=Y_train,y=X_train_s[:,i])</span><br><span class="line">    plt.title(colname[i])</span><br><span class="line">plt.subplots_adjust(hspace=<span class="number">0.4</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<img src="/2022/07/28/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E7%AC%AC%E4%BA%94%E7%AB%A0%20%20%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20220728200255063.png" alt="image-20220728200255063" style="zoom:50%;">
<h3 id="创建一个多层感知机">创建一个多层感知机</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MLP</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line"></span><br><span class="line">        <span class="built_in">super</span>(MLP, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.hidden1=nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">57</span>,<span class="number">30</span>,bias=<span class="literal">True</span>),</span><br><span class="line">            nn.ReLU()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.hidden2 = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">30</span>, <span class="number">10</span>, bias=<span class="literal">True</span>),</span><br><span class="line">            nn.ReLU()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.classifica = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">10</span>,<span class="number">2</span>, bias=<span class="literal">True</span>),</span><br><span class="line">            nn.Sigmoid()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        fc1=self.hidden1(x)</span><br><span class="line">        fc2=self.hidden2(fc1)</span><br><span class="line">        output=self.classifica(fc2)</span><br><span class="line">        <span class="keyword">return</span> fc1,fc2,output</span><br></pre></td></tr></table></figure>
<h3 id="数据载入与转换">数据载入与转换</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 需要将处理好的数据转化为张量进行使用</span></span><br><span class="line"><span class="comment"># 分类数据使用int64即可</span></span><br><span class="line">x_train_nots=torch.from_numpy(X_train_s.astype(np.float32))</span><br><span class="line">y_train_tar=torch.from_numpy(Y_train.astype(np.int64))</span><br><span class="line">x_test_nots=torch.from_numpy(X_test_s.astype(np.float32))</span><br><span class="line">y_test_tar=torch.from_numpy(Y_test.astype(np.int64))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将其合并为一个数据集</span></span><br><span class="line">train_data=Data.TensorDataset(x_train_nots,y_train_tar)</span><br><span class="line"><span class="comment"># 放入数据容器</span></span><br><span class="line">train_data_loader=Data.DataLoader(</span><br><span class="line">    dataset=train_data,</span><br><span class="line">    shuffle=<span class="literal">True</span>,</span><br><span class="line">    batch_size=<span class="number">64</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h3 id="优化器和损失函数">优化器和损失函数</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">mlp=MLP()</span><br><span class="line"><span class="comment"># 定义优化器</span></span><br><span class="line">opt=Adam(mlp.parameters(),lr=<span class="number">0.0003</span>)</span><br><span class="line"><span class="comment"># 定义损失函数</span></span><br><span class="line">loss_fn=nn.CrossEntropyLoss()</span><br><span class="line"><span class="comment"># 记录历史信息</span></span><br><span class="line">history1=hl.History()</span><br><span class="line"><span class="comment"># 使用画布可视化</span></span><br><span class="line">canvas=hl.Canvas()</span><br><span class="line"><span class="comment"># 中间过程</span></span><br><span class="line">print_step=<span class="number">30</span></span><br></pre></td></tr></table></figure>
<h3 id="训练过程">训练过程</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">50</span>):</span><br><span class="line">	<span class="comment"># 获取每一次的label和target</span></span><br><span class="line">    <span class="keyword">for</span> step,(bx,by) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_data_loader):</span><br><span class="line">        _,_,out=mlp(bx)</span><br><span class="line">        <span class="comment"># 计算损失</span></span><br><span class="line">        loss=loss_fn(out,by)</span><br><span class="line">        <span class="comment"># 梯度清零</span></span><br><span class="line">        opt.zero_grad()</span><br><span class="line">        <span class="comment"># 反向传播</span></span><br><span class="line">        loss.backward()</span><br><span class="line">        <span class="comment"># 更新参数</span></span><br><span class="line">        opt.step()</span><br><span class="line">        niter=epoch*<span class="built_in">len</span>(train_data_loader)+step+<span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> niter%print_step==<span class="number">0</span>:</span><br><span class="line">            _,_,output=mlp(x_test_nots)</span><br><span class="line">            <span class="comment"># 查看</span></span><br><span class="line">            _,pre_lab=torch.<span class="built_in">max</span>(output,<span class="number">1</span>)</span><br><span class="line">            <span class="comment"># 计算精度</span></span><br><span class="line">            test_accuracy=accuracy_score(y_test_tar,pre_lab)</span><br><span class="line">            <span class="comment"># 添加epoch精度和损失</span></span><br><span class="line">            history1.log(niter,train_loss=loss,test_accuracy=test_accuracy)</span><br><span class="line">            <span class="keyword">with</span> canvas:</span><br><span class="line">                canvas.draw_plot(history1[<span class="string">&#x27;train_loss&#x27;</span>])</span><br><span class="line">                canvas.draw_plot(history1[<span class="string">&#x27;test_accuracy&#x27;</span>])</span><br><span class="line">_,_,output=mlp(x_test_nots)</span><br><span class="line">_,pre_lab=torch.<span class="built_in">max</span>(output,<span class="number">1</span>)</span><br><span class="line">test_accuracy=accuracy_score(y_test_tar,pre_lab)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Test_Accuracy&quot;</span>,test_accuracy)</span><br></pre></td></tr></table></figure>
<img src="/2022/07/28/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E7%AC%AC%E4%BA%94%E7%AB%A0%20%20%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20220728200304101.png" alt="image-20220728200304101" style="zoom:50%;">
<h3 id="获取中间层输出">获取中间层输出</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取第二个隐层的输出</span></span><br><span class="line">_,test_fc2,_=mlp(x_test_nots)</span><br><span class="line"><span class="comment"># TSNE降维</span></span><br><span class="line">test_fc2_tsne=TSNE(n_components=<span class="number">2</span>).fit_transform(test_fc2.data.numpy())</span><br><span class="line"><span class="comment"># 可视化特征</span></span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>,<span class="number">6</span>))</span><br><span class="line"><span class="comment"># 可视化前设置</span></span><br><span class="line">plt.xlim([<span class="built_in">min</span>(test_fc2_tsne[:,<span class="number">0</span>]-<span class="number">1</span>),<span class="built_in">max</span>(test_fc2_tsne[:,<span class="number">0</span>])+<span class="number">1</span>])</span><br><span class="line">plt.ylim([<span class="built_in">min</span>(test_fc2_tsne[:,<span class="number">1</span>]-<span class="number">1</span>),<span class="built_in">max</span>(test_fc2_tsne[:,<span class="number">1</span>])+<span class="number">1</span>])</span><br><span class="line">plt.plot(test_fc2_tsne[Y_test==<span class="number">0</span>,<span class="number">0</span>],test_fc2_tsne[Y_test==<span class="number">0</span>,<span class="number">1</span>],<span class="string">&quot;bo&quot;</span>,label=<span class="string">&quot;0&quot;</span>)</span><br><span class="line">plt.plot(test_fc2_tsne[Y_test==<span class="number">1</span>,<span class="number">0</span>],test_fc2_tsne[Y_test==<span class="number">1</span>,<span class="number">1</span>],<span class="string">&quot;rd&quot;</span>,label=<span class="string">&quot;1&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.title(<span class="string">&quot;test_fcc2_tsne&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<img src="/2022/07/28/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E7%AC%AC%E4%BA%94%E7%AB%A0%20%20%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20220728200311379.png" alt="image-20220728200311379" style="zoom:50%;">
<h3 id="通过Hook调用中间层信息">通过Hook调用中间层信息</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过辅助函数来获取指定层名称的特征</span></span><br><span class="line">activation=&#123;&#125;</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_activation</span>(<span class="params">name</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">hook</span>(<span class="params">model,<span class="built_in">input</span>,output</span>):</span><br><span class="line">        activation[name]=output.detach()</span><br><span class="line">    <span class="keyword">return</span> hook</span><br><span class="line"></span><br><span class="line">mlp.classifica.register_forward_hook(get_activation(<span class="string">&#x27;classifica&#x27;</span>))</span><br><span class="line">_,_,_=mlp(x_test_nots)</span><br><span class="line">classfica=activation[<span class="string">&#x27;classifica&#x27;</span>].data.numpy()</span><br><span class="line"><span class="comment"># 可视化特征</span></span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>,<span class="number">6</span>))</span><br><span class="line">plt.plot(classfica[Y_test==<span class="number">0</span>,<span class="number">0</span>],classfica[Y_test==<span class="number">0</span>,<span class="number">1</span>],<span class="string">&quot;bo&quot;</span>,label=<span class="string">&quot;0&quot;</span>)</span><br><span class="line">plt.plot(classfica[Y_test==<span class="number">1</span>,<span class="number">0</span>],classfica[Y_test==<span class="number">1</span>,<span class="number">1</span>],<span class="string">&quot;rd&quot;</span>,label=<span class="string">&quot;1&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<img src="/2022/07/28/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E7%AC%AC%E4%BA%94%E7%AB%A0%20%20%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20220728200317576.png" alt="image-20220728200317576" style="zoom:50%;">
<hr>
<h2 id="1-3-MLP回归模型">1.3    MLP回归模型</h2>
<p>回归模型的数据选择sklearn.datasets中的加利福尼亚房价数据。</p>
<h3 id="模块准备">模块准备</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error,mean_absolute_error</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> fetch_california_housing</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> SGD</span><br><span class="line"><span class="keyword">import</span> torch.utils.data <span class="keyword">as</span> Data</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br></pre></td></tr></table></figure>
<h3 id="数据处理">数据处理</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">housedata=fetch_california_housing()</span><br><span class="line">X_train,X_test,y_train,y_test=train_test_split(</span><br><span class="line">    housedata.data,</span><br><span class="line">    housedata.target,</span><br><span class="line">    test_size=<span class="number">0.3</span>,</span><br><span class="line">    random_state=<span class="number">42</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 标准化</span></span><br><span class="line">scale=StandardScaler()</span><br><span class="line">X_train_s=scale.fit_transform(X_train)</span><br><span class="line">X_test_s=scale.transform(X_test)</span><br></pre></td></tr></table></figure>
<h3 id="数据探查">数据探查</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 转化为数据表，探查数据情况</span></span><br><span class="line">housedatadf=pd.DataFrame(data=X_train_s,columns=housedata.feature_names)</span><br><span class="line">housedatadf[<span class="string">&#x27;target&#x27;</span>]=y_train</span><br><span class="line"><span class="comment"># 可视化热力图</span></span><br><span class="line">datacor=np.corrcoef(housedatadf.values,rowvar=<span class="number">0</span>)</span><br><span class="line">datacor=pd.DataFrame(data=datacor,columns=housedatadf.columns,index=housedatadf.columns)</span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>,<span class="number">6</span>))</span><br><span class="line">ax=sns.heatmap(datacor,square=<span class="literal">True</span>,annot=<span class="literal">True</span>,fmt=<span class="string">&quot;.3f&quot;</span>,linewidths=<span class="number">.5</span>,cmap=<span class="string">&quot;YlGnBu&quot;</span>,cbar_kws=&#123;<span class="string">&quot;fraction&quot;</span>:<span class="number">0.046</span>,<span class="string">&quot;pad&quot;</span>:<span class="number">0.03</span>&#125;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h3 id="数据转化">数据转化</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 转化为张量</span></span><br><span class="line">train_xt=torch.from_numpy(X_train_s.astype(np.float32))</span><br><span class="line">train_yt=torch.from_numpy(y_train.astype(np.float32))</span><br><span class="line">test_xt=torch.from_numpy(X_test_s.astype(np.float32))</span><br><span class="line">test_yt=torch.from_numpy(y_test.astype(np.float32))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 放到数据容器</span></span><br><span class="line">train_data=Data.TensorDataset(train_xt,train_yt)</span><br><span class="line">test_data=Data.TensorDataset(test_xt,test_yt)</span><br><span class="line">train_loader=Data.DataLoader(</span><br><span class="line">    dataset=train_data,</span><br><span class="line">    shuffle=<span class="literal">True</span>,</span><br><span class="line">    batch_size=<span class="number">64</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<img src="/2022/07/28/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E7%AC%AC%E4%BA%94%E7%AB%A0%20%20%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20220728200324585.png" alt="image-20220728200324585" style="zoom:50%;">
<h3 id="定义一个多层感知机">定义一个多层感知机</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MLP</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(MLP, self).__init__()</span><br><span class="line">        self.hidden1=nn.Linear(<span class="number">8</span>,<span class="number">100</span>,bias=<span class="literal">True</span>)</span><br><span class="line">        self.hidden2=nn.Linear(<span class="number">100</span>,<span class="number">100</span>)</span><br><span class="line">        self.hidden3=nn.Linear(<span class="number">100</span>,<span class="number">50</span>)</span><br><span class="line">        self.predict=nn.Linear(<span class="number">50</span>,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        x=F.relu(self.hidden1(x))</span><br><span class="line">        x=F.relu(self.hidden2(x))</span><br><span class="line">        x=F.relu(self.hidden3(x))</span><br><span class="line">        output=self.predict(x)</span><br><span class="line">        <span class="comment"># output: [batch,1]</span></span><br><span class="line">        <span class="comment"># output[:,0]: [batch]</span></span><br><span class="line">        <span class="keyword">return</span> output[:,<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<h3 id="训练参数定义">训练参数定义</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mlp=MLP()</span><br><span class="line">optimizer=torch.optim.SGD(mlp.parameters(),lr=<span class="number">0.003</span>)</span><br><span class="line">loss_func=nn.MSELoss()</span><br><span class="line">train_loss_all=[]</span><br></pre></td></tr></table></figure>
<h3 id="训练过程-v2">训练过程</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">60</span>):</span><br><span class="line">    train_loss=<span class="number">0</span></span><br><span class="line">    train_num=<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> (bx,by) <span class="keyword">in</span> train_loader:</span><br><span class="line">        output=mlp(bx)</span><br><span class="line">        loss=loss_func(output,by)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        train_loss+=loss.item()*bx.size(<span class="number">0</span>)</span><br><span class="line">        train_num+=bx.size(<span class="number">0</span>)</span><br><span class="line">    train_loss_all.append(train_loss/train_num)</span><br></pre></td></tr></table></figure>
<h3 id="结果可视化">结果可视化</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">6</span>))</span><br><span class="line">plt.plot(train_loss_all,<span class="string">&#x27;ro-&#x27;</span>,label=<span class="string">&quot;Train Loss&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.grid()</span><br><span class="line">plt.xlabel(<span class="string">&quot;epoch&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;loss&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<img src="/2022/07/28/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E7%AC%AC%E4%BA%94%E7%AB%A0%20%20%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20220728200331572.png" alt="image-20220728200331572" style="zoom:50%;">
<h3 id="预测测试集">预测测试集</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对测试集进行预测</span></span><br><span class="line">pre_y=mlp(test_xt)</span><br><span class="line">pre_y=pre_y.data.numpy()</span><br><span class="line">mae=mean_absolute_error(y_test,pre_y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;在测试集上的绝对值误差为： &quot;</span>,mae)</span><br></pre></td></tr></table></figure>
<img src="/2022/07/28/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E7%AC%AC%E4%BA%94%E7%AB%A0%20%20%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20220322193302295.png" alt="image-20220322193302295" style="zoom:50%;">
<h3 id="可视化差异">可视化差异</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 可视化差异</span></span><br><span class="line">index=np.argsort(y_test)</span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>,<span class="number">5</span>))</span><br><span class="line">plt.plot(np.arange(<span class="built_in">len</span>(y_test)),y_test[index],<span class="string">&#x27;r&#x27;</span>,label=<span class="string">&quot;original Y&quot;</span>)</span><br><span class="line">plt.scatter(np.arange(<span class="built_in">len</span>(pre_y)),pre_y[index],s=<span class="number">3</span>,c=<span class="string">&quot;b&quot;</span>,label=<span class="string">&quot;Prediction&quot;</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&quot;upper left&quot;</span>)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.xlabel(<span class="string">&quot;Index&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Y&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<img src="/2022/07/28/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E7%AC%AC%E4%BA%94%E7%AB%A0%20%20%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20220728200338389.png" alt="image-20220728200338389" style="zoom:50%;"><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 不想学辣 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 神经网络 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[第四章  基于PyTorch的可视化工具]]></title>
      <url>/2022/07/28/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E7%AC%AC%E5%9B%9B%E7%AB%A0%20%20%E5%9F%BA%E4%BA%8EPyTorch%E7%9A%84%E7%9B%B8%E5%85%B3%E5%8F%AF%E8%A7%86%E5%8C%96%E5%B7%A5%E5%85%B7/</url>
      <content type="html"><![CDATA[<h1>第四章    基于PyTorch的可视化工具</h1>
<hr>
<h2 id="1-网络结构的可视化">1.    网络结构的可视化</h2>
<p>本节我们定义一个简单CNN对手写数据集进行分类，并通过相关的可视化库进行可视化。</p>
<p><strong>模块导入</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.utils <span class="keyword">as</span> vutils</span><br><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> SGD</span><br><span class="line"><span class="keyword">import</span> torch.utils.data <span class="keyword">as</span> Data</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span>  accuracy_score</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure>
<p><strong>数据准备</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 首先是获取手写数据集</span></span><br><span class="line">train_data=torchvision.datasets.MNIST(</span><br><span class="line">    root=<span class="string">&quot;./data/MNIST&quot;</span>,</span><br><span class="line">    train=<span class="literal">True</span>, <span class="comment"># 只使用训练集</span></span><br><span class="line">    transform=torchvision.transforms.ToTensor(), <span class="comment"># 这里是使用了tv的transforms接口，转换为Tensor</span></span><br><span class="line">    download=<span class="literal">False</span> <span class="comment"># 如果下载过了就不需要重新下载，可改为False</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 有了数据集之后捏，就需要把数据分批处理</span></span><br><span class="line"><span class="comment"># 我们一般是创建一个DataLoader</span></span><br><span class="line">train_loader=Data.DataLoader(</span><br><span class="line">    dataset=train_data,</span><br><span class="line">    batch_size=<span class="number">256</span>,</span><br><span class="line">    shuffle=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可以看下数据的格式</span></span><br><span class="line"><span class="keyword">for</span> step,(b_x,b_y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">    <span class="keyword">if</span> step&gt;<span class="number">0</span>:</span><br><span class="line">        <span class="keyword">break</span> <span class="comment"># 只拿出一个batch查看</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(b_x.shape)</span><br><span class="line"><span class="built_in">print</span>(b_y.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 然后是测试数据集</span></span><br><span class="line">test_data=torchvision.datasets.MNIST(</span><br><span class="line">    root=<span class="string">&quot;./data/MNIST&quot;</span>,</span><br><span class="line">    train=<span class="literal">False</span>,  <span class="comment"># 不使用训练集</span></span><br><span class="line">    download=<span class="literal">False</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里我们需要个数据添加一个通道(channel)</span></span><br><span class="line"><span class="comment"># 并且将数值范围缩放到[0,1]</span></span><br><span class="line"></span><br><span class="line">test_data_x=test_data.data.<span class="built_in">type</span>(torch.FloatTensor)/<span class="number">255</span></span><br><span class="line">test_data_x=torch.unsqueeze(test_data_x,dim=<span class="number">1</span>)</span><br><span class="line">test_data_y=test_data.targets <span class="comment"># 数据集中提供的标签数据</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Test_x&quot;</span>,test_data_x.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Test_y&quot;</span>,test_data_y.shape)</span><br></pre></td></tr></table></figure>
<p>结果如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">torch.Size([256, 1, 28, 28])</span></span><br><span class="line"><span class="string">torch.Size([256])</span></span><br><span class="line"><span class="string">Test_x torch.Size([10000, 1, 28, 28])</span></span><br><span class="line"><span class="string">Test_y torch.Size([10000])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p><strong>网络搭建</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 搭建一个CNN</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ConvNet</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(ConvNet,self).__init__()</span><br><span class="line">        <span class="comment"># 本网络由两个卷积层和一个全连接层构成</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 第一个卷积层</span></span><br><span class="line">        self.conv1=nn.Sequential(</span><br><span class="line">            <span class="comment"># 1-&gt;16</span></span><br><span class="line">            nn.Conv2d(<span class="number">1</span>,<span class="number">16</span>,<span class="number">3</span>,padding=<span class="number">1</span>,stride=<span class="number">1</span>),</span><br><span class="line">            <span class="comment"># 激活函数</span></span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            <span class="comment"># 卷积做完后进行池化</span></span><br><span class="line">            <span class="comment"># 本网络使用平均池化，目的是压缩信息量</span></span><br><span class="line">            nn.AvgPool2d(kernel_size=<span class="number">2</span>,stride=<span class="number">2</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 第二个卷积层</span></span><br><span class="line">        self.conv2=nn.Sequential(</span><br><span class="line">            <span class="comment"># 16-&gt;32</span></span><br><span class="line">            nn.Conv2d(<span class="number">16</span>,<span class="number">32</span>,kernel_size=<span class="number">3</span>,stride=<span class="number">1</span>,padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 第三层全连接层</span></span><br><span class="line">        self.mlp=nn.Sequential(</span><br><span class="line">            nn.Linear(</span><br><span class="line">                <span class="comment"># 输入特征数</span></span><br><span class="line">                <span class="comment"># 图片有32个channel</span></span><br><span class="line">                <span class="comment"># 且大小为： 28&gt;&gt;2</span></span><br><span class="line">                in_features=<span class="number">32</span>*<span class="number">7</span>*<span class="number">7</span>,</span><br><span class="line">                out_features=<span class="number">128</span></span><br><span class="line">            ),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">128</span>,<span class="number">64</span>),</span><br><span class="line">            nn.ReLU()</span><br><span class="line">        )</span><br><span class="line">        <span class="comment"># 最后的输出映射十个数字</span></span><br><span class="line">        self.out=nn.Linear(<span class="number">64</span>,<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        <span class="comment"># return self.out(self.mlp(self.conv2(self.conv1(x))))</span></span><br><span class="line">        <span class="comment"># 注意此时是图像数据</span></span><br><span class="line">        <span class="comment"># 为了让MLP线性层能够处理</span></span><br><span class="line">        <span class="comment"># 需要平铺为一维向量</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># x:-&gt;[batch,1,28,28]</span></span><br><span class="line">        x=self.conv2(self.conv1(x))</span><br><span class="line">        <span class="comment"># x:-&gt;[batch,32,7,7]</span></span><br><span class="line">        x=x.view(x.size(<span class="number">0</span>),-<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># x:-&gt;[32*7*7]^T</span></span><br><span class="line">        <span class="keyword">return</span> self.out(self.mlp(x))         <span class="comment"># x:-&gt;10</span></span><br><span class="line"></span><br><span class="line">Conv1=ConvNet()</span><br><span class="line"><span class="built_in">print</span>(Conv1)</span><br></pre></td></tr></table></figure>
<p><strong>HiddenLayer可视化</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 借助hiddenlayer库进行可视化</span></span><br><span class="line"><span class="keyword">import</span> hiddenlayer <span class="keyword">as</span> hl</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化CNN</span></span><br><span class="line">hl_graph=hl.build_graph(Conv1,torch.zeros([<span class="number">1</span>,<span class="number">1</span>,<span class="number">28</span>,<span class="number">28</span>]))</span><br><span class="line">hl_graph.theme=hl.graph.THEMES[<span class="string">&quot;blue&quot;</span>].copy()</span><br><span class="line"><span class="comment"># 可以将其保存为图片</span></span><br><span class="line">hl_graph.save(<span class="string">r&quot;C:\Users\落花雨\Desktop\0001.png&quot;</span>,<span class="built_in">format</span>=<span class="string">&quot;png&quot;</span>)</span><br></pre></td></tr></table></figure>
<p><strong>PyTorchViz可视化</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torchviz <span class="keyword">import</span> make_dot</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用make_dot可视化网络</span></span><br><span class="line">x=torch.randn(<span class="number">1</span>,<span class="number">1</span>,<span class="number">28</span>,<span class="number">28</span>).requires_grad_(<span class="literal">True</span>)</span><br><span class="line">y=Conv1(x)</span><br><span class="line">ConvVis=make_dot(y,params=<span class="built_in">dict</span>(<span class="built_in">list</span>(Conv1.named_parameters())+[(<span class="string">&quot;x&quot;</span>,x)]))</span><br><span class="line"><span class="comment"># 将其保存为图片</span></span><br><span class="line">ConvVis.<span class="built_in">format</span>=<span class="string">&quot;png&quot;</span></span><br><span class="line">ConvVis.directory=<span class="string">r&quot;C:\Users\落花雨\Desktop&quot;</span></span><br><span class="line">ConvVis.view() <span class="comment"># 会自动在当前目录下生成文件</span></span><br></pre></td></tr></table></figure>
<hr>
<h2 id="2-训练过程可视化">2.  训练过程可视化</h2>
<h3 id="2-1-tensorboardX">2.1 tensorboardX</h3>
<p>tensorboardX的部分API如下：</p>
<table>
<thead>
<tr>
<th style="text-align:center">函数</th>
<th style="text-align:center">功能</th>
<th style="text-align:center">用法</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">SummaryWriter()</td>
<td style="text-align:center">创建编写器，保存日志</td>
<td style="text-align:center">writer=SummaryWriter()</td>
</tr>
<tr>
<td style="text-align:center">writer.add_scalar()</td>
<td style="text-align:center">添加标量</td>
<td style="text-align:center">writer.add_scalar(‘myscalar’,value,iteration)</td>
</tr>
<tr>
<td style="text-align:center">writer.add_image()</td>
<td style="text-align:center">添加图像</td>
<td style="text-align:center">writer.add_image(‘imresult’,x,itertation)</td>
</tr>
<tr>
<td style="text-align:center">writer.add_histogram()</td>
<td style="text-align:center">添加直方图</td>
<td style="text-align:center">writer.add_histogram(‘hist’,array,iteration)</td>
</tr>
<tr>
<td style="text-align:center">writer.add_graph()</td>
<td style="text-align:center">添加网络结构</td>
<td style="text-align:center">writer.add_graph(model,input_to_model=None)</td>
</tr>
<tr>
<td style="text-align:center">writer.add_audio()</td>
<td style="text-align:center">添加音频</td>
<td style="text-align:center">add_audio(tag,audio,iteration,sample_rate)</td>
</tr>
<tr>
<td style="text-align:center">writer.add_text()</td>
<td style="text-align:center">添加文本</td>
<td style="text-align:center">writer.add_text(tag,text_string,global_step=None)</td>
</tr>
</tbody>
</table>
<p>以下案例展现了tensorboard的使用方式</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 我们利用tensorboardX进行可视化</span></span><br><span class="line">Sumwriter=SummaryWriter(log_dir=<span class="string">&quot;data/log/chap4&quot;</span>)</span><br><span class="line"><span class="comment"># 定义优化器</span></span><br><span class="line">optimizer=torch.optim.Adam(CNN1.parameters(),lr=<span class="number">0.0003</span>)</span><br><span class="line"><span class="comment"># 定义损失函数</span></span><br><span class="line">loss_func=nn.CrossEntropyLoss()</span><br><span class="line"><span class="comment"># 初始化损失</span></span><br><span class="line">train_loss=<span class="number">0</span></span><br><span class="line"><span class="comment"># 计算迭代输出次数</span></span><br><span class="line"><span class="comment"># 每迭代一百次进行一次输出</span></span><br><span class="line">print_step=<span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行训练</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> step,(b_x,b_y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">        <span class="comment"># 计算每个batch损失</span></span><br><span class="line">        output=CNN1(b_x)</span><br><span class="line">        <span class="comment"># 交叉熵</span></span><br><span class="line">        loss=loss_func(output,b_y)</span><br><span class="line">        <span class="comment"># 梯度初始化</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        <span class="comment"># 计算梯度并优化</span></span><br><span class="line">        optimizer.step()</span><br><span class="line">        <span class="comment"># 计算累计损失和</span></span><br><span class="line">        train_loss+=loss</span><br><span class="line">        <span class="comment"># 计算迭代次数</span></span><br><span class="line">        niter=epoch*<span class="built_in">len</span>(train_loader)+step+<span class="number">1</span></span><br><span class="line">        <span class="comment"># 每一百次进行输出</span></span><br><span class="line">        <span class="keyword">if</span> niter%print_step==<span class="number">0</span>:</span><br><span class="line">            <span class="comment"># 为日志添加训练集损失函数</span></span><br><span class="line">            Sumwriter.add_scalar(tag=<span class="string">&quot;train_loss&quot;</span>,scalar_value=train_loss.item()/niter,</span><br><span class="line">                                     global_step=niter)</span><br><span class="line">            <span class="comment"># 计算在测试集上的精度</span></span><br><span class="line">            output=CNN1(test_data_x)</span><br><span class="line">            <span class="comment"># 在维度1上的最大值</span></span><br><span class="line">            <span class="comment"># 前面是值，后面是最大值索引</span></span><br><span class="line">            _,pre_lab=torch.<span class="built_in">max</span>(output,<span class="number">1</span>)</span><br><span class="line">            acc=accuracy_score(test_data_y,pre_lab)</span><br><span class="line">            <span class="comment"># 为训练日志添加预测精度</span></span><br><span class="line">            Sumwriter.add_scalar(tag=<span class="string">&quot;test acc&quot;</span>,scalar_value=acc.item(),global_step=niter)</span><br><span class="line">            <span class="comment"># 为训练日志添加可视化图像</span></span><br><span class="line">            <span class="comment"># 使用当前batch的图像</span></span><br><span class="line">            b_x_im=vutils.make_grid(b_x,nrow=<span class="number">12</span>)</span><br><span class="line">            Sumwriter.add_image(tag=<span class="string">&quot;train image sample&quot;</span>,img_tensor=b_x_im,global_step=niter)</span><br><span class="line">            <span class="comment"># 使用直方图可视化网络参数的分布情况</span></span><br><span class="line">            <span class="keyword">for</span> name,param <span class="keyword">in</span> CNN1.named_parameters():</span><br><span class="line">                Sumwriter.add_histogram(name,param.data.numpy(),niter)</span><br></pre></td></tr></table></figure>
<h2 id="3-Visdom可视化">3.  Visdom可视化</h2>
<p>Visdom是Facebook专门为PyTorch开发的一款可视化工具，可视化的同时支持Tensor和Numpy两种数据格式。</p>
<table>
<thead>
<tr>
<th style="text-align:center">函数</th>
<th style="text-align:center">功能</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">vis.image</td>
<td style="text-align:center">可视化一张图像</td>
</tr>
<tr>
<td style="text-align:center">vis.images</td>
<td style="text-align:center">可视化一个batch的图像，或者一个图像列表</td>
</tr>
<tr>
<td style="text-align:center">vis.text</td>
<td style="text-align:center">可视化文本</td>
</tr>
<tr>
<td style="text-align:center">vis.audio</td>
<td style="text-align:center">播放音频</td>
</tr>
<tr>
<td style="text-align:center">vis.video</td>
<td style="text-align:center">播放视频</td>
</tr>
<tr>
<td style="text-align:center">vis.matplot</td>
<td style="text-align:center">可视化matplotlib的图像</td>
</tr>
<tr>
<td style="text-align:center">vis.scatter</td>
<td style="text-align:center">2D或3D的散点图</td>
</tr>
<tr>
<td style="text-align:center">vis.line</td>
<td style="text-align:center">线图</td>
</tr>
<tr>
<td style="text-align:center">vis.stem</td>
<td style="text-align:center">茎叶图</td>
</tr>
<tr>
<td style="text-align:center">vis.hearmap</td>
<td style="text-align:center">热力图</td>
</tr>
<tr>
<td style="text-align:center">vis.bar</td>
<td style="text-align:center">条形图</td>
</tr>
<tr>
<td style="text-align:center">vis.histogram</td>
<td style="text-align:center">直方图</td>
</tr>
<tr>
<td style="text-align:center">vis.boxplot</td>
<td style="text-align:center">盒形图</td>
</tr>
<tr>
<td style="text-align:center">vis.surf</td>
<td style="text-align:center">曲面图</td>
</tr>
<tr>
<td style="text-align:center">vis.contour</td>
<td style="text-align:center">等高线图</td>
</tr>
<tr>
<td style="text-align:center">vis.quiver</td>
<td style="text-align:center">箭头图</td>
</tr>
<tr>
<td style="text-align:center">vis.mesh</td>
<td style="text-align:center">网格图</td>
</tr>
</tbody>
</table>
<p>Visdom服务器需要先挂起</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m visdom.server</span><br></pre></td></tr></table></figure>
<p><strong>以下使用一个案例来运用Visdom</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> visdom <span class="keyword">import</span> Visdom</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入鸢尾花数据集</span></span><br><span class="line"><span class="comment"># 为: x:(150,4) y:(150)</span></span><br><span class="line">ix,iy=load_iris(return_X_y=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p><strong>散点图</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 接下来绘制散点图</span></span><br><span class="line">vis=Visdom()</span><br><span class="line">vis.scatter(ix[:,<span class="number">0</span>:<span class="number">2</span>],Y=iy+<span class="number">1</span>,win=<span class="string">&quot;windows1&quot;</span>,env=<span class="string">&quot;main&quot;</span>)</span><br><span class="line">vis.scatter(ix[:,<span class="number">0</span>:<span class="number">3</span>],Y=iy+<span class="number">1</span>,win=<span class="string">&quot;3D 散点图&quot;</span>,env=<span class="string">&quot;main&quot;</span>,</span><br><span class="line">            opts=<span class="built_in">dict</span>(markersize=<span class="number">4</span>,</span><br><span class="line">                      xlabel=<span class="string">&quot;特征1&quot;</span>,</span><br><span class="line">                      ylabel=<span class="string">&quot;特征2&quot;</span>))</span><br></pre></td></tr></table></figure>
<img src="/2022/07/28/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E7%AC%AC%E5%9B%9B%E7%AB%A0%20%20%E5%9F%BA%E4%BA%8EPyTorch%E7%9A%84%E7%9B%B8%E5%85%B3%E5%8F%AF%E8%A7%86%E5%8C%96%E5%B7%A5%E5%85%B7/image-20220728200129712.png" alt="image-20220728200129712" style="zoom:50%;">
<img src="/2022/07/28/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E7%AC%AC%E5%9B%9B%E7%AB%A0%20%20%E5%9F%BA%E4%BA%8EPyTorch%E7%9A%84%E7%9B%B8%E5%85%B3%E5%8F%AF%E8%A7%86%E5%8C%96%E5%B7%A5%E5%85%B7/image-20220728200135598.png" alt="image-20220728200135598" style="zoom:50%;">
<p><strong>折线图</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 绘制折线图</span></span><br><span class="line">x=torch.linspace(-<span class="number">6</span>,<span class="number">6</span>,<span class="number">100</span>).view((-<span class="number">1</span>,<span class="number">1</span>))</span><br><span class="line">sigmoid=torch.nn.Sigmoid()</span><br><span class="line">sigmoidy=sigmoid(x)</span><br><span class="line">tanh=torch.nn.Tanh()</span><br><span class="line">tanhy=tanh(x)</span><br><span class="line">relu=torch.nn.ReLU()</span><br><span class="line">reluy=relu(x)</span><br><span class="line"></span><br><span class="line">ploty=torch.cat((sigmoidy,tanhy,reluy),dim=<span class="number">1</span>)</span><br><span class="line">plotx=torch.cat((x,x,x),dim=<span class="number">1</span>)</span><br><span class="line">vis.line(Y=ploty,X=plotx,win=<span class="string">&quot;line plot&quot;</span>,env=<span class="string">&quot;main&quot;</span>,</span><br><span class="line">         opts=<span class="built_in">dict</span>(dash=np.array([<span class="string">&quot;solid&quot;</span>,<span class="string">&quot;dash&quot;</span>,<span class="string">&quot;dashdot&quot;</span>]),</span><br><span class="line">                   legend=[<span class="string">&#x27;sigmoid&#x27;</span>,<span class="string">&#x27;tanh&#x27;</span>,<span class="string">&#x27;relu&#x27;</span>]))</span><br></pre></td></tr></table></figure>
<img src="/2022/07/28/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E7%AC%AC%E5%9B%9B%E7%AB%A0%20%20%E5%9F%BA%E4%BA%8EPyTorch%E7%9A%84%E7%9B%B8%E5%85%B3%E5%8F%AF%E8%A7%86%E5%8C%96%E5%B7%A5%E5%85%B7/image-20220728200141579.png" alt="image-20220728200141579" style="zoom:50%;">
<p><strong>茎叶图</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 茎叶图</span></span><br><span class="line">x=torch.linspace(-<span class="number">6</span>,<span class="number">6</span>,<span class="number">100</span>).view((-<span class="number">1</span>,<span class="number">1</span>))</span><br><span class="line">y1=torch.sin(x)</span><br><span class="line">y2=torch.cos(x)</span><br><span class="line"></span><br><span class="line">plotx=torch.cat((y1,y2),<span class="number">1</span>)</span><br><span class="line">ploty=torch.cat((x,x),<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">vis.stem(X=plotx,Y=ploty,win=<span class="string">&quot;stem plot&quot;</span>,env=<span class="string">&quot;main&quot;</span>,</span><br><span class="line">         opts=<span class="built_in">dict</span>(legend=[<span class="string">&#x27;sin&#x27;</span>,<span class="string">&#x27;cos&#x27;</span>],title=<span class="string">&quot;茎叶图&quot;</span>))</span><br></pre></td></tr></table></figure>
<img src="/2022/07/28/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E7%AC%AC%E5%9B%9B%E7%AB%A0%20%20%E5%9F%BA%E4%BA%8EPyTorch%E7%9A%84%E7%9B%B8%E5%85%B3%E5%8F%AF%E8%A7%86%E5%8C%96%E5%B7%A5%E5%85%B7/image-20220728200149240.png" alt="image-20220728200149240" style="zoom:50%;">
<p><strong>热力图</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 热力图</span></span><br><span class="line"><span class="comment"># 计算相关系数</span></span><br><span class="line">irs_cor=torch.from_numpy(np.corrcoef(ix,rowvar=<span class="literal">False</span>))</span><br><span class="line">vis.heatmap(irs_cor,win=<span class="string">&#x27;heatmap&#x27;</span>,env=<span class="string">&quot;main&quot;</span>,opts=<span class="built_in">dict</span>(</span><br><span class="line">    rownames=[<span class="string">&quot;x1&quot;</span>,<span class="string">&quot;x2&quot;</span>,<span class="string">&quot;x3&quot;</span>,<span class="string">&quot;x4&quot;</span>],</span><br><span class="line">    columnnames=[<span class="string">&quot;x1&quot;</span>,<span class="string">&quot;x2&quot;</span>,<span class="string">&quot;x3&quot;</span>,<span class="string">&quot;x4&quot;</span>],</span><br><span class="line">    title=<span class="string">&quot;热力图&quot;</span></span><br><span class="line">))</span><br></pre></td></tr></table></figure>
<img src="/2022/07/28/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E7%AC%AC%E5%9B%9B%E7%AB%A0%20%20%E5%9F%BA%E4%BA%8EPyTorch%E7%9A%84%E7%9B%B8%E5%85%B3%E5%8F%AF%E8%A7%86%E5%8C%96%E5%B7%A5%E5%85%B7/image-20220728200156034.png" alt="image-20220728200156034" style="zoom:50%;">
<p><strong>图片</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建新环境并显示手写数字集合</span></span><br><span class="line">bx=<span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> step,(x,by) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">    bx=x</span><br><span class="line">    <span class="keyword">if</span> step&gt;<span class="number">0</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">vis.image(bx[<span class="number">0</span>,...],win=<span class="string">&quot;one image&quot;</span>,env=<span class="string">&quot;Myimage&quot;</span>,opts=<span class="built_in">dict</span>(</span><br><span class="line">    title=<span class="string">&quot;图片&quot;</span></span><br><span class="line">))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成一个图像网络</span></span><br><span class="line">vis.images(bx,win=<span class="string">&quot;batch image&quot;</span>,env=<span class="string">&quot;Myimage&quot;</span>,nrow=<span class="number">16</span>,opts=<span class="built_in">dict</span>(</span><br><span class="line">    title=<span class="string">&quot;一批图片&quot;</span></span><br><span class="line">))</span><br></pre></td></tr></table></figure>
<img src="/2022/07/28/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E7%AC%AC%E5%9B%9B%E7%AB%A0%20%20%E5%9F%BA%E4%BA%8EPyTorch%E7%9A%84%E7%9B%B8%E5%85%B3%E5%8F%AF%E8%A7%86%E5%8C%96%E5%B7%A5%E5%85%B7/image-20220728200203965.png" alt="image-20220728200203965" style="zoom:50%;">
<p><strong>文本</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 可视化一段文本</span></span><br><span class="line">text=<span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">asdsadasfhoisauew </span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">vis.text(text,win=<span class="string">&quot;text plot&quot;</span>,env=<span class="string">&quot;Myimage&quot;</span>,opts=<span class="built_in">dict</span>(</span><br><span class="line">    title=<span class="string">&quot;文本&quot;</span></span><br><span class="line">))</span><br></pre></td></tr></table></figure>
<img src="/2022/07/28/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E7%AC%AC%E5%9B%9B%E7%AB%A0%20%20%E5%9F%BA%E4%BA%8EPyTorch%E7%9A%84%E7%9B%B8%E5%85%B3%E5%8F%AF%E8%A7%86%E5%8C%96%E5%B7%A5%E5%85%B7/image-20220728200210071.png" alt="image-20220728200210071" style="zoom:50%;">
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 不想学辣 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[第三章  深度神经网络]]></title>
      <url>/2022/07/28/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E7%AC%AC%E4%B8%89%E7%AB%A0%20%20DNN%20%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
      <content type="html"><![CDATA[<h1>第三章  深度神经网络</h1>
<hr>
<h2 id="1-随机梯度下降">1.  随机梯度下降</h2>
<p>通常，我们需要设计一个模型的损失函数来约束我们的训练过程，让其向着使用者想要的方向发展。针对分类问题可以用交叉熵，针对回归问题可以用均方根误差。</p>
<p>模型的训练并不是漫无目的的，而是需要向着损失函数最少的方向发展。此时就需要利用梯度下降算法。</p>
<p>梯度下降算法(gradient descent)是一个一阶最优化算法，通常也称为最速下降法。使用规定步长距离向着函数当前点梯度的反方向前进，不断迭代搜索直到陷入局部最优解。</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>W</mi><mo>:</mo><mo>=</mo><mi>W</mi><mo>−</mo><mi>α</mi><mi mathvariant="normal">▽</mi><mi>W</mi><mspace linebreak="newline"></mspace><mi>b</mi><mo>:</mo><mo>=</mo><mi>b</mi><mo>−</mo><mi>α</mi><mi mathvariant="normal">▽</mi><mi>b</mi></mrow><annotation encoding="application/x-tex">W:=W-\alpha\triangledown W
\\
b:=b-\alpha\triangledown b
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">:=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mord amsrm">▽</span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">b</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">:=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">b</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mord amsrm">▽</span><span class="mord mathnormal">b</span></span></span></span></span></p>
<p>由于普通的梯度下降算法每次更新都需要使用所有样本，当样本总量特别大时，对算法的速度影响特别大，于是就有了随机梯度下降(stochastic gradient descent,SGD)算法，每次只随机取部分样本进行优化。</p>
<p>使用梯度下降时，通常会指定一个学习率 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span></span></span></span> ，但该学习率比较难确定，且各个参数使用的学习率还有可能不同。针对这种情况，可以采用变化学习率 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>η</mi></mrow><annotation encoding="application/x-tex">\eta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">η</span></span></span></span> 进行训练，如在网络前期使用大学习率进行更新，而后期则采用较小的学习率。SGD的另一个缺点就是容易陷入局部最优解，针对这种情况，学者提出了基于动量的随机梯度算法。在优化时引入动量，能够加速学习，特别是面对小而连续且有很多噪声的梯度。引入动量在一定程度上不仅增加了学习参数的稳定性，而且会更快学习到收敛的参数。</p>
<p>原本的梯度下降算法更新仅与当前梯度值相关，而不涉及之前的梯度。而动量梯度下降法则对各个mini-batch求得梯度<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>▽</mo><mi>W</mi></mrow><annotation encoding="application/x-tex">\bigtriangledown W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord">▽</span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span></span></span></span>,<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>▽</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">\bigtriangledown b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord">▽</span><span class="mord mathnormal">b</span></span></span></span>使用指数加权平均得到<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>V</mi><mrow><mo>▽</mo><mi>W</mi></mrow></msub></mrow><annotation encoding="application/x-tex">V_{\bigtriangledown W}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">▽</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">W</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span>,<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>V</mi><mrow><mo>▽</mo><mi>b</mi></mrow></msub></mrow><annotation encoding="application/x-tex">V_{\bigtriangledown b}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">▽</span><span class="mord mathnormal mtight">b</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span>。并使用新的参数进行更新。(滚雪球)</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>V</mi><mrow><mo>▽</mo><msub><mi>W</mi><mn>0</mn></msub></mrow></msub><mo>=</mo><mn>0</mn><mspace linebreak="newline"></mspace><msub><mi>V</mi><mrow><mo>▽</mo><msub><mi>W</mi><mn>1</mn></msub></mrow></msub><mo>=</mo><mi>β</mi><msub><mi>V</mi><mrow><mo>▽</mo><msub><mi>W</mi><mn>0</mn></msub></mrow></msub><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>β</mi><mo stretchy="false">)</mo><mrow><mo>▽</mo><msub><mi>W</mi><mn>1</mn></msub></mrow><mspace linebreak="newline"></mspace><msub><mi>V</mi><mrow><mo>▽</mo><msub><mi>W</mi><mn>2</mn></msub></mrow></msub><mo>=</mo><mi>β</mi><msub><mi>V</mi><mrow><mo>▽</mo><msub><mi>W</mi><mn>1</mn></msub></mrow></msub><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>β</mi><mo stretchy="false">)</mo><mrow><mo>▽</mo><msub><mi>W</mi><mn>2</mn></msub></mrow><mspace linebreak="newline"></mspace><mo>⋯</mo></mrow><annotation encoding="application/x-tex">V_{\bigtriangledown W_0}=0
\\
V_{\bigtriangledown W_1}=\beta V_{\bigtriangledown W_0}+(1-\beta){\bigtriangledown W_1}
\\
V_{\bigtriangledown W_2}=\beta V_{\bigtriangledown W_1}+(1-\beta){\bigtriangledown W_2}
\\
\cdots
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">▽</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.1389em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">▽</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.1389em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.9805em;vertical-align:-0.2861em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">▽</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.1389em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="mclose">)</span><span class="mord"><span class="mord">▽</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">▽</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.1389em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.9805em;vertical-align:-0.2861em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">▽</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.1389em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="mclose">)</span><span class="mord"><span class="mord">▽</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.313em;"></span><span class="minner">⋯</span></span></span></span></span></p>
<p>使用指数加权平均之后的梯度代替原梯度进行参数更新，每个指数加权平均后的梯度都含有之前所有梯度的信息。</p>
<p>在训练开始的时候，参数会与最终的最优值点距离较远，因此需要使用较大的学习率。而经过几轮的训练后，则需要减小学习率。有些算法是优化了学习率等参数的变化，如一系列自适应算法Adadelta、RMSProp和Adam。</p>
<hr>
<h2 id="2-优化器">2.  优化器</h2>
<p>Pytorch中的optim模块，提供了多种可直接使用的优化算法。</p>
<table>
<thead>
<tr>
<th style="text-align:center">API</th>
<th style="text-align:center">FUC</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">torch.optim.Adadelta()</td>
<td style="text-align:center">Adadelta算法</td>
</tr>
<tr>
<td style="text-align:center">torch.optim.Adagrad()</td>
<td style="text-align:center">-</td>
</tr>
<tr>
<td style="text-align:center">torch.optim.Adam()</td>
<td style="text-align:center">-</td>
</tr>
<tr>
<td style="text-align:center">torch.optim.Adamax()</td>
<td style="text-align:center">-</td>
</tr>
<tr>
<td style="text-align:center">torch.optim.ASGD()</td>
<td style="text-align:center">-</td>
</tr>
<tr>
<td style="text-align:center">torch.optim.LBFGS()</td>
<td style="text-align:center">-</td>
</tr>
<tr>
<td style="text-align:center">torch.optim.RMSprop()</td>
<td style="text-align:center">-</td>
</tr>
<tr>
<td style="text-align:center">torch.optim.SGD()</td>
<td style="text-align:center">-</td>
</tr>
<tr>
<td style="text-align:center">torch.optim.Rprop()</td>
<td style="text-align:center">-</td>
</tr>
</tbody>
</table>
<p>以Adam类为例，其参数的使用情况如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">torch.optim.Adam(</span><br><span class="line">    params, <span class="comment"># 需要优化的参数迭代器，通常为module.parameters()</span></span><br><span class="line">    lr=<span class="number">0.001</span>, <span class="comment"># 算法学习率</span></span><br><span class="line">    betas=(<span class="number">0.9</span>,<span class="number">0.999</span>), <span class="comment"># 计算梯度及梯度平方的运行平均值系数</span></span><br><span class="line">    eps=<span class="number">1e-08</span>, <span class="comment"># 为了增加数值计算的稳定性而加到分母里的项</span></span><br><span class="line">    weight_decay=<span class="number">0</span> <span class="comment"># 权重衰减(L2惩罚)</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p><strong>案例</strong></p>
<p>下面构建一个简单的测试网络，用于演示优化器。</p>
<ul>
<li>
<p>咱先搞一个测试网络</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">TestNet</span>(nn.Module):</span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 继承下module类</span></span><br><span class="line">        <span class="built_in">super</span>(TestNet,self).__init__()</span><br><span class="line">        <span class="comment"># 定义一下隐藏层</span></span><br><span class="line">        self.hidden=nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">13</span>,<span class="number">10</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">        )</span><br><span class="line">        <span class="comment"># 定义预测回归层</span></span><br><span class="line">        self.regression=nn.Linear(<span class="number">10</span>,<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 定义向前传播路径</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">            x=self.hidden(x)</span><br><span class="line">            output=self.regression(x)</span><br><span class="line">            <span class="keyword">return</span> output</span><br><span class="line"><span class="comment"># 创建个对象</span></span><br><span class="line">testnet=TestNet()</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>然后去定义我们的优化器</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">optimizer=Adam(testnet.parameters(),lr=<span class="number">0.001</span>)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>当然如果想要给每一层添加不同的学习率，可以指定参数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">optimizer=Adam(</span><br><span class="line">    [        &#123;<span class="string">&quot;params&quot;</span>:testnet.hidden.parameters(),<span class="string">&quot;lr&quot;</span>:<span class="number">0.001</span>&#125;,</span><br><span class="line">    &#123;<span class="string">&quot;params&quot;</span>:testnet.regression.parameters(),<span class="string">&quot;lr&quot;</span>:<span class="number">0.01</span>&#125;,</span><br><span class="line">    ],</span><br><span class="line">    lr=<span class="number">1e-2</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>有了优化器后，需要对参数进行更新，一般的步骤是梯度清空、反向传播。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> <span class="built_in">input</span>, target <span class="keyword">in</span> dataset:</span><br><span class="line">	<span class="comment"># 每次都需要进行梯度清零</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    <span class="comment"># 计算预测值</span></span><br><span class="line">    output=testnetst(<span class="built_in">input</span>)</span><br><span class="line">    <span class="comment"># 计算损失</span></span><br><span class="line">    loss=loss_fn(output,target)</span><br><span class="line">    <span class="comment"># 反向传播</span></span><br><span class="line">    loss.backward()</span><br><span class="line">    <span class="comment"># 更新参数</span></span><br><span class="line">    optimizer.step()</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>针对学习率的调整，可以使用torch.optim.lr_scheduler模块下的调整方式，不同的epoch可以设置大小不同的学习率。</p>
<ul>
<li>
<p><code>lr_scheduler.LambdaLR(optimize,lr_lambda,last_epoch=-1)</code>last_epoch表示合适开始调整学习率，-1表示设置为初始值，可以直接调整</p>
</li>
<li>
<p><code>lr_scheduler.StepLR(optimizer,step_size,gamma=0.1,last_epoch=-1)</code>等间隔调整学习率，学习率每经过step_size指定的时间间隔调整为原来的gamma倍(间隔指的一般是epoch的间隔)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 一般在此时定义学习率调整方法</span></span><br><span class="line"><span class="comment"># 将优化器封装进去</span></span><br><span class="line">scheduler=...</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">	train(...)</span><br><span class="line">	validate(...)</span><br><span class="line">	<span class="comment"># 更新学习率</span></span><br><span class="line">	scheduler.step(...)</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<hr>
<h2 id="3-损失函数">3.  损失函数</h2>
<p>损失函数是优化对象，PyTorch提供了部分API</p>
<table>
<thead>
<tr>
<th style="text-align:center">类</th>
<th style="text-align:center">算法</th>
<th style="text-align:center">适用问题</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">nn.L1Loss()</td>
<td style="text-align:center">平均绝对值误差</td>
<td style="text-align:center">回归</td>
</tr>
<tr>
<td style="text-align:center">nn.MSELoss()</td>
<td style="text-align:center">均方误差</td>
<td style="text-align:center">回归</td>
</tr>
<tr>
<td style="text-align:center">nn.CrossEntropyLoss()</td>
<td style="text-align:center">交叉熵</td>
<td style="text-align:center">多分类</td>
</tr>
<tr>
<td style="text-align:center">nn.NLLLoss()</td>
<td style="text-align:center">负对数似然函数</td>
<td style="text-align:center">多分类</td>
</tr>
<tr>
<td style="text-align:center">nn.NLLLoss2d()</td>
<td style="text-align:center">图片负对数似然函数</td>
<td style="text-align:center">图像分割</td>
</tr>
<tr>
<td style="text-align:center">nn.KLDivLoss()</td>
<td style="text-align:center">KL散度</td>
<td style="text-align:center">回归</td>
</tr>
<tr>
<td style="text-align:center">nn.BCELoss()</td>
<td style="text-align:center">二分类交叉熵</td>
<td style="text-align:center">二分类</td>
</tr>
<tr>
<td style="text-align:center">nn.MarginRankingLoss()</td>
<td style="text-align:center">评价相似度</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">nn.MultiLabelMarginLoss()</td>
<td style="text-align:center">多标签分类</td>
<td style="text-align:center">多标签分类</td>
</tr>
<tr>
<td style="text-align:center">nn.SmoothL1Loss()</td>
<td style="text-align:center">平滑L1</td>
<td style="text-align:center">回归</td>
</tr>
<tr>
<td style="text-align:center">nn.SoftMarginLoss()</td>
<td style="text-align:center">多标签二分类</td>
<td style="text-align:center">多标签分类</td>
</tr>
</tbody>
</table>
<hr>
<h2 id="4-过拟合">4.  过拟合</h2>
<p>在统计学上，过拟合是指过于精确匹配特定数据集，导致模型不能良好拟合其他数据或预测未来观测结果的现象。</p>
<h3 id="4-1-过拟合的概念">4.1  过拟合的概念</h3>
<p>深度学习模型的过拟合通常是指针对设计好的深度学习网络，在使用训练数据集训练时，在训练数据集上能够获得很高的识别精度，或者很低的均方根误差，但该模型对测试集的测试结果反而不尽人意。</p>
<p>由于深度学习存在大量参数，使得其在各领域的表现优异，但也会导致其更容易过拟合。</p>
<hr>
<h3 id="4-2-防止过拟合的方法">4.2 防止过拟合的方法</h3>
<ul>
<li>增加数据量</li>
<li>合理的数据切分</li>
<li>正则化方法
<ul>
<li>在损失函数上添加对训练参数的惩罚范数，通过惩罚范数对咬训练的参数进行约束，防止模型过拟合。<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mn>1</mn></mrow><annotation encoding="application/x-tex">L1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">L</span><span class="mord">1</span></span></span></span>范数目的是让参数的绝对值最小，趋向于使用更少的参数，而<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mn>2</mn></mrow><annotation encoding="application/x-tex">L2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">L</span><span class="mord">2</span></span></span></span>范数目的是将参数的平方和最小化，会趋向于使用更多的小参数。</li>
</ul>
</li>
<li>Dropout
<ul>
<li>引入Dropout层，每个训练批次中，通过忽略一定百分比神经元数量，来减少网络的过拟合现象。即：在网络向前传播时，让某一神经元依照概率<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">p</span></span></span></span>停止工作。这样能够得到泛化能力更强的网络，鲁棒性也更好，但是有可能过度依赖某些局部特征。</li>
</ul>
</li>
<li>提前结束训练</li>
</ul>
<hr>
<h2 id="5-参数初始化">5.  参数初始化</h2>
<p>使用初始化方法能够获得更加稳定的结果。</p>
<table>
<thead>
<tr>
<th style="text-align:center">API</th>
<th style="text-align:center">FUC</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">nn.init.uniform_(tensor,a=0.0,b=1.0)</td>
<td style="text-align:center">从均匀分布U(a,b)中生成值</td>
</tr>
<tr>
<td style="text-align:center">nn.init.normal_(tensor,mean=0.0,std=1.0)</td>
<td style="text-align:center">从给定均值mean和标准差std的正态分布中填充值</td>
</tr>
<tr>
<td style="text-align:center">nn.init.constant_(tensor,val)</td>
<td style="text-align:center">使用预设的常量来填充</td>
</tr>
<tr>
<td style="text-align:center">nn.init.eye_(tensor)</td>
<td style="text-align:center">用单位矩阵来填充</td>
</tr>
<tr>
<td style="text-align:center">nn.init.dirac_(tensor)</td>
<td style="text-align:center">使用Dirac delat函数填充</td>
</tr>
<tr>
<td style="text-align:center">nn.init.xavier_uniform_(tensor,gain=1.0)</td>
<td style="text-align:center">使用Glorot initialization均匀分布生成</td>
</tr>
<tr>
<td style="text-align:center">nn.init.xavier_normal_(tensor,gain=1.0)</td>
<td style="text-align:center">使用Glorot initialization正态分布生成</td>
</tr>
</tbody>
</table>
<p><strong>案例</strong></p>
<p><strong>针对某一层权重进行初始化</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义一个卷积层</span></span><br><span class="line">conv1=nn.Conv2d(<span class="number">3</span>,<span class="number">16</span>,<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用标准正态分布初始化权重</span></span><br><span class="line"><span class="comment"># 随机数种子，能够让结果复现</span></span><br><span class="line">torch.manual_seed(<span class="number">123</span>)</span><br><span class="line">torch.nn.init.normal(conv1.weight,mean=<span class="number">0</span>,std=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用直方图可视化其权重</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>,<span class="number">6</span>))</span><br><span class="line">plt.hist(conv1.weight.data.numpy().reshape((-<span class="number">1</span>,<span class="number">1</span>)),bins=<span class="number">30</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<img src="/2022/07/28/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E7%AC%AC%E4%B8%89%E7%AB%A0%20%20DNN%20%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20220728200100447.png" alt="image-20220728200100447" style="zoom:50%;">
<p>上述方法定义了其权重，我们也能对其偏置进行初始化。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nn.init.constant(conv1.bias,val=<span class="number">0.1</span>)</span><br></pre></td></tr></table></figure>
<p><strong>针对整个网络的权重初始化方法</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 建立一个测试网络</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TestNet</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(TestNet,self).__init__()</span><br><span class="line">        <span class="comment"># 卷积层</span></span><br><span class="line">        self.conv1=nn.Conv2d(<span class="number">3</span>,<span class="number">16</span>,<span class="number">3</span>)</span><br><span class="line">        <span class="comment"># 隐藏层</span></span><br><span class="line">        self.hidden=nn.Sequential(</span><br><span class="line">            <span class="comment"># 说起来，线性层的io是特征个数</span></span><br><span class="line">            <span class="comment"># 而卷积层的io是通道数</span></span><br><span class="line">            nn.Linear(<span class="number">100</span>,<span class="number">100</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">100</span>,<span class="number">50</span>),</span><br><span class="line">            nn.Softplus()</span><br><span class="line">        )</span><br><span class="line">        <span class="comment"># 线性预测层</span></span><br><span class="line">        self.cla=nn.Linear(<span class="number">50</span>,<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义向前传播</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        <span class="comment"># 先过一次卷积</span></span><br><span class="line">        x=self.conv1(x)</span><br><span class="line">        <span class="comment"># 现在要过线性层，叠加压缩</span></span><br><span class="line">        x=x.view(x.shape[<span class="number">0</span>],-<span class="number">1</span>)</span><br><span class="line">        x=self.hidden(x)</span><br><span class="line">        <span class="keyword">return</span> self.cla(x)</span><br><span class="line"></span><br><span class="line">testNet=TestNet()</span><br></pre></td></tr></table></figure>
<p>模型的结构以如下方式存储：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">TestNet(</span><br><span class="line">  (conv1): Conv2d(<span class="number">3</span>, <span class="number">16</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (hidden): Sequential(</span><br><span class="line">    (<span class="number">0</span>): Linear(in_features=<span class="number">100</span>, out_features=<span class="number">100</span>, bias=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">1</span>): ReLU()</span><br><span class="line">    (<span class="number">2</span>): Linear(in_features=<span class="number">100</span>, out_features=<span class="number">50</span>, bias=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">3</span>): Softplus(beta=<span class="number">1</span>, threshold=<span class="number">20</span>)</span><br><span class="line">  )</span><br><span class="line">  (cla): Linear(in_features=<span class="number">50</span>, out_features=<span class="number">10</span>, bias=<span class="literal">True</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>我们可以通过自定义函数的方式，对网络的权重进行初始化。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">init_weight</span>(<span class="params">m</span>):</span><br><span class="line">    <span class="comment"># 我们对每一层的参数进行初始化</span></span><br><span class="line">    <span class="comment"># 判断类型</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(m,nn.Conv2d):</span><br><span class="line">        <span class="comment"># 卷积层的话用标准正态分布</span></span><br><span class="line">        nn.init.normal(m.weight,mean=<span class="number">0.0</span>,std=<span class="number">0.5</span>)</span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m,nn.Linear):</span><br><span class="line">        <span class="comment"># 全连接层</span></span><br><span class="line">        nn.init.uniform(m.weight,a=-<span class="number">0.1</span>,b=<span class="number">0.1</span>)</span><br><span class="line">        <span class="comment"># 将偏置设定为0.01</span></span><br><span class="line">        m.bias.data.fill_(<span class="number">0.01</span>)</span><br></pre></td></tr></table></figure>
<p>最后通过apply方法运用</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 然后module自带一个apply接口，我们通过这个接口就能将定义的初始化方法逐层运用</span></span><br><span class="line">torch.manual_seed(<span class="number">12</span>)</span><br><span class="line">testNet.apply(init_weight)</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="6-自定义网络">6.  自定义网络</h2>
<p>本章以案例的形式进行。</p>
<p>我们创建一个简单的全连接神经网络。</p>
<p><strong>模块导入</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> SGD</span><br><span class="line"><span class="keyword">import</span> torch.utils.data <span class="keyword">as</span> Data</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure>
<p><strong>数据加载</strong></p>
<p>我们以sk自带的波士顿房价信息数据作为数据源</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 波士顿房价信息</span></span><br><span class="line"><span class="comment"># 我们可以看看这是个啥</span></span><br><span class="line">boston_x,boston_y=load_boston(return_X_y=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;X&quot;</span>,boston_x.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Y&quot;</span>,boston_y.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># X (506, 13)</span></span><br><span class="line"><span class="comment"># Y (506,)</span></span><br></pre></td></tr></table></figure>
<p>房价信息分布情况如下:</p>
<img src="/2022/07/28/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E7%AC%AC%E4%B8%89%E7%AB%A0%20%20DNN%20%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20220728200108707.png" alt="image-20220728200108707" style="zoom:50%;">
<p>我们先给数据做一个标准化，然后通过转化成Tensor读入数据加载器中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 接着做一个标准化</span></span><br><span class="line">tem=StandardScaler(with_mean=<span class="literal">True</span>,with_std=<span class="literal">True</span>)</span><br><span class="line">boston_xs=StandardScaler(boston_x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据标准化的目的是为了消除量纲的影响，适应权重</span></span><br><span class="line"><span class="comment"># 接着需要将数据转化为Tensor</span></span><br><span class="line">train_xt=torch.from_numpy(boston_xs.astype(np.float32))</span><br><span class="line">train_yt=torch.from_numpy(boston_y.astype(np.float32))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 然后呢，通过torch.utils.data进行张量数据预处理</span></span><br><span class="line"><span class="comment"># 首先是数据整合</span></span><br><span class="line">train_data=Data.TensorDataset(train_xt,train_yt)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 接着咱定义一个DataLoader，方便批处理</span></span><br><span class="line">train_loader=Data.DataLoader(</span><br><span class="line">    dataset=train_data,</span><br><span class="line">    batch_size=<span class="number">32</span>,</span><br><span class="line">    shuffle=<span class="literal">True</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p><strong>多层感知机与模型训练</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 来一个多层感知机</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MLPmodel</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(MLPmodel,self).__init__()</span><br><span class="line">        self.hidden=nn.Linear(<span class="number">13</span>,<span class="number">10</span>,<span class="literal">True</span>)</span><br><span class="line">        self.activel=nn.ReLU()</span><br><span class="line">        self.hidden2=nn.Linear(<span class="number">10</span>,<span class="number">10</span>)</span><br><span class="line">        self.active2=nn.Softplus()</span><br><span class="line">        self.regression=nn.Linear(<span class="number">10</span>,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        x=self.hidden(x)</span><br><span class="line">        x=self.activel(x)</span><br><span class="line">        x=self.hidden2(x)</span><br><span class="line">        x=self.active2(x)</span><br><span class="line">        <span class="keyword">return</span> self.regression(x)</span><br><span class="line"></span><br><span class="line">mlp=MLPmodel()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 接着我们需要定义优化器</span></span><br><span class="line">optimizer=SGD(mlp.parameters(),lr=<span class="number">0.01</span>)</span><br><span class="line"><span class="comment"># 定义损失函数</span></span><br><span class="line">loss_fn=nn.MSELoss()</span><br><span class="line">loss_list=[]</span><br><span class="line"><span class="comment"># 进行训练</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">50</span>):</span><br><span class="line">    <span class="keyword">for</span> step,(x,y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">        <span class="comment"># 批处理，每一批拿出32个数据</span></span><br><span class="line">        output=mlp(x).flatten() <span class="comment"># 这里是调用forward方法，得到batch的预测结果</span></span><br><span class="line">        train_loss=loss_fn(output,y) <span class="comment"># 均方根误差</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 更新梯度下降</span></span><br><span class="line">        optimizer.zero_grad() <span class="comment"># 得先清个零，不然梯度会累加</span></span><br><span class="line">        train_loss.backward() <span class="comment"># 对损失函数反向传播</span></span><br><span class="line">        optimizer.step() <span class="comment"># 更新梯度</span></span><br><span class="line">        loss_list.append(train_loss.item())</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>,<span class="number">6</span>))</span><br><span class="line">plt.plot(loss_list,<span class="string">&#x27;r-&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>损失函数最终收敛且效果还不错</p>
<img src="/2022/07/28/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E7%AC%AC%E4%B8%89%E7%AB%A0%20%20DNN%20%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20220728200115413.png" alt="image-20220728200115413" style="zoom:50%;">
<p>或者我们在定义模型的时候，可以采用层级容器<code>nn.Sequential</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MLPmodel</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(MLPmodel,self).__init__()</span><br><span class="line">        self.hidden=nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">13</span>,<span class="number">10</span>,<span class="literal">True</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">10</span>,<span class="number">10</span>),</span><br><span class="line">            nn.Softplus()</span><br><span class="line">        )</span><br><span class="line">        self.regression=nn.Linear(<span class="number">10</span>,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        <span class="keyword">return</span> self.regression(self.hidden(x))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<hr>
<h2 id="7-模型加载与保存">7.  模型加载与保存</h2>
<p>一般有两种方式保存模型</p>
<p>方法一是整个模型一起保存了</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 模型的保存</span></span><br><span class="line">torch.save(mlp,<span class="string">r&quot;D:\mlp.pkl&quot;</span>)</span><br><span class="line"><span class="comment"># 我们可以载入模型</span></span><br><span class="line">N_MLP=torch.load(<span class="string">r&quot;D:\mlp.pkl&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 看看最后的效果</span></span><br><span class="line"><span class="built_in">print</span>(N_MLP)</span><br></pre></td></tr></table></figure>
<p>结果如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">MLPmodel(</span></span><br><span class="line"><span class="string">  (hidden): Sequential(</span></span><br><span class="line"><span class="string">    (0): Linear(in_features=13, out_features=10, bias=True)</span></span><br><span class="line"><span class="string">    (1): ReLU()</span></span><br><span class="line"><span class="string">    (2): Linear(in_features=10, out_features=10, bias=True)</span></span><br><span class="line"><span class="string">    (3): Softplus(beta=1, threshold=20)</span></span><br><span class="line"><span class="string">  )</span></span><br><span class="line"><span class="string">  (regression): Linear(in_features=10, out_features=1, bias=True)</span></span><br><span class="line"><span class="string">)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>方法二则是存储模型的参数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 或者只保存模型的参数</span></span><br><span class="line">torch.save(mlp.state_dict(),<span class="string">r&quot;D:\mlp_parameters.pkl&quot;</span>)</span><br><span class="line">N_PA=torch.load(<span class="string">r&quot;D:\mlp_parameters.pkl&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(N_PA)</span><br><span class="line">mlp.parameters=N_PA</span><br></pre></td></tr></table></figure>
<p>结果如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">OrderedDict([(&#x27;hidden.0.weight&#x27;, tensor([[-0.1682, -0.1582,  0.1312, -0.3572, -0.3382, -0.9072,  0.0774,  0.2961,</span></span><br><span class="line"><span class="string">          0.2461,  0.2169,  0.4627,  0.1251, -0.3596],</span></span><br><span class="line"><span class="string">        [ 0.4775, -0.9221, -0.0299, -1.2689,  0.2501, -0.5053,  0.1822, -0.3906,</span></span><br><span class="line"><span class="string">          0.6780,  0.2467,  1.0531, -0.2952,  0.8564],</span></span><br><span class="line"><span class="string">        [-0.0895, -0.0592, -0.1250,  0.2151,  0.3281, -0.5135, -0.0162,  0.0673,</span></span><br><span class="line"><span class="string">         -0.0072,  0.0629, -0.3387, -0.2451,  0.5141],</span></span><br><span class="line"><span class="string">        [-0.5001, -0.1233,  0.0952, -0.3362, -0.3671, -0.7980, -0.0222,  0.2918,</span></span><br><span class="line"><span class="string">         -0.4627, -0.2075,  0.3375,  0.0857, -0.2409],</span></span><br><span class="line"><span class="string">        [-0.1358, -0.0618, -0.3784, -0.2013, -0.0251, -0.4589,  0.1205,  0.3719,</span></span><br><span class="line"><span class="string">         -0.2736,  0.2368,  0.1762,  0.1612, -0.0624],</span></span><br><span class="line"><span class="string">        [ 0.1940, -0.0896, -0.0613, -0.1808,  0.0264,  0.0394,  0.1249,  0.1263,</span></span><br><span class="line"><span class="string">          0.0100, -0.1044,  0.2247, -0.2154, -0.1233],</span></span><br><span class="line"><span class="string">        [-0.5380, -0.3994, -0.1833, -0.6604,  0.0714, -0.7688,  0.3499, -0.1702,</span></span><br><span class="line"><span class="string">          0.5361, -0.0058,  0.7915,  0.1717, -0.4402],</span></span><br><span class="line"><span class="string">        [-0.2098, -0.4535, -0.0479, -0.5998,  0.1112, -0.5911,  0.0431, -0.0999,</span></span><br><span class="line"><span class="string">          0.3863,  0.1855,  0.5273, -0.2039, -0.4222],</span></span><br><span class="line"><span class="string">        [ 0.1951, -0.0404, -0.1607,  0.0127, -0.3299, -0.2891, -0.1950,  0.0701,</span></span><br><span class="line"><span class="string">         -0.0849,  0.1689,  0.1037, -0.0746,  0.0188],</span></span><br><span class="line"><span class="string">        [-0.4732, -0.4200,  0.1540,  0.1451,  0.2494, -0.8197,  0.3682,  0.1772,</span></span><br><span class="line"><span class="string">         -0.8664,  0.2181, -0.0903,  0.1827,  0.4916]])), (&#x27;hidden.0.bias&#x27;, tensor([-0.3963, -2.1458, -0.2775,  0.6463, -0.0655, -0.3270, -0.2103, -0.5783,</span></span><br><span class="line"><span class="string">        -0.2289,  0.8186])), (&#x27;hidden.2.weight&#x27;, tensor([[-0.3831, -0.4322,  0.0813, -0.2163,  0.0978,  0.1741, -0.5562, -0.3374,</span></span><br><span class="line"><span class="string">          0.2419, -0.2607],</span></span><br><span class="line"><span class="string">        [-0.1779, -1.1630,  0.0807, -0.4886, -0.1338, -0.1174, -0.3692, -0.2244,</span></span><br><span class="line"><span class="string">         -0.1358, -0.4588],</span></span><br><span class="line"><span class="string">        [-0.4465, -0.6129,  0.0062, -0.2336, -0.0784, -0.0142, -0.5327, -0.2607,</span></span><br><span class="line"><span class="string">          0.1711, -0.0604],</span></span><br><span class="line"><span class="string">        [ 0.5467, -0.1358, -0.2299,  0.1825, -0.1145,  0.0242,  0.5876,  0.6566,</span></span><br><span class="line"><span class="string">         -0.2516, -0.2423],</span></span><br><span class="line"><span class="string">        [-0.2812, -1.0388, -0.3839, -0.4795,  0.0591,  0.1484, -0.6015, -0.5771,</span></span><br><span class="line"><span class="string">         -0.2436, -0.7602],</span></span><br><span class="line"><span class="string">        [-0.2085, -1.2226, -0.4565, -0.3518, -0.1664, -0.2956, -0.3706, -0.0673,</span></span><br><span class="line"><span class="string">         -0.1313, -0.4169],</span></span><br><span class="line"><span class="string">        [-0.2528, -1.0902, -0.1404,  0.1635, -0.1880, -0.2121, -0.3874, -0.0765,</span></span><br><span class="line"><span class="string">          0.1254,  0.0216],</span></span><br><span class="line"><span class="string">        [-0.2530, -1.2780, -0.1043, -0.4072, -0.1811, -0.0711, -0.1489, -0.4098,</span></span><br><span class="line"><span class="string">          0.1178, -0.4283],</span></span><br><span class="line"><span class="string">        [-0.3297, -1.0258, -0.2573, -0.5826,  0.0516,  0.1250, -0.0474, -0.4518,</span></span><br><span class="line"><span class="string">          0.0899, -0.2287],</span></span><br><span class="line"><span class="string">        [-0.2147, -0.5633, -0.4821, -0.4490, -0.3171, -0.2347, -0.0139, -0.0884,</span></span><br><span class="line"><span class="string">         -0.2636, -0.4779]])), (&#x27;hidden.2.bias&#x27;, tensor([1.0290, 0.8320, 0.7612, 2.1910, 1.4279, 1.0426, 0.9651, 1.1743, 1.0405,</span></span><br><span class="line"><span class="string">        2.1511])), (&#x27;regression.weight&#x27;, tensor([[1.8570, 1.4353, 1.7404, 2.6612, 2.2527, 1.5736, 1.8867, 1.7221, 1.9856,</span></span><br><span class="line"><span class="string">         2.7336]])), (&#x27;regression.bias&#x27;, tensor([4.4975]))])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 不想学辣 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[第二章  PyTorch入门]]></title>
      <url>/2022/07/28/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E7%AC%AC%E4%BA%8C%E7%AB%A0%20%20PyTorch%E5%85%A5%E9%97%A8/</url>
      <content type="html"><![CDATA[<h1>第二章  PyTorch入门</h1>
<h2 id="1-张量">1.  张量</h2>
<hr>
<h3 id="1-1-张量">1.1  张量</h3>
<p>张量的概念其实就是高维数组</p>
<ul>
<li>标量</li>
<li>向量</li>
<li>矩阵</li>
<li>张量</li>
</ul>
<p>张量的<strong>数据类型</strong></p>
<table>
<thead>
<tr>
<th style="text-align:center">数据类型</th>
<th style="text-align:center">dtype</th>
<th style="text-align:center">CPU tensor</th>
<th style="text-align:center">GPU tensor</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">32位浮点型</td>
<td style="text-align:center">torch.float</td>
<td style="text-align:center">torch.FloatTensor</td>
<td style="text-align:center">torch.cuda.FloatTensor</td>
</tr>
<tr>
<td style="text-align:center">64位浮点型</td>
<td style="text-align:center">torch.double</td>
<td style="text-align:center">torch.DoubleTensor</td>
<td style="text-align:center">torch.cuda.DoubleTensor</td>
</tr>
<tr>
<td style="text-align:center">16位浮点型</td>
<td style="text-align:center">torch.half</td>
<td style="text-align:center">torch.HalfTensor</td>
<td style="text-align:center">torch.cuda.HalfTensor</td>
</tr>
<tr>
<td style="text-align:center">8位无符号整型</td>
<td style="text-align:center">torch.uint8</td>
<td style="text-align:center">torch.ByteTensor</td>
<td style="text-align:center">torch.cuda.ByteTensor</td>
</tr>
<tr>
<td style="text-align:center">8位有符号整型</td>
<td style="text-align:center">torch.int8</td>
<td style="text-align:center">torch.CharTensor</td>
<td style="text-align:center">torch.cuda.CharTensor</td>
</tr>
<tr>
<td style="text-align:center">16位有符号整型</td>
<td style="text-align:center">torch.short</td>
<td style="text-align:center">torch.ShortTensor</td>
<td style="text-align:center">torch.cuda.ShortTensor</td>
</tr>
<tr>
<td style="text-align:center">32位有符号整型</td>
<td style="text-align:center">torch.int</td>
<td style="text-align:center">torch.IntTensor</td>
<td style="text-align:center">torch.cuda.IntTensor</td>
</tr>
<tr>
<td style="text-align:center">64位有符号整型</td>
<td style="text-align:center">torch.long</td>
<td style="text-align:center">torch.LongTensor</td>
<td style="text-align:center">torch.cuda.LongTensor</td>
</tr>
</tbody>
</table>
<p>常见的<strong>数据类型操作</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># torch中默认的数据类型是float32</span></span><br><span class="line"><span class="comment"># 我们可以通过Tensor的dtype方法查看</span></span><br><span class="line">a=torch.Tensor(<span class="number">3</span>,<span class="number">2</span>)</span><br><span class="line">a.dtype</span><br><span class="line"></span><br><span class="line"><span class="comment"># 我们可以改变初始的数据类型</span></span><br><span class="line">torch.set_default_tensor_type(torch.DoubleTensor)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 若是不想修改源数据而转换类型</span></span><br><span class="line"><span class="comment"># 可以调用long\float\double\int\short等方法进行转变</span></span><br><span class="line">new=a.long()</span><br><span class="line">new.dtype</span><br><span class="line"></span><br><span class="line"><span class="comment"># 判断一个张量的数据类型</span></span><br><span class="line"><span class="built_in">isinstance</span>(a,torch.FloatTensor)</span><br><span class="line"><span class="comment"># True</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># GPU</span></span><br><span class="line"><span class="built_in">isinstance</span>(data,torch.cuda.DoubleTensor)</span><br></pre></td></tr></table></figure>
<p>常见的张量<strong>生成方式</strong></p>
<ul>
<li>
<p>使用**torch.tensor()**生成</p>
<p>Python中的列表和序列可以通过<code>torch.tensor()</code>转化成张量，并且能够通过<code>shape</code>属性查看维度，<code>size()</code>方法计算形状，<code>numel()</code>方法计算元素个数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 注意只有浮点型的能计算梯度</span></span><br><span class="line">b=torch.tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],dtype=torch.DoubleTensor,requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">b.dim()</span><br><span class="line">b.shape</span><br><span class="line">b.size()</span><br><span class="line">b.numel()</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>使用**torch.Tensor()**生成</p>
<p>与torch.tensor()方法不同在于，前者只能接收现有数据，而后者能够接收维度形态。如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">b=torch.Tensor(<span class="number">2</span>,<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>使用**Like()**方法生成</p>
<p>该方法能够生成维度与传入张量相同的新张量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 例如</span></span><br><span class="line">c=torch.Tensor(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 全一</span></span><br><span class="line">torch.ones_like(c)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 全零</span></span><br><span class="line">torch.zeros_like(c)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机</span></span><br><span class="line">torch.rand_like(c)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>使用**new()**方法生成</p>
<p>该方法生成的张量将复制原始张量的数据类型，但维度可以不同</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># D.dtype --&gt; torch.DoubleTensor</span></span><br><span class="line"></span><br><span class="line">e=[[<span class="number">2</span>,<span class="number">1</span>],[<span class="number">7</span>,<span class="number">8</span>]]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 注意new方法是从需要copy类型的张量上出发</span></span><br><span class="line"><span class="comment"># 而like则是从torch本身上出发</span></span><br><span class="line">e=D.new_tensor(e)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 做一个全1填充</span></span><br><span class="line">D.new_full(e,fill_value=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">D.new_zeros(e)</span><br><span class="line"></span><br><span class="line">D.new_empty(e)</span><br><span class="line"></span><br><span class="line">D.new_ones(e)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>张量和<strong>Numpy</strong>的互相转换</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">F=np.ones((<span class="number">3</span>,<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 方法一</span></span><br><span class="line">torch.as_tensor(F)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 方法二</span></span><br><span class="line">torch.from_numpy()</span><br><span class="line"></span><br><span class="line"><span class="comment"># tensor转numpy</span></span><br><span class="line">new=F.numpy()</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>通过<strong>随机数</strong>生成</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置随机数种子</span></span><br><span class="line"><span class="comment"># 该种子能够保证生成的随机数是可以重复出现的</span></span><br><span class="line">torch.manual_seed(<span class="number">123</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成一个正态分布的随机数</span></span><br><span class="line">torch.normal(mean=<span class="number">0.0</span>,std=torch.tensor(<span class="number">1.0</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定mean和std的数量的话，就会生成许多个随机数</span></span><br><span class="line">torch.normal(mean=torch.arange(<span class="number">1</span>,<span class="number">5.0</span>),std=torch.arange(<span class="number">1</span>,<span class="number">5.0</span>))</span><br><span class="line"><span class="comment"># 这样就能得到四个随机数</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成零一区间随机数</span></span><br><span class="line">torch.rand(<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成标准正态分布</span></span><br><span class="line">torch.randn(<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">torch.rand_like(<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机打散</span></span><br><span class="line">torch.randperm(n)</span><br><span class="line"><span class="comment"># 会将0~n-1个数随机打散排列</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p>其他生成张量的函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 范围生成张量</span></span><br><span class="line">torch.arange(start=<span class="number">0</span>,end=<span class="number">10</span>,step=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 等间隔张量</span></span><br><span class="line">torch.linspace(start=<span class="number">1</span>,end=<span class="number">10</span>,step=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对数间隔张量</span></span><br><span class="line">torch.logspace(start=<span class="number">0.1</span>,end=<span class="number">1.0</span>,steps=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 其他预定义的</span></span><br><span class="line">torch.zeros()</span><br><span class="line">torch.ones()</span><br><span class="line">torch.eyes()</span><br><span class="line">torch.full(,value)</span><br><span class="line">torch.empty()</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="1-2-张量操作">1.2  张量操作</h3>
<h4 id="1-2-1-改变张量形状">1.2.1 改变张量形状</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># reshape方法能够设置张量形状大小</span></span><br><span class="line">torch.arange(<span class="number">12.0</span>).reshape(<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line"><span class="comment"># 而在这里采用负数的形式，则会默认前面进行填充</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># torch的reshape方法</span></span><br><span class="line">torch.reshape(<span class="built_in">input</span>=A,shape=(<span class="number">2</span>,-<span class="number">1</span>))</span><br><span class="line"><span class="comment"># 或是直接在原始数据上修改</span></span><br><span class="line">A.resize_(<span class="number">2</span>,<span class="number">6</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># view方法</span></span><br><span class="line"><span class="comment"># view与reshape完全一致</span></span><br><span class="line">A.view(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 同样，提供了便捷的_as方法</span></span><br><span class="line">A.resize_as_(B)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 插入维度</span></span><br><span class="line"><span class="comment"># 通过unsqueeze()函数可以在指定方向插入新的维度</span></span><br><span class="line">torch.unsqueeze(A,dim=<span class="number">0</span>) <span class="comment"># 在0维度插入，前面的维度不变，后面的往后推</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 压缩维度</span></span><br><span class="line"><span class="comment"># 压缩维度只能压缩数据量为1的维度</span></span><br><span class="line">torch.squeeze(dim=n)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 扩展维度</span></span><br><span class="line">torch.expand(<span class="number">3</span>,-<span class="number">1</span>)</span><br><span class="line">torch.expand_as(C)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 复制维</span></span><br><span class="line">D.repeat(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>) <span class="comment"># 会将张量看做一个整体</span></span><br></pre></td></tr></table></figure>
<h4 id="1-2-2-张量索引操作">1.2.2 张量索引操作</h4>
<p>tensor的切片索引非常大胆</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对一个四位数据进行操作</span></span><br><span class="line">a=torch.rand(<span class="number">4</span>,<span class="number">3</span>,<span class="number">28</span>,<span class="number">28</span>)</span><br><span class="line">a[<span class="number">0</span>].shape <span class="comment"># torch.Size([3,28,28])</span></span><br><span class="line">a[<span class="number">0</span>,<span class="number">0</span>].shape <span class="comment"># torch.Size([28,28])</span></span><br><span class="line">a[<span class="number">0</span>,<span class="number">0</span>,<span class="number">2</span>,<span class="number">4</span>] <span class="comment"># tensor(0.8082)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 可以与切片一起使用</span></span><br><span class="line">a[:<span class="number">2</span>].shape <span class="comment"># torch.Size([2,3,28,28])</span></span><br><span class="line">a[:<span class="number">2</span>,<span class="number">1</span>:,:,:].shape</span><br><span class="line">a[:<span class="number">2</span>,-<span class="number">1</span>,:,:].shape</span><br><span class="line"></span><br><span class="line"><span class="comment"># 隔点采样</span></span><br><span class="line">a[:,:,<span class="number">0</span>:<span class="number">28</span>:<span class="number">2</span>,<span class="number">0</span>:<span class="number">15</span>:<span class="number">3</span>].shape</span><br><span class="line">a[:,:,::<span class="number">2</span>,::<span class="number">2</span>].shape</span><br><span class="line"></span><br><span class="line"><span class="comment"># 具体索引方式</span></span><br><span class="line">torch.index_select(dim,[])</span><br><span class="line">torch.index_select(<span class="number">0</span>,[<span class="number">1</span>,<span class="number">2</span>]) <span class="comment"># 从第一个维度上选择1,2个数据</span></span><br><span class="line">a.index_select(<span class="number">2</span>,torch.arange(<span class="number">8</span>)).shape</span><br><span class="line"><span class="comment"># torch.Size([4,3,8,28])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 任意多的维度</span></span><br><span class="line"><span class="comment"># ...</span></span><br><span class="line">a[...].shape</span><br><span class="line">a[<span class="number">0</span>,...].shape <span class="comment"># ==a[0]</span></span><br><span class="line">a[<span class="number">0</span>:,...,::<span class="number">2</span>] <span class="comment"># 对第一个维度和最后一个维度做限定</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过掩码选取</span></span><br><span class="line">x=torch.randn(<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">mask=x.ge(<span class="number">0.5</span>) <span class="comment"># 一个零一矩阵，大于0.5时为1</span></span><br><span class="line">torch.masked_select(x,mask) <span class="comment"># 直接获取一个vectory，是mask为1的数据</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 打平选取</span></span><br><span class="line"><span class="comment"># 先将数据排成一排</span></span><br><span class="line"><span class="comment"># 然后再选取</span></span><br><span class="line">scr=torch.tensor([[<span class="number">4</span>,<span class="number">3</span>,<span class="number">5</span>],</span><br><span class="line">                  [<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>]])</span><br><span class="line">torch.take(scr,torch.tensor[[<span class="number">0</span>,<span class="number">2</span>,-<span class="number">1</span>]])</span><br><span class="line"><span class="comment"># tensor([4,5,8])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取上三角部分</span></span><br><span class="line">torch.tril(A,diagonal=<span class="number">0</span>)</span><br><span class="line"><span class="comment"># 获取下三角部分</span></span><br><span class="line">torch.triu(A,diagonal=<span class="number">0</span>)</span><br><span class="line"><span class="comment"># diagonal用于控制对角线的位置</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过对角线元素生成矩阵</span></span><br><span class="line">torch.diag(torch.tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]))</span><br></pre></td></tr></table></figure>
<h4 id="1-2-3-张量的拼接和拆分">1.2.3 张量的拼接和拆分</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">A=torch.arange(<span class="number">6.0</span>).reshape(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">B=torch.linspace(<span class="number">0</span>,<span class="number">10</span>,<span class="number">6</span>).reshape(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过torch.cat方式拼接，指定拼接维度</span></span><br><span class="line">C=torch.cat((A,B),dim=<span class="number">0</span>) <span class="comment"># 在维度0上进行拼接</span></span><br><span class="line">C.shape</span><br><span class="line"><span class="comment"># torch.Size([4,3])</span></span><br><span class="line"></span><br><span class="line">C=torch.cat((A,B),dim=<span class="number">1</span>)</span><br><span class="line">C.shape</span><br><span class="line"><span class="comment"># torch.Size([2,6])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 拼接多个</span></span><br><span class="line">torch.cat((A[:,<span class="number">1</span>:<span class="number">2</span>],A,B),dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 值得注意的是，做维度拼接必须在非拼接维上能够匹配</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># stack与cat不同的是，stack会添加新的维度，而不是合并同维度数据</span></span><br><span class="line">F=torch.stack((A,B),dim=<span class="number">0</span>)</span><br><span class="line">F.shape</span><br><span class="line"><span class="comment"># torch.Size([2,2,3])</span></span><br></pre></td></tr></table></figure>
<p><code>split</code>是按长度分割</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">a=torch.rand(<span class="number">4</span>,<span class="number">32</span>,<span class="number">8</span>)</span><br><span class="line"><span class="comment"># 将指定维度进行切割，每一份长度是第一个参数</span></span><br><span class="line"><span class="comment"># 不够的地方取余数</span></span><br><span class="line">t=a.split(<span class="number">7</span>,dim=<span class="number">1</span>)</span><br><span class="line">t[<span class="number">4</span>].shape</span><br><span class="line"><span class="comment"># torch.Size([4, 4, 8])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 也能指定长度</span></span><br><span class="line">a.split([<span class="number">15</span>,<span class="number">1</span>,<span class="number">16</span>],dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p><code>chunk</code>是等距分割，但不能指定大小</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 分成两份</span></span><br><span class="line">a.chunk(<span class="number">2</span>,dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h4 id="1-2-4-转置">1.2.4 转置</h4>
<p><code>.t</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a=torch.randn(<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line"><span class="comment"># .t只能用于二维矩阵</span></span><br><span class="line">a.t()</span><br></pre></td></tr></table></figure>
<p><code>transpose</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># transpose能交换任意两个维度</span></span><br><span class="line"><span class="comment"># 但是维度打乱后的数据不再联系</span></span><br><span class="line"><span class="comment"># 需要使用contiguous进行处理</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 注意view会丢失维度信息！</span></span><br><span class="line"><span class="comment"># 需要跟踪维度信息</span></span><br><span class="line">al=a.transpose(<span class="number">1</span>,<span class="number">3</span>).contiguous().view(<span class="number">4</span>,<span class="number">3</span>*<span class="number">32</span>*<span class="number">32</span>).view(<span class="number">4</span>,<span class="number">32</span>,<span class="number">32</span>,<span class="number">3</span>).transpose(<span class="number">1</span>,<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<p><code>permute</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># permute可以多次交换</span></span><br><span class="line"><span class="comment"># 自动调用transpose</span></span><br><span class="line"></span><br><span class="line">b.permute(<span class="number">0</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="1-3-张量计算">1.3  张量计算</h3>
<h4 id="1-3-1-大小比较">1.3.1 大小比较</h4>
<p>部分<strong>比较函数</strong>如下：</p>
<table>
<thead>
<tr>
<th style="text-align:center">函数</th>
<th style="text-align:center">功能</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">torch.allclose()</td>
<td style="text-align:center">比较两个元素是否接近</td>
</tr>
<tr>
<td style="text-align:center">torch.eq()</td>
<td style="text-align:center">比较两个元素是否相等</td>
</tr>
<tr>
<td style="text-align:center">torch.equal()</td>
<td style="text-align:center">比较两个元素是否相等且数据类型一致</td>
</tr>
<tr>
<td style="text-align:center"><a href="http://torch.ge">torch.ge</a>()</td>
<td style="text-align:center">大于等于</td>
</tr>
<tr>
<td style="text-align:center"><a href="http://torch.gt">torch.gt</a>()</td>
<td style="text-align:center">大于</td>
</tr>
<tr>
<td style="text-align:center">torch.le()</td>
<td style="text-align:center">小于等于</td>
</tr>
<tr>
<td style="text-align:center"><a href="http://torch.lt">torch.lt</a>()</td>
<td style="text-align:center">小于</td>
</tr>
<tr>
<td style="text-align:center"><a href="http://torch.ne">torch.ne</a>()</td>
<td style="text-align:center">不等于</td>
</tr>
<tr>
<td style="text-align:center">torch.isnan()</td>
<td style="text-align:center">是否为空</td>
</tr>
</tbody>
</table>
<p>allclose()函数非常有意思，其公式表示为：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="normal">∣</mi><mi>A</mi><mo>−</mo><mi>B</mi><mi mathvariant="normal">∣</mi><mo>≤</mo><mi>a</mi><mi>t</mi><mi>o</mi><mi>l</mi><mo>+</mo><mi>r</mi><mi>t</mi><mi>o</mi><mi>l</mi><mo>×</mo><mi mathvariant="normal">∣</mi><mi>B</mi><mi mathvariant="normal">∣</mi></mrow><annotation encoding="application/x-tex">|A-B|\le atol+rtol\times|B|
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∣</span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mord">∣</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">t</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mord">∣</span></span></span></span></span></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">torch.allclose(A,B,rtol=<span class="number">1e-05</span>,atol=<span class="number">1e-08</span>,equal_nan=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># equal_nan 为True时，当元素为NAN时，表示接近</span></span><br></pre></td></tr></table></figure>
<p>其他的用法基本上相同，都是逐元素比较</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.eq(A,B)</span><br></pre></td></tr></table></figure>
<p>注意所有的比较要求数据的维度相同</p>
<h4 id="1-3-2-基本运算">1.3.2 基本运算</h4>
<p>张量的基本运算可以分为两种，一种是逐元素之间的计算，另一种则是矩阵之间的计算</p>
<ul>
<li>
<p>加减乘除运算</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 元素乘法</span></span><br><span class="line">A*B</span><br><span class="line"></span><br><span class="line"><span class="comment"># 元素除法</span></span><br><span class="line">A/B</span><br><span class="line"></span><br><span class="line"><span class="comment"># 元素加法</span></span><br><span class="line">A+B</span><br><span class="line"></span><br><span class="line"><span class="comment"># 元素减法</span></span><br><span class="line">A-B</span><br><span class="line"></span><br><span class="line"><span class="comment"># 整除</span></span><br><span class="line">A//B</span><br><span class="line"></span><br><span class="line"><span class="comment"># 幂运算</span></span><br><span class="line">A**<span class="number">3</span></span><br><span class="line">torch.<span class="built_in">pow</span>(A,<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 指数运算</span></span><br><span class="line">torch.exp(A)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对数运算</span></span><br><span class="line">torch.log(A)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 平方根</span></span><br><span class="line">A**<span class="number">0.5</span></span><br><span class="line">torch.sqrt(A)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 平方根导数</span></span><br><span class="line"><span class="number">1</span>/(A**<span class="number">0.5</span>)</span><br><span class="line">torch.rsqrt(A)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 元素限定裁剪</span></span><br><span class="line"><span class="comment"># 给定一个上下限用于限制元素大小</span></span><br><span class="line"><span class="comment"># 小于下限时会被重置为下限</span></span><br><span class="line"><span class="comment"># 大于上限则会被重置为上限</span></span><br><span class="line">torch.clamp_max(A,<span class="number">4</span>)</span><br><span class="line">torch.clamp_min(A,<span class="number">3</span>)</span><br><span class="line">torch.clamp(A,<span class="number">2</span>,<span class="number">5</span>)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>矩阵间的运算</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 求转置</span></span><br><span class="line">torch.t(A)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 矩阵乘法</span></span><br><span class="line">A.matmul(C)</span><br><span class="line"><span class="comment"># 注意矩阵乘法只计算最后两个维度的值</span></span><br><span class="line"><span class="comment"># 如元素A[2,3,2] B[2,2,3]</span></span><br><span class="line"><span class="comment"># 此时的矩阵乘法相当于stack((A[0].matmul(B[0])),(A[1].matmul(B[1]))</span></span><br><span class="line"><span class="comment"># 可以简写成torch.mm</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算矩阵的逆</span></span><br><span class="line">torch.inverse() <span class="comment"># 当然需要矩阵有逆矩阵</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算矩阵的迹</span></span><br><span class="line">torch.trace()</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="1-3-3-统计运算">1.3.3 统计运算</h3>
<table>
<thead>
<tr>
<th style="text-align:center">函数</th>
<th style="text-align:center">功能</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">torch.max(dim=n)</td>
<td style="text-align:center">计算张量对应维度下的最大值</td>
</tr>
<tr>
<td style="text-align:center">torch.argmax(dim=n)</td>
<td style="text-align:center">获得最大值位置</td>
</tr>
<tr>
<td style="text-align:center">torch.min(dim=n)</td>
<td style="text-align:center">最小值</td>
</tr>
<tr>
<td style="text-align:center">torch.argmin(dim=n)</td>
<td style="text-align:center">最小值位置</td>
</tr>
<tr>
<td style="text-align:center">torch.sort()</td>
<td style="text-align:center">排序并获得下标</td>
</tr>
<tr>
<td style="text-align:center">torch.argsort()</td>
<td style="text-align:center">序列下标</td>
</tr>
<tr>
<td style="text-align:center">torch.topk()</td>
<td style="text-align:center">取出第k大的值和下标</td>
</tr>
<tr>
<td style="text-align:center">torch.kthvalue()</td>
<td style="text-align:center">获得指定第k小的值和下标</td>
</tr>
<tr>
<td style="text-align:center">torch.mean()</td>
<td style="text-align:center">根据指定维度计算标准差</td>
</tr>
<tr>
<td style="text-align:center">torch.sum()</td>
<td style="text-align:center">根据指定维度求和</td>
</tr>
<tr>
<td style="text-align:center">torch.cumsum()</td>
<td style="text-align:center">根据指定维度计算累加和</td>
</tr>
<tr>
<td style="text-align:center">torch.median()</td>
<td style="text-align:center">根据指定维度计算中位数</td>
</tr>
<tr>
<td style="text-align:center">torch.cumprod()</td>
<td style="text-align:center">根据指定维度计算累乘</td>
</tr>
<tr>
<td style="text-align:center">torch.std()</td>
<td style="text-align:center">根据指定维度计算标准差</td>
</tr>
</tbody>
</table>
<p>torch.max在不同维度下的运作：返回当前维度下的最大值，例如[2,3,4]在dim=0出取最大，返回一个[3,4]，这个矩阵每个值都由dim=0的维度下取相应位置的最大值。如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">a</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"> tensor([[[-1.0190,  0.8085, -0.0339, -0.7646],</span></span><br><span class="line"><span class="string">         [ 0.7205,  0.6350, -0.2577, -0.2069],</span></span><br><span class="line"><span class="string">         [-0.8420,  0.7809, -1.2055, -2.6755]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[ 0.3683,  0.1512, -1.5940, -0.1101],</span></span><br><span class="line"><span class="string">         [-1.9924,  0.7249, -0.6083, -1.0755],</span></span><br><span class="line"><span class="string">         [-3.5662, -1.5086, -0.0512,  1.3599]]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">         </span><br><span class="line">a.<span class="built_in">max</span>(dim=<span class="number">0</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">torch.return_types.max(</span></span><br><span class="line"><span class="string">values=tensor([[ 0.3683,  0.8085, -0.0339, -0.1101],</span></span><br><span class="line"><span class="string">        [ 0.7205,  0.7249, -0.2577, -0.2069],</span></span><br><span class="line"><span class="string">        [-0.8420,  0.7809, -0.0512,  1.3599]]),</span></span><br><span class="line"><span class="string">indices=tensor([[1, 0, 0, 1],</span></span><br><span class="line"><span class="string">        [0, 1, 0, 0],</span></span><br><span class="line"><span class="string">        [0, 0, 1, 1]]))</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">a.<span class="built_in">max</span>(dim=<span class="number">1</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">torch.return_types.max(</span></span><br><span class="line"><span class="string">values=tensor([[ 0.7205,  0.8085, -0.0339, -0.2069],</span></span><br><span class="line"><span class="string">        [ 0.3683,  0.7249, -0.0512,  1.3599]]),</span></span><br><span class="line"><span class="string">indices=tensor([[1, 0, 0, 1],</span></span><br><span class="line"><span class="string">        [0, 1, 2, 2]]))</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>可以看到，返回值都是指定维度消失，保留其他维度</p>
<p><code>sort()</code>方法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">val,idx=torch.sort(A,descending=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p><code>topk()</code>方法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取前4个大值</span></span><br><span class="line">val,idx=torch.topk(A,<span class="number">4</span>,dim=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p><code>kthvalue()</code>方法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获得第k个小值</span></span><br><span class="line">torch.kthvalue(A,<span class="number">3</span>,dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="2-自动微分">2.  自动微分</h2>
<p>通过设置<code>requires_grad</code>即可实现自动微分。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">x=torch.Tensor([[<span class="number">1.</span>,<span class="number">2.</span>],[<span class="number">3.</span>,<span class="number">4.</span>]],requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># x设置为需要微分的变量</span></span><br><span class="line"></span><br><span class="line">y=torch.<span class="built_in">sum</span>(A**<span class="number">2</span>+A*<span class="number">2</span>+<span class="number">1</span>)</span><br><span class="line">y.backward()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 再去求梯度</span></span><br><span class="line">y.grad()</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="3-torch-nn模块">3.  torch.nn模块</h2>
<h3 id="3-1-卷积层">3.1  卷积层</h3>
<p>卷积可以看做是输入和卷积核之间的内积运算，是两个实值函数之间的一种数学运算。</p>
<p>卷积运算具有三个比较重要的特点，即<strong>卷积稀疏连接</strong>、<strong>参数共享</strong>、<strong>等变表示</strong>。</p>
<p>在CNN中，通过卷积核使得输入单元与输出单元呈现<strong>稀疏连接</strong>，这能<strong>减少需要训练的参数量</strong>，<strong>加快网络计算速度</strong>。</p>
<p>且模型中同一组参数将被相同的卷积核处理，只需要<strong>训练一个参数集</strong>即可，且卷积核大小远小于输入输出，减少了需要学习的参数数量。针对每个卷积层，可以使用多个卷积核获取输入的特征映射，对数据(尤其是图像)具有很强的特征提取和表示能力，并且在卷积运算后，使得卷积神经网络结构对输入的图像具有<strong>平移不变性</strong>。</p>
<p>PyTorch在卷积层提供了多种维度的卷积和逆卷积过程。</p>
<table>
<thead>
<tr>
<th style="text-align:center">API</th>
<th style="text-align:center">功能</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">torch.nn.Conv1d()</td>
<td style="text-align:center">针对输入信号应用一维卷积</td>
</tr>
<tr>
<td style="text-align:center">torch.nn.Conv2d()</td>
<td style="text-align:center">针对输入信号应用二维卷积</td>
</tr>
<tr>
<td style="text-align:center">torch.nn.Conv3d()</td>
<td style="text-align:center">针对输入信号应用三维卷积</td>
</tr>
<tr>
<td style="text-align:center">torch.nn.ConvTranspose1d()</td>
<td style="text-align:center">针对输入信号应用一维转置卷积</td>
</tr>
<tr>
<td style="text-align:center">torch.nn.ConvTranspose2d()</td>
<td style="text-align:center">针对输入信号应用二维转置卷积</td>
</tr>
<tr>
<td style="text-align:center">torch.nn.ConvTranspose3d()</td>
<td style="text-align:center">针对输入信号应用三维转置卷积</td>
</tr>
</tbody>
</table>
<p>以<code>torch.nn.Conv2d()</code>为例，其参数构造为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.Conv2d(</span><br><span class="line">    in_channels, <span class="comment"># 输入图像通道数，如RGB为三通道</span></span><br><span class="line">    out_channels, <span class="comment"># 输出图像特征数量，也就是卷积核数量</span></span><br><span class="line">    kernel_size, <span class="comment"># 卷积核大小</span></span><br><span class="line">    stride, <span class="comment"># 卷积步长，默认为1</span></span><br><span class="line">    padding, <span class="comment"># 在输入两边填充零的数量，默认为0</span></span><br><span class="line">    dilation, <span class="comment"># 卷积核元素之间的步幅，可调整卷积孔洞大小</span></span><br><span class="line">    groups, <span class="comment"># 从输入通道到输出通道的阻塞连接数</span></span><br><span class="line">    bias, <span class="comment"># 布尔值，是否添加偏置</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p><strong>案例</strong></p>
<ul>
<li>
<p>首先读入图片</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">path=<span class="string">r&quot;C:\Users\落花雨\Desktop\01.jpg&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取图像并转化为灰度</span></span><br><span class="line">mymin=Image.<span class="built_in">open</span>(path)</span><br><span class="line">myimgray=np.array(mymin.convert(<span class="string">&quot;L&quot;</span>),dtype=np.float32)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化图片</span></span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>,<span class="number">8</span>),dpi=<span class="number">300</span>)</span><br><span class="line">plt.imshow(myimgray,cmap=plt.cm.gray)</span><br><span class="line">plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<img src="/2022/07/28/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E7%AC%AC%E4%BA%8C%E7%AB%A0%20%20PyTorch%E5%85%A5%E9%97%A8/image-20220728195841284.png" alt="image-20220728195841284" style="zoom:50%;">
</li>
<li>
<p>需要将图片转为张量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将数组转化为张量</span></span><br><span class="line">imh,imw=myimgray.shape</span><br><span class="line"><span class="comment"># 图片在torch中存储： batch channel height weight</span></span><br><span class="line">myimgray_t=torch.from_numpy(myimgray.reshape((<span class="number">1</span>,<span class="number">1</span>,imh,imw)))</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>接着呢，我们定义两个卷积核，其中核一是边缘检测核，而核二是随机核。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 我们用两个卷积核进行操作，第一个使用轮廓卷积核</span></span><br><span class="line"><span class="comment"># 第二个则采用随机数</span></span><br><span class="line">kersize=<span class="number">5</span></span><br><span class="line">ker=torch.ones(kersize,kersize,dtype=torch.float32)*-<span class="number">1</span></span><br><span class="line">ker[<span class="number">2</span>,<span class="number">2</span>]=<span class="number">24</span></span><br><span class="line">ker=ker.reshape((<span class="number">1</span>,<span class="number">1</span>,kersize,kersize))</span><br><span class="line"><span class="comment"># 定义卷积层</span></span><br><span class="line">conv2d=nn.Conv2d(<span class="number">1</span>,<span class="number">2</span>,(<span class="number">5</span>,<span class="number">5</span>),bias=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># 通过conv2d的weight参数可以修改卷积核</span></span><br><span class="line">conv2d.weight.data[<span class="number">0</span>]=ker</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>最后的卷积操作</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 卷积操作</span></span><br><span class="line">imconv2dout=conv2d(myimgray_t)</span><br><span class="line"><span class="comment"># 维度压缩</span></span><br><span class="line">imconv2dout_im=imconv2dout.data.squeeze()</span><br><span class="line"><span class="comment"># 可视化</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>,<span class="number">6</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">plt.imshow(imconv2dout_im[<span class="number">0</span>],cmap=plt.cm.gray)</span><br><span class="line">plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">plt.imshow(imconv2dout_im[<span class="number">1</span>],cmap=plt.cm.gray)</span><br><span class="line">plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<img src="/2022/07/28/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E7%AC%AC%E4%BA%8C%E7%AB%A0%20%20PyTorch%E5%85%A5%E9%97%A8/image-20220728195902448.png" alt="image-20220728195902448" style="zoom:50%;">
</li>
</ul>
<hr>
<h3 id="3-2-池化层">3.2  池化层</h3>
<p>池化操作的一个重要目的是对卷积后得到的特征进行进一步处理(主要是降维)，池化层可以起到对数据进一步浓缩的效果，从而<strong>缓解计算时内存的压力</strong>。</p>
<p>池化会将一定改大小的区域用一个<strong>代表元素</strong>表示，譬如将一个5*5范围的元素做平均，得到一个代表元素，该过程就称为平均池化。</p>
<p><strong>API：</strong></p>
<table>
<thead>
<tr>
<th style="text-align:center">API</th>
<th style="text-align:center">FUC</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">nn.MaxPool1d()</td>
<td style="text-align:center">针对输入信号上应用1D最大值池化</td>
</tr>
<tr>
<td style="text-align:center">nn.MaxPool2d()</td>
<td style="text-align:center">针对输入信号上应用2D最大值池化</td>
</tr>
<tr>
<td style="text-align:center">nn.MaxPool3d()</td>
<td style="text-align:center">针对输入信号上应用3D最大值池化</td>
</tr>
<tr>
<td style="text-align:center">nn.MaxUnPool1d()</td>
<td style="text-align:center">1D最大池化的部分逆运算</td>
</tr>
<tr>
<td style="text-align:center">nn.MaxUnPool2d()</td>
<td style="text-align:center">2D最大池化的部分逆运算</td>
</tr>
<tr>
<td style="text-align:center">nn.MaxUnPool3d()</td>
<td style="text-align:center">3D最大池化的部分逆运算</td>
</tr>
<tr>
<td style="text-align:center">nn.AvgPool1d()</td>
<td style="text-align:center">1D平均池化</td>
</tr>
<tr>
<td style="text-align:center">nn.AvgPool2d()</td>
<td style="text-align:center">2D平均池化</td>
</tr>
<tr>
<td style="text-align:center">nn.AvgPool3d()</td>
<td style="text-align:center">3D平均池化</td>
</tr>
<tr>
<td style="text-align:center">nn.AdaptiveMaxPool1d()</td>
<td style="text-align:center">1D自适应最大池化</td>
</tr>
<tr>
<td style="text-align:center">nn.AdaptiveMaxPool2d()</td>
<td style="text-align:center">2D自适应最大池化</td>
</tr>
<tr>
<td style="text-align:center">nn.AdaptiveMaxPool3d()</td>
<td style="text-align:center">3D自适应最大池化</td>
</tr>
<tr>
<td style="text-align:center">nn.AdaptiveAvgPool1d()</td>
<td style="text-align:center">1D自适应平均池化</td>
</tr>
<tr>
<td style="text-align:center">nn.AdaptiveAvgPool2d()</td>
<td style="text-align:center">2D自适应平均池化</td>
</tr>
<tr>
<td style="text-align:center">nn.AdaptiveAvgPool3d()</td>
<td style="text-align:center">3D自适应平均池化</td>
</tr>
</tbody>
</table>
<p>以<code>nn.MaxPool2d()</code>为例，其参数使用为</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">nn.MaxPool2d(</span><br><span class="line">    		kernel_size, <span class="comment"># 池化窗口大小</span></span><br><span class="line">             stride=<span class="literal">None</span>, <span class="comment"># 最大池化窗口移动步长</span></span><br><span class="line">             padding=<span class="number">0</span>, <span class="comment"># 补充零的层数</span></span><br><span class="line">             dilation=<span class="number">1</span>, <span class="comment"># 控制窗口元素步幅参数</span></span><br><span class="line">             return_indices=<span class="literal">False</span>, <span class="comment"># 为True会返回最大值索引</span></span><br><span class="line">             ceil_mode=<span class="literal">False</span> <span class="comment"># True时向上取整，默认向下取整</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p><strong>案例</strong></p>
<ul>
<li>
<p>我们对刚刚经过卷积的图像做最大池化处理：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对卷积后的结果进行最大值池化</span></span><br><span class="line">maxpool2=nn.MaxPool2d(<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">pool2_out=maxpool2(imconv2dout)</span><br><span class="line">pool2_out_im=pool2_out.data.squeeze()</span><br></pre></td></tr></table></figure>
<img src="/2022/07/28/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E7%AC%AC%E4%BA%8C%E7%AB%A0%20%20PyTorch%E5%85%A5%E9%97%A8/image-20220728195913488.png" alt="image-20220728195913488" style="zoom:50%;">
</li>
<li>
<p>平均池化处理</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 平均值池化</span></span><br><span class="line">avgpool2d=nn.AvgPool2d(<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">pool2_out=avgpool2d(imconv2dout)</span><br><span class="line">pool2_out_im=pool2_out.data.squeeze()</span><br></pre></td></tr></table></figure>
<img src="/2022/07/28/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E7%AC%AC%E4%BA%8C%E7%AB%A0%20%20PyTorch%E5%85%A5%E9%97%A8/image-20220728195923125.png" alt="image-20220728195923125" style="zoom:50%;">
</li>
<li>
<p>自适应池化处理</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 自适应平均值池化</span></span><br><span class="line"><span class="comment"># 可以用output_size去指定特征映射尺寸</span></span><br><span class="line">adaavgpool2=nn.AdaptiveAvgPool2d(output_size=(<span class="number">100</span>,<span class="number">100</span>))</span><br><span class="line">pool2_out=adaavgpool2(imconv2dout)</span><br><span class="line">pool2_out_im=pool2_out.data.squeeze()</span><br></pre></td></tr></table></figure>
<img src="/2022/07/28/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91%E7%AC%AC%E4%BA%8C%E7%AB%A0%20%20PyTorch%E5%85%A5%E9%97%A8/image-20220728195931904.png" alt="image-20220728195931904" style="zoom:50%;">
</li>
</ul>
<p><strong>补充</strong></p>
<ul>
<li>
<p>关于tensor.data和tensor.detach</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 一般情况下Tensor会带有梯度信息、是否求导等动态图计算中需要使用的信息</span></span><br><span class="line"><span class="comment"># 那这些信息拿来做一些事情比如绘图就不方便</span></span><br><span class="line"><span class="comment"># 就需要从其中拿到数据</span></span><br><span class="line"></span><br><span class="line">A.data <span class="comment"># 取出数据本体，但共享内存，修改互相影响</span></span><br><span class="line">A.detach <span class="comment"># 同样，只不过在反向传播时，会判断数据是否被修改，修改会报错</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<hr>
<h3 id="3-3-激活函数">3.3  激活函数</h3>
<p>通常的激活函数为S型(sigmoid)激活函数、双曲正切(Tanh)激活函数、线性修正单元(ReLU)激活函数</p>
<table>
<thead>
<tr>
<th style="text-align:center">API</th>
<th style="text-align:center">FUC</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">nn.Sigmoid</td>
<td style="text-align:center">-</td>
</tr>
<tr>
<td style="text-align:center">nn.Tanh</td>
<td style="text-align:center">-</td>
</tr>
<tr>
<td style="text-align:center">nn.ReLU</td>
<td style="text-align:center">-</td>
</tr>
<tr>
<td style="text-align:center">nn.Softplus</td>
<td style="text-align:center">-</td>
</tr>
</tbody>
</table>
<ul>
<li>
<p><strong>Sigmoid</strong></p>
<p>也称为logistic激活函数，其输出在(0,1)之间，作为早期的激活函数，其缺点比较明显。当输入远离坐标原点时，函数的梯度会变的很小，影响参数的更新速度。</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi><mrow><mo>−</mo><mi>x</mi></mrow></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">f(x)=\frac{1}{1+e^{-x}}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.0908em;vertical-align:-0.7693em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6973em;"><span style="top:-2.989em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mathnormal mtight">x</span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7693em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
</li>
<li>
<p><strong>Tanh</strong></p>
<p>输出期间在(-1,1)之间，整个函数以0为中心，虽然梯度消失仍然存在，但其以0对称的特点使得其效果优于Sigmoid。</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><msup><mi>e</mi><mi>x</mi></msup><mo>−</mo><msup><mi>e</mi><mrow><mo>−</mo><mi>x</mi></mrow></msup></mrow><mrow><msup><mi>e</mi><mi>x</mi></msup><mo>+</mo><msup><mi>e</mi><mrow><mo>−</mo><mi>x</mi></mrow></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">f(x)=\frac{e^x-e^{-x}}{e^x+e^{-x}}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.2177em;vertical-align:-0.7693em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.4483em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.5904em;"><span style="top:-2.989em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6973em;"><span style="top:-2.989em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mathnormal mtight">x</span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7713em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mathnormal mtight">x</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7693em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
</li>
<li>
<p><strong>ReLU</strong></p>
<p>ReLU只保留大于0的输出，当输入为正数时，不存在梯度饱和问题，计算速度很快。</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(x)=max(0,x)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">ma</span><span class="mord mathnormal">x</span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span></span></p>
</li>
<li>
<p><strong>Softplus</strong></p>
<p>Softplus是平滑近似ReLU，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span></span></span></span>默认取值为1，该函数对于任意位置都可导，且保留了ReLU的优点。</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mi>β</mi></mfrac><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><mn>1</mn><mo>+</mo><msup><mi>e</mi><mrow><mi>β</mi><mi>x</mi></mrow></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(x)=\frac{1}{\beta}log(1+e^{\beta x})
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.2019em;vertical-align:-0.8804em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8804em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1491em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05278em;">β</span><span class="mord mathnormal mtight">x</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
</li>
</ul>
<hr>
<h3 id="3-4-循环层">3.4  循环层</h3>
<p>PyTorch提供了三种循环层的实现。</p>
<table>
<thead>
<tr>
<th style="text-align:center">API</th>
<th style="text-align:center">FUC</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">nn.RNN</td>
<td style="text-align:center">多层RNN单元</td>
</tr>
<tr>
<td style="text-align:center">nn.LSTM</td>
<td style="text-align:center">多层长短期记忆LSTM单元</td>
</tr>
<tr>
<td style="text-align:center">nn.GRU</td>
<td style="text-align:center">多层门限循环GRU单元</td>
</tr>
<tr>
<td style="text-align:center">nn.RNNCell</td>
<td style="text-align:center">一个RNN单元</td>
</tr>
<tr>
<td style="text-align:center">nn.LSTMCell</td>
<td style="text-align:center">-</td>
</tr>
<tr>
<td style="text-align:center">nn.GRUCell</td>
<td style="text-align:center">-</td>
</tr>
</tbody>
</table>
<p>以nn.RNN 为例，其参数信息为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">nn.RNN(</span><br><span class="line">    input_size, <span class="comment"># 输入x的特征数量</span></span><br><span class="line">    hidden_size, <span class="comment"># 隐层的特征数量</span></span><br><span class="line">    num_layers, <span class="comment"># RNN网络层数</span></span><br><span class="line">    nonlinearity, <span class="comment"># 指定非线性函数使用tanh还是relu，默认tanh</span></span><br><span class="line">    bias, <span class="comment"># 偏置权重</span></span><br><span class="line">    bathc_first, <span class="comment"># True时，限制输入和输出shape为[batch_size,time_step,feature]</span></span><br><span class="line">    dropout, <span class="comment"># 值非零时，除了最后一层，其他RNN层的输出都会套上一个dropout层</span></span><br><span class="line">    bidirectional <span class="comment"># 该值为True时，会变成一个双向RNN</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>具体使用内容见后续循环神经网络。</p>
<h3 id="3-5-全连接层">3.5 全连接层</h3>
<p>通常所说的全连接层是指一个由多个神经元所组成的层，其所有的输出和该层所有的输入都有连接，即每个输入都会影响所有神经元的输出。</p>
<p>在PyTorch中，nn.linear()表示线性变换，全连接层可以看做线性变换层加上一个激活函数。</p>
<p>其相关参数如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">nn.Linear(</span><br><span class="line">    in_features, <span class="comment"># 输入样本特征数量</span></span><br><span class="line">    out_features, <span class="comment"># 输出样本特征数量</span></span><br><span class="line">    bias <span class="comment"># 是否添加偏置</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p><strong>案例</strong></p>
<p>现在利用PyTorch构建一个多层感知机。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MLP</span>(nn.Module):</span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">		<span class="built_in">super</span>(MLP,self).__init__()</span><br><span class="line">		self.model=nn.Sequential(</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># nn.Sequential就是一个容器</span></span><br><span class="line">            <span class="comment"># 可以添加任何继承自nn.Module的类</span></span><br><span class="line">            <span class="comment"># 并让输入依次经过容器内放置的神经元</span></span><br><span class="line">            </span><br><span class="line">            nn.Linear(<span class="number">784</span>,<span class="number">200</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">200</span>,<span class="number">200</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">200</span>,<span class="number">10</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">            <span class="comment"># 继承了nn.module.forward的方法</span></span><br><span class="line">            <span class="keyword">return</span> self.model(x)</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="4-数据操作和预处理">4.  数据操作和预处理</h2>
<p>在PyTorch中，torch.utils.data模块包含着一些常用的数据预处理函数。</p>
<table>
<thead>
<tr>
<th style="text-align:center">API</th>
<th style="text-align:center">FUC</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">torch.utils.data.TensorDataset()</td>
<td style="text-align:center">将数据处理为张量</td>
</tr>
<tr>
<td style="text-align:center">torch.utils.data.ConcatDataset()</td>
<td style="text-align:center">连接多个数据集</td>
</tr>
<tr>
<td style="text-align:center">torch.utils.data.Subset()</td>
<td style="text-align:center">根据索引获取数据集的子集</td>
</tr>
<tr>
<td style="text-align:center">torch.utils.data.DataLoader()</td>
<td style="text-align:center">数据加载器</td>
</tr>
<tr>
<td style="text-align:center">torch.utils.data.random_split()</td>
<td style="text-align:center">随机将数据集拆分成给定长度的非重叠新数据集</td>
</tr>
</tbody>
</table>
<h3 id="4-1-高维数组">4.1  高维数组</h3>
<p><strong>回归数据案例</strong></p>
<ul>
<li>
<p>预先加载数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.utils.data <span class="keyword">as</span> Data</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston,load_iris</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取波士顿回归数据</span></span><br><span class="line">boston_x,boston_y=load_boston(return_X_y=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 这两个是numpy数据，类型为float64</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p>需要将numpy转化为tensor</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">train_xt=torch.from_numpy(boston_x.astype(np.float32))</span><br><span class="line">train_yt=torch.from_numpy(boston_y.astype(np.float32))</span><br><span class="line"><span class="comment"># 这样我们就得到了Tensor.float32数据啦</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p>在训练全连接神经网络时，通常一次使用一个batch的数据进行权重更新。torch.utils.data.DataLoader()可以将输入的数据集打包成一个加载器，每次迭代可使用一个batch数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 利用TD函数将XY整合到一起</span></span><br><span class="line">train_data=Data.TensorDataset(train_xt,train_yt)</span><br><span class="line"><span class="comment"># 定义一个加载器，将训练数据集进行批量处理</span></span><br><span class="line">train_loader=Data.DataLoader(</span><br><span class="line">    dataset=train_data, <span class="comment"># 使用的数据集</span></span><br><span class="line">    batch_size=<span class="number">64</span>, <span class="comment"># 批处理样本大小</span></span><br><span class="line">    shuffle=<span class="literal">True</span>, <span class="comment"># 每次迭代前打乱</span></span><br><span class="line">    num_workers=<span class="number">1</span>, <span class="comment"># 使用两个进程</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>现在我们就能获取到一个batch的数据了</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> step,(b_x,b_y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">    b_x.shape</span><br><span class="line">    <span class="comment"># torch.Size([64,13])</span></span><br><span class="line">    b_y.shape</span><br><span class="line">    <span class="comment"># torch.Size([64])</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<hr>
<h3 id="4-2-图像数据">4.2  图像数据</h3>
<p><strong>以文件夹路径数据为例</strong></p>
<ul>
<li>
<p>torchvision的datasets模块包含ImageFolder()函数，该函数可以读取如下格式的数据集：</p>
<ul>
<li>root/dog/001.png</li>
<li>root/cat/026.png…</li>
</ul>
</li>
<li>
<p>为了保证图像数据的一致性，需要先做一些变换</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"></span><br><span class="line">train_data_transforms=transforms.Compose([</span><br><span class="line">	transforms.RandomResizedCrop(<span class="number">224</span>), <span class="comment"># 随机长宽比裁剪为224*224</span></span><br><span class="line">    transforms.RandomHorizontalFlip(), <span class="comment"># 依概率p=0.5水平翻转</span></span><br><span class="line">    transforms.ToTensor() <span class="comment"># 转化为张量并归一化至[0-1]</span></span><br><span class="line">    <span class="comment"># 此过程还会将图像的形状从[H,W,C]转化为[C,H,W]</span></span><br><span class="line">    <span class="comment"># 标准化处理</span></span><br><span class="line">    transforms.Normalize([<span class="number">0.485</span>,<span class="number">0.456</span>,<span class="number">0.406</span>],</span><br><span class="line">                        [<span class="number">0.229</span>,<span class="number">0.224</span>,<span class="number">0.225</span>])</span><br><span class="line">])</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>接着我们就能去读取图像了</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">train_data_dir=<span class="string">&quot;data/chap2/imagedata/&quot;</span></span><br><span class="line"><span class="comment"># 文件夹路径与变换信息</span></span><br><span class="line">train_data=ImageFolder(train_data_dir,transform=train_data_transforms)</span><br><span class="line">train_data_loader=Data.DataLoder(</span><br><span class="line">    train_data,batch_size=<span class="number">4</span>,shuffle=<span class="literal">True</span>,num_works=<span class="number">1</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<hr>
<h3 id="4-3-文本数据">4.3  文本数据</h3>
<p>这一章内容因数据而异，暂且按下不表。</p>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 不想学辣 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[【数论】最大公约数]]></title>
      <url>/2022/07/28/%E3%80%90%E6%95%B0%E8%AE%BA%E3%80%91%E6%9C%80%E5%A4%A7%E5%85%AC%E7%BA%A6%E6%95%B0/</url>
      <content type="html"><![CDATA[<h2 id="前置知识点">前置知识点</h2>
<h3 id="整除">整除</h3>
<p>对于整数 a 和整数 b（ b ≠ 0 ），若存在整数 q，使得 a = q * b，那么称 a 能被 b 整除</p>
<p>例如 14 = 2 * 7，那么 14 能被 7 整除</p>
<h3 id="约数与倍数">约数与倍数</h3>
<p>若整数 a 能够被整数b整除，则称 b 是 a 的约数（因数），a 是 b 的倍数</p>
<p>例如 14 能够被 7 整除，那么 7 就是 14 的约数，14 就是 7 的倍数</p>
<h3 id="公约数">公约数</h3>
<p>若整数 d 既是整数 a 的约数，也是整数 b 的约数，那么 d 是 a, b 的公约数</p>
<p>例如 7 即是 14 的约数，也是 21 的约数，那么 7 是 14 与 21 的公约数</p>
<h3 id="最大公约数">最大公约数</h3>
<p>公约数中最大的整数便称为最大公约数，整数 a 与整数 b 的最大公约数记为 gcd( a, b )，也记为 ( a, b )</p>
<p>例如 14 与 21 的公约数有 { ±1，±7 }，其中整数 7 是最大的公约数，那么 gcd( 14, 21 ) = 7</p>
<h2 id="辗转相除法">辗转相除法</h2>
<p><strong>概念</strong></p>
<p>这里先给出几个定理，证明过程最后再叙述</p>
<p><strong>① gcd( a, b ) = gcd( b, a )</strong></p>
<p><strong>② gcd( a, b ) = gcd( |a|, |b| )</strong></p>
<p><strong>③ gcd( a, 0 ) = |a|, 其中 a ≠ 0， 即 0 和任意整数 a 的最大公约数均为 |a|</strong></p>
<p><strong>④ 设 a, b, c, q 是四个整数，若有 a = q * b + c，则 gcd( a, b ) = gcd( b, c )</strong></p>
<p>通俗地说，若 c 是 a 除以 b 的余数，那么 a 和 b 的最大公约数等于 b 和 c 的最大公约数</p>
<p>有了上述那些定理，我们便有了求两个数最大公约数的方法：</p>
<p>例如求 15 和 21 的最大公约数</p>
<p>我们知道，15 的约数有 { ±1，±3，±5，±15 }，21 的约数有 { ±1，±3，±7，±21 }</p>
<p>那么 15 和 21 的公约数为 { ±1，±3 }，最大公约数是 3，即 gcd( 15, 21 ) = 3</p>
<p>运用之前提到过的那些定理</p>
<p>我们发现 15 = 0 * 21 + 15, 那么 gcd( 15, 21 ) = gcd( 21, 15 )</p>
<p>又 21 = 1 * 15 + 6 , 那么 gcd( 21, 15 ) = gcd( 15, 6 )</p>
<p>又 15 = 2 * 6 + 3，那么 gcd( 15, 6 ) = gcd( 6, 3 )</p>
<p>又 6 = 2 * 3 + 0，那么 gcd( 6, 3 ) = gcd( 3, 0 )</p>
<p>又 gcd(3, 0 ) = 3，故 gcd( 15, 21 ) = 3</p>
<p><strong>定理证明</strong></p>
<h4 id="①-gcd-a-b-gcd-b-a">① gcd( a, b ) = gcd( b, a )</h4>
<p>设整数 a 的因数为 { ±a1, ±a2, …, ±an }，整数 b 的因数为 { ±b1, ±b2, …, ±bm }</p>
<p>最大公约数是两约数集合交集中的最大项，与集合顺序无关</p>
<p>故 gcd( a, b ) = gcd( b, a )</p>
<h4 id="②-gcd-a-b-gcd-a-b">② gcd( a, b ) = gcd( |a|, |b| )</h4>
<p>设整数 a 的约数为 { ±a1, ±a2, …, ±an }，则对任意整数 i（ 1 ≤ i ≤ n ），存在整数 q，使 a = q * ai</p>
<p>而 -a = (-q) * ai，故 a 的约数均为 -a 的约数，同样地， -a 的约数也为 a 的约数</p>
<p>故 a, -a, |a| 的约数集合相同，同理 b, -b, |b| 的约数集合也相同</p>
<p>而最大公约数是两约数集合的交集中的最大项，故 gcd( a, b ) = gcd( |a|, |b| )</p>
<h4 id="③-gcd-a-0-a-其中-a-≠-0">③ gcd( a, 0 ) = |a|, 其中 a ≠ 0</h4>
<p>因为 a 的最大约数是 |a|</p>
<p>而任意非 0 整数都是 0 的约数，即 0 = 0 * n（ n ≠ 0 ）</p>
<p>故 gcd( a, 0 ) = |a|</p>
<h4 id="④-设-a-b-c-q-为四个整数，若有-a-q-b-c，则-gcd-a-b-gcd-b-c">④ 设 a, b, c, q 为四个整数，若有 a = q * b + c，则 gcd( a, b ) = gcd( b, c )</h4>
<p>（Ⅰ）设 d’ = gcd( a, b )，d” = gcd( b, c )</p>
<p>故有整数 q1, q2, 使得 a = q1 * d’，b = q2 * d’</p>
<p>将上面两式代入 a = q * b + c 有</p>
<p>c = a - q * b = q1 * d’ - q * q2 * d’ = ( q1 - q * q2 ) * d’</p>
<p>因为 q, q1, q2 均是整数，故 c 能被 d’ 整除，故 d’ 也是 c的约数</p>
<p>故 d’ 也是 b 与 c 的公约数，即有 d’ ≤ gcd( b, c ) = d”</p>
<p>（Ⅱ）同理有整数 q3, q4，使得 b = q3 * d”, c = q4 * d”</p>
<p>将上面两式代入 a = q * b + c 有</p>
<p>a = q * q3 * d” + q4 * d” = ( q * q3 + q4 ) * d”</p>
<p>因为 q, q3, q4 均是整数，故 a 能被 d” 整除，故 d” 也是 a 的约数</p>
<p>故 d” 也是 a 和 b 的公约数，即有 d” ≤ gcd( a, b ) = d’</p>
<p>（Ⅲ）由上述知 d’ ≤ d” 且 d” ≤ d’</p>
<p>故 d’ = d”，即 gcd( a, b ) = gcd( b, c )</p>
<p>证毕</p>
<p>通过以上证明，我们发现辗转相除法的本质在于不断缩小计算范围，直到无法化简(b=0)为止，此时剩下的数a(不可再分)，就是最大公因数：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>a</mi><mo>=</mo><mi>q</mi><mi>b</mi><mo>+</mo><msup><mi>q</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mi>c</mi><mo>+</mo><msup><mi>q</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msup><mi>d</mi><mo>+</mo><mi>β</mi><mspace linebreak="newline"></mspace><mo>=</mo><mo stretchy="false">(</mo><mi>q</mi><mi>n</mi><mi>k</mi><mo stretchy="false">)</mo><mo>+</mo><mo stretchy="false">(</mo><msup><mi>q</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><msup><mi>n</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mi>k</mi><mo stretchy="false">)</mo><mo>+</mo><mo stretchy="false">(</mo><msup><mi>q</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msup><msup><mi>n</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msup><mi>k</mi><mo stretchy="false">)</mo><mo>+</mo><mi>β</mi></mrow><annotation encoding="application/x-tex">a=qb+q&#x27;c+q&#x27;&#x27;d+\beta
\\=(qnk)+(q&#x27;n&#x27;k)+(q&#x27;&#x27;n&#x27;&#x27;k)+\beta
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mord mathnormal">b</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.9963em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8019em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mord mathnormal">c</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.9963em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8019em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′′</span></span></span></span></span></span></span></span></span><span class="mord mathnormal">d</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.3669em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mord mathnormal" style="margin-right:0.03148em;">nk</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0519em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8019em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8019em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0519em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8019em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′′</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8019em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′′</span></span></span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span></span></span></span></span></p>
<p>其中，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span></span></span></span> 为：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>e</mi><mo>=</mo><mn>0</mn><mo>∗</mo><mi>e</mi><mo>+</mo><mi>β</mi></mrow><annotation encoding="application/x-tex">e=0*e+\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">e</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">e</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span></span></span></span>，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi><mo>=</mo><mi>e</mi></mrow><annotation encoding="application/x-tex">\beta=e</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">e</span></span></span></span></p>
<p>可写作<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo>=</mo><mi>a</mi><mi>x</mi><mo>+</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">y=ax+b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">a</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">b</span></span></span></span>的线性格式。</p>
<h2 id="代码实现">代码实现</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 递归版辗转相除法</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gcd</span>(<span class="params">a,b</span>):</span><br><span class="line">    <span class="keyword">if</span> b==<span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> a</span><br><span class="line">    <span class="keyword">return</span> gcd(<span class="built_in">abs</span>(b),<span class="built_in">abs</span>(a)%<span class="built_in">abs</span>(b))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 非递归</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gcd1</span>(<span class="params">a,b</span>):</span><br><span class="line">    a,b=<span class="built_in">abs</span>(a),<span class="built_in">abs</span>(b)</span><br><span class="line">    <span class="keyword">while</span> <span class="number">1</span>:</span><br><span class="line">        c=a%b</span><br><span class="line">        <span class="keyword">if</span> c==<span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> b</span><br><span class="line">        a=b</span><br><span class="line">        b=c</span><br><span class="line"></span><br><span class="line"><span class="comment"># 更相减损术</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gcd2</span>(<span class="params">a,b</span>):</span><br><span class="line">    <span class="keyword">if</span> a==<span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> b</span><br><span class="line">    <span class="keyword">if</span> b==<span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> a</span><br><span class="line">    a,b=<span class="built_in">abs</span>(a),<span class="built_in">abs</span>(b)</span><br><span class="line">    <span class="keyword">while</span> a!=b:</span><br><span class="line">        <span class="keyword">if</span> a&gt;b:</span><br><span class="line">            a=a-b</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            b=b-a</span><br><span class="line">    <span class="keyword">return</span> a</span><br></pre></td></tr></table></figure>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 不想学辣 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 数学 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[592 分数加减法运算]]></title>
      <url>/2022/07/27/%E3%80%90LeetCode%E3%80%91_592/</url>
      <content type="html"><![CDATA[<h2 id="题干">题干</h2>
<p>给定一个表示分数加减运算的字符串 <code>expression</code> ，你需要返回一个字符串形式的计算结果。</p>
<p>这个结果应该是不可约分的分数，即最简分数。 如果最终结果是一个整数，例如 <code>2</code>，你需要将它转换成分数形式，其分母为<code>1</code>。所以在上述例子中, <code>2 </code>应该被转换为<code> 2/1</code>。</p>
<p><img src="/2022/07/27/%E3%80%90LeetCode%E3%80%91_592/image-20220727212728977.png" alt="image-20220727212728977"></p>
<h2 id="思路">思路</h2>
<p>本题主要考量的是对字符串的操作和数学理解。</p>
<p>首先，对字符串的操作核心在于：</p>
<ul>
<li>判断单个字符串是符号还是数字</li>
<li>对数字进行读取</li>
<li>根据符号判断运算规则</li>
</ul>
<p>而数学理解在于如何计算分式，实际上，直接对其进行操作(每过一个操作符进行一次算数操作)会导致一个问题，那就是最终得到的结果是一个整数或浮点数，将其转化为分式难免会产生数据丢失，而且较为困难。</p>
<p>我们可以记录分子<code>numerator</code>和分母<code>denominator</code>的量，通过约分得到最终的分式结果，就像中学题直接处理分数一般。</p>
<p>设两个数<code>a,b</code>的分子分母为：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>a</mi><mi>n</mi></msub><mo separator="true">,</mo><msub><mi>a</mi><mi>d</mi></msub><mo separator="true">,</mo><msub><mi>b</mi><mi>n</mi></msub><mo separator="true">,</mo><msub><mi>b</mi><mi>d</mi></msub></mrow><annotation encoding="application/x-tex">a_n,a_d,b_n,b_d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，分式相加公式如下：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>n</mi><mi>e</mi><mi>w</mi><mo>=</mo><mfrac><mrow><msub><mi>a</mi><mi>n</mi></msub><mo>∗</mo><msub><mi>b</mi><mi>d</mi></msub><mo>+</mo><msub><mi>b</mi><mi>n</mi></msub><mo>∗</mo><msub><mi>a</mi><mi>d</mi></msub></mrow><mrow><msub><mi>a</mi><mi>d</mi></msub><mo>∗</mo><msub><mi>b</mi><mi>d</mi></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">new=\frac{a_n*b_d+b_n*a_d}{a_d*b_d}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.2074em;vertical-align:-0.836em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.836em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<p>最后通过<strong>约分</strong>得到最终结果。</p>
<h2 id="代码">代码</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fractionAddition</span>(<span class="params">self, expression: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line"></span><br><span class="line">        <span class="comment"># d1*d2*d3</span></span><br><span class="line">        <span class="comment"># (n1*d2+n2*d1)*d3+n3*(n1*d2+n2*d1)</span></span><br><span class="line">        <span class="comment"># gcd(n,d)</span></span><br><span class="line"></span><br><span class="line">        numerator,denominator=<span class="number">0</span>,<span class="number">1</span></span><br><span class="line">        i=<span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> i&lt;<span class="built_in">len</span>(expression):</span><br><span class="line"></span><br><span class="line">            <span class="comment"># determine the sign</span></span><br><span class="line">            sign=<span class="number">1</span> <span class="comment"># maybe begin without &quot;+&quot;</span></span><br><span class="line">            <span class="keyword">if</span> expression[i] <span class="keyword">in</span> [<span class="string">&quot;+&quot;</span>,<span class="string">&quot;-&quot;</span>]:</span><br><span class="line">                <span class="keyword">if</span> expression[i]==<span class="string">&quot;-&quot;</span>:</span><br><span class="line">                    sign=-<span class="number">1</span></span><br><span class="line">                i+=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># determine the numerator            </span></span><br><span class="line">            nume_=<span class="number">0</span></span><br><span class="line">            <span class="keyword">while</span> i&lt;<span class="built_in">len</span>(expression) <span class="keyword">and</span> expression[i].isdigit():</span><br><span class="line">                nume_=nume_*<span class="number">10</span>+<span class="built_in">int</span>(expression[i])</span><br><span class="line">                i+=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># determine the denominator</span></span><br><span class="line">            i+=<span class="number">1</span></span><br><span class="line">            deno_=<span class="number">0</span></span><br><span class="line">            <span class="keyword">while</span> i&lt;<span class="built_in">len</span>(expression) <span class="keyword">and</span> expression[i].isdigit():</span><br><span class="line">                deno_=deno_*<span class="number">10</span>+<span class="built_in">int</span>(expression[i])</span><br><span class="line">                i+=<span class="number">1</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># calculate fraction1 and fraction2</span></span><br><span class="line">            numerator=numerator*deno_+sign*nume_*denominator</span><br><span class="line">            denominator*=deno_</span><br><span class="line"></span><br><span class="line">            <span class="comment"># next loop</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> denominator==<span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&quot;0/1&quot;</span></span><br><span class="line"></span><br><span class="line">        g=gcd(numerator,denominator)</span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&quot;<span class="subst">&#123;numerator//g&#125;</span>/<span class="subst">&#123;denominator//g&#125;</span>&quot;</span></span><br></pre></td></tr></table></figure>
<h2 id="注意点">注意点</h2>
<ul>
<li>在做字符串操作时，一定要明确每一步到了哪个位置，该位置上要进行什么操作。</li>
<li>注意意群的规律</li>
</ul>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 不想学辣 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 算法 </tag>
            
            <tag> LeetCode </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Unit2 介词和并列连词]]></title>
      <url>/2022/06/24/%E3%80%90%E8%8B%B1%E8%AF%AD%E3%80%91Unit2%20%E4%BB%8B%E8%AF%8D%E5%92%8C%E5%B9%B6%E5%88%97%E8%BF%9E%E8%AF%8D/</url>
      <content type="html"><![CDATA[<h1>Unit2 介词和并列连词</h1>
<hr>
<h2 id="一、介词">一、介词</h2>
<p>介词是一种虚词，不能单独使用，介词之后一般有名词或代词(宾格)或相当于名词的其他词类、短语或从句做他的宾语，即构成介词短语，常用于表示状态。</p>
<h3 id="1-1-常见介词及辨析">1.1  常见介词及辨析</h3>
<ul>
<li>
<p>表示地点时，<code>at, in, on</code>的区别</p>
<p><code>at</code>后面跟的是比较小的地方，比如村庄，小城市，门牌等；<code>in</code>后面接比较大的地方，比如国家、城市等；<code>on</code>表示在某物之上，且表面接触。例如：<code>on the road, in/on the stree, on the farm, in the field</code></p>
</li>
<li>
<p>表示时间时<code>at, on , in</code>的区别</p>
<ol>
<li>
<p><code>at</code>表示时间点</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">at six</span><br><span class="line">at noon</span><br><span class="line">at midnight</span><br><span class="line">at night</span><br><span class="line">at sunrise</span><br><span class="line">at the weekend</span><br><span class="line">at Christmas</span><br></pre></td></tr></table></figure>
</li>
<li>
<p><code>on</code>表示在特定某一天或某天的上午，下午，晚上(时间段)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">on Monday</span><br><span class="line">on Sunday afternoon</span><br></pre></td></tr></table></figure>
</li>
<li>
<p><code>in</code>表示一段时间，后面跟上小时、周、月、年、季等表示一段时间的名词</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">in three hours</span><br><span class="line">in a week</span><br><span class="line">in a month</span><br><span class="line">in tree years</span><br></pre></td></tr></table></figure>
<p><code>in</code>是不受限制的时间段，<code>at</code>是具体时间点，<code>on</code>是特定某天，其关系可以为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">work</span>(<span class="params">time</span>):</span><br><span class="line">	res=<span class="string">&quot;in&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">type</span>(time)==<span class="string">&quot;时间点&quot;</span>:</span><br><span class="line">        res=<span class="string">&quot;at&quot;</span></span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">type</span>(time)==<span class="string">&quot;时间段&quot;</span>:</span><br><span class="line">        <span class="keyword">if</span> time==<span class="string">&quot;具体某天&quot;</span> <span class="keyword">or</span> time==<span class="string">&quot;具体某天某段时间&quot;</span>:</span><br><span class="line">            res=<span class="string">&quot;on&quot;</span></span><br><span class="line">    <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
</li>
</ol>
</li>
<li>
<p>表示持续时间的<code>since, for, in, after</code>的区别</p>
<ol>
<li>
<p><code>since</code>接过去某个时间点，表示“自…以来”，常用于完成时。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">She has been working here since <span class="number">2007.</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p><code>for</code>接一段具体的时间，常用于完成时，表示时间的延续。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">I have studied English <span class="keyword">for</span> <span class="number">7</span> years.</span><br></pre></td></tr></table></figure>
</li>
<li>
<p><code>in+一段时间</code>与非延续性动词连用，表示一段时间以后，多用于将来时。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Jack will be back <span class="keyword">in</span> a week.</span><br></pre></td></tr></table></figure>
</li>
<li>
<p><code>after+一段时间</code>表示“…之后”，常用于过去时。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">After one month, the baby began to learn climbing.</span><br></pre></td></tr></table></figure>
</li>
</ol>
</li>
<li>
<p>表示方位的介词<code>in, on, to, off</code>的区别</p>
<ol>
<li>
<p><code>in</code>表示在境内</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">in</span> China</span><br><span class="line"><span class="keyword">in</span> Europe</span><br></pre></td></tr></table></figure>
</li>
<li>
<p><code>on</code>表示相邻或在边界上，不在境内</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">on the border between Kenya and Tanzania.</span><br></pre></td></tr></table></figure>
</li>
<li>
<p><code>to</code>表示在境外，不接壤</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Beijing lies to the north of Shanghai.</span><br></pre></td></tr></table></figure>
</li>
<li>
<p><code>off</code>表示在海面上靠近海岸的地方</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">off the southwest coast of the U.S.</span><br></pre></td></tr></table></figure>
</li>
</ol>
</li>
<li>
<p>表示运动方向或目的的介词</p>
<ol>
<li>
<p><code>across</code>表示穿过物体表面或横过</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">across the street</span><br><span class="line">across the English Channel</span><br></pre></td></tr></table></figure>
</li>
<li>
<p><code>through</code>表示在某一空间通过或纵向穿过</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">through the forest</span><br><span class="line">go through the valley</span><br></pre></td></tr></table></figure>
</li>
<li>
<p><code>along</code>表示沿着一条线平行</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">go along the bank of the river</span><br></pre></td></tr></table></figure>
</li>
<li>
<p><code>up</code>表示向上，由南到北，由东到西，由沿海到内陆，由小地方到大地方，由农村到城市，反之则用<code>down</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">go up to London for the day</span><br><span class="line">drive all the way down from Wuhan in Guilin</span><br></pre></td></tr></table></figure>
</li>
<li>
<p><code>to</code>表示动作的目的地</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">travel to Beijing</span><br><span class="line">our weekly trip to the supermarket</span><br></pre></td></tr></table></figure>
</li>
<li>
<p><code>towards</code>指朝向，而无到达的意思</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">walk towards the river</span><br><span class="line">look out towards the sea</span><br></pre></td></tr></table></figure>
</li>
<li>
<p><code>for</code>表示前往的目的地，与其连用的动词有<code>leave, start off, set out, head, sail</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">leave <span class="keyword">for</span> New York</span><br><span class="line">a ship heading <span class="keyword">for</span> Dalian</span><br></pre></td></tr></table></figure>
</li>
</ol>
</li>
<li>
<p>表示“除…之外”的介词</p>
<p><strong>besides</strong>：表包含，意为“除…之外还有”</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Besides the Black, six couples attended the party last Saturday.</span><br></pre></td></tr></table></figure>
<p><strong>except</strong>：表示排除，意为&quot;除…之外&quot;</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">The museum <span class="keyword">is</span> <span class="built_in">open</span> every day <span class="keyword">except</span> Tuesday.</span><br></pre></td></tr></table></figure>
<p><strong>but</strong>：表示排除，多和<code>nobody, none, no one, nothing, anything, everyone, all, who等连用</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Nothing but trouble will come of this plan. <span class="comment"># 注意排除的是前面主语部分</span></span><br><span class="line"><span class="comment"># A but B</span></span><br><span class="line"><span class="comment"># 表示全集A挖去子集B剩下的集合</span></span><br></pre></td></tr></table></figure>
<p><strong>except for</strong>：表示出去整体中的部分，意为“只不过，只是”，有大体肯定，细节指正的意思</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Your composition <span class="keyword">is</span> very good <span class="keyword">except</span> <span class="keyword">for</span> a few spelling mistakes.</span><br></pre></td></tr></table></figure>
</li>
<li>
<p><code>among</code>和<code>between</code></p>
<p><strong>among</strong>：表示三个或以上的人或物之间，后接复数名词或集体名词</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">The news sparked a heated debate among people on social media.</span><br><span class="line"><span class="comment"># 这一消息在社交媒体上引发了人们的激烈讨论</span></span><br></pre></td></tr></table></figure>
<p><strong>between</strong>：用于两者之间，或者三个以上的两两之间</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Peter sat between Mary <span class="keyword">and</span> Jane.</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>表示价格、比率、标准、速度的介词</p>
<p><strong>at</strong>：表示价值、价格、比率或速度，例如<code>buy sth. at a half price</code></p>
<p><strong>for</strong>：表示交换，指总价钱，如<code>pay $3 for a ticket</code></p>
<p><strong>by</strong>：表示度量单位或标准，后接计量单位和名词，一般是单数，前面需要加冠词<code>the</code>，数词或复数名词前不加。如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">We<span class="string">&#x27;re paid by the hour. # 我们按小时计费</span></span><br><span class="line"><span class="string">Increase by 20% # 增长20%</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p><code>against</code></p>
<p>​	值得注意的是，<code>against</code>是介词，而不是动词</p>
<ul>
<li>
<p>表示“反对，不利于，对着，违背”</p>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">We are <span class="built_in">all</span> against his idea.</span><br><span class="line">He was married against his will. <span class="comment"># 他结婚是违背本意的</span></span><br><span class="line">There were <span class="number">20</span> votes <span class="keyword">for</span> him <span class="keyword">and</span> <span class="number">12</span> against him. <span class="comment"># 有20票赞成他，12票反对他</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p>表示“靠着，盯着，迎着”</p>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">He stood <span class="keyword">with</span> his back against the door.</span><br><span class="line">He hit his head against the window.</span><br><span class="line">Bright red flags flow <span class="keyword">in</span> the wind against the blue sky.</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li>
<p><code>beyond</code></p>
<ul>
<li>
<p>表示位置，意思是“在…的那一边，在…之外，在更远处&quot;</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">The new housing estate stretches beyond the playing-fields. <span class="comment"># 新的住宅区一直延伸到游乐场的另一边</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p>表示时间，意思是“迟于，超过&quot;</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Some shops keep <span class="built_in">open</span> beyond midnight. <span class="comment"># 有些商店营业到半夜之后</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p>表示范围、水平、限度、能力，意思是“超出，多余，为…所不能及&quot;</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Your work <span class="keyword">is</span> beyond <span class="built_in">all</span> praise. <span class="comment"># 你的作品让人称赞不已</span></span><br><span class="line">She was really touched beyond words. <span class="comment"># 她确实被感动的无法形容</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p>表示年龄或数量，意思是&quot;超过&quot;</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">He didn<span class="string">&#x27;t believe in people living beyond 150. # 他不能相信人能活到150岁以上</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p>用在否定和疑问句中，意思是“除…之外&quot;</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">I know nothing beyond what he told me. <span class="comment"># 除了他告诉我的，我一无所知</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 常用搭配</span></span><br><span class="line">beyond belief <span class="comment"># 难以置信</span></span><br><span class="line">beyond doubt <span class="comment"># 无疑的</span></span><br><span class="line">beyond compare <span class="comment"># 无与伦比的，举世无双</span></span><br><span class="line">beyond recognition <span class="comment"># 认不出来，无法辨认</span></span><br><span class="line">beyond control <span class="comment"># 无法控制的</span></span><br><span class="line">beyond repair <span class="comment"># 无法修理</span></span><br><span class="line">beyond description <span class="comment"># 难以形容</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<hr>
<h3 id="1-2-固定介词搭配">1.2  固定介词搭配</h3>
<ul>
<li>
<p>介词+名词</p>
<ol>
<li>
<p><code>at</code>+名词</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">at war <span class="comment"># 正在交战</span></span><br><span class="line">at work <span class="comment"># 正在工作</span></span><br><span class="line">at peace <span class="comment"># 处于和平或平静状态</span></span><br><span class="line">at table <span class="comment"># 正在吃饭</span></span><br><span class="line">at meeting <span class="comment"># 在开会</span></span><br><span class="line">be at school <span class="comment"># 正在上学</span></span><br><span class="line">at church <span class="comment"># 在做礼拜</span></span><br><span class="line">at breakfast/lunch/supper <span class="comment"># 正在吃早(午/晚)饭</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p><code>in</code>+名词</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">in</span> progress <span class="comment"># 正在进展中</span></span><br><span class="line"><span class="keyword">in</span> fashion <span class="comment"># 流行</span></span><br><span class="line"><span class="keyword">in</span> church <span class="comment"># 在做礼拜</span></span><br><span class="line"><span class="keyword">in</span> danger <span class="comment"># 处在危险中</span></span><br><span class="line"><span class="keyword">in</span> <span class="keyword">class</span> <span class="comment"># 在上课</span></span><br><span class="line"><span class="keyword">in</span> turn <span class="comment"># 依次</span></span><br><span class="line"><span class="keyword">in</span> action <span class="comment"># 在运转</span></span><br><span class="line"><span class="keyword">in</span> hospital <span class="comment"># 在住院</span></span><br><span class="line"><span class="keyword">in</span> tears <span class="comment"># 在流泪</span></span><br><span class="line"><span class="keyword">in</span> office <span class="comment"># 在执政</span></span><br><span class="line"><span class="keyword">in</span> power <span class="comment"># 掌握权力</span></span><br><span class="line"><span class="keyword">in</span> operation <span class="comment"># 生效，起作用</span></span><br><span class="line"><span class="keyword">in</span> need <span class="comment"># 在贫困中</span></span><br><span class="line"><span class="keyword">in</span> addition <span class="comment"># 此外</span></span><br><span class="line"><span class="keyword">in</span> time <span class="comment"># 及时</span></span><br><span class="line"><span class="keyword">in</span> trouble <span class="comment"># 处于困境之中</span></span><br><span class="line"><span class="keyword">in</span> one<span class="string">&#x27;s opinion # 根据某人的看法</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p><code>on</code>+名词</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">on strike <span class="comment"># 在罢工</span></span><br><span class="line">on leave <span class="comment"># 在休假</span></span><br><span class="line">on the rise <span class="comment"># 在上涨</span></span><br><span class="line">on a visit <span class="comment"># 正在访问</span></span><br><span class="line">on sale <span class="comment"># 正在出售</span></span><br><span class="line">on time <span class="comment"># 准时</span></span><br><span class="line">on earth <span class="comment"># 究竟；在地球上</span></span><br><span class="line">on the contrary <span class="comment"># 相反</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p><code>under</code>+名词</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">under consideration <span class="comment"># 在考虑之中</span></span><br><span class="line">under construction <span class="comment"># 在修建中</span></span><br><span class="line">under discussion <span class="comment"># 在讨论中</span></span><br><span class="line">under treatment <span class="comment"># 在治疗中</span></span><br><span class="line">under repair <span class="comment"># 在修理中</span></span><br><span class="line">under attack <span class="comment"># 受到攻击</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
</li>
<li>
<p>形容词+介词</p>
<ol>
<li>
<p>与<code>at</code>有关的</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">be angry at sth. <span class="comment"># 对某事感到生气</span></span><br><span class="line">be good at <span class="comment"># 擅长于</span></span><br><span class="line">be bad at <span class="comment"># 不擅长</span></span><br><span class="line">be surprised at <span class="comment"># 对...感到吃惊</span></span><br><span class="line">be clever at <span class="comment"># 擅长</span></span><br><span class="line">be terrified at <span class="comment"># 对...感到害怕</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p>与<code>of</code>有关的</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">be afraid of <span class="comment"># 害怕</span></span><br><span class="line">be sure of <span class="comment"># 对...有把握</span></span><br><span class="line">be full of <span class="comment"># 充满</span></span><br><span class="line">be tired of <span class="comment"># 对...感到厌倦</span></span><br><span class="line">be fond of <span class="comment"># 喜欢</span></span><br><span class="line">be proud of <span class="comment"># 对...感到自豪</span></span><br><span class="line">be worthy of <span class="comment"># 应得到某物</span></span><br><span class="line">be centain of <span class="comment"># 对...确定的</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p>与<code>with</code>有关的</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">be angry <span class="keyword">with</span> sb. <span class="comment"># 对某人感到生气</span></span><br><span class="line">be strict <span class="keyword">with</span> sb. <span class="comment"># 对某人要求严格</span></span><br><span class="line">be careful <span class="keyword">with</span> <span class="comment"># 受到...欢迎</span></span><br><span class="line">be busy <span class="keyword">with</span> <span class="comment"># 因...而繁忙</span></span><br><span class="line">be popular <span class="keyword">with</span> <span class="comment"># 受到...欢迎</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p>与<code>to</code>有关的</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">be <span class="built_in">next</span> to <span class="comment"># 与...相邻</span></span><br><span class="line">be good to <span class="comment"># 对...好</span></span><br><span class="line">be polite to <span class="comment"># 对...有礼貌</span></span><br><span class="line">be kind to <span class="comment"># 友好对待</span></span><br><span class="line">be cruel to <span class="comment"># 对...残暴</span></span><br><span class="line">be rude to <span class="comment"># 对...无理</span></span><br><span class="line">be married to <span class="comment"># 嫁给,娶</span></span><br><span class="line">be close to <span class="comment"># 靠近，挨着</span></span><br><span class="line">be near to <span class="comment"># 距离...近</span></span><br><span class="line">be similar to <span class="comment"># 与...相似</span></span><br><span class="line">be known to <span class="comment"># 为...所知</span></span><br><span class="line">be due to <span class="comment"># 是由于</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p>与<code>for</code>有关的</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">be good <span class="keyword">for</span> <span class="comment"># 对...有利</span></span><br><span class="line">be free <span class="keyword">for</span> <span class="comment"># 对...免费</span></span><br><span class="line">be fit <span class="keyword">for</span> <span class="comment"># 对...合适的</span></span><br><span class="line">be unfit <span class="keyword">for</span> <span class="comment"># 对...不合适</span></span><br><span class="line">be eager <span class="keyword">for</span> <span class="comment"># 渴望</span></span><br><span class="line">be hungry <span class="keyword">for</span> <span class="comment"># 渴望</span></span><br><span class="line">be anxious <span class="keyword">for</span> <span class="comment"># 为...感到焦虑，担心</span></span><br><span class="line">be sorry <span class="keyword">for</span> <span class="comment"># 为...感到抱歉</span></span><br><span class="line">be known <span class="keyword">for</span> <span class="comment"># 因...而闻名</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p>与<code>from</code>有关的</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">be far <span class="keyword">from</span> <span class="comment"># 远离</span></span><br><span class="line">be different <span class="keyword">from</span> <span class="comment"># 不同于</span></span><br><span class="line">be free <span class="keyword">from</span> <span class="comment"># 使...免于</span></span><br><span class="line">be safe <span class="keyword">from</span> <span class="comment"># 没有...的危险</span></span><br><span class="line">be absent <span class="keyword">from</span> <span class="comment"># 缺席</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
</li>
<li>
<p>“动词+介词”固定搭配</p>
<ol>
<li>
<p>动词+<code>at</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">glare at <span class="comment"># 瞪着</span></span><br><span class="line">laugh at <span class="comment"># 嘲笑</span></span><br><span class="line">stare at <span class="comment"># 瞪着</span></span><br><span class="line">arrive at <span class="comment"># 到达，抵达</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p>动词+<code>for</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mistake... <span class="keyword">for</span>... 将...误作</span><br><span class="line">search <span class="keyword">for</span> 搜寻</span><br><span class="line">pay <span class="keyword">for</span> <span class="comment"># 为...付费</span></span><br><span class="line">run <span class="keyword">for</span> <span class="comment"># 竞选</span></span><br><span class="line">blame...<span class="keyword">for</span>... <span class="comment"># 因...责备</span></span><br><span class="line">charge <span class="keyword">for</span> <span class="comment"># 索价，收费</span></span><br><span class="line">leave... <span class="keyword">for</span>... <span class="comment"># 离开，前往</span></span><br><span class="line">account <span class="keyword">for</span> <span class="comment"># 解释，是...的原因，占</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p>动词+<code>from</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">die from # 死于</span><br><span class="line">hear from sb. # 收到某人的来信</span><br><span class="line">keep...from... # 阻止...做</span><br><span class="line">prevent...from... # 阻止...做</span><br><span class="line">stop...from... # 阻止...做</span><br><span class="line"># stoping him from doing it!</span><br><span class="line">protect...from...  # 保护...免受...</span><br><span class="line">distinguish...from... # 使...区别于...</span><br><span class="line">recover from... # 从...回复</span><br><span class="line">separate... from... # 将....与...分离</span><br><span class="line">suffer from # 遭受，受...之苦</span><br><span class="line">tell...from... # 将...与...区分</span><br><span class="line">discourage sb. from. # 劝别人不要</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>动词+<code>in</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">involve ... <span class="keyword">in</span> ... <span class="comment"># 将...牵扯进来</span></span><br><span class="line">result <span class="keyword">in</span> <span class="comment"># 导致，造成</span></span><br><span class="line">result <span class="keyword">from</span> <span class="comment"># 由...造成，因...产生</span></span><br><span class="line">succeed <span class="keyword">in</span> <span class="comment"># 在...方面成功</span></span><br><span class="line">lie <span class="keyword">in</span> <span class="comment"># 在于</span></span><br><span class="line">believe <span class="keyword">in</span> <span class="comment"># 信任，相信</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p>动词+<code>into</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">divide...into... <span class="comment"># 将...划分为</span></span><br><span class="line">change...into... <span class="comment"># 将...转变</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p>动词+<code>of</code></p>
</li>
<li>
<p>动词+<code>on/upon</code></p>
</li>
<li>
<p>动词+介词<code>to</code></p>
</li>
<li>
<p>动词+<code>with</code></p>
</li>
</ol>
</li>
</ul>
</li>
</ul>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 不想学辣 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 英语 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Unit1  冠词、名词、代词和数词]]></title>
      <url>/2022/06/24/%E3%80%90%E8%8B%B1%E8%AF%AD%E3%80%91Unit1%20%20%E5%86%A0%E8%AF%8D%E3%80%81%E5%90%8D%E8%AF%8D%E3%80%81%E4%BB%A3%E8%AF%8D%E5%92%8C%E6%95%B0%E8%AF%8D/</url>
      <content type="html"><![CDATA[<h1>Unit1  冠词、名词、代词和数词</h1>
<hr>
<h2 id="一、冠词">一、冠词</h2>
<p>冠词用在名词之前，分不定冠词<code>a\an</code>和定冠词<code>the</code>两类</p>
<h3 id="1-1-不定冠词">1.1  不定冠词</h3>
<ol>
<li>
<p>表示<strong>初次提及</strong>，<strong>非特指</strong>的时候，需要使用不定冠词</p>
<p><strong>例句</strong>：</p>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">The Wilsons live <span class="keyword">in</span> an A-shaped house near the coast. It <span class="keyword">is</span> a 17th-century cottage.</span><br><span class="line"><span class="comment"># 威尔逊先生一家住在海边的一个A字形房子里，那是一个17世纪的小屋</span></span><br></pre></td></tr></table></figure>
<ol start="2">
<li>
<p>表示<strong>数量</strong>“一个”</p>
<p>不定冠词表示数量时，等同于<code>one</code>，用于人名前，则是表示<strong>不认识此人</strong>或与某名人有<strong>类似性质</strong>的人或事情，以为<code>a certain</code></p>
<p><strong>例句</strong>：</p>
</li>
</ol>
  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Hello, could I speak to Mr.Smith?</span><br><span class="line">Sorry, wrong number. There isn<span class="string">&#x27;t a Mr.Smith here.</span></span><br></pre></td></tr></table></figure>
<ol start="3">
<li>
<p>用于<code>quite,rather,many,half,what,such</code>之后或<code>so(as,too,how)+形容词</code>之后</p>
<p><strong>例句</strong>：</p>
</li>
</ol>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">This room <span class="keyword">is</span> rather a big one.</span><br><span class="line">She <span class="keyword">is</span> so lovely a girl that <span class="built_in">all</span> of us like her very much.</span><br></pre></td></tr></table></figure>
<ol start="4">
<li>
<p>用于某些抽象名词之前，表示具体化</p>
<p><strong>例句</strong>：</p>
</li>
</ol>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">It would be a pity to cut down these trees.</span><br><span class="line">He <span class="keyword">is</span> a great success <span class="keyword">as</span> a scientist.</span><br></pre></td></tr></table></figure>
<p>​	类似的单词还有<code>pleasure,pride,honor,failure,comfort,promise,danger,reality</code>等。</p>
<ol start="5">
<li>
<p>固定短语搭配</p>
<p><strong>例句</strong>：</p>
</li>
</ol>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a bit </span><br><span class="line">at a loss</span><br><span class="line">at a time </span><br><span class="line">come to a stop</span><br><span class="line">......</span><br></pre></td></tr></table></figure>
<ol start="6">
<li><code>a/an</code>的使用区分</li>
</ol>
<ul>
<li>
<p>以元音音素开头的单词前面用<code>an</code>，例如<code>an eraser</code>、<code>an hornor</code>等</p>
</li>
<li>
<p>以辅音读音开头的单词前面需要用<code>a</code>，例如<code>a book</code></p>
</li>
<li>
<p>在26个英文字母中，<code>a,e,i,o,f,h,l,m,n,r,s,x</code>等字母的读音是以元音音素开头，需要用<code>an</code>，其他用<code>a</code></p>
<ul>
<li>
<pre><code class="language-python">There is an &quot;m&quot; and a &quot;u&quot; in the word &quot;mysterious&quot;
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">### 1.2  定冠词</span><br><span class="line"></span><br><span class="line">1. 表示上文提及过的，或是双方都已知晓的</span><br><span class="line"></span><br><span class="line">   此时相当于指示代词`this、that、those、these`等</span><br><span class="line"></span><br><span class="line">   例句：</span><br><span class="line"></span><br><span class="line">   ```python</span><br><span class="line">   A waiter came and waited. John caught my look and we both got up and, ignoring the waiter, made our way to the buffet.</span><br><span class="line">   # 一个侍者走了过来，候在附近。约翰领会了我的眼神，我们两个都站了起来，没有理睬那个侍者，朝自助餐台走去。</span><br></pre></td></tr></table></figure>

</code></pre>
</li>
</ul>
</li>
</ul>
<ol start="2">
<li>
<p>用于独一无二的事物前</p>
<p>例如<code>the sun</code>，<code>the sky</code>，<code>the earth</code>等等</p>
<p><strong>例句</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Copernicus concluded that the earth goes <span class="built_in">round</span> the sun.</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>用于序数词，最高级前</p>
<p><strong>例句</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Tom <span class="keyword">is</span> the last person that I want to see. <span class="comment"># 汤姆是我最不想见的人</span></span><br><span class="line">Is Shanghai the second largest city <span class="keyword">in</span> China? <span class="comment"># 上海是中国第二大城市吗</span></span><br><span class="line">He <span class="keyword">is</span> the smartest boy <span class="keyword">in</span> our <span class="keyword">class</span>. <span class="comment"># 他是我们班上最聪明的男生</span></span><br></pre></td></tr></table></figure>
<p><strong>注意</strong>：</p>
<ul>
<li>
<p>序数词前使用不定冠词是，表示“再、又”的意思</p>
</li>
<li>
<pre><code class="language-python">It's the second time I've read the book. I want to read it a third time.
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+ 用于&quot;the+比较级&quot;表示“两者中较...的”部分</span><br><span class="line"></span><br><span class="line">+ ```python</span><br><span class="line">  Of the two sisters, Betty is the younger one, but she is the tallest girl in her class.</span><br></pre></td></tr></table></figure>

</code></pre>
</li>
<li>
<p>有时<code>most</code>表示“非常&quot;,但并不是最高级，此时不需要加<code>the</code></p>
</li>
<li>
<pre><code class="language-python">He is the most famous doctor in this hospital and he is a most amazing person.
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">4. 用于`the more..., the more`结构</span><br><span class="line"></span><br><span class="line">   此时表示&quot;越..., 越...&quot;</span><br><span class="line"></span><br><span class="line">   **例句**：</span><br><span class="line"></span><br><span class="line">   ```python</span><br><span class="line">   The more money you make, the more you can spend.</span><br><span class="line">   The harder you work, the more progress you will get.</span><br></pre></td></tr></table></figure>

</code></pre>
</li>
</ul>
</li>
<li>
<p>定冠词还能用于以下几种情况</p>
<ul>
<li>用于复数姓氏前表示某某夫妇或者一家人，例如<code>the Smiths</code></li>
<li>在逢十的复数名词前，表示年代，例如<code>in the 1990s</code></li>
<li>在表示西洋乐器的名词前加，但球类运动不加</li>
<li>用于&quot;动词+人+介词+the+人体部位&quot;，此时不用物主代词，如：<code>beat him on the shoulder</code></li>
<li>用于单位名词前表示标准，即表示计量标准，相当于汉语的“按”，“论”，“每”，但<code>by</code>表示<code>依据</code>讲的时候后面跟<strong>抽象名词</strong>是不用任何冠词的，例如<code>by weight, by length, by width</code></li>
<li>用于<code>the+某些形容词或过去分词</code>中表示一类人，如<code>the rich</code>，<code>the poor</code></li>
<li>用于<code>the+police/public等集合名词</code>表示这类人的总称</li>
<li>用于修饰<code>same, only, very</code>等形容词，可用于<code>the same, the only, the very</code>结构中</li>
<li>下文将具体展示<code>the</code>的用法</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">In the 1980s, the Smiths were already <span class="keyword">in</span> their thirties <span class="keyword">and</span> lived <span class="keyword">in</span> a village. Their doughter liked playing the piano <span class="keyword">while</span> their son liked playing football.</span><br><span class="line">Near their house there was <span class="keyword">as</span> fair where bananas are usually sold by weight <span class="keyword">and</span> eggs by the dozen.It was the only fair <span class="keyword">in</span> the area. </span><br><span class="line">The fair was <span class="built_in">open</span> to the public only during two <span class="built_in">open</span>-house weekends. Both the poor <span class="keyword">and</span> the rich went there. The old took the children <span class="keyword">in</span> the hand tightly <span class="keyword">in</span> case they got lose.</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>还有固定的短语搭配</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">all</span> the time</span><br><span class="line">the other day</span><br><span class="line"><span class="built_in">all</span> the year around</span><br><span class="line">at the age of </span><br><span class="line">......</span><br></pre></td></tr></table></figure>
</li>
</ol>
<hr>
<h3 id="1-3-不用冠词的情况">1.3  不用冠词的情况</h3>
<ol>
<li>
<p>身份、职位、头衔名词前</p>
<p>例如<code>be elected chairman</code></p>
</li>
<li>
<p>球类、棋类名词前</p>
<p>例如<code>play football, play chess</code></p>
</li>
<li>
<p>一日三餐的名词前</p>
<p>例如<code>have breakfast/lunch/supper</code></p>
</li>
<li>
<p>交通方式名词前</p>
<p>例如<code>by bike, by ship, by plane</code></p>
</li>
<li>
<p>一些地点名词前</p>
<p>例如<code>bed, church, school, hospital, prison</code>等</p>
<p>若在这些地方加上了<code>the</code>，表示去这些场所做其他的事情</p>
</li>
<li>
<p>使用定冠词与不使用定冠词的短语辨析</p>
<p>某些固定搭配使用定冠词和不使用时会出现含义差别。</p>
<table>
<thead>
<tr>
<th style="text-align:center">定冠词</th>
<th style="text-align:center">不加</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">in the front of 在(范围内的)面前</td>
<td style="text-align:center">in front of 在(范围外的)前面</td>
</tr>
<tr>
<td style="text-align:center">at the table 在桌旁</td>
<td style="text-align:center">at table 吃饭</td>
</tr>
<tr>
<td style="text-align:center">go to the school 去学校</td>
<td style="text-align:center">go to school 上学</td>
</tr>
<tr>
<td style="text-align:center">in the charge of 在…管理之下</td>
<td style="text-align:center">in charge of 主管，负责</td>
</tr>
<tr>
<td style="text-align:center">in the case of 就…来说</td>
<td style="text-align:center">in case of 假如，万一</td>
</tr>
<tr>
<td style="text-align:center">the last week 相对过去某个时间而言的上个星期</td>
<td style="text-align:center">last week 说话时以前的上个星期</td>
</tr>
<tr>
<td style="text-align:center">go to the sea 去海边</td>
<td style="text-align:center">go to sea 出航</td>
</tr>
</tbody>
</table>
</li>
</ol>
<hr>
<h2 id="二、名词">二、名词</h2>
<p>名词是表示人、事物、地点或抽象概念的名称的词，有专有名词和普通名词之分，还有不可数和可数名词之分。</p>
<p><strong>可数名词</strong>，分为单数和复数两种形式。可数名词前可以用不定冠词、数词或some、many等修饰。如：<code>a man、a desk、an apple、an orange、some books、some children、two pens</code></p>
<p><strong>不可数名词</strong>，不可数名词，没有复数形式，前面不能用不定冠词、数词或many等词语修饰，但可以用some，a little，much等词语来修饰。有时可以与一些量词短语搭配，这些量词短语中的名词一般是可数的，有单数形式，也可以有复数形式，一般使用的量词短语a(或an） /little/bit/piece…</p>
<p>如：<code>some water，a little milk ，much food，a piece of bread，two bottles of ink，some glasses of water</code></p>
<h3 id="2-1-常见名词构词法">2.1 常见名词构词法</h3>
<ol>
<li>
<p>由<code>-ment</code>构成</p>
<p><code>-ment</code>表示行为的结果或具体工具</p>
<p><strong>例如</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">move(移动，使运动)--movement(运动，移动)</span><br><span class="line">develop(发展)--development(发展)</span><br><span class="line">measure(测量)--measurement(测量)</span><br><span class="line">equip(装备)--equipment(装备，设备)</span><br><span class="line">achieve(达到，完成)--achievement(达到，成就)</span><br><span class="line">agree(同意，商定)--agreement(同意，协议)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>由<code>-tion, -ation, -sion</code>构成</p>
<p><code>-tion, -ation, -sion</code>表示行为的过程</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">explain(解释)--explanation(解释)</span><br><span class="line">produce(生产)--production(生产)</span><br><span class="line">divide(划分)--division(划分)</span><br><span class="line">express(表示，表达)--expression(表示，表达)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>由<code>-ness</code>构成</p>
<p>形容词后面加后缀<code>-ness</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cold(寒冷的)--coldness(寒冷)</span><br><span class="line">dark(黑暗的)--darkness(黑暗)</span><br><span class="line">useful(有用的)--usefulness(用处)</span><br><span class="line">exact(精确地)--exactness(精确)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>由<code>-ence, -ance</code>构成</p>
<p>某些动词或形容词后面加<code>-ence</code>或<code>-ance</code>可构成相应的抽象名词</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">enter(进入)--entrance(入口处)</span><br><span class="line">resist(抵抗)--resistance(抵抗)</span><br><span class="line">depend(依赖，依靠)--dependence(依靠，依赖)</span><br><span class="line">different(不同的)--difference(不同，差别)</span><br><span class="line">absent(缺席，不在的)--absence(缺席，不在)</span><br><span class="line">refer(参考)--reference(参考)</span><br><span class="line">important(重要的)--importance(重要性)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>由<code>-y, -ty, -ity</code>构成</p>
<p>某些形容词后面加<code>-y,-ty,-ity</code>等表示性质状态的后缀，构成抽象名词</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">difficult(困难的)--difficulty(困难)</span><br><span class="line">electric(电的)--electricity(电)</span><br><span class="line">safe(安全的)--safety(安全)</span><br><span class="line">cruel(残酷的)--cruelty(残酷)</span><br><span class="line">able(有能力的)--ability(能力)</span><br><span class="line">active(积极地，活跃的)--activity(活动)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>有些动词变名词较为复杂，需要注意</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">succeed--success 成功</span><br><span class="line">pronounce--pronounciation 发音</span><br><span class="line">explain--explanation 解释</span><br><span class="line">decide--decision 决定</span><br><span class="line">enter--entrance 进入</span><br><span class="line">permit--permission 允许</span><br><span class="line">refuse--refusal 拒绝</span><br><span class="line">consider--consideration 考虑</span><br><span class="line">discover--discovery 发现</span><br><span class="line">bury--burial 埋葬</span><br><span class="line">conclude--conclusion 结论</span><br><span class="line">arrive 推断 --arrival 到达</span><br><span class="line">weigh 重 --weight 重量</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h3 id="2-2-抽象名词具体化">2.2  抽象名词具体化</h3>
<p>​	抽象名词一般为不可数名词，但当抽象名词表示为具体的东西时，可用作可数名词且<strong>词义发生变化</strong>。这种语言现象叫做抽象名词的具体化。</p>
<table>
<thead>
<tr>
<th style="text-align:center">用作抽象名词</th>
<th style="text-align:center">具体化(可数)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">in surprise 惊讶地</td>
<td style="text-align:center">a surprise 让人惊讶的事情</td>
</tr>
<tr>
<td style="text-align:center">win success 获得成功</td>
<td style="text-align:center">a success 一个(件)成功的人(事)</td>
</tr>
<tr>
<td style="text-align:center">win honor 赢得荣誉</td>
<td style="text-align:center">an honor 一件引以为荣的事</td>
</tr>
<tr>
<td style="text-align:center">Failure is the mother of success 失败是成功之母</td>
<td style="text-align:center">a failure 一个失败者</td>
</tr>
<tr>
<td style="text-align:center">by experience 靠经验</td>
<td style="text-align:center">an experience 一次经历</td>
</tr>
<tr>
<td style="text-align:center">full of youth and vitality 充满青春和活力</td>
<td style="text-align:center">a youth 一个年轻人</td>
</tr>
<tr>
<td style="text-align:center">have pity on sb. 怜悯某人</td>
<td style="text-align:center">a pity 可惜的事情</td>
</tr>
<tr>
<td style="text-align:center">with pleasure 乐意</td>
<td style="text-align:center">a pleasure 乐事</td>
</tr>
</tbody>
</table>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">He had had six failures and would have a seventh <span class="keyword">try</span>.</span><br><span class="line">他经历六次失败，并将进行第七次尝试</span><br><span class="line">A knowledge of English is a must in international trade.</span><br><span class="line">懂英语对于做国际贸易来说是必不可少的</span><br><span class="line">She made an apology to her mother <span class="keyword">for</span> her wrong doings.</span><br><span class="line">她为自己做错了事向妈妈道歉</span><br></pre></td></tr></table></figure>
<h3 id="2-3-名词的数">2.3  名词的数</h3>
<h4 id="1-可数名词变复数的规则变化">1.  可数名词变复数的规则变化</h4>
<ul>
<li>
<p>一般在词尾<code>-s</code>:</p>
<ul>
<li>清辅音后读<code>/s/</code>：<code>map-maps</code></li>
<li>浊辅音和元音后读<code>/z/</code>：<code>bag-bags,car-cars</code></li>
</ul>
</li>
<li>
<p>以<code>s,sh,ch,x</code>等结尾的词加<code>-es</code>，读<code>/iz/</code>：<code>bus-buses；watch-watches</code></p>
<ul>
<li>值得注意的是：<code>stomach-stomachs</code></li>
</ul>
</li>
<li>
<p>以<code>y</code>结尾的专有名词或以元音字母<code>+y</code>结尾的名词变复数时，直接加<code>-s</code></p>
<ul>
<li><code>two Marys; the Henrys; monkey--monkeys; holiday--holidays</code></li>
</ul>
</li>
<li>
<p>以<code>o</code>结尾的前面是辅音字母，变为复数时，有一些加<code>-es</code></p>
<ul>
<li><code>hero-heroes; potato-potatoes; tomato-tomatoes </code></li>
<li><code>Heroes eat potatoes and tomatoes 英雄吃马铃薯和西红柿</code></li>
<li>一般是活的加<code>-es</code>，不活的加<code>-s</code></li>
</ul>
</li>
<li>
<p>以<code>f</code>或<code>fe</code>结尾的名词变复数时，有的加<code>-s</code>，有的变<code>f</code>或<code>fe</code>为<code>v</code>再加<code>-es</code></p>
<ul>
<li>
<p>只加<code>s</code>的情况</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">chief--chiefs</span><br><span class="line">belief--beliefs</span><br><span class="line">roof--roofs</span><br><span class="line">cliff--cliffs</span><br><span class="line">safe--safes</span><br><span class="line">gulf--gulfs</span><br></pre></td></tr></table></figure>
<p>助记：“长官”，”信仰“，”房顶“和”悬崖“是”安全“的”港湾“</p>
</li>
<li>
<p>变<code>f</code>或<code>fe</code>为<code>v</code>再加<code>-es</code>的情况</p>
   <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">wife--wives</span><br><span class="line">half--halves</span><br><span class="line">knife--knives</span><br><span class="line">wolf--wolves</span><br><span class="line">leaf--leaves</span><br><span class="line">life--lives</span><br><span class="line">thief--thieves</span><br></pre></td></tr></table></figure>
<p>助记：“妻子”用“半”把“刀”阻止“狼”称为偷盗“树叶“”生命“的”小偷“</p>
</li>
</ul>
</li>
</ul>
<h4 id="2-可数名词边复数不规则变化">2. 可数名词边复数不规则变化</h4>
<ul>
<li>
<pre><code class="language-python">child--children
foot--feet
tooth--teeth
mouse--mice
man--men
woman--women

# 一个词加man或woman构成合成词，其复数也是men或women
# 但German不是合成词
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+ 单复数同形，如`deer, sheep, fish, Chinese, Japanese`</span><br><span class="line"></span><br><span class="line">+ 以`s`结尾，仍为单数的</span><br><span class="line"></span><br><span class="line">  + `maths, politics, physics`等学科名词，一般是不可数名词，为单数</span><br><span class="line"></span><br><span class="line">  + `news`为不可数名词</span><br><span class="line"></span><br><span class="line">  + 以复数名词出现的书名、剧名、报纸、杂志名，也可视为单数</span><br><span class="line"></span><br><span class="line">    + ```python</span><br><span class="line">      The Arabian Nights is a very interesting story-book.</span><br></pre></td></tr></table></figure>

+ 表示由两部分构成的东西，如`glasses, trousers, clothes`在表达具体数目是，需要借助数量名词`pair`和`suit`，如`a pair of glasses, two pairs of trousers`

+ 另外部分名词在表示复数形式时，可能有特别的含义，如`goods, waters, fishes`

</code></pre>
</li>
</ul>
<h4 id="3-不可数名词">3.不可数名词</h4>
<p>比较常见的不可数名词有：<code>advice, news, information, progress, work, fun, weather, music, health, luck</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># hair 指一个人全部头发时，是不可数名词，但如果指每一根头发时，是可数的，可以说one hair、two hairs</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 可以说drink beer, drink coffee, drink gin, 但在要酒水时应该说： a (glass of) beer, a gin, two gins</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># experience指“经历”时是可数名词：</span></span><br><span class="line">He had an exciting experience/some exciting experiences last week.</span><br><span class="line"></span><br><span class="line"><span class="comment"># work意味&quot;职业、就业、工作&quot;时事不可数名词:</span></span><br><span class="line">He <span class="keyword">is</span> looking <span class="keyword">for</span> work/<span class="keyword">for</span> a job.</span><br><span class="line"></span><br><span class="line"><span class="comment"># works(只有复数形式)可以表示工商，或是文学和音乐作品：</span></span><br><span class="line">Shakespeare<span class="string">&#x27;s complete works.</span></span><br></pre></td></tr></table></figure>
<h4 id="4-名词的所有格">4.名词的所有格</h4>
<p>名词所有格表示从属关系，分为**'s所有格<strong>和</strong>of所有格**，一般来说’s表示有生命的东西，of往往用于无生命的东西。</p>
<h5 id="4-1-‘s所有格的构成方法">4.1 -‘s所有格的构成方法</h5>
<p>一般情况下，直接加<code>-'s</code>就行了</p>
<ul>
<li>
<pre><code class="language-python">children's books
today's paper
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">带词尾`-s`的复数名词只加`-&#x27;`</span><br><span class="line"></span><br><span class="line">+ ```python</span><br><span class="line">  girls&#x27; school</span><br><span class="line">  the Smiths&#x27; car</span><br></pre></td></tr></table></figure>

</code></pre>
</li>
</ul>
<p>带词尾<code>-s</code>的单数名词通常仍要加<code>-'s</code></p>
<ul>
<li>
<pre><code class="language-python">the boss's plan
the hostess's worry
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">带词尾`-s`的人名，可以只加`-&#x27;s`或是`-&#x27;`</span><br><span class="line"></span><br><span class="line">用`and`连接的并列名词的所有格要分两种情况，即表示各自的所有关系时，要分别在并列名词后加`-&#x27;s`，表示共同的关系时，只需要在最后一个名词后加`-&#x27;s`</span><br><span class="line"></span><br><span class="line">+ ```python</span><br><span class="line">  Tom&#x27;s and Jim&#x27;s rooms.</span><br><span class="line">  Tom and Jim&#x27;s room.</span><br></pre></td></tr></table></figure>

</code></pre>
</li>
</ul>
<h5 id="4-2-of-名词构成的所有关系">4.2 <code>of</code>+名词构成的所有关系</h5>
<p><code>of</code>所有格多用于无生命的东西，例如<code>the cover of the book</code>，但也有例外：</p>
<ul>
<li>
<pre><code class="language-python">the housing problem of the poor.
the skills of the workers who have been well trained.
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">当然，有些表示时间、距离等无生命名词和表示世界、国家、诚征的名词，也可以用`-&#x27;s`或`-&#x27;`</span><br><span class="line"></span><br><span class="line">+ ```python</span><br><span class="line">  five minutes&#x27; walk</span><br><span class="line">  today&#x27;s newspaper</span><br></pre></td></tr></table></figure>

</code></pre>
</li>
</ul>
<h5 id="4-3-双重所有格">4.3 双重所有格</h5>
<p>双重所有格是指将<code>-'s</code>和<code>of</code>两个所有格结合起来用，构成<code>of + 名词's</code>的格式，表示整体中的一个或部分，用于修饰<code>of</code>前面的名词，但此时该名词一定要有一个量词修饰，且不能是<code>one</code>和<code>the</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Two classmates of my siste<span class="string">r&#x27;s will come to join us.</span></span><br><span class="line"><span class="string"># 全集：my sister&#x27;</span>s (classmate)</span><br><span class="line"><span class="comment"># 子集: two classmate (of my sister&#x27;s classmate)</span></span><br></pre></td></tr></table></figure>
<p>双重所有格也可以由<code>of+名词性物主代词</code>构成，例如：<code>a friend of mine</code></p>
<hr>
<h2 id="三、代词">三、代词</h2>
<p>所谓代词，是代替名词的词类。大部分代词具有名词和形容词的功能。根据其意义、特征和在句中的作用，代词可分为：</p>
<ul>
<li>人称代词</li>
<li>物主代词</li>
<li>指示代词</li>
<li>反身代词</li>
<li>相互代词</li>
<li>疑问代词</li>
<li>关系代词</li>
<li>连接代词</li>
<li>不定代词</li>
</ul>
<p>共九种。</p>
<h3 id="3-1-人称代词主格与宾格的用法">3.1 人称代词主格与宾格的用法</h3>
<p>人称代词有主格和宾格之分，主格代词一般在句中做主语、表语，宾格代词一般做动词的宾语和介词的宾语。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">If you keep a pet, you need to spend some time taking care of it.</span><br><span class="line"><span class="comment"># 两个 you 分别做主语, it 做宾语</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># we,you,they  有时可泛指&quot;人们&quot;</span></span><br><span class="line">They say prices are going to rise again.</span><br><span class="line"></span><br><span class="line"><span class="comment"># she 可以用来指代国家、船只、大地、月亮等</span></span><br><span class="line">China will always do what she has promised to do.</span><br><span class="line"></span><br><span class="line">The Titanic was on her first voyage when she sank.</span><br><span class="line"></span><br><span class="line"><span class="comment"># 注意人称代词并列时的顺序</span></span><br><span class="line">You <span class="keyword">and</span> I are good friends.</span><br><span class="line">You <span class="keyword">and</span> he must be there at seven o<span class="string">&#x27;clock.</span></span><br><span class="line"><span class="string">You, he and I will be put in the same class. </span></span><br></pre></td></tr></table></figure>
<h3 id="3-2-名词性和形容词性物主代词">3.2  名词性和形容词性物主代词</h3>
<p>物主代词是表示所有关系的代词，可以分为形容词性，名词词性两种</p>
<table>
<thead>
<tr>
<th>第…人称</th>
<th>单复数</th>
<th>形容词性物主代词</th>
<th>名词性物主代词</th>
<th>中文意思</th>
</tr>
</thead>
<tbody>
<tr>
<td>第一人称</td>
<td>单数</td>
<td>my</td>
<td>mine</td>
<td>我的</td>
</tr>
<tr>
<td>第一人称</td>
<td>复数</td>
<td>ours</td>
<td>ours</td>
<td>我们的</td>
</tr>
<tr>
<td>第二人称</td>
<td>单数</td>
<td>your</td>
<td>yours</td>
<td>你的</td>
</tr>
<tr>
<td>第二人称</td>
<td>复数</td>
<td>yours</td>
<td>yours</td>
<td>你们的</td>
</tr>
<tr>
<td>第三人称</td>
<td>单数</td>
<td>his, her, its</td>
<td>his, hers, its</td>
<td>他的, 她的, 它的</td>
</tr>
<tr>
<td>第三人称</td>
<td>复数</td>
<td>their</td>
<td>theirs</td>
<td>他们的, 她们的, 它们的</td>
</tr>
</tbody>
</table>
<p>形容词性物主代词不可单独使用，必须放在名词前做定语。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">My name <span class="keyword">is</span> John Green.</span><br><span class="line">They wash their hair every day.</span><br></pre></td></tr></table></figure>
<p>名词性物主代词可以单独使用，相当于“形容词性物主代词+名词”，常做宾语和表语。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">These are his books. Yours are over there.</span><br><span class="line">I forgot to bring my dictionary. Could I use yours?</span><br><span class="line">Whose book <span class="keyword">is</span> this? It<span class="string">&#x27;s hers.</span></span><br></pre></td></tr></table></figure>
<h3 id="3-3-反身代词的用法">3.3 反身代词的用法</h3>
<p>反身代词是一种表示反射或强调的代词，表示“我(们)自己&quot;，“你(们)自己”，“他/她/它们自己”。</p>
<p>第一、二人称的反身代词是由形容词性物主代词+<code>-self</code>或<code>-selves</code>构成，第三人称反身代词由人身代词的宾格加<code>-self</code>或<code>-selves</code>构成，反身代词常做宾语、表语和同位语。</p>
<p><strong>做宾语</strong></p>
<p>有些动词常与反身代词连用，如<code>bathe, amuse, blame, feed, dress, cut, enjoy, hurt, introduce, behave</code>等</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Little Albert <span class="keyword">is</span> only four, but he can feed himself, wash himself <span class="keyword">and</span> dress himself.</span><br></pre></td></tr></table></figure>
<p>常见的表达有：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">dress oneslef 自己穿衣</span><br><span class="line">say to oneself 心里想</span><br><span class="line">devote oneself to 致力于</span><br><span class="line">seat oneself 坐下</span><br><span class="line">enjoy oneself 过得快乐</span><br><span class="line">talk/speak to oneself 自言自语</span><br><span class="line"><span class="built_in">help</span> oneself to 随便吃</span><br><span class="line">teach oneself 自学</span><br><span class="line">hide oneself 把自己藏起来</span><br></pre></td></tr></table></figure>
<p><strong>作表语</strong></p>
<p>反身代词可用作表语</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">The boy <span class="keyword">in</span> the picture <span class="keyword">is</span> myself, <span class="keyword">not</span> anyone <span class="keyword">else</span>.</span><br><span class="line">I am <span class="keyword">not</span> myself today. 我今天不舒服</span><br></pre></td></tr></table></figure>
<p><strong>做同位语</strong></p>
<p>反身代词可以加强名词或代词的语气，强调&quot;自己，亲自，本人&quot;等意思，通常跟在名词、代词之后，也可以用于句尾，此时反身代词应重读。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">I<span class="string">&#x27;m afraid I can&#x27;</span>t <span class="built_in">help</span> you. Yo<span class="string">u&#x27;ll have to do it yourself.</span></span><br><span class="line"><span class="string"># 恐怕我帮不了你了，你得自己做</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">You should ask the students themselves.</span></span><br><span class="line"><span class="string"># 你应该问学生们自己</span></span><br></pre></td></tr></table></figure>
<p>反身代词还常与<code>for, of, in, by</code>等介词搭配，构成固定短语</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> oneself 亲自</span><br><span class="line">of oneself 自动地</span><br><span class="line"><span class="keyword">in</span> oneself 本身固有</span><br><span class="line">by oneself 独自</span><br></pre></td></tr></table></figure>
<h3 id="3-4-疑问代词">3.4 疑问代词</h3>
<p>疑问代词有<code>who(主格), whom(宾语), whose(所有格), what(什么), which(哪个)</code>等，一般都放在句首，并在句中作为某一句子成分。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Who <span class="keyword">is</span> going to speak to us tomorrow.</span><br><span class="line">Whom are you talking about?</span><br><span class="line">Whose umbrella <span class="keyword">is</span> this?</span><br><span class="line">What did he say?</span><br><span class="line">Which <span class="keyword">is</span> yours, the blue pen <span class="keyword">or</span> the red one?</span><br></pre></td></tr></table></figure>
<p>疑问代词可用于名词性从句中，用在名词性从句时，倒装句的语序需要改为陈述句语序。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Do you know what he has said. <span class="comment"># 你知道他说了什么吗</span></span><br><span class="line"><span class="comment"># 疑问代词what引导一个宾语从句，而他本身又在从句中做宾语</span></span><br><span class="line"></span><br><span class="line">Who will be <span class="keyword">in</span> charge of the work <span class="keyword">is</span> still <span class="keyword">not</span> decided. <span class="comment"># 谁负责这项工作现在还没有定</span></span><br><span class="line"><span class="comment"># 疑问代词who引导一个主语从句，它本身又在从句中做主语</span></span><br></pre></td></tr></table></figure>
<h3 id="3-5-不定代词">3.5  不定代词</h3>
<p><strong>both, either, neither</strong></p>
<p><code>both</code>意为“(两者)都”，<code>either</code>意味着“(两者中)任意一个”，<code>neither</code>意为&quot;(两者)都不&quot;，若要指三者或以上，<code>all</code>表示三者都，则用<code>any</code>表示三者中任何一个，<code>none</code>表示三者都不。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">He has two sons, both of whom are clever.</span><br><span class="line">He has two sons, either of whom <span class="keyword">is</span> clever.</span><br><span class="line">He has two sons, neither of whom <span class="keyword">is</span> clever.</span><br></pre></td></tr></table></figure>
<p><strong>each和every</strong></p>
<p><code>each</code>可做代词、形容词、副词，<code>every</code>是形容词，仅具有形容词的功能。</p>
<ul>
<li>
<p><code>each</code>指两个或两个以上的人或事物中的“每个”，强调<code>one by one</code>的含义，<code>every</code>指三个或以上的人或事物的“全体”，与<code>all</code>意思相近。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">He gave a book to each of his parents.</span><br><span class="line">Every worker was there <span class="keyword">and</span> each did his own work.</span><br></pre></td></tr></table></figure>
</li>
<li>
<p><code>each</code>作形容词时，修饰单数名词，接第三人称单数形式，做代词时，单独使用，接动词三单，放在复数名词和代词后做同位语时，谓语动词用复数形式。若<code>each of them</code>做主语，谓语动词可做单数形式也可用作复数形式。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Each man carries his own bag. <span class="comment"># 修饰单数名词</span></span><br><span class="line">We each have our own office. <span class="comment"># 做we的同位语</span></span><br><span class="line">Each carries his own bag. <span class="comment"># 代词</span></span><br><span class="line">Each of them are/<span class="keyword">is</span> here. <span class="comment"># 代词</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p><code>every</code>与<code>not</code>连用，表示部分否定，<code>each</code>做代词一般不与否定句连用，在否定句中多用<code>neither, none, no</code>等代替。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Every man <span class="keyword">is</span> <span class="keyword">not</span> honest. <span class="comment"># 并不是每个人都很城市</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p><code>each</code>的前面不可使用<code>almost, nearly, not</code>等词汇，但<code>every</code>之前可以采用。注意在否定句中一般不用<code>each</code>! <code>each of</code>这种表达要换成<code>none of</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Almost every windows was broken. <span class="comment"># 几乎每一扇窗子都是破的 # 不可用almost each</span></span><br><span class="line">Not every child enjoyed the party. <span class="comment"># 并非所有孩子都喜欢这个派对</span></span><br><span class="line"><span class="literal">None</span> of the answers were correct. <span class="comment"># 所有答案都是不正确的(全盘否定)</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p><code>every</code>总是修饰单数名词，后面接三单。代表<code>each</code>和<code>every</code>的物主代词可用<code>his</code>，也可用<code>their</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Each carried their/his own bag.</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>some和any</strong></p>
<p><code>some</code>多用于肯定句，<code>any</code>多用于否定句、疑问句或条件句。在表示请求、建议、反问或是希望得到肯定回答的疑问句中，常用<code>some</code>而不用<code>any</code>。<code>some</code>可与数词连用，表示“大约”的意思。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Would you mind buying me some candies on your way home?</span><br><span class="line">Will you give me some paper?</span><br><span class="line">She gained some <span class="number">25</span> pounds <span class="keyword">in</span> weight during pregnancy. <span class="comment"># 她在怀孕期间增重了大约25磅</span></span><br></pre></td></tr></table></figure>
<p><strong>few, a few, little, a little</strong></p>
<ul>
<li>
<p><code>few / a few</code>用来修饰可数名词，<code>few</code>表示否定意义，意为“没有，几乎没有”,<code>a few</code>表示肯定意义，意为“有几个”</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">He has few friends here, so he freels lonely. <span class="comment"># 他在这没啥朋友，因此感到寂寞</span></span><br><span class="line">There are a few eggs <span class="keyword">in</span> the basket. <span class="comment"># 篮子里有几个鸡蛋</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p><code>little / a little</code>用来修饰不可数名词，与<code>few</code>类似，<code>little</code>表示否定，<code>a little</code>表示肯定</p>
</li>
</ul>
<p><strong>another, the other, others</strong></p>
<ul>
<li>
<p><code>another</code>或<code>another+单数可数名词</code>泛指“另一个，再一个”，其复数形式时<code>others</code>或<code>other+复数名词</code>，泛指&quot;别的人(或事物)&quot;，常见的搭配有<code>one ... another</code>，<code>some ... others</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">This glass <span class="keyword">is</span> broken. Give me another, please.</span><br><span class="line">There are may people <span class="keyword">in</span> the park. Some are walking, some are jogging, <span class="keyword">and</span> others are dancing.</span><br></pre></td></tr></table></figure>
</li>
<li>
<p><code>the other</code>特指两者中的一个，常有<code>one... the other ...</code>的搭配，复数形式为<code>the others</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">He has a book <span class="keyword">in</span> one hand, <span class="keyword">and</span> a pan <span class="keyword">in</span> the other.</span><br><span class="line">Of the four boys, one <span class="keyword">is</span> <span class="keyword">in</span> Grade One, the others are <span class="keyword">in</span> Grade Two.</span><br></pre></td></tr></table></figure>
</li>
<li>
<p><code>another</code>还可用于<code>another+基数词+复数名词</code>，如<code>another three cups</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 与 other 和 another相关的习惯性用语：</span></span><br><span class="line">other than(除...之外)</span><br><span class="line">each other=one another(相互)</span><br><span class="line">one after another(一个接一个)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>复合不定代词</strong></p>
<p>由<code>some, any, no, every</code>加上<code>body, oen, things</code>构成的不定代词叫做符合不定代词。常见的有：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">somebody 某人</span><br><span class="line">someone 某认</span><br><span class="line">something 某物</span><br><span class="line"></span><br><span class="line">anybody 任何人</span><br><span class="line">anyone 任何人</span><br><span class="line">nobody 无一人</span><br><span class="line"></span><br><span class="line">everybody 每个人</span><br><span class="line">everyone 每个人</span><br><span class="line">everything 每件事，一切</span><br><span class="line"></span><br><span class="line">nothing 无一物</span><br></pre></td></tr></table></figure>
<p>复合不定代词相当于名词，在句中可做主语、宾语和表语，且不能作定语。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Everything goes <span class="keyword">as</span> planned. <span class="comment"># 做主语</span></span><br><span class="line">I don<span class="string">&#x27;t have anything to say. # 做宾语</span></span><br><span class="line"><span class="string">Money is not everything. # 做表语</span></span><br></pre></td></tr></table></figure>
<p>复合不定代词被定语所修饰时，定语必须放在他们后边。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">There <span class="keyword">is</span> nothing wrong <span class="keyword">with</span> the machine.</span><br></pre></td></tr></table></figure>
<p><strong>替代词it, that, (the) one(s), those 的用法</strong></p>
<ul>
<li>
<p>替代词it, one, that辨析</p>
<p><code>it/ one/ that</code>三者均可做代词，指代前面提到的名词，一般来说，<code>it</code>指代的是上文提到的同一物品， <code>one, that</code>则是同名异物。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">I have lost my umbrella, I<span class="string">&#x27;m looking for it.</span></span><br><span class="line"><span class="string">I have lost my umbrella, I thing I must buy one.</span></span><br><span class="line"><span class="string">The umnbrella you bought is cheaper than that I bought.</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p>one 与 ones的区别</p>
<p><code>one=a/an+上文出现的名词</code>，复数用<code>ones</code>，主格与宾格相同</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">There are many school bags, I want to buy one.</span><br><span class="line">The only jokes I tell are the ones that I hear <span class="keyword">from</span> my friends.</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>that 与 the + 名词</p>
<p><code>that=the+上文出现的名词</code>，包括可数名词单数和不可数名词，指代复数名词时用<code>those</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">The weather <span class="keyword">in</span> Nanjing <span class="keyword">is</span> hotter than that <span class="keyword">in</span> Beijing.</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>代替单数可数名词时用<code>one</code>和<code>that</code>均可，一般泛指用<code>one</code>，特指用<code>that</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">I don<span class="string">&#x27;t have a computer, and I&#x27;</span>ve decided to buy one.</span><br><span class="line">The computer <span class="keyword">is</span> different <span class="keyword">from</span> that we are using.</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>后跟<code>of</code>短语时，一般只能用<code>that(those)</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">The light of the sun <span class="keyword">is</span> much brighter than that of the moon.</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>代替特指的可数名词时，若无前置定语，<code>that</code>或<code>the one</code>可以互相换用</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">This film <span class="keyword">is</span> more interesting than that (the one) we saw last night.</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>it非人称代词的用法</strong></p>
<ul>
<li>
<p>it表示时间、距离、价值、天气、气候及温度</p>
<p><code>it</code>在作非人称代词时，主要用于指时间、距离、价值、天气、气候及温度</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">It<span class="string">&#x27;s too late to go there now.</span></span><br><span class="line"><span class="string">It rained all day yesterday.</span></span><br><span class="line"><span class="string">It can get very hot here.</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p>it引导的强调句型</p>
<p><code>it</code>引导的强调句的结构为：<code>It+be+被强调部分+that/who+其他</code>，此类强调句由普通句转换而来，用于强调句子的主语、宾语或状语。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Karl bought Mary a bicycle on her birthday.</span><br><span class="line"></span><br><span class="line">It was Karl that/who bought Mary a bicycle on her birthday.</span><br><span class="line">It was a bicycle that Karl bought Mary on her birthday.</span><br></pre></td></tr></table></figure>
<p><code>not...until...</code>句型也可用于强调句型，其结构为：<code>It is not until + 被强调部分 + that + 其他</code>，表示“直到…才&quot;</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">It was <span class="keyword">not</span> until she took off her dark glasses that I realized she was a film star.</span><br><span class="line">=</span><br><span class="line">I didn<span class="string">&#x27;t realize she was a famous film star until she took off her dark glasses.</span></span><br><span class="line"><span class="string">=</span></span><br><span class="line"><span class="string">Not until she took off her dark glasses did I realize she was a film star.</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p>it做形式主语</p>
<p>当不定式、动名词、从句等复杂成分用作句子主语时，为保持句子平衡，通常把真正的主语放在句末，在句首使用形式主语it`</p>
<p><code>It + be + adj. + for/of sb. to do sth. </code>意为某人做某事，当形容词侧重描述某人的品质、特征时，需要使用<code>of</code>，当侧重动作本身则需要使用<code>for</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">It<span class="string">&#x27;s very kind of you to help me with my English.</span></span><br><span class="line"><span class="string">It&#x27;</span>s very hard <span class="keyword">for</span> me to answer such a complicated question.</span><br></pre></td></tr></table></figure>
<p><code>It takes sb. + 时间段 + to do sth.</code>意为“某人做某事花了…时间</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">It took me two months to finish writing this book.</span><br></pre></td></tr></table></figure>
<p><code>It is said/reported/learned that</code>意为“据说/据报道/据悉…&quot;</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">It <span class="keyword">is</span> reported that a female worker <span class="keyword">in</span> the gas station put out the fire.</span><br></pre></td></tr></table></figure>
<p><code>It is suggested/ordered that...</code>意为“据建议/有命令”主句中的过去分词是表示请求、建议、命令等词语时，<code>that</code>后面的从句要用虚拟语气，谓语部分采用&quot;should+动词原形&quot;的形式。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">It is suggested that some measures (should) be taken to protect the special plant.</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>it做形式宾语</p>
<p>当不定式、动名词、从句等复杂成分用作宾语且后面跟上宾语补足语时，通常会使用形式宾语<code>it</code>代替，而将真正的宾语移至句末，其基本结构为“动词+ it + 宾语补足语 + 不定式(动名词或从句)&quot;。常用于该结构的动词有：<code>think, believe, make, find, consider, feel, take</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">I find it hard to translate this Chinese sentence into English.</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 某些表示“喜怒哀乐”的动词，如like, enjoy, love, hate等，往往不能直接跟宾语从句，需使用it作形式宾语</span></span><br><span class="line">I don<span class="string">&#x27;t like it that he&#x27;</span>s so lazy.</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>it用于表示时间的固定句式</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># It&#x27;s time for sth. 该做某事了</span></span><br><span class="line">It<span class="string">&#x27;s time for class.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># It&#x27;</span>s time to do sth. 到了该做某事的时间了</span><br><span class="line">It<span class="string">&#x27;s time to have lunch.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># It&#x27;</span>s time <span class="keyword">for</span> sb. to do sth. 某人该做某事了</span><br><span class="line">It<span class="string">&#x27;s time for us to go home.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># It&#x27;</span>s (about/high) time + that 从句. 意为<span class="string">&quot;某人该做某事了&quot;</span>,从句谓语动词需要用过去式，有时也用<span class="string">&quot;should+动词原形&quot;</span></span><br><span class="line">It<span class="string">&#x27;s high time you started thinking about saving for your old age.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># It&#x27;</span>s the first(second) time + that 从句. 意为“某人第一/第二次做某事<span class="string">&quot;</span></span><br><span class="line"><span class="string">It&#x27;s the first time that the boy has spoken to a foreigner.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># It&#x27;s + 时间段 + since 从句. 意为“自从...有一段时间了&quot;</span></span><br><span class="line">How time flies! It<span class="string">&#x27;s three months since I saw you last time.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># It&#x27;</span>s + 时间段 + before 从句,意为“过多长的时间才....<span class="string">&quot;&quot;</span></span><br><span class="line">It was several minutes before we realised what was happening.</span><br></pre></td></tr></table></figure>
</li>
</ul>
<hr>
<h2 id="四、数词">四、数词</h2>
<h3 id="4-1-基数词">4.1  基数词</h3>
<ul>
<li>
<p>基数词的基本用法</p>
<p>用作基数词单位的<code>hundred, thousand, million, billion</code>通常不带复数词尾<code>-s</code>，但若用于表示数百、数千、数百万这样的泛指，则用复数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">About two thousand people died <span class="keyword">in</span> the earthquake.</span><br><span class="line">Thousands of people go to the seaside every year.</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>表示整十的基数词用法</p>
<p>表示整十的基数词用复数形式可以表示人的大概岁数或某个年龄</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">He <span class="keyword">is</span> <span class="keyword">in</span> his early twenties. <span class="comment"># 他的年纪在20出头</span></span><br><span class="line">This story took place <span class="keyword">in</span> the 1930s. <span class="comment"># 故事发生在20世纪30年代</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="4-2-序数词">4.2  序数词</h3>
<ul>
<li>
<p>序数词的构成</p>
<p>大部分的序数词是由基数词加<code>-th</code>构成，如：<code>seven-seventh, ten-tenth</code></p>
<p>以<code>-t</code>结尾的基数词只在词尾加<code>-h</code>, 如<code>eight-eighth</code></p>
<p>以<code>-ve</code>结尾的基数词改<code>-ve</code>为<code>-f</code>再加<code>-th</code>，如<code>five-fifth, twelve-twelfth</code></p>
<p>以<code>-y</code>结尾的基数词改<code>-y</code>为<code>-ie</code>再加<code>-th</code>，如<code>twenty-twentieth, thirty-thirtieth</code></p>
<p>几十几的序数词只在个位数体现，如<code>twenty-one-twenty-first</code></p>
<p>特殊的序数词：<code>one-first, two-second, three-third, nine-ninth</code></p>
</li>
<li>
<p>不定冠词a与序数词连用</p>
<p>序数词前加<code>a</code>表示“再一次”</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Can I <span class="keyword">try</span> a second time?</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>序数词用于分数中</p>
<p>描述分数时，分子用基数词，分母用序数词，分子大于1时，分母加<code>s</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span>/<span class="number">5</span>: one fifth</span><br><span class="line"><span class="number">2</span>/<span class="number">3</span>: two thirds</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="4-3-倍数">4.3  倍数</h3>
<p>英语中表达倍数常用下列句型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">A <span class="keyword">is</span> three/four ... times the size/height/length/width ... of B.</span><br><span class="line">A <span class="keyword">is</span> three/four ... times <span class="keyword">as</span> big/higt/long/wide ... <span class="keyword">as</span> B.</span><br><span class="line">A <span class="keyword">is</span> three/four ... times bigger/higher/longer/wider ... than B.</span><br><span class="line"></span><br><span class="line"><span class="meta">... </span>times + more + 名词 + than ...</span><br><span class="line"><span class="meta">... </span>times + <span class="keyword">as</span> many(much) + 名词 + <span class="keyword">as</span> ...</span><br><span class="line"><span class="meta">... </span>times + what 从句</span><br></pre></td></tr></table></figure>
<p>用<code>times</code>表示倍数时，一般只限于三倍或三倍以上的倍数，表示两杯常用<code>twice</code>或<code>double</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">The box <span class="keyword">is</span> one-third bigger than that one.</span><br><span class="line">This dictionary <span class="keyword">is</span> five times <span class="keyword">as</span> thick <span class="keyword">as</span> the one you borrowed <span class="keyword">from</span> the library.</span><br></pre></td></tr></table></figure>
<h3 id="4-4-数词相关的主谓一致">4.4  数词相关的主谓一致</h3>
<ul>
<li>
<p>表示时间、路程、金钱或重量等重复名词的主谓一致</p>
<p>当名词词组中心词为表示时间、路程、金钱或重量等复数名词时，往往根据意义一致的原则，把这些复数名词看做一个整体，谓语采用单数形式。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Twenty dollars <span class="keyword">is</span> <span class="keyword">not</span> enough.</span><br><span class="line">Two months has passed before we realized that.</span><br><span class="line"></span><br><span class="line"><span class="comment"># 但是数词单独用来表示人或物，谓语动词一般用复数</span></span><br><span class="line">Three were killed <span class="keyword">and</span> ten were missing <span class="keyword">in</span> that accident.</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>分数、百分数中的主谓一致</p>
<p>如果句子主语是”分数或百分数+of+名词或代词“的形式，谓语动词的单、复数形式取决于<code>of</code>介词短语中的名词或代词的数，如果<code>of</code>介词短语中的名词或代词为单数含义或不可数名词，则谓语动词用单数形式，如果<code>of</code>介词短语中名词或滴啊次为复数含义，谓语动词也用复数形式。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Two thirds of the earth <span class="keyword">is</span> convered <span class="keyword">with</span> water.</span><br><span class="line">Two thirds of the people present are against the plan.</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>&quot;many a/more than one + 单数名词&quot;结构主谓一致</p>
<p>如果主语是该结构，尽管从意义上来看还是复数，但谓语动词仍用单数形式。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Many a student <span class="keyword">in</span> this <span class="keyword">class</span> <span class="title class_">has</span> expected <span class="keyword">as</span> long <span class="keyword">break</span>. <span class="comment"># 在班上的很多学生都期待能多休息一会</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 不想学辣 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 英语 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[欢迎光临岁染！]]></title>
      <url>/2022/06/23/%E3%80%90%E6%9D%82%E8%B0%88%E3%80%91hello-world/</url>
      <content type="html"><![CDATA[<h1>岁染🍉</h1>
<p>关于岁染这两个字，其实并没有什么来头啦，是我高中玩崩坏三时取的名字Wwww</p>
<p>若是硬要披上一件风衣，那我可能会选择“岁月静好，莫染尘埃🌙”</p>
<hr>
<p>欢迎陌生人(可能一辈子都不会有的吧)，或是老熟人来光顾！</p>
<p>这里有闲适的下午茶，这里有清脆的风铃声，这里有风划过的痕迹，这里有雨落下的声音，这里，有一个孤独而又不想向生活低头的人。</p>
<p>人生有很多后悔的事情，有很多人恨不得早点遇见，有很多事恨不得早点去做。</p>
<p>如果说有什么不后悔的，那便是你我此刻的相遇💌</p>
<hr>
<blockquote>
<p>先生，您有东西忘在店里啦！诺，就是我的心哦❤️~</p>
</blockquote>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
        <categories>
            
            <category> 琐碎日常 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> hexo </tag>
            
        </tags>
        
    </entry>
    
  
  
</search>
